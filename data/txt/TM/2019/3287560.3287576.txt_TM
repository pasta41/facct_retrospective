
Consequential decision-making typically incentivizes individuals to
behave strategically, tailoring their behavior to the specifics of the
decision rule. A long line of work has therefore sought to counteract
strategic behavior by designing more conservative decision bound-
aries in an effort to increase robustness to the effects of strategic
covariate shift.
We show that these efforts benefit the institutional decision
maker at the expense of the individuals being classified. Introducing
a notion of social burden, we prove that any increase in institutional
utility necessarily leads to a corresponding increase in social bur-
den. Moreover, we show that the negative externalities of strategic
classification can disproportionately harm disadvantaged groups
in the population.
Our results highlight that strategy-robustness must be weighed
against considerations of social welfare and fairness.
CCS CONCEPTS
• Computing methodologies →Machine learning; Stochastic
games;
KEYWORDS
Strategic classification, fairness, machine learning
ACM Reference Format:
Smitha Milli, John Miller, Anca D. Dragan, and Moritz Hardt. 2019. The
Social Cost of Strategic Classification. In FAT* ’19: Conference on Fairness,
Accountability, and Transparency (FAT* ’19), January 29–31, 2019, Atlanta,
GA, USA. ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/
3287560.3287576
1 INTRODUCTION
As machine learning increasingly supports consequential decision
making, its vulnerability to manipulation and gaming is of grow-
ing concern. When individuals learn to adapt their behavior to
the specifics of a statistical decision rule, its original predictive
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
FAT* ’19, January 29–31, 2019, Atlanta, GA, USA
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-6125-5/19/01. . . $15.00
https://doi.org/10.1145/3287560.3287576
power will deteriorate. This widely observed empirical phenome-
non, known as Campbell’s Law or Goodhart’s Law, is often summa-
rized as: “Once a measure becomes a target, it ceases to be a good
measure” [26].
Institutions using machine learning to make high-stakes deci-
sions naturally wish to make their classifiers robust to strategic
behavior. A growing line of work has sought algorithms that achieve
higher utility for the institution in settings where we anticipate
a strategic response from the the classified individuals [4, 10, 14].
Broadly speaking, the resulting solution concepts correspond to
more conservative decision boundaries that increase robustness to
some form of distributional shift.
But there is a flip side to strategic classification. As insitutional
utility increases as a result of more cautious decision rules, honest
individuals worthy of a positive classification outcome may face a
higher bar for success.
The costs incurred by individuals as a consequence of strategic
classification are by no means hypothetical, as the example of lend-
ing shows. In the United States, credit scores are widely deployed to
allocate credit. However, even creditworthy individuals routinely
engage in artificial practices intended to improve their credit scores,
such as opening up a certain number of credit lines in a certain
time period [9].
In this work, we study the tension between accuracy to the in-
stitution and impact to the individuals being classified. We first
introduce a general measure of the cost of strategic classification,
which we call the social burden. Informally, the social burden mea-
sures the expected cost that a positive individual needs to incur to
be correctly classified correctly.
For a broad class of cost functions, we prove there exists an
intrinsic trade-off between institutional accuracy and social burden:
any increase in institutional accuracy comes at an increase in social
burden. Moreover, we precisely characterize this trade-off and show
the commonly considered Stackelberg equilibrium solution achieves
maximal institutional accuracy at the expense of maximal social
burden.
Equipped with this generic trade-off result, we turn towards a
more careful study of how the social burden of strategic classifi-
cation impacts different subpopulations. We find that the social
burden can fall disproportionally on disadvantaged subpopulations,
under two different notions by which one group can be disadvan-
taged relative to another group. Furthermore, we show that as the
institution improves its accuracy, it exacerbates the gap between
the burden to an advantaged and disadvantaged group. Finally, we
illustrate these conditions and their consequences with a case study
on FICO data.
1.1 Our Contributions
In this paper, we make the following contributions:
(1) We prove a general result demonstrating the trade-off be-
tween institutional accuracy and individual utility in the
strategic setting. Our theoretical characterization is supple-
mentedwith examples illustratingwhen an institutionwould
prefer to operate along different points in this trade-off curve.
(2) We show fairness considerations inevitably arise in the strate-
gic setting. When individuals incur cost as a consequence of
making a classifier robust to strategic behavior, we show the
costs can disproportionally fall by disadvantaged subpopula-
tions. Furthermore, as the institution increases its robustness,
it also increases the disparity between subpopulations.
(3) Using FICO credit data as a case-study, we empirically vali-
date our modeling assumptions and illustrate both the gen-
eral trade-offs and fairness concerns involved with strategic
classification in a concrete setting.
Reflecting on our results, we argue that the existing view of strate-
gic classification has been instituition-centric, ignoring the social
burden resulting from improved institutional utility. Our frame-
work makes it possible to select context-specific trade-offs between
institutional and individual utility, leading to a richer space of solu-
tions.
Another key insight is that discussions of strategy-robustness
must go hand in hand with considerations of fairness and the real
possibility that robustness-promoting mechanisms can have dis-
parate impact in different segments of the population.

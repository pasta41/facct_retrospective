
Data too sensitive to be "open" for analysis and re-purposing typi-
cally remains "closed" as proprietary information. This dichotomy
undermines efforts to make algorithmic systems more fair, trans-
parent, and accountable. Access to proprietary data in particular
is needed by government agencies to enforce policy, researchers
to evaluate methods, and the public to hold agencies accountable;
all of these needs must be met while preserving individual privacy
and firm competitiveness. In this paper, we describe an integrated
legal-technical approach provided by a third-party public-private
data trust designed to balance these competing interests. Basic
membership allows firms and agencies to enable low-risk access
to data for compliance reporting and core methods research, while
modular data sharing agreements support a wide array of projects
and use cases. Unless specifically stated otherwise in an agreement,
all data access is initially provided to end users through customized
synthetic datasets that offer a) strong privacy guarantees, b) re-
moval of signals that could expose competitive advantage, and c)
removal of biases that could reinforce discriminatory policies, all
while maintaining fidelity to the original data. We find that using
synthetic data in conjunction with strong legal protections over
raw data strikes a balance between transparency, proprietorship,
privacy, and research objectives. This legal-technical framework
can form the basis for data trusts in a variety of contexts.
CCS CONCEPTS
• Social and professional topics → Socio-technical systems;
• Applied computing → IT governance;
KEYWORDS
data ethics; data governance; privacy; algorithmic bias; data sharing
ACM Reference Format:
Meg Young, Luke Rodriguez, Emily Keller, Feiyang Sun, Boyang Sa, Jan
Whittington, Bill Howe. 2019. Beyond Open vs. Closed: Balancing Individual
Privacy and Public Accountability in Data Sharing. In FAT* ’19: Conference on
Fairness, Accountability, and Transparency, January 29–31, 2019, Atlanta, GA,
USA. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3287560.
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
FAT* ’19, January 29–31, 2019, Atlanta, GA, USA
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-6125-5/19/01. . . $15.00
https://doi.org/10.1145/3287560.3287577
1 INTRODUCTION
The mechanisms by which algorithms can be made more fair, ac-
countable, and transparent require broad access to sensitive data,
data that is typically "closed" due to concerns over proprietor-
ship and privacy. Data ownership models in competitive markets
foreclose the possibility of inter-organizational data sharing and
collaborative analysis between researchers, firms, and the public
sector. Data deemed too sensitive to release through open data
efforts typically remain unavailable, leading to convenience sam-
pling effects where researchers, startups, and the general public
put disproportionate attention on already opened data, whether
or not it is suitable for their purposes. To combat this perceived
dichotomy between open and closed data, we emphasize the release
of semi-synthetic datasets that control bias and account for privacy,
organized through a suite of data governance policies to facilitate
responsible data sharing in public-private partnerships.
The transportation sector helps to motivate and illustrate our
approach. Private firms hold an increasing share of information
about urban transportation provision; including widely adopted
services like car share[31], ride share [42], bike share [67], predic-
tion apps for public transportation [24], and routing apps [13]. Like
the taxi and limousine services that preceded them, city agencies
increasingly require these new services to share data in order to
enforce permit requirements, enable integrative models of demand
and ridership, and analyze their policy implications. To date, exist-
ing data sharing paradigms have failed to deliver granular access
to firm data; when it is shared, it is often encumbered with con-
tractual obligations that preclude linking data across competing
firms. As corporate data is zealously guarded to protect competitive
advantage, releasing data via open data portals or detailed APIs is
untenable in many situations. Notably, in the absence of access to
firm information, researchers spend considerable resources simulat-
ing it, as evidenced by work modeling the supply and distribution
of car share vehicles [31]. Researchers have also used data mining
[29], social experiment [27], and intercept surveys at “hot spot”
[51] to collect TNC related data due to the absence of direct access
to firm information. However, each data source has its own biases,
which may lead to distortions in research findings. For example, dis-
parities in wait times based on passenger race were not present in
data mined from Uber’s API [29] but were present in data collected
via 1,500 rides in a controlled field study [27].
This paper describes dilemmas attributable to the current data
sharing paradigm for (i) privacy, (ii) fairness, and (iii) accountability
in the urban transportation data domain. In each case, we exam-
ine how purely technical approaches are incomplete. In turn, we
provide evidence in favor of co-designed legal and technical tools
to address these gaps. In the discussion, we describe the design
of a legal-technical infrastructure called the Transportation Data
Figure 1: Overview of the TransportationData Collaborative
Collaborative (TDC) that offers an alternative to "open" or "closed"
dichotomy. The TDC emphasizes the release of customized syn-
thetic datasets for most use cases, along with structured data use
agreements to govern access to high fidelity data. These mecha-
nisms provide flexible access that balance the competing interests
between individuals, firms, governments, and researchers. Finally,
we report from initial experiences operating the TDC in Seattle, WA,
where it is being used by government agencies, private firms, and
university researchers to enable granular data access, integration
across competing firms, and the removal of bias that can propa-
gate inequity. We find it can enable research access to data that
would otherwise remain unavailable while protecting privacy and
enforcing compliance.


Targeted advertising is meant to improve the efficiency of match-
ing advertisers to their customers. However, targeted advertising
can also be abused by malicious advertisers to efficiently reach
people susceptible to false stories, stoke grievances, and incite so-
cial conflict. Since targeted ads are not seen by non-targeted and
non-vulnerable people, malicious ads are likely to go unreported
and their effects undetected. This work examines a specific case
of malicious advertising, exploring the extent to which political
ads 1 from the Russian Intelligence Research Agency (IRA) run
prior to 2016 U.S. elections exploited Facebook’s targeted advertis-
ing infrastructure to efficiently target ads on divisive or polarizing
topics (e.g., immigration, race-based policing) at vulnerable sub-
populations. In particular, we do the following: (a) We conduct
U.S. census-representative surveys to characterize how users with
different political ideologies report, approve, and perceive truth in
the content of the IRA ads. Our surveys show that many ads are
“divisive”: they elicit very different reactions from people belonging
to different socially salient groups. (b) We characterize how these
divisive ads are targeted to sub-populations that feel particularly
aggrieved by the status quo. Our findings support existing calls for
greater transparency of content and targeting of political ads. (c)
We particularly focus on how the Facebook ad API facilitates such
targeting. We show how the enormous amount of personal data
Facebook aggregates about users and makes available to advertisers
enables such malicious targeting.
1We deployed a system that shows the ads and the demographics of their targeting
audiences (available at http://www.socially-divisive-ads.dcc.ufmg.br/ ).
* These authors contributed equally to this work.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
FAT* ’19, January 29–31, 2019, Atlanta, GA, USA
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-6125-5/19/01. . . $15.00
https://doi.org/10.1145/3287560.3287580
CCS CONCEPTS
• General and reference→ Empirical studies;Measurement;
•Human-centered computing→ Social networking sites;Em-
pirical studies in collaborative and social computing;
KEYWORDS
advertisements, targeting, social divisiveness, news media, social
media, perception bias
ACM Reference Format:
Filipe N. Ribeiro*, Koustuv Saha*, Mahmoudreza Babaei, Lucas Henrique,
Johnnatan Messias, Fabricio Benevenuto, Oana Goga, Krishna P. Gummadi,
and Elissa M. Redmiles. 2019. On Microtargeting Socially Divisive Ads:
[0.1em] A Case Study of Russia-Linked Ad Campaigns on Facebook. In
FAT* ’19: Conference on Fairness, Accountability, and Transparency (FAT* ’19),
January 29–31, 2019, Atlanta, GA, USA. ACM, New York, NY, USA, 10 pages.
https://doi.org/10.1145/3287560.3287580
1 INTRODUCTION
Online targeted advertising refers to the ability of an advertiser to
select audience for their ads. Such advertising constitutes the pri-
mary source of revenue for many online sites including most social
media websites such as Facebook, Twitter, YouTube, and Pinterest.
Consequently, these websites accumulate detailed demographic,
behavioral and interest profiles of their users enabling advertisers
to “microtarget”, i.e., choose small (tens or hundreds to thousands)
of users with very specific attributes like people living in a zipcode
that read New York Times or Breitbart. Beyond raising numerous
privacy concerns [17, 24], targeted advertising platforms have come
under scrutiny for enabling discriminatory advertising, where ads
announcing housing or job opportunities are targeted to exclude
people belonging to certain races or gender [4, 8, 10, 23].
In this paper, we analyze the potential for a new form of abuse on
targeted advertising platforms namely, socially divisive advertising,
where malicious advertisers incite social conflict by publishing ads
on divisive societal issues of the day (e.g., immigration and racial-
bias in policing in the lead up to 2016 US presidential elections).
Specifically, we focus on how ad targeting on social media sites
such as Facebook can be leveraged to selectively target groups on
different sides of a divisive issue with (potentially false) messages
Filipe N. Ribeiro*, Koustuv Saha*, Mahmoudreza Babaei, Lucas Henrique, Johnnatan Messias, Fabricio Benevenuto, Oana Goga,
Krishna P. Gummadi, and Elissa M. Redmiles
that are deliberately crafted to stoke their grievances and thereby,
worsen social discord. We also investigate whether targeted ad
platforms allow such malicious campaigns to be carried out in
stealth, by excluding people who are likely to report (i.e., alert site
administrators or media watchdog groups about) such ads.
Our study is based on an in-depth analysis of a publicly released
dataset of Facebook ads run by a Russian agency called Internet
Research Agency (IRA) before and during the American Election on
the year of 2016 2 3. Our analysis is centered around three high-level
research questions:
RQ 1: How divisive is the content of the IRA ads?We quantify the divi-
siveness of an ad by analyzing the differences in reactions of people
with different ideological persuasions to the ad. Specifically, using
US census-representative surveys, we look at how conservative-
and liberal-minded people differ in (a) how likely they are to re-
port the ad, (b) how strongly they approve or disapprove the ad’s
content, and (c) how they perceive truthood (or falsehood) in ad’s
claims. Our analysis shows that IRA ads elicit starkly different
and polarizing responses from people with different ideological
pursuasions.
RQ 2: How effectively done was the targeting of the socially divisive
ads? We find that the “Click Through Rate” (CTR), a traditional
measure of effectiveness of targeting, of the IRA ads are an order of
magnitude (10 times) higher than that of typical Facebook ads. The
high CTR suggests that the ads have been targeted very efficiently. A
deeper analysis of the demographic biases in the targeted audience
reveals that the ads have been targeted at people who are more
likely to approve the content and perceive fewer false claims, and
are less likely to report.
RQ 3: What features of Facebook’s ad API were leveraged in targeting
the ads?We also analyze the construction or specification of “tar-
geting formulae” for the ads, i.e., the combination of Facebook user
attributes that are used when selecting the audience for the ads.
We find widespread use of interest attributes such as “Black Con-
sciousness movement” and “Chicano movement” that are mostly
shared by people from specific demographic groups such as African-
Americans and Mexican-Americans. We show how Facebook ad
API’s suggestion feature may be exploited by the advertisers to
find interest attributes that correlate very strongly to specific social
demographic groups.
1.1 Related Work
Prior work has highlighted several forms of abuses of targeted
advertising in Facebook, such as for inappropriately exposing the
private information of users to advertisers [24], and for allowing
discriminatory advertising (e.g., to exclude users belonging to a
certain race or gender from receiving their ads) [23]. Our effort
highlights a new and different form of potential abuse of these
targeted advertising platforms in creating a social discord.
A rich body of prior work have focused on understanding filter
bubbles, echo chambers, polarization, and ideological discourse in
social media as an emergent phenomenon [7, 9, 12, 14, 15, 19, 22].
We provide a complementary perspective on the topic by examining
how echo chambers and polarization can be engineered on social
2www.wsj.com/articles/you-cant-buy-the-presidency-for-100-000-1508104629
3www.nytimes.com/2017/11/01/us/politics/ russia-2016-election-facebook.html
Figure 1: Example of an Ad from the Dataset.
media through targeted advertising. A recent work conducted a
detailed study about Facebook Ads environment by analyzing thou-
sands of ads collected through a browser plugin[2]. More closely
related to our work, Kim et al. gathered Facebook ads from individ-
uals and analyzed who are behind divisive ad campaigns, reporting
suspicious foreign entities [16]. Differently, we focus on understand-
ing the disruptive ability of microtargeting for providing divisive
political ad campaigns.
Finally, our effort is complementary to prior work that attempts
to understand the abuse of social media by misinformation cam-
paigns, especially along political elections [18, 25]. Our work pro-
vides a better comprehension about a key disseminationmechanism
of fake news stories, highlighting how advertising platforms allow
injection of misinformation in social systems and choose vulnerable
people as the target.

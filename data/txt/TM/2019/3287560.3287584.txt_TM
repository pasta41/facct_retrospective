
We map the recently proposed notions of algorithmic fairness to
economic models of Equality of opportunity (EOP)‚Äîan extensively
studied ideal of fairness in political philosophy. We formally show
that through our conceptual mapping, many existing definition of
algorithmic fairness, such as predictive value parity and equality
of odds, can be interpreted as special cases of EOP. In this respect,
our work serves as a unifying moral framework for understand-
ing existing notions of algorithmic fairness. Most importantly, this
framework allows us to explicitly spell out the moral assumptions
underlying each notion of fairness, and interpret recent fairness
impossibility results in a new light. Last but not least and inspired
by luck egalitarian models of EOP, we propose a new family of mea-
sures for algorithmic fairness.We illustrate our proposal empirically
and show that employing a measure of algorithmic (un)fairness
when its underlying moral assumptions are not satisfied, can have
devastating consequences for the disadvantaged group‚Äôs welfare.
CCS CONCEPTS
‚Ä¢ Computing methodologies ‚Üí Supervised learning; Batch
learning; ‚Ä¢ Applied computing ‚Üí Economics; Sociology;
KEYWORDS
Equality of Opportunity (EOP), Fairness for Machine Learning,
Rawlsian and Luck Egalitarian EOP, Statistical Parity, Equality of
Odds, Predictive Value Parity
ACM Reference Format:
Hoda Heidari, Michele Loi, Krishna P. Gummadi, and Andreas Krause. 2019.
A Moral Framework for Understanding Fair ML, through Economic Models
of Equality of Opportunity. In FAT* ‚Äô19: Conference on Fairness, Account-
ability, and Transparency (FAT* ‚Äô19), January 29‚Äì31, 2019, Atlanta, GA, USA.
ACM,NewYork, NY, USA, 10 pages. https://doi.org/10.1145/3287560.3287584
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
FAT* ‚Äô19, January 29‚Äì31, 2019, Atlanta, GA, USA
¬© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-6125-5/19/01. . . $15.00
https://doi.org/10.1145/3287560.3287584
1 INTRODUCTION
Equality of opportunity (EOP) is a widely supported ideal of fair-
ness, and it has been extensively studied in political philosophy
over the past 50 years [1, 7, 9, 10, 22, 27]. The concept assumes the
existence of a broad range of positions, some of which are more
desirable than others. In contrast to equality of outcomes (or posi-
tions), an equal opportunity policy seeks to create a level playing
field among individuals, after which they are free to compete for
different positions. The positions that individuals earn under the
condition of equality of opportunity reflect their merit or deserv-
ingness, and for that reason, inequality in outcomes is considered
ethically acceptable [24].
Equality of opportunity emphasizes the importance of personal
(or native) qualifications, and seeks to minimize the impact of cir-
cumstances and arbitrary factors on individual outcomes [7, 9, 10,
22]. For instance within the context of employment, one (narrow)
interpretation of EOP requires that desirable jobs are given to those
persons most likely to perform well in them‚Äîe.g. those with the
necessary education and experience‚Äîand not according to arbitrary
factors, such as race or family background. According to Rawls‚Äôs
(broader) interpretation of EOP, native talent and ambition can jus-
tify inequality in social positions, whereas circumstances of birth
and upbringing such as sex, race, and social background can not.
Many consider the distinction between morally acceptable and
unacceptable inequality the most significant contribution of the
egalitarian doctrine [26].
Prior work in economics has sought to formally characterize
conditions of equality of opportunity to allow for its precise mea-
surement in practical domains (see e.g. [12, 25]). At a high level,
in these models an individual‚Äôs outcome/position is assumed to
be affected by two main factors: his/her circumstance c and effort
e . Circumstance c is meant to capture all factors that are deemed
irrelevant, or for which the individual should not be held morally
accountable; for instance c could specify the socio-economic status
he/she is born into. Effort e captures all accountability factors‚Äî
those that can morally justify inequality. (Prior work in economics
refers to e as effort for the sake of concreteness, but e summarizes
all factors for which the individual can be held morally accountable;
the term ‚Äúeffort" should not be interpreted in its ordinary sense
here.) For any circumstance c and any effort level e , a policy œï in-
duces a distribution of utility among people of circumstance c and
effort e . Formally, an EOP policy will ensure that an individual‚Äôs
final utility will be, to the extent possible, only a function of their
effort and not their circumstances.
While EOP has been traditionally discussed in the context of
employment practices, its scope has been expanded over time to
other areas, including lending, housing, college admissions, and
beyond [29]. Decisions made in such domains are increasingly auto-
mated andmade throughAlgorithmic Data Driven DecisionMaking
systems (A3DMs). We argue, therefore, that it is only natural to
study fairness for A3DMs through the lens of EOP. In this work, we
draw a formal connection between the recently proposed notions of
fairness for supervised learning and economic models of EOP. We
observe that in practice, predictive models inevitably make errors
(e.g. the model may mistakenly predict that a credit-worthy appli-
cant won‚Äôt pay back their loan in time). Sometimes these errors
are beneficial to the subject, and sometimes they cause harm. We
posit that in this context, EOP would require similar individuals
(in terms of what they can be held accountable for) to have the
same prospect of receiving this benefit/harm, irrespective of their
irrelevant characteristics.
More precisely, we assume that a person‚Äôs features can be par-
titioned into two sets: those for which we consider it morally ac-
ceptable to hold him/her accountable, and those for which it is
not so. We will broadly refer to the former set of attributes as the
individual‚Äôs accountability features, and the latter, as their arbitrary
or irrelevant features. Note that there is considerable disagreement
on the criteria to determine what factors should belong to each
category. Roemer [23] for instance proposes that societies decide
this democratically. We take a neutral stance on this issue and
leave it to domain experts and stake-holders to reach a resolution.
Throughout, we assume this partition has been identified and is
given.
We distinguish between an individual‚Äôs actual and effort-based
utility when subjected to algorithmic decision making. We assume
an individual‚Äôs advantage or total utility as the result of being
subject to A3DMs, is the difference between their actual and effort-
based utility (Section 2). Our main conceptual contribution is to
map the supervised learning setting to economic models of EOP by
treating predictive models as policies, irrelevant features as individ-
ual circumstance, and effort-based utilities as effort (Figure 1). We
show that using this mapping many existing notions of fairness for
classification, such as predictive value parity [18] and equality of
odds [14], can be interpreted as special cases of EOP. In particular,
equality of odds is equivalent to Rawlsian EOP, if we assume all
individuals with the same true label are equally accountable for
their labels and have the same effort-based utility (Section 3.1).
Similarly, predictive value parity is equivalent to luck egalitarian
EOP if the predicted label/risk is assumed to reflect an individual‚Äôs
effort-based utility (Section 4). In this respect, our work serves as a
unifying framework for understanding existing notions of algorith-
mic fairness as special cases of EOP. Importantly, this framework
allows us to explicitly spell out the moral assumptions underlying
each notion of fairness, and interpret recent fairness impossibility
results [18] in a new light.
Last but not least, inspired by Roemer‚Äôs model of egalitarian EOP
we present a new family of measures for algorithmic (un)fairness,
applicable to supervised learning tasks beyond binary classifica-
tion. We illustrate our proposal on a real-world regression dataset,
and compare it with existing notions of fairness for regression. We
Policy ùùì Predictive model h 
Effort e Effort-based utility d
Circumstance c Irrelevant features z
Utility u Actual - effort-based utility (a - d) 
Economic Models of EOP Fair Machine Learning
Figure 1: Our proposed conceptual mapping between Fair
ML and economic literature on EOP.
empirically show that employing the wrong measure of algorith-
mic fairness‚Äîwhen the moral assumptions underlying it are not
satisfied‚Äîcan have devastating consequences on the welfare of the
disadvantaged group.
We emphasize that our work is not meant to advocate for any par-
ticular notion of algorithmic fairness, rather our goal is to establish‚Äî
both formally and via real-world examples‚Äîthat implicit in each
notion of fairness is a distinct set of moral assumptions about de-
cision subjects; therefore, each notion of fairness is suitable only
in certain application domains and not others. By making these
assumptions explicit, our framework presents practitioners with a
normative guideline to choose the most suitable notion of fairness
specifically for every real-world context in which A3DMs are to be
deployed.
1.1 Equality of Opportunity: An Overview
Equality of opportunity has been extensively debated among po-
litical philosophers. Philosophers such as Rawls [22], Dworkin [9],
Arneson [1], and Cohen [7] contributed to the egalitarian school of
thought by proposing different criteria for making the cut between
arbitrary and accountability factors. The detailed discussion of their
influential ideas is outside the scope of this work, and the interested
reader is referred to excellent surveys by Arneson [2] and Roemer
and Trannoy [26].
In this section, we briefly mention several prominent interpre-
tations of EOP and discuss their relevance to A3DMs. Following
Arneson [3], we recount three main conceptions of equality of
opportunity:
‚Ä¢ Libertarian EOP: A person is morally at liberty to do what
she pleases with what she legitimately owns (e.g. self, busi-
ness, etc.) as long as it does not infringe upon other people‚Äôs
moral rights (e.g. the use of force, fraud, theft, or damage
on persons or property of another individual is considered a
violation of their rights). Other than these restrictions, any
outcome that occurs as the result of people‚Äôs free choices on
their legitimate possessions is considered just. In the context
of A3DMs and assuming no gross violations of individuals‚Äô
data privacy rights, this interpretation of EOP leaves the en-
terprise at total liberty to implement any algorithm it wishes
through Economic Models of Equality of Opportunity FAT* ‚Äô19, January 29‚Äì31, 2019, Atlanta, GA, USA
for decision making. The algorithm can utilize all available
information, including individuals‚Äô sensitive features such as
race or gender, to make (statistically) accurate predictions.
‚Ä¢ Formal EOP: Also known as ‚Äúcareers open to talents", for-
mal EOP require desirable social positions to be open to all
who possess the attributes relevant for the performance of
the duties of the position (e.g. anyone who meets the formal
requirements of the job) and wish to apply for them [25].
The applications must be assessed only based on relevant
attributes/qualifications that advances the morally innocent
goals of the enterprise. Direct discrimination based on factors
deemed arbitrary (e.g. race or gender) is therefore prohibited
under this interpretation of EOP. Formal EOP would permit
differences in people‚Äôs circumstances‚Äîe.g. their gender‚Äîto
have indirect, but nonetheless deep impact on their prospects.
For instance, if women are less likely to receive higher edu-
cation due to prejudice against female students, as long as
a hiring algorithm is blind to gender and applies the same
educational requirement to male and female job applicants,
formal equality of opportunity is maintained. In context of
A3DMs, Formal EOP is equivalent to the removal of the sen-
sitive feature information from the learning pipeline. In the
fair ML community, this is sometimes referred to as ‚Äúfairness
through blindness".
‚Ä¢ Substantive EOP: Substantive EOPmoves the starting point
of the competition for desirable positions further back in
time, and requires not only open competition for desirable
positions, but also fair access to the necessary qualifications
for the position. This implies access to qualifications (e.g.
formal requirements for a job) should not to be affected by
arbitrary factors, such as race gender or social class. The
concept is closely related to indirect discrimination: if the
A3DM indirectly discriminates against people with a certain
irrelevant feature (e.g. women or African Americans) this
may be an indication that the irrelevant/arbitrary feature has
played a role in the acquisition of the requirements. When
there are no alternative morally acceptable explanations for
it, indirect discrimination is often considered in violation of
substantive EOP.
Our focus in this work is on substantive EOP, and in particular, on
two of its refinements, called Rawlsian EOP and Luck Egalitarian
EOP.
Rawlsian EOP. According to Rawls, those who have the same
level of talent or ability and are equally willing to use them must
have the same prospect of obtaining desirable social positions, re-
gardless of arbitrary factors such as socio-economic background [22].
This Rawlsian conception of EOP has been translated into pre-
cise mathematical terms as follows [19]: let c denote circumstance,
capturing factors that are not considered legitimate sources of in-
equality among individuals. Let scalar e summarize factors that are
viewed as legitimate sources of inequality. For the sake of brevity,
the economic literature refer to e as ‚Äúeffort", but e is meant to sum-
marize all factors an individual can be held morally accountable
for.1 Let u specify individual utility, which is a consequence of ef-
fort, circumstance, and policy. Formally, let Fœï (.|c, e ) specify the
cumulative distribution of utility under policy œï at a fixed effort
level e and circumstance c . Rawlsian/Fair EOP requires that for
individuals with similar effort e , the distribution of utility should
be the same‚Äîregardless of their circumstances:
Definition 1 (Rawlsian Eqality of Opportunity (R-EOP)).
A policy œï satisfies Rawlsian EOP if for all circumstances c, c ‚Ä≤ and all
effort levels e ,
Fœï (.|c, e ) = Fœï (.|c ‚Ä≤, e ).
Note that this conception of EOP takes an absolutist view of effort:
it assumes e is a scalar whose absolute value is meaningful and can
be compared across individuals. This view requires effort e to be
inherent to individuals and not itself impacted by the circumstance
c or the policy œï.
Luck Egalitarian EOP. Unlike fair EOP, luck egalitarian EOP
offers a relative view of effort, and allows for the possibility of cir-
cumstance c and implemented policy œï impacting the distribution
of effort e . In this setting, Roemer [24] argues that ‚Äúin comparing
efforts of individuals in different types [circumstances], we should
somehow adjust for the fact that those efforts are drawn from distri-
butions which are different". As the solution he goes on to propose
‚Äúmeasuring a person‚Äôs effort by his rank in the effort distribution of
his type/circumstance, rather than by the absolute level of effort he
expends".
Formally, let Fc,œïE be the effort distribution of type c under pol-
icy œï. Roemer argues that ‚Äúthis distribution is a characteristic of
the type c , not of any individual belonging to the type. Therefore,
an inter-type comparable measure of effort must factor out the
goodness or badness of this distribution". Roemer declares two in-
dividuals as having exercised the same level of effort if they sit at
the same quantile or rank of the effort distribution for their corre-
sponding types. More precisely, let the indirect utility distribution
function Fœï (.|c,œÄ ) specify the distribution of utility for individuals
of type c at the œÄ th quantile (0 ‚â§ œÄ ‚â§ 1) of Fc,œïE . Equalizing opportu-
nities means choosing the policy œï to equalize utility distributions,
Fœï (.|c,œÄ ), across types at fixed levels of œÄ :2
Definition 2 (Luck Egalitarian Eqality of Opportunity
(e-EOP)). A policyœï satisfies Luck Egalitarian EOP if for all œÄ ‚àà [0, 1]
and any two circumstances c, c ‚Ä≤:
Fœï (.|c,œÄ ) = Fœï (.|c ‚Ä≤,œÄ ).
To better understand the subtle difference between Rawlsian
EOP and luck egalitarian EOP, consider the following example:
suppose in the context of employment decisions, we consider years
of education as effort, and gender as circumstance. Suppose Alice
1Note that in Rawls‚Äôs formulation of EOP, talent and ambition are treated as a legiti-
mate source of inequality, even when they are independent of a person‚Äôs effort and
responsibility. The mathematical formulation proposed here includes talent, ability and
ambition all in the scalar e . Whether natural talent should be treated as a legitimate
source of inequality is a subject of controversy. As stated earlier, throughout this work
we assume such questions have been already answered through a democratic process
and/or deliberation among stakeholders and domain experts.
2Note that in Roemer‚Äôs original work, utility is assumed to be a deterministic function
of c, e, œï . Here we changed the definition slightly to allow for the possibility of
non-deterministic dependence.
and Bob both have 5 years of education, whereas Anna and Ben
have 3 and 7 years of education, respectively. Rawlsian EOP would
require Alice and Bob to have the same employment prospects, so
it would ensure that factors such as sexism wouldn‚Äôt affect Alice‚Äôs
employment chances, negatively (compared to Bob). Luck egali-
tarian EOP goes a step further and calculates everyone‚Äôs rank (in
terms of years of education) among all applicants of their gender. In
our example, Alice is ranked 1st and Anna is ranked 2nd. Similarly,
Bob is ranked 2nd and Ben is ranked 1st. A luck egalitarian EOP
policy would ensure that Alice and Ben have the same employment
prospects, and may indeed assign Bob to a less desirable position
than Alice‚Äîeven though they have similar years of education.
Next, we will discuss the above two refinements of substantive
EOP in the context of supervised learning.

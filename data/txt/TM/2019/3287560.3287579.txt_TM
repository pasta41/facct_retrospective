
We identify and explore differential access to population-level sig-
naling (also known as information design) as a source of unequal
access to opportunity. A population-level signaler has potentially
noisy observations of a binary type for each member of a popula-
tion and, based on this, produces a signal about each member. A
decision-maker infers types from signals and accepts those indi-
viduals whose type is high in expectation. We assume the signaler
of the disadvantaged population reveals her observations to the
decision-maker, whereas the signaler of the advantaged population
forms signals strategically. We study the expected utility of the
populations as measured by the fraction of accepted members, as
well as the false positive rates (FPR) and false negative rates (FNR).
We first show the intuitive results that for a fixed environment,
the advantaged population has higher expected utility, higher FPR,
and lower FNR, than the disadvantaged one (despite having identical
population quality), and that more accurate observations improve
the expected utility of the advantaged population while harming
that of the disadvantaged one. We next explore the introduction
of a publicly-observable signal, such as a test score, as a potential
intervention. Our main finding is that this natural intervention,
intended to reduce the inequality between the populations’ utilities,
may actually exacerbate it in settings where observations and test
scores are noisy.
CCS CONCEPTS
• Theory of computation → Algorithmic game theory;
KEYWORDS
Fairness; strategic signaling; information design; university admis-
sions
ACM Reference Format:
Nicole Immorlica, Katrina Ligett, and Juba Ziani. 2019. Access to Population-
Level Signaling as a Source of Inequality. In FAT* ’19: Conference on Fairness,
Accountability, and Transparency, January 29–31, 2019, Atlanta, GA, USA.
ACM,NewYork, NY, USA, 10 pages. https://doi.org/10.1145/3287560.3287579
Ligett’s research was funded in part by the HUJI Cyber Security Research Center in
conjunction with the Israel National Cyber Directorate (INCD) in the Prime Minister’s
Office, the Israeli Science Foundation, and by a DARPA Brandeis subcontract. Ziani’s
research was supported in part by NSF grants CNS-1331343 and CNS-1518941, the
Linde Graduate Fellowship at Caltech, and the inaugural PIMCO Graduate Fellowship
at Caltech.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
FAT* ’19, January 29–31, 2019, Atlanta, GA, USA
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-6125-5/19/01. . . $15.00
https://doi.org/10.1145/3287560.3287579
1 INTRODUCTION
Settings where personal data drive consequential decisions, at large
scale, abound—financial data determine loan decisions, personal
history affects bail and sentencing, academic records feed into
admissions and hiring. Data-driven decision-making is not reserved
for major life events, of course; on a minute-by-minute basis, our
digital trails are used to determine the news we see, the job ads we
are shown, and the behaviors we are nudged towards.
There has been an explosion of interest recently in the ways in
which such data-driven decision-making can reinforce and amplify
injustices. One goal of the literature has been to identify the points
in the decision-making pipeline that can contribute to unfairness.
For example, are data more noisy or less plentiful for a disadvantaged
population than for an advantaged one? Are the available data less
relevant to the decision-making task with respect to the disadvan-
taged population? Has the disadvantaged population historically
been prevented or discouraged from acquiring good data profiles that
would lead to favorable decisions? Is the decision-maker simply
making worse decisions about the disadvantaged population, despite
access to data that could prevent it?
In this paper, we study access to population-level signaling as a
source of inequity that, to our knowledge, has not received attention
in the literature. We consider settings where the data of individuals
in a population passes to a population-level signaler, and the signaler
determines what function of the data is provided as a signal to
a decision-maker. The signaler can serve as an advocate for the
population by filtering or noising its individuals’ data, but cannot
outright lie to the decision-maker; whatever function the signaler
chooses to map from individuals’ data to signals must be fixed and
known to the decision-maker.
Examples of population-level strategic signalers include high
schools, who, in order to increase the chances that their students
will be admitted to prestigious universities, inflate their grades,
refuse to release class rankings [35], and provide glowing recom-
mendation letters for more than just the best students. Likewise,
law firms advocate on behalf of their client populations by selec-
tively revealing information or advocating for trial vs. plea bargains.
Even the choice of advertisements we see online is based on signals
about us sold by exchanges, who wish to make their ad-viewing
population seem as valuable as possible.
Our interest in asymmetric information in general and in popula-
tion level strategic signaling in particular are inspired by the recent
wave of interest in these issues in the economics literature (see Sec-
tion 2 for an overview). In particular, the model we adopt to study
these issues in the context of inequity parallels the highly influential
work on Bayesian persuasion [28] and information design [5].
In order to explore the role that population-level strategic sig-
naling can play in reinforcing inequity, we investigate its impact in
a stylized model of university admissions.
We consider a setting in which a high school’s information about
its students is noisy but unbiased. Throughout, we call this noisy
information grades, but emphasize that it may incorporate addi-
tional sources of information such as observations of personality
and effort, that are also indicative of student quality. Importantly,
all relevant information about student quality is observed directly
by the school alone.
The school then aggregates each student’s information into a
signal about that student that is transmitted to the university. This
aggregation method is called a signaling scheme, or informally, a
(randomized) mapping from a student’s information to a recom-
mendation. A school could, for instance, choose to give the same
recommendation for all its students, effectively aggregating the
information about all students into one statement about average
quality. Or, for example, the school could choose to provide positive
recommendations to only those students that it believes, based on
its information, to have high ability.
The university makes admission decisions based on these rec-
ommendations, with the goal of admitting qualified students and
rejecting unqualified ones.
tions designed to maximize the number of their students admitted
by the university. We call such a school strategic. Alternatively, a
school might simply report the information it has collected on its
students to the university directly. We call such a school revealing.
As is common in economics, we assume that the university knows
the signaling scheme chosen by the school (but does not know
the realization of any randomness the school uses in its mapping).
One justification typically given for such an assumption is that
the university could learn this mapping over time, as it observes
student quality from past years.
As expected, we find that strategic schools with accurate in-
formation about their students have a significant advantage over
revealing schools, and, in the absence of intervention, strategic
schools get more of their students (including unqualified ones)
admitted by the university.
A common intervention in this setting is the standardized test.
The university could require students to take a standardized test
before being considered for admission, and use test scores in addi-
tion to the school’s recommendations in an effort to enable more-
informed admissions decisions. Intuitively, the role of the standard-
ized test is that it “adds information back in” that was obfuscated
by a strategic school in its recommendations, and so one might nat-
urally expect the test to reduce inequity in the admissions process.
While such a standardized test does increase the accuracy of admis-
sions decisions, we show that when the test is a noisy estimate of
student quality, it may in fact exacerbate the impact of disparities
in signaling between schools.
Summary of contributions. We highlight access to strategic pop-
ulation level signaling, as studied in the economics literature, as
a potential source of inequity. We derive the optimal signaling
scheme for a school in Section 4.1 and compute the resulting school
utility and false positive and negative rates in Section 4.2. We then
show in Section 4.3 that disparities in abilities to signal strategically
can constitute a non-negligible source of inequity. In Section 5,
complementarities between students.
we study the effect of a standardized test that students must take
before applying to the university, and highlight its limitations in
addressing signaling-based inequity.

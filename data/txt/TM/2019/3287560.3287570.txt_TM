
To help their users to discover important items at a particular time,
major websites like Twitter, Yelp, TripAdvisor or NYTimes provide
Top-K recommendations (e.g., 10 Trending Topics, Top 5 Hotels
in Paris or 10 Most Viewed News Stories), which rely on crowd-
sourced popularity signals to select the items. However, diferent
sections of a crowd may have diferent preferences, and there is
a large silent majority who do not explicitly express their opinion.
Also, the crowd often consists of actors like bots, spammers, or peo-
ple running orchestrated campaigns. Recommendation algorithms
today largely do not consider such nuances, hence are vulnerable
to strategic manipulation by small but hyper-active user groups.
To fairly aggregate the preferences of all users while recommend-
ing top-K items, we borrow ideas from prior research on social
choice theory, and identify a voting mechanism called Single Trans-
ferable Vote (STV) as having many of the fairness properties we
desire in top-K item (s)elections. We develop an innovative mecha-
nism to attribute preferences of silent majority which also make
STV completely operational. We show the generalizability of our
approach by implementing it on two diferent real-world datasets.
Through extensive experimentation and comparison with state-of-
the-art techniques, we show that our proposed approach provides
maximum user satisfaction, and cuts down drastically on items
disliked by most but hyper-actively promoted by a few users.
CCS CONCEPTS
· Information systems→ Recommender systems; ·Human-
centered computing → Social media;
KEYWORDS
Top-K Recommendation; Fair Representation; Twitter Trends; Most
Popular News; Fairness in Recommendation
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proit or commercial advantage and that copies bear this notice and the full citation
on the irst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speciic permission and/or a
fee. Request permissions from permissions@acm.org.
FAT* ’19, January 29–31, 2019, Atlanta, GA, USA
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-6125-5/19/01. . . $15.00
https://doi.org/10.1145/3287560.3287570
ACM Reference Format:
Abhijnan Chakraborty, Gourab K Patro, Niloy Ganguly, Krishna P. Gum-
madi, and Patrick Loiseau. 2019. Equality of Voice: Towards Fair Repre-
sentation in, Crowdsourced Top-K Recommendations. In FAT* ’19: Con-
ference on Fairness, Accountability, and Transparency (FAT* ’19), January
29–31, 2019, Atlanta, GA, USA. ACM, New York, NY, USA, 10 pages. https:
//doi.org/10.1145/3287560.3287570
1 INTRODUCTION
Many websites today are deploying top-K recommendations to help
their users ind important items. For instance, social media sites like
Twitter recommend 10 ‘Trending Topics’ to let users know about
breaking news stories. Review aggregators like Yelp or TripAdvisor
show top 10 restaurants or hotels in a particular city. News websites
like CNN or NYTimes show 10 most viewed or most shared stories.
While some of these recommendations are personalized, i.e., tailored
to a particular user, others are non-personalized and the same items
are recommended to all users (at least in a geographical area).
Such recommendations implicitly rely on crowd-sourced pop-
ularity signals to select the items. Recently, concerns have been
raised about the potential for bias in such crowdsourced recom-
mendation algorithms [2]. For instance, Google’s search query au-
tocomplete feature has been criticized for favoring certain political
parties [38]. In another work [9], we showed that the majority of
Twitter trends are promoted by crowds whose demographics difer
signiicantly from Twitter’s overall user population, and certain
demographic groups (e.g., middle-aged black female) are severely
under-represented in the process.
In this paper, we propose to reimagine top-K non-personalized
crowdsourced recommendations (e.g., trending topics ormost viewed
news articles) as the outcomes of a multi-winner election that is pe-
riodically repeated. We show that the observed biases in top-K
recommendations can be attributed to the unfairness in the elec-
toral system. More speciically in Twitter, we observe that during
any single election cycle (5 to 15 minutes), (a) only a tiny fraction
(< 0.1%) of the overall user population express candidate (topics
or hashtag) preferences, i.e., a vast majority of voters are silent, (b)
some people vote multiple times, i.e., there is no one person, one vote
principle, and (c) voters choose from several thousands of potential
candidates (topics or hashtags), splitting their votes over several
moderate and reasonable topics, and thereby, allowing extreme top-
ics (representing highly biased view points) to be selected. Today’s
trending topic (s)election algorithms are vulnerable to electing such
fringe trends with as low as 0.001% of the electorate support.
from extensive prior research on social choice theory. We focus on
electoral mechanisms that attempt to ensure two types of fairness
criteria: proportional representation that requires the divisions in
(the topical interests of) the electorate to be relected proportionally
in the elected body (i.e., selected items) and anti-plurality, where
an extremist candidate (item) highly disliked by a vast majority of
voters has little chance of getting (s)elected. We survey existing
literature and identify a voting mechanism Single Transferable Vote
(STV) as having the properties we desire in top-K item (s)elections.
However, implementing STV-based item selection poses a tech-
nical challenge: to deter strategic manipulation, STV requires every
user to provide a preference ranking over all candidates. Requiring
the website users to rank thousands of candidate items makes the
scheme impractical. We solve this challenge by proposing to auto-
matically infer the preference rankings for users. Fortunately, we
can leverage the rich existing literature on personalized recommen-
dations to rank items according to individual personal preferences
of users. In fact, sites like Facebook and Twitter already use personal
preferences to order topics in users’ newsfeeds [30]. Additionally,
our approach enables us to account for (i.e., automatically infer
the ranking choices for) the large fraction of the electorate that is
otherwise silent and inactive during any election.
We demonstrate the practicality and efectiveness of our ideas
by conducting a comparative analysis of diferent mechanisms for
top-K recommendations using real-world data from social media
site Twitter and news media site Adressa. Over the course of a
month, we collected trending topics recommended by Twitter itself,
and computed in parallel the topics that would be recommended
by four diferent election mechanisms including plurality voting
(where the candidates with most irst place votes win) and STV. At
a high-level, our indings demonstrate that trending topics elected
by STV are signiicantly less demographically biased than those
selected by both plurality-based voting schemes and Twitter itself.
At a lower-level, our analysis reveals how the improvement in STV
selected topics arise from STV’s fairness criteria of proportional
representation (which selects topics such that most users have at
least one of their highly preferred topics included in the elected set)
and anti-plurality (which rejects highly biased topics disliked by a
majority of users). We further evaluate the mechanisms for recom-
mending most popular Adressa news stories every day throughout
a two-months period, and make similar observations.
In summary, we make the following contributions in this paper:
(a) by mapping crowdsourced recommendations to multi-winner
elections, we show how the bias in recommendation can be traced
back to the unfairness in the electoral process; (b) we establish
the fairness properties desired in crowdsourced recommendations,
and identify an electoral method, STV, which ensures fair repre-
sentation in such contexts; (c) we implement STV by devising a
mechanism to provide equality of voice even to the users who are
otherwise silent during the election cycle. To the best of our knowl-
edge, ours is the irst attempt to introduce fairness in crowdsourced
recommendations, and we hope that the work will be an important
addition to the growing literature on fairness, bias and transparency
of algorithmic decision making systems.

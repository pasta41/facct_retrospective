
In this position paper, we argue for ap-
plying recent research on ensuring so-
ciotechnical systems are fair and non-
discriminatory to the privacy protections
those systems may provide. Privacy lit-
erature seldom considers whether a pro-
posed privacy scheme protects all persons
uniformly, irrespective of membership in
protected classes or particular risk in the
face of privacy failure. Just as algorith-
mic decision-making systems may have dis-
criminatory outcomes even without explicit
or deliberate discrimination, so also pri-
vacy regimes may disproportionately fail to
protect vulnerable members of their target
population, resulting in disparate impact
with respect to the effectiveness of privacy
protections.
We propose a research agenda that will
illuminate this issue, along with related is-
sues in the intersection of fairness and pri-
vacy, and present case studies that show
how the outcomes of this research may
change existing thinking and research on
privacy and fairness. We believe it is im-
portant to ensure that technologies and
policies intended to protect the users and
subjects of information systems provide
such protection in an equitable fashion.
Keywords: Fairness, Privacy,
1 INTRODUCTION
Distinct ethical, legal, and social effects of tech-
nology do not exist in isolation, but often interact
in complex ways. Understanding these interac-
tions is crucial; we argue that research on fair-
ness in information systems and privacy are both
∗ People and Information Research Team (PIReT)
at the point where we can and must consider
their interaction. We are by no means the first
to consider these concerns and their possible rela-
tionship; Dwork and Mulligan (2013) argue for a
shifting the focus of legal analysis of information
systems from privacy and transparency to other
social factors including fairness. We argue here
for expanding the lens to include both concepts
together.
Privacy has a long history of study in com-
puter science, ethics, and law, and there are var-
ious technical and non-technical mechanisms for
protecting it under its various definitions. Con-
temporary analyses of fairness do not have as
long a history, though they are grounded in more
than fifty years of legal work on fairness and
nondiscrimination, with precursors reaching fur-
ther back in scholarly discourse.
We seek to understand how fairness and pri-
vacy interact and complement or compete with
each other. We identify three high-level questions
of interest in understanding this interaction:
1. Are technical or non-technical privacy pro-
tection schemes fair, under contemporary
definitions of fairness?
2. When and how do privacy protection tech-
nologies or policies improve or impede the
fairness of the systems they affect?
3. When and how do technologies or policies
aimed at improving fairness enhance or re-
duce the privacy protections of the people
involved?
We expect the answers to these questions to
vary based on domain, technology, and the spe-
cific definitions of privacy and fairness under con-
sideration. Further, we qualify our questions as
c© 2018 M.D. Ekstrand, R. Joshaghani & H. Mehrpouyan.
Privacy for All
regarding the ‘contemporary’ definition of fair-
ness, because (as we discuss in the next section)
much privacy technology and policy is connected
to concepts of fairness, such as fair information
practices, that are useful and important but dis-
tinct from fairness as it relates to equitable treat-
ment across classes of people.
In this position paper, we build our argument
by first rehearsing the concept space of privacy
and fairness and connect to key literature; we
then describe some of the ways we see privacy and
fairness interacting with examples. We then lay
out a research agenda for understanding privacy
and fairness, primarily focused around question
(1) with an eye towards ensuring future privacy-
protecting systems are fair, and provide several
examples of how the community’s understanding
and application of privacy and fairness research
may change in response to our research agenda.
This work builds on the goals set out by Dwork
et al. (2014) in ensuring privacy is not limited to
most people, but is extended so far as we can
guarantee to all subjects of an information sys-
tem. We expand this issue into a broad agenda at
the intersection of privacy and fairness that con-
siders the entire sociotechnical system in which
a technical, legal, or social privacy mechanism
is deployed and situating it in the current lan-
guage of algorithmic fairness. While privacy and
non-discrimination have been treated together at
length (Custers, 2013), they are often covered as
related but distinct concerns; we see a pressing
need for research on their intersection, building
on the goals of Dwork et al. (2014) and the joint
pursuit of privacy and fairness by Hajian et al.
(2015).
We invite discussion and collaboration on these
topics, in order to make computing technology
in practice better for all people it affects. Our
present treatment focuses primarily on the U.S.
context, drawing from U.S. legal doctrines and
policy approaches; translating and reevaluating
the concerns we raise in other legal and cultural
contexts is important future work.
Our philosophical approach to these topics is
grounded in the work of Franklin (1999), partic-
ularly in our interest in understanding who pays
for and who benefits from any particular technol-
ogy or policy, and in promoting technology that
is equitable and participatory.

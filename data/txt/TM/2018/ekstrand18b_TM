
In the research literature, evaluations of
recommender system effectiveness typically
report results over a given data set, pro-
viding an aggregate measure of effective-
ness over each instance (e.g. user) in the
data set. Recent advances in information
retrieval evaluation, however, demonstrate
the importance of considering the distribu-
tion of effectiveness across diverse groups
of varying sizes. For example, do users
of different ages or genders obtain simi-
lar utility from the system, particularly if
their group is a relatively small subset of
the user base? We apply this consider-
ation to recommender systems, using of-
fline evaluation and a utility-based metric
of recommendation effectiveness to explore
whether different user demographic groups
experience similar recommendation accu-
racy. We find demographic differences in
measured recommender effectiveness across
two data sets containing different types of
feedback in different domains; these differ-
ences sometimes, but not always, correlate
with the size of the user group in question.
Demographic effects also have a complex—
and likely detrimental—interaction with
popularity bias, a known deficiency of
recommender evaluation. These results
demonstrate the need for recommender
∗ This paper can be reproduced with scripts available
at https://dx.doi.org/10.18122/B2GM6F.
† This paper is an extension of the poster by Ekstrand
and Pera (2017).
system evaluation protocols that explicitly
quantify the degree to which the system
is meeting the information needs of all its
users, as well as the need for researchers
and operators to move beyond näıve eval-
uations that favor the needs of larger sub-
sets of the user population while ignoring
smaller subsets.
Keywords: recommender systems, fair
evaluation
1 INTRODUCTION
Recommender systems are algorithmic tools for
identifying items (e.g., products or services) of in-
terest to users (Adomavicius and Tuzhilin, 2005;
Ekstrand et al., 2010; Ricci et al., 2015). They
are usually deployed to help mitigate information
overload (Resnick et al., 1994). Internet-scale
item spaces offer many more choices than hu-
mans can process, diminishing the quality of their
decision-making abilities (Toffler, 1990; Gross,
1964). Recommender systems alleviate this prob-
lem by allowing users to more quickly focus
on items likely to match their particular tastes.
They are deployed across the modern Internet,
suggesting products in e-commerce sites, movies
and music in streaming media platforms, new
connections on social networks, and many more
types of items.
We are concerned with the fairness of recom-
mender systems, a surprisingly tricky concept to
define. In addition to the numerous types and op-
c© 2018 M.D. Ekstrand, M. Tian, I. Madrazo Azpiazu, J.D. Ekstrand, O. Anuyah, D. McNeill & M.S. Pera.
All the Cool Kids
erationalizations of fairness in the research liter-
ature, recommender fairness must identify which
stakeholder groups to consider for fair treatment
(Burke, 2017).
Both offline (Herlocker et al., 2004; Shani
and Gunawardana, 2011) and online (Knijnen-
burg et al., 2012) evaluations of recommender
systems typically focus on evaluating the sys-
tem’s effectiveness in aggregate over the en-
tire population of users. While individual user
characteristics are sometimes taken into ac-
count, as in demographic-informed recommen-
dation (Pazzani, 1999; Ghazanfar and Prugel-
Bennett, 2010), the end evaluation still aggre-
gates over all users.
Recent developments in human-centered infor-
mation retrieval have incorporated user demo-
graphics and characteristics to evaluate search
engines and understand users’ search behavior.
Weber and Castillo (2010) use light user informa-
tion augmented with census-based demograph-
ics to understand who is using a search engine.
Mehrotra et al. (2017) follow this trend by mea-
suring Bing’s ability to satisfy the information
needs of different subgroups of its user popula-
tion, e.g. assessing whether it meets the needs
of grandparents as effectively as those of young
professionals.
This attention is necessary because the largest
subgroup of users will tend to dominate over-
all statistics. If other subgroups have different
needs, their satisfaction will carry less weight
in the final analysis. This can lead to a mis-
guided perception of the performance of the sys-
tem and, more importantly, make it more diffi-
cult to identify how to better serve specific de-
mographic groups.
Our fundamental research question is this: Do
different demographic groups obtain different util-
ity from the recommender system? This is a
starting point for many further questions, such
as whether particular demographic groups need
to be better served by recommender systems and,
if so, how they can be identified and supported
in their information needs.
To address this question, we present an em-
pirical analysis of the effectiveness of collabora-
tive filtering recommendation strategies, strati-
fied by the gender and age of the users in the
data set. We apply widely-used recommendation
techniques across two domains, musical artists
and movies, using publicly-available data. We
also explore the effect of rebalancing the data set
by gender, the influence of user profile size on
recommendation quality, and the interaction of
demographic effects with previously documented
biases in recommender evaluation, all in the con-
text of demographically-distributed differences in
effectiveness.
Our work is inspired by that of Mehrotra et al.
(2017). We translate the concepts of their anal-
ysis from search engines to recommender sys-
tems. While our experiment is less sophisticated
than Mehrotra et al.’s and necessarily limited by
our offline experimental setting, it is fully re-
producible using widely-distributed public data
sets and can be easily adapted to additional al-
gorithms, domains, and applications.

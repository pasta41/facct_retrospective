
Actuarial risk assessments might be unduly
perceived as a neutral way to counteract
implicit bias and increase the fairness of
decisions made at almost every juncture
of the criminal justice system, from pre-
trial release to sentencing, parole and pro-
bation. In recent times these assessments
have come under increased scrutiny, as crit-
ics claim that the statistical techniques
underlying them might reproduce existing
patterns of discrimination and historical bi-
ases that are reflected in the data. Much
of this debate is centered around compet-
ing notions of fairness and predictive accu-
racy, resting on the contested use of vari-
ables that act as “proxies” for character-
istics legally protected against discrimina-
tion, such as race and gender.
We argue that a core ethical debate sur-
rounding the use of regression in risk as-
sessments is not simply one of bias or ac-
curacy. Rather, it’s one of purpose. If ma-
chine learning is operationalized merely in
the service of predicting individual future
crime, then it becomes difficult to break
cycles of criminalization that are driven by
the iatrogenic effects of the criminal jus-
tice system itself. We posit that machine
learning should not be used for prediction,
but rather to surface covariates that are fed
into a causal model for understanding the
social, structural and psychological drivers
of crime. We propose an alternative appli-
cation of machine learning and causal in-
ference away from predicting risk scores to
risk mitigation.
Keywords: causal inference, criminal jus-
tice, interventions, risk assessment tools
1 INTRODUCTION
In 2016, a team of investigative journalists from
ProPublica published an article (Angwin et al.,
2016) claiming that COMPAS, a proprietary risk
assessment tool that has been used in the U.S.
criminal justice system, was racially biased. The
article sparked a national debate about the ex-
panding use of algorithmic decision-making aids
in the courts. This debate is emblematic of a
much broader conversation around the appropri-
ate use of data and statistical methods in soci-
ety, in spheres as varied as health care, hous-
ing, employment and education. For example,
Selbst (Selbst, 2016) cites media debates on con-
sumer finance (Economist, 2017), employment
(Wang, 2017), housing (Biggs, 2016), health care
(Siwicki, 2017), and sentencing (Tashea, 2017).
While these issues are largely framed in terms
of new technology, driven by “big data” or “ar-
tificial intelligence,” the methods and tools in
question are often incremental iterations on much
older actuarial decision-making practices. This
is certainly the case for risk assessments, which
have existed in some form in the U.S. criminal
justice system since the 1920’s.
By placing the current debate around risk as-
sessment in a broader context, we can get a fuller
understanding of the way these actuarial tools
have evolved to achieve a varied set of social and
institutional agendas. The current debate around
risk assessment tends to characterize or implicitly
c© 2018 C. Barabas, K. Dinakar, J. Ito, M. Virza & J. Zittrain.
Interventions over Predictions:Reframing the Ethical Debate for Actuarial Risk Assessment
concede the purpose of these tools as fundamen-
tally predictive in nature. The more significant
power of data-driven risk assessment can be as
a broader diagnostic tool, one used to help prac-
titioners address risk as a dynamic, intervenable
phenomenon. When risk assessments are recast
in this light, we can ask whether or not regres-
sion and machine learning methods can help in
diagnosis and intervention, rather than predic-
tion. We make a case for why causal inference, a
statistical method designed explicitly to establish
a causal connection between a “treatment” and
an outcome of interest, provides a more desirable
framework for developing intervention-driven risk
assessments in the criminal justice system.

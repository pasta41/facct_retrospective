 
The moral authority of ethics codes stems from an assumption that 
they serve a unified society, yet this ignores the political aspects 
of any shared resource. The sociologist Howard S. Becker 
challenged researchers to clarify their power and responsibility in 
the classic essay: Whose Side Are We On. Building on Becker’s 
hierarchy of credibility, we report on a critical discourse analysis 
of data ethics codes and emerging conceptualizations of 
beneficence, or the “social good”, of data technology. The 
analysis revealed that ethics codes from corporations and 
professional associations conflated consumers with society and 
were largely silent on agency. Interviews with community 
organizers about social change in the digital era supplement the 
analysis, surfacing the limits of technical solutions to concerns of 
marginalized communities. Given evidence that highlights the 
gulf between the documents and lived experiences, we argue that 
ethics codes that elevate consumers may simultaneously 
subordinate the needs of vulnerable populations. Understanding 
contested digital resources is central to the emerging field of 
public interest technology. We introduce the concept of digital 
differential vulnerability to explain disproportionate exposures to 
harm within data technology and suggest recommendations for 
future ethics codes.. 
CCS CONCEPTS 
• codes of ethics • computing profession • machine learning 
KEYWORDS 
ethics codes, social movements, digital differential vulnerability, 
digital vulnerability, data science, public interest technology 
 
ACM Reference format: 
Anne L. Washington and Rachel S. Kuo. 2020. Whose Side are Ethics 
Codes On? Power, Responsibility and the Social Good. In Proceedings of 
ACM Fairness Accountability Transparency conference (FAT’20). ACM, 
Barcelona, Spain, 10 pages. https://doi.org/10.1145/3351095.3372844 
 
1 Introduction 
Concerns about the power and responsibility of data technology 
spurred the recent simultaneous publication of multiple ethics 
codes. Organizations that published data ethics codes recognized 
the growing need to articulate the technology's potential benefit to 
society or the "social good". We report on a critical discourse 
analysis of ethics codes written between 2015-2019 about data 
science, machine learning, computer science, and artificial 
intelligence (AI). We use the term data technology to encompass 
all data-intensive research. We interrogate how ethics codes 
promote benefits across society. Drawing on a classic provocation 
[9] for social science researchers to reflect on their position in 
society, we frame our investigation by asking: whose side are the 
ethics codes on? 
 
Challenging the assumption that the public good is readily 
obvious, we argue that all populations are not uniformly 
considered in ethics codes and, more troubling, ethics codes do 
little to support vulnerable populations. A vulnerable population is 
defined here as a group that has been historically and 
systematically disenfranchised in addition to those currently 
experiencing a marginalized status, as defined in the Belmont 
Report on research ethics [46]. We introduce the term “digital 
differential vulnerability” to explain the spectrum of population 
experiences with data technologies. 
 
Current disputes about the fairness and accuracy of data 
technology reveal tensions in defining the benefits across society. 
Vicious attacks drive female users off platforms designed for free 
speech [15]. Cambridge Analytica gathered the social networks of 
casual online labor workers [27, 14] disproportionately targeting 
people who rely on unstable employment. Facial recognition 
software in photo applications humiliates users by auto-tagging 
Permission to make digital or hard copies of all or part of this work for personal or 
classroom use is granted without fee provided that copies are not made or distributed 
for profit or commercial advantage and that copies bear this notice and the full citation 
on the first page. Copyrights for components of this work owned by others than the 
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or 
republish, to post on servers or to redistribute to lists, requires prior specific 
permission and/or a fee. Request permissions from permissions@acm.org. 
 
FAT* '20, January 27–30, 2020, Barcelona, Spain © 2020 Copyright is held by the 
owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-6936-
7/20/02…$15.00 https://doi.org/10.1145/3351095.3372844 
https://doi.org/10.1145/1234567890 
 
 
 
their photos with animal names [48]. These examples reveal 
disagreements over the equal distribution of benefits from data 
technologies throughout society. Many of these examples came to 
light concurrently to the production and publication of the ethics 
codes in this study. 
 
Our research design employed multiple methods to focus on 
language shared across a set of ethics codes. We grounded our 
methodology in inductive qualitative coding and critical discourse 
analysis to capture meaning from 15 ethics codes written between 
2015-2018. We contrasted these findings to interviews with 
community organizers who have lived experience of these 
technologies. A quantitative corpus analysis verified inductive 
findings and compared the five ethics codes written by 
corporations to the ten written by professional associations. 
 
The language in this set of corporate and association ethics codes 
conveyed a sense of duty to society but also narrowly addressed 
clients and customers. Our results challenge the assumption that 
ethics codes consider concerns of society at large. The current 
generation of ethics codes mask differential vulnerability and the 
contested nature of shared resources, including the social good. 
We underscore this point around disproportionate exposure to risk 
and potential harm by interviewing activists and organizers who 
identify with a historically marginalized community and who rely 
heavily on these technologies. 
 
We argue that ethics codes that elevate the concerns of customer 
populations may also subordinate the needs of vulnerable 
populations creating a two-tiered system of social value. We 
suggest that ethics codes that want to establish credible moral 
leadership would extend a sense of commitment and 
accountability to vulnerable populations. 
 

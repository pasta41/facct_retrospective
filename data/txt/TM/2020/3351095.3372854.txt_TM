
Ethics curricula in computer science departments should include a
focus on the political action of students. While ‘ethics’ holds signifi-
cant sway over current discourse in computer science, recent work,
particularly in data science, has shown that this discourse elides
the underlying political nature of the problems that it aims to solve.
In order to avoid these pitfalls—such as co-option, whitewashing,
and assumed universal values—we should recognize and teach the
political nature of computing technologies, largely through science
and technology studies. Education is an essential focus not just in-
trinsically, but also because computing students end up joining the
companies which have outsize impacts on our lives. At those com-
panies, students both have a responsibility to society and agency
beyond just engineering decisions, albeit not uniformly. I propose
that we move away from strict ethics curricula and include exam-
ples of and calls for political action of students and future engineers.
Through such examples—calls to action, practitioner reflections,
legislative engagement, direct action—we might allow engineers to
better recognize both their diverse agencies and responsibilities.
CCS CONCEPTS
• Social and professional topics→ Codes of ethics; Comput-
ing education; Accreditation; Socio-technical systems.
KEYWORDS
politics, civics, activism, science and technology studies
ACM Reference Format:
Jared Moore. 2020. Towards a more representative politics in the ethics
of computer science. In Conference on Fairness, Accountability, and Trans-
parency (FAT* ’20), January 27–30, 2020, Barcelona, Spain. ACM, New York,
NY, USA, 11 pages. https://doi.org/10.1145/3351095.3372854
1 INTRODUCTION
Ethics is a hot word in computer science. Companies, organiza-
tions, and universities have begun to use the term in principles,
declarations, and promotional material. Lately, this has occurred in
the space of ‘artificial intelligence (AI) ethics.’ Ethics commitments
have bled over into curricula as well. For example, in spring 2019
the Mozilla Foundation awarded grants to a number of computer
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
FAT* ’20, January 27–30, 2020, Barcelona, Spain
© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-6936-7/20/02. . . $15.00
https://doi.org/10.1145/3351095.3372854
science programs in order to increase the extent of ethics education
[71]. Furthermore, a recent list shows more than 200 university
courses that claim to fall in the category of tech ethics [38].
Clearly, something is afoot. At first glance, such attention might
have those of us who argue that values are embedded in technology
celebrating. The situation is not so clear. Such developments in
ethics may actually be missing the original point of the critiques (as
say [46]). Companies continue to develop computing technologies
that arguably undermine common normative frameworks such as
distributive justice and human rights, while still using the language
of ethics.1
Take Amazon, for example. It appears to allow deployment of
facial recognition technology on the U.S.-Mexico border [28]. The
topics usually covered in discussions of AI ethics fail to capture the
significance of such situations. The question of whether facial recog-
nition technology ‘fairly’ identifies people across racial groups2
appears moot when any contribution to the further criminalization
of asylum seekers and exclusion from economic opportunity flouts
principles of distributive justice.
Let us assume that someone has come to the conclusion that
such a use of facial recognition technology, one that further harms
asylum seekers, is unethical under a given theory which appears
reasonable given broad interpretations of any class of ethical frame-
works. The question then remains of what to do about it. This is
particularly relevant given that ethics in computing seems to be
restricted to applied engineering questions or ‘microethics.’ Applied
in this sense, ethics would dictate how to change the design of a
system, but not how to change structural systems of oppression in
which such a system operates.
Of course, the description of the action of companies and engi-
neers in relation to philosophical definitions of ethics is useful—
whether, for example, Amazon’s use of facial recognition technol-
ogy on the U.S. border would be permissible in the strict egalitari-
anism distributive justice. Nevertheless, such an examination, if the
only one conducted, would squelch the important political nature
of the case, being: how do we operationalize our conclusion? Fur-
thermore, current CS ethics curricula appear to be mainly applied
and professional in nature. That is to say, current ethics education
may not even go so far as to consider the structure of society.
Here, I do not necessarily mean to endorse distributive justice,
but rather to highlight a difference between what are construed as
chiefly ethical and political issues. Our interest, as would be that
of anyone concluding an ethical chain of reasoning, should be to
promote the world in which we find resolution of the ethical issue.
This promotion is inherently political.
1For an examination of distributive justice see [62].
2See discussions of mathematical fairness in the literature, e.g. [60].
Essentially, current debates in computer science are political
and not just ethical ones. They involve questions of not just ‘what
values does this technology assume,’ but also ‘what kind of society
does this technology create,’ ‘how can I create the kind of society
in which I want to live.’ The recognition and discussion of moral
principles—ethics—of course are necessary but may not be sufficient
for this.3
It is not apparent whether the current teaching of ethics in com-
puter science covers the politics of technology in both design and
action. In particular, the focus on applied ethics blunts the political
nature of the situations in which computer scientists find them-
selves. Furthermore, ethics carries its own history and should have
us ask: whose ethical theories are we using and whom might they
leave out? Relevant are not only ethical theories, but also their pro-
fessional realization. While scholars have historically found that
both ethics codes and classes appear to have little impact on the
actions of engineers (as [26] discuss) this may be due to the limits
of the framing of such ethics.
Nevertheless, despite the limits of ethics as they exist in computer
science, practitioners have begun to act. Reporting from summer
2019 details the actions of Stanford computing students to resist the
big tech companies, who the students see as perpetuating injustice
by supporting groups such as the U.S. Immigration and Customs
Enforcement agency [42]. At Google in fall 2018, thousands of
workers walked out to protest the company’s sexual harassment
policies. That came a year after tech workers organized to oppose
building infrastructure to support the Trump administration’s Mus-
lim ban [52]. The Tech Worker’s Coalition aims to organize both
gig workers and software engineers to advance more just policies.
Google has terminated contracts with the U.S. Department of De-
fense (DoD) due to pressure from employees, with some speaking
up under the hashtag #TechWontBuildIt [82]. Companies such as
Amazon [28] and Wayfair [43] have seen similar pressure. Amazon
has also faced pressure with regard to climate justice [56] and has
responded with increased environmental commitments [11].
After the 2016 U.S. presidential election, it was widely acknowl-
edged that ‘fake news’ and targeted ads significantly contributed
to the outcome of the election. While the C.E.O Mark Zuckerberg
initially said this was “a pretty crazy idea” [92], he later changed
his mind after facing pressure from his employees. The editor of
Wired, investigating this case, found that “the place that you can
put the most pressure on executives comes from engineers” [87].
Other commentators have begun to say the same [75]. Clearly tech
employees have agency beyond being ‘just an engineer’ [45].
Many turn to technology company executives to answer for
ethical issues because executives, supposedly, have the agency to
make changes. We can see this, for example, in the furor over
Mark Zuckerberg’s U.S. Congressional testimony [96]. However,
other scholars, as will be discussed, also advocate for employees to
embrace their own obligations to society.
I explore how computer scientists might explore their agencies
through ethics education. Of course, agency is intersectional, not
uniform, and may be explored through means other than education.
3Such political implications are quite related to economic ones as [37] explore in
human-computer interaction. See also [99] for more examples of the capital model of
modern data systems and [94] for a theoretical analysis of them.
To study how tech employees might develop their ethical reason-
ing, I created and taught a course on ethics to computer scientists
at the University of Washington. In line with this paper, the course
aimed for students to develop both a broader conception of the
dilemmas in current computing technologies and a more expan-
sive framework for their own ethical responsibilities. A colleague
and I then re-made the course to further focus on the structural
and political implications of computing technologies and included
previous and potential actions of stakeholders of such systems.4
While questions of ethics in computer science are relevant inter-
nationally, this paper focuses primarily on the U.S. because it is the
political system I know best. I would greatly appreciate collabora-
tion with scholars knowledgeable of other political systems.
In this paper, I argue that ethics curricula in computer science
departments should cover social activism and politics as extensions
of classical discussions of ethics. This argument proceeds in four
parts. First, I review literature on the topics of ethics, civics, and
employee responsibility. Second, I offer an argument for why we
should cover political engagement in addition to ethics. Third, I ex-
plore how to implement such a change and offer recommendations.
Fourth, I consider critiques one might have for my approach.

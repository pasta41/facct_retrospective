
We examine the way race and racial categories are adopted in
algorithmic fairness frameworks. Current methodologies fail to ad-
equately account for the socially constructed nature of race, instead
adopting a conceptualization of race as a fixed attribute. Treating
race as an attribute, rather than a structural, institutional, and rela-
tional phenomenon, can serve to minimize the structural aspects
of algorithmic unfairness. In this work, we focus on the history of
racial categories and turn to critical race theory and sociological
work on race and ethnicity to ground conceptualizations of race for
fairness research, drawing on lessons from public health, biomedi-
cal research, and social survey research. We argue that algorithmic
fairness researchers need to take into account the multidimension-
ality of race, take seriously the processes of conceptualizing and
operationalizing race, focus on social processes which produce
racial inequality, and consider perspectives of those most affected
by sociotechnical systems.
CCS CONCEPTS
• Applied computing→ Sociology; • Social and professional
topics → Race and ethnicity.
KEYWORDS
algorithmic fairness, critical race theory, race and ethnicity
ACM Reference Format:
Alex Hanna, Emily Denton, Andrew Smart, and Jamila Smith-Loud. 2020.
Towards a Critical Race Methodology in Algorithmic Fairness. In Conference
on Fairness, Accountability, and Transparency (FAT* ’20), January 27–30, 2020,
Barcelona, Spain. ACM, New York, NY, USA, 12 pages. https://doi.org/10.
1145/3351095.3372826
∗Both authors contributed equally to this research.
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
FAT* ’20, January 27–30, 2020, Barcelona, Spain
© 2020 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-6936-7/20/02.
https://doi.org/10.1145/3351095.3372826
The problem does not end with the collection of racial
data; it only begins. The problem accelerates when
we attempt to analyze these data statistically... The
racialization of data is an artifact of both the strug-
gles to preserve and to destroy racial stratification.
Before the data can be deracialized, we must deracial-
ize the social circumstances that have created racial
stratification.
– Tufuku Zuberi [125, pp. 102]
1 INTRODUCTION
In recent years, there has been increasing recognition of the poten-
tial for algorithmic systems to reproduce or amplify existing social
inequities. In response, the research field of algorithmic fairness has
emerged. This rapidly evolving research area is focused on devel-
oping tools and techniques with aspirations to make development,
use, and resulting impact of algorithmic systems conform to various
social and legal notions of fairness. The concept of fairness, in ad-
dition to being situational, evolving, and contested from a number
of philosophical and legal traditions, can only be understood in
reference to the different social groups that constitute the organi-
zation of society. Consequently, the vast majority of algorithmic
fairness frameworks are specified with reference to these social
groups, often requiring a formal encoding of the groups into the
dataset and/or algorithm.
However, most social groups relevant to fairness analysis re-
flect highly contextual and unstable social constructs. These social
groups are often defined with recourse to legal anti-discrimination
concepts such as "protected classes," which, in the US, refers to race,
color, national origin, religion, sex, age, or disability. However, the
process of drawing boundaries around distinct social groups for
fairness research is fraught; the construction of categories has a
long history of political struggle and legal argumentation.
Numerous recent works have highlighted the limitations of cur-
rent algorithmic fairness frameworks [53, 108]. Several of these
critiques point to the tendency to abstract away critical social and
historical contexts and minimize the structural conditions that un-
derpin problems of algorithmic unfairness. We build on this critical
research, focusing specifically on the use of race and racial cate-
gories within this field. IN this literature, the topic of the instability
of racial categories has gone relative unexplored, with the notable
exception of Benthall and Haynes [12], which we discuss in detail
below.
Race is a major axis around which algorithmic allocation of
resources and representation is bound. It may indeed be the most
significant axis, given attention by investigative journalists (e.g. [7])
and critical race and technology scholars (e.g. [11, 20, 21, 24, 85]).
Because of this, it is imperative that the race-based methodologies
and racial categories themselves are interrogated and critically
evaluated.
In this paper we develop several lines of critique directed at the
treatment of race within algorithmic fairness methodologies. In
short, we observe that current methodologies fail to adequately
account for the socially constructed nature of race, instead adopting
a conceptualization of race as a fixed attribute. This manifests in the
widespread use of racial categories as if they represent natural and
objective differences between groups. Treating race as an attribute,
rather than a structural, institutional, and relational phenomenon,
in turn serves to minimize the structural aspects of algorithmic
unfairness.
The process of operationalizing race is fundamentally a project
of racial classification and thus must be understood as a political
project, or, more specifically, what Omi and Winant [86] refer to
as a racial project. The tools for measuring individual characteris-
tics, such as national censuses and other population-level survey
instruments, were and are still often based in the politics of racial
oppression and domination. While we acknowledge the importance
of measuring race for the purposes of understanding patterns of
differential performance or differentially adverse impact of algo-
rithmic systems, in this work, we emphasize that data collection
and annotation efforts must be grounded in the social and historical
contexts of racial classification and racial category formation. To
oversimplify is to do violence, or even more, to re-inscribe violence
on communities that already experience structural violence.
It is useful to distinguish between two ways in which race comes
into play in algorithmic fairness research: (i) the operationalization
of race, i.e. the process of converting the abstract concept of race
into something that is concrete and measurable and (ii) the use of
racial variables within algorithmic frameworks. These aspects are
tightly interconnected since race must be operationalized before
racial variables can be utilized.
Our contributions are as follows: we review the use of race in
prior fairness work and discuss an intervention in the debate on
racial categories. We then survey the history of racial classifica-
tion, scientific racism, and racial classification in national censuses.
We introduce the notion of multidimensionality of race, and sub-
sequently review how different disciplines have dealt with the
tricky problem of operationalizing race, most notably in biomedical,
survey, and public health research. In light of these discussions,
we address how race has been treated in the group fairness and
disaggregated analysis paradigms. Lastly, we argue that fairness re-
searchers need to take into account the multidimensionality of race,
take seriously the processes of conceptualizing and operationaliz-
ing race, focus on processes of racism, and consider perspectives of
those most affected by sociotechnical systems.

 
Algorithmic decision-making (ADM) is becoming increasingly im-
portant in all areas of social life. In higher education, machine-
learning systems have manifold uses because they can efficiently 
process large amounts of student data and use these data to arrive 
at effective decisions. Despite the potential upsides of ADM sys-
tems, fairness concerns are gaining momentum in academic and 
public discourses. The criticism largely focuses on the disparate ef-
fects of ADM. That is, algorithms may not serve as objective and 
fair decision-makers but, rather, reproduce biases existing within 
the respective training data. This study adopted a different approach 
by focusing on individual perceptions of fairness. Specifically, we 
looked at two different dimensions of perceived fairness: (i) proce-
dural fairness and (ii) distributive fairness. Using cross-sectional 
survey data (n = 304) from a large German university, we tested 
whether students’ assessments of fairness differ with respect to al-
gorithmic vs. human decision-making (HDM) within the higher ed-
ucation context. Furthermore, we investigated whether fairness per-
ceptions have subsequent effects on three different outcome varia-
bles, which are hugely important for universities: (1) exit, (2) voice, 
and (3) organizational reputation. The results of our survey suggest 
that participants evaluated ADM higher than HDM in terms of both 
procedural and distributive fairness. Concerning the subsequent ef-
fects of fairness perceptions, we find that (1) distributive fairness 
as well as procedural fairness perceptions have a negative impact 
on the intention to protest against an ADM system, whereas (2) 
only procedural fairness perceptions negatively affect the likeli-
hood of exiting. Finally, (3) distributive fairness, but not procedural 
fairness perceptions have a positive effect on organizational repu-
tation. For universities aiming to implement ADM systems, it is 
crucial, therefore, to take possible fairness issues and their further 
implications into account. 
CCS CONCEPTS 
• Human-centered computing → Empirical studies in HCI; • Ap-
plied Computing → Sociology; • Applied Computing → Educa-
tion 
KEYWORDS 
Distributive Fairness, Procedural Fairness, Artificial Intelligence, 
Algorithmic Decision Making, Higher Education Systems, Reputa-
tion, Voice, Exit 
ACM Reference format: 
Frank Marcinkowski, Kimon Kieslich, Christopher Starke, and Marco Lün-
ich. 2020. Implications of AI (Un-)Fairness in Higher Education Admis-
sions: The Effects of Perceived AI (Un-)Fairness on Exit, Voice and Organ-
izational Reputation. In FAT* ’20: Conference on Fairness, Accountability, 
and Transparency (FAT* 20), January 27–30, 2020, ACM, Barcelona, 
Spain, 9 pages. https://doi.org/10.1145/3351095.3372867 
1 ARTIFICIAL INTELLIGENCE IN HIGHER 
EDUCATION SYSTEMS 
Algorithmic decision-making (ADM) is being applied increas-
ingly in virtually all sectors of social life, such as medicine [23,36], 
public administration [38], and finance [21]. In addition, institu-
tions of higher education, such as universities, have begun imple-
menting artificial intelligence (AI) applications to predict student 
performance, analyze academic teaching, communicate with stu-
dents through the use of bots, perform dropout detection and struc-
ture their financial organization [4,11,14,31,40] (for an overview of 
the use of AI applications in German universities, see [24]). Even 
the possibility of university admission [1,9] was recently part of the 
public discourse:  
Permission to make digital or hard copies of all or part of this work for personal or 
classroom use is granted without fee provided that copies are not made or distributed 
for profit or commercial advantage and that copies bear this notice and the full cita-
tion on the first page. Copyrights for components of this work owned by others than 
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or 
republish, to post on servers or to redistribute to lists, requires prior specific permis-
sion and/or a fee. Request permissions from Permissions@acm.org. 
FAT* '20, January 27–30, 2020, Barcelona, Spain 
© 2020 Association for Computing Machinery. 
ACM ISBN 978-1-4503-6936-7/20/02…$15.00 
https://doi.org/10.1145/3351095.3372867 
 
 
 
It’s easy to imagine, for example, how a college-admis-
sions committee might turn the laborious and uncertain 
sifting of applicants over to a machine-learning model; 
such a model might purport to optimize an entering cohort 
not just for academic success but also for harmonious re-
lationships and generous alumni donations [41].  
Such a system could be quite valuable as universities spend con-
siderable financial and human resources on the admission process. 
In Germany, many study programs at public universities are freely 
accessible and free of charge. However, it is not always possible to 
enroll directly in a program at one’s university of choice. If there 
are fewer courses of study available than are requested by interested 
parties, admission is restricted. At the time of this study, about 40% 
of the programs nationwide were admission-restricted [18], with 
the rest being admission-free. Courses in medicine, pharmacy, vet-
erinary medicine, dentistry, and communication science are so pop-
ular that they are restricted at all universities nationwide. In addi-
tion, a large number of degree programs at individual universities 
have restricted admission. At the university where we conducted 
this empirical study, these also include programs, for example, in 
political science, economics, and sociology. In principle, re-
strictions apply to study programs that grant access to professions 
with a particularly high income or that open up access to popular 
occupational fields (e.g., media business).  
The principle of “best selection” generally guides the selection 
process at higher education institutions; that is, the primary concern 
is about selecting those applicants who possess as many of the nec-
essary skills and abilities as possible. In a broader sense, the aim is 
to keep the dropout rate as low as possible because high dropout 
rates not only damage the reputation of study courses and degree 
programs but also harm institutes financially, as their public fund-
ing is dependent, among other things, on the number of graduates 
they produce. Applicants with the best average grades on their 
school reports fill most of the study spaces. In addition, universities 
can define further selection criteria for local admission procedures, 
such as selection interviews, internships, weighting of certain 
grades in the diploma, or a completed study ability test. These cri-
teria differ from university to university and from subject to sub-
ject. Since selection interviews, evaluations of motivation letters, 
or aptitude tests are very resource-intensive, it appears logical to 
consider the use of automated procedures with AI in the admission 
process. The use of ADM has the potential to make this process 
more cost-effective and faster, which could benefit both the univer-
sity and the applicants [40]. 
Yet a controversial discourse also exists regarding the fairness 
of student admission systems in general. On the one hand, it in-
cludes the question of which data or information to account for and 
whether this information is valid. On the other hand, it addresses 
individual fairness perceptions of decision-making practices and 
decision outcomes. Thus, we conceptually distinguish two faces of 
fairness. While factual fairness refers to objectively measurable 
features, perceived fairness is a construct that relates to individual 
perceptions. Factual and perceived fairness are presumably corre-
lated, but conceptually distinct. Despite the scant empirical re-
search within the social sciences [5], fairness must be treated as a 
pivotal value with respect to ADM. In a survey, Araujo et al. [3] 
found that fairness was the second most important value for ADM 
among Dutch citizens. Given the importance of fairness, it also 
seems to be of interest to evaluate the outcomes of perceived fair-
ness or unfairness of ADM. Considering that AI-driven systems 
take over tasks that humans previously executed, it is crucial to in-
vestigate differences between ADM and HDM with regard to per-
ceived fairness. 
Thus, this study addressed two research questions. First, we in-
vestigated whether ADM is perceived as fairer or more unfair than 
HDM in terms of procedural and distributive fairness. Second, we 
tested the effects of AI fairness perceptions on attitudes and behav-
iors relevant to the university organization—namely, exit, voice, 
and organizational reputation. In particular, we examined the ef-
fects of perceived procedural and distributional AI fairness on the 
intentions to protest ADM and refrain from applying to a university 
that uses ADM in the application process. Furthermore, we exam-
ined the link between AI fairness and the overall reputation of a 
university that uses such a system.  

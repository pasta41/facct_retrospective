
A recent normative turn in computer science has brought concerns
about fairness, bias, and accountability to the core of the field. Yet
recent scholarship has warned that much of this technical work
treats problematic features of the status quo as fixed, and fails to
address deeper patterns of injustice and inequality. While acknowl-
edging these critiques, we posit that computational research has
valuable roles to play in addressing social problems — roles whose
value can be recognized even from a perspective that aspires toward
fundamental social change. In this paper, we articulate four such
roles, through an analysis that considers the opportunities as well
as the significant risks inherent in such work. Computing research
can serve as a diagnostic, helping us to understand and measure so-
cial problems with precision and clarity. As a formalizer, computing
shapes how social problems are explicitly defined — changing how
those problems, and possible responses to them, are understood.
Computing serves as rebuttal when it illuminates the boundaries
of what is possible through technical means. And computing acts
as synecdoche when it makes long-standing social problems newly
salient in the public eye. We offer these paths forward as modalities
that leverage the particular strengths of computational work in
the service of social change, without overclaiming computing’s
capacity to solve social problems on its own.
CCS CONCEPTS
• Social and professional topics → Computing / technology pol-
icy; • Applied computing → Computers in other domains.
KEYWORDS
social change, inequality, discrimination, societal implications of
AI
ACM Reference Format:
Rediet Abebe, Solon Barocas, Jon Kleinberg, Karen Levy, Manish Raghavan,
and David G. Robinson. 2020. Roles for Computing in Social Change. In
Conference on Fairness, Accountability, and Transparency (FAT* ’20), January
27–30, 2020, Barcelona, Spain. ACM, New York, NY, USA, 9 pages. https:
//doi.org/10.1145/3351095.3372871
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
FAT* ’20, January 27–30, 2020, Barcelona, Spain
© 2020 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-6936-7/20/01.
https://doi.org/10.1145/3351095.3372871
1 INTRODUCTION
In high-stakes decision-making, algorithmic systems have the po-
tential to predict outcomes more accurately and to allocate scarce
societal resources more efficiently — but also the potential to intro-
duce, perpetuate, and worsen inequality. Algorithmic accountabil-
ity, fairness, and bias have quickly become watchwords of main-
stream technical research and practice, gaining currency both in
computer science scholarship and in technology companies. And
these concerns are having a public moment, with policymakers and
practitioners newly attuned to their import.
Recently, these concerns have sparked debate about the relation-
ship between computing and social change— in particular, about the
degree to which technical interventions can address fundamental
problems of justice and equity. Scholars have recently raised con-
cerns about taking a computational lens to certain social problems,
questioning whether modifications to automated decision-making
can ever address the structural conditions that relegate certain so-
cial groups to the margins of society [20, 32, 37, 41, 45, 49]. On
these accounts, realizing principles of justice and equity requires
addressing the root social, economic, and political origins of these
problems — not optimizing around them [10, 15, 31, 36, 44, 50, 55,
75, 78, 81, 89, 93].
This debate has happened against the backdrop of a long his-
tory of critical reflection on the values embodied in technical ar-
tifacts, and the need to design with such values in mind. Scholars
have spent decades working to draw attention to the normative
commitments expressed in and through technology. This call for
recognition of values has been a core project of science and tech-
nology studies [7, 59, 94], Values-in-Design [42, 58], legal scholar-
ship [28, 68, 85], and allied disciplines for years, and remains an
active area of research. Algorithms have become objects of particu-
lar scrutiny over the past decade [48].
Within computer science, the machine learning and mechanism
design communities have been particularly active in taking up these
concerns. Both fields have been heeding the call for attention to
values, politics, and “social good” more generally, holding more
than twenty technical workshops and conferences between them
on some variation of fairness, bias, discrimination, accountability,
and transparency in the last five years (e.g., [2, 40]).
And yet, these recent efforts have been met with concern that
computer science has failed to target the right point of intervention.
In focusing on changes to decision-making and allocation, these
endeavors risk obscuring the background conditions that sustain
injustices. For instance, a computational intervention that aims to
equalize offers of college admission across demographic groups
might function as a less ambitious substitute for the deeper and
more challenging work of improving high school instruction in low-
income neighborhoods. Similarly, an intervention at the selection
phase in an employment context might mask the impact of a hostile
workplace culture or other barriers to long-term employee suc-
cess — problems for which other (and perhaps non-technological)
responses might be indicated [11].
There is a long-standing tension between strategies that seek to
intervene incrementally within the contours of an existing social
and political system and those that seek more wholesale social and
political reform. Existing work has made clear how computational
approaches may contribute to the former style of intervention. Here,
we ask whether, and to what extent, computing can contribute to
the latter style as well. We pose this question while recognizing the
critical scholarship we have described above, and we emphatically
reject the idea that technological interventions can unilaterally
“solve” injustice in society — an approach some critics condemn as
“solutionism” [73]. Our goal is to cut a path between solutionist and
critical perspectives by describing potential roles through which
computing work can support, rather than supplant, other ways of
understanding and addressing social problems.
Meaningful advancement toward social change is always the
work of many hands. We explore where and how technical ap-
proaches might be part of the solution, and how we might exploit
their unique properties as a route to broader reforms. In this way,
we seek to address two distinct audiences: this paper is a call to
our colleagues in computer science to reflect on how we go about
our work in this area, as well as a response to our fellow critical
scholars who question computing’s value in addressing social prob-
lems. In what follows, we propose a series of four potential roles
for computing research that may be well-aligned with efforts for
broader social change.1
The roles we offer here are intentionally modest: they are ways
to leverage the particular attributes of computational work without
overclaiming its capacity. We argue that these are worthy and
plausible aspirations for our nascent field. Our list is illustrative,
not exhaustive, and our categories are not mutually exclusive. And
like any attempt to effectuate change, the approaches we outline
carry hazards of their own, which we also explore below.2

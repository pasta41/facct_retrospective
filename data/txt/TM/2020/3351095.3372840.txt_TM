
Although computer scientists are eager to help address social prob-
lems, the eld faces a growing awareness thatmanywell-intentioned
applications of algorithms in social contexts have led to signi cant
harm. We argue that addressing this gap between the eld’s desire
to do good and the harmful impacts of many of its interventions
requires looking to the epistemic and methodological underpin-
nings of algorithms.We diagnose the dominant mode of algorithmic
reasoning as “algorithmic formalism” and describe how formalist
orientations lead to harmful algorithmic interventions. Addressing
these harms requires pursuing a new mode of algorithmic thinking
that is attentive to the internal limits of algorithms and to the social
concerns that fall beyond the bounds of algorithmic formalism. To
understand what a methodological evolution beyond formalism
looks like and what it may achieve, we turn to the twentieth cen-
tury evolution in American legal thought from legal formalism to
legal realism. Drawing on the lessons of legal realism, we propose
a new mode of algorithmic thinking—“algorithmic realism”—that
provides tools for computer scientists to account for the realities
of social life and of algorithmic impacts. These realist approaches,
although not foolproof, will better equip computer scientists to
reduce algorithmic harms and to reason well about doing good.
CCS CONCEPTS
•Theory of computation→Design and analysis of algorithms;
• Applied computing → Law, social and behavioral sciences.
KEYWORDS
algorithms, law, STS, critical algorithm studies, epistemology
ACM Reference Format:
Ben Green and Salomé Viljoen. 2020. Algorithmic Realism: Expanding the
Boundaries of Algorithmic Thought. In Conference on Fairness, Accountabil-
ity, and Transparency (FAT* ’20), January 27–30, 2020, Barcelona, Spain.ACM,
New York, NY, USA, 13 pages. https://doi.org/10.1145/3351095.3372840
1 INTRODUCTION
Much of the work in computer science labs and technology compa-
nies is motivated by a desire to improve society. Many computer
scientists aim to “change the world” [113] and contribute to “social
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for pro t or commercial advantage and that copies bear this notice and the full citation
on the rst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speci c permission
and/or a fee. Request permissions from permissions@acm.org.
FAT* ’20, January 27–30, 2020, Barcelona, Spain
© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-6936-7/20/02. . . $15.00
https://doi.org/10.1145/3351095.3372840
good” [50], leading to the development of algorithms for use in
courts [5], city governments [53], hospitals [139], schools [154],
and other essential societal institutions. Yet alongside computer sci-
ence’s growing interest in addressing social challenges has come a
recognition—driven by a ected communities and scholarship in sci-
ence, technology, and society (STS) and critical algorithm studies—
that many well-intentioned applications of algorithms have led to
harm. Algorithms can be biased [5], discriminatory [7], dehuman-
izing [107], and violent [66, 111]. They can exclude people from
receiving social services [42, 109], spread hateful ideas [124, 144],
and facilitate government oppression of minorities [89, 103].
Computer science thus faces a gap between its desire to do good
and the harmful impacts of many of its interventions. The challenge
for the eld is how to account for social and political concerns in
order to more reliably achieve its aims. Our goal in this paper is
to engage with this challenge and to elaborate a positive vision of
how computer science can better contribute to society.
To engage in this task, we consider the relationship between
“algorithmic thinking” (how algorithms are canonically taught and
understood) and “algorithmic interventions” (how algorithms are
deployed to address social problems). We are speci cally interested
in interrogating the in uence of “algorithmic thinking” on “algo-
rithmic interventions,” and focus on the application of optimization
and machine learning algorithms. The divergent meanings of “algo-
rithms” within critical discourse and computer science [37] re ects
the di erences between algorithms in theory and the “algorithmic
systems—intricate, dynamic arrangements of people and code”—
that exist in practice [134]. Understanding the relationship between
these two notions of algorithms thus requires approaching algo-
rithms as “‘multiples’—unstable objects that are enacted through
the varied practices that people use to engage with them” [133].
Algorithmic thinking can be understood as a mode of reason-
ing: it shapes how computer scientists see the world, understand
problems, and develop solutions to those problems. Like all method-
ologies, algorithmics relies on de ning the bounds of its analysis.
Considerations that fall within a method’s analytic boundaries are
the subject of “sharp focus” [131]—but when aspects of the world
fall outside these boundaries, a method “has no hope of discovering
these truths, since it has no means of representing them” [4]. Thus,
as computer science increasingly engages with social and political
contexts, the eld has come up against the limits of algorithmic
thinking: computer science lacks the language and methods to fully
recognize, reason about, and evaluate the social aspects and im-
pacts of algorithmic interventions. In turn, even well-intentioned
algorithmic interventions are at risk of producing social harms.
Enabling computer science to responsibly navigate its social ef-
fects requires several steps: 1) diagnosing the attributes of algorith-
mic thinking and how those attributes lead to harm, 2) evaluating
the potential and limits of current eorts to reform algorithms, 3)
describing how the eld can expand its epistemic and methodologi-
cal boundaries, and 4) articulating the tenets of a computer science
practice that is evolved based on the concerns raised by a ected
communities and disciplines such as STS. This paper takes on each
of these tasks in turn.
First, we argue that many of the harms of algorithmic inter-
ventions derive from the dominant mode of thinking within com-
puter science, which we characterize as “algorithmic formalism.”
Algorithmic formalism involves three key orientations: objectiv-
ity/neutrality, internalism, and universalism. Although often rea-
sonable (even valuable) within the context of traditional algorithmic
work, these orientations can lead to algorithmic interventions that
entrench existing social conditions, narrow the range of possible
reforms, and impose algorithmic logics at the expense of others.
Characterizing these concerns—which draw heavily on STS and
critical algorithm studies—under the banner of formalism provides
a path to evaluating and pursuing potential remedies.
Second, we evaluate the dominant approaches to reducing al-
gorithmic harms, such as e orts to promote algorithmic fairness,
ethics, and various forms of data and model documentation. Such
e orts provide important mechanisms to mitigate certain algorith-
mic harms. Yet these reforms involve incorporating new processes
or metrics into the formal method, and thus do not allow prac-
titioners to transcend formalism itself. Additions of form—most
notably, algorithmic fairness—fail to provide the epistemic and
methodological tools necessary to fully identify and act upon the
social implications of algorithmic work. To solve the chronic fail-
ures of algorithmic formalism, computer scientists need new modes
of reasoning about the social, both as a terrain of intervention and
as an attribute of their own work. This requires an evolution of
algorithmic reasoning, expanding the bounds of what it means to
“think” algorithmically and “do” algorithmic interventions.
Third, we consider a possible path forward. An epistemic and
methodological evolution is a daunting task, and it is not obvious
how such a shift could occur or that it would be productive. With
this in mind, we draw on our characterization of algorithmic for-
malism to explore a parallel to formalism in another eld—law—and
to how legal formalism was addressed with a methodological evolu-
tion toward legal realism. From around 1860 through the beginning
of the twentieth century, American legal thought was characterized
by legal formalism: a project to systematize law around scienti c
and deductive principles. Because this mode of thought adhered to
objective principles but did not consider those principles’ actual
impacts, its application upheld highly unequal social conditions.
These impacts provoked critiques that led to a methodological evo-
lution toward legal realism. Legal realism did not wholly supplant
formalism, but instead provided lawyers and judges with additional
tools to account for the realities of social life and of the law’s im-
pacts. This shift—which expanded the terrain on which law could
be evaluated and debated—suggests both a path toward reforming
computer science and the utility of such a path.
Fourth, drawing on the lessons of legal realism, we propose a
new mode of computer science thinking—“algorithmic realism”—
that responds to the concerns raised by STS and related disciplines.
Compared to algorithmic formalism, algorithmic realism provides
three alternative orientations: a re exive political consciousness, a
porousness that recognizes the complexity and uidity of the social
world, and contextualism. As such, algorithmic realism provides the
epistemic and methodological tools to develop algorithmic inter-
ventions that question unjust social conditions, expand the range of
possible reforms, and account for a wide array of values and goals.
At rst glance the law may seem like an unusual place to look
for inspiration regarding computer science. With a few exceptions
[76, 88], law and computer science are typically seen as in tension,
or subject to opposing logics: technology moves “fast” while law is
“slow,” technology is about “innovation” while law is about “regula-
tion,” and so on. Yet several parallels suggest why this comparison
is apt. Algorithmic interventions operate in a manner akin to legal
ones, often taking the place of (or, more precisely, o ering a partic-
ular technical form of) legal reforms. Like the law, algorithms are
commonly invoked as neutral mechanisms of formalized decision
making. Yet in practice, both are subject to debates regarding the
proper role for discretion, ways to combat discrimination, and de-
terminations of the legitimate bases for decision making. Moreover,
the recent surge of enthusiasm for “public interest technology” ex-
plicitly follows in the footsteps of (and indeed, takes its name from)
a prior movement in legal education [129].
Of course, our goal is not to claim a neat one-to-one correspon-
dence between computer science and law (there certainly are sub-
stantial di erences), but to point to how the lessons of law can
inform computer science. Like computer science, the law involves
training in a methodological practice that structures how its prac-
titioners create and evaluate social interventions. Modes of legal
thought in uence legal interventions in much the same way that
modes of algorithmic thought in uence algorithmic interventions.
Legal scholars have long considered the relationship between the
intended and actual impacts of social interventions. Thus, we see
the parallel to legal formalism/realism as a way to identify a bridge
between the deconstructive critique of algorithmic formalism from
STS and a new mode of computer science practice—algorithmic
realism—that productively engages with these critiques.
Following the history of law, the distinction between algorith-
mic formalism and realism does not re ect a rigid dichotomy: the
evolution toward realism is an expansion of computer science to em-
brace realist orientations alongside formalist ones, not a wholesale
rejection of formalism. It is precisely the formalism of algorithmic
methods that has enabled many of computer science’s most exciting
advances [27, 84, 148]. Algorithmic realism provides complemen-
tary approaches that make sociotechnical considerations legible and
commonplace within computer science thinking. This expanded
epistemic and methodological toolkit can help computer scientists
to address existing problems more fully and to see new questions.
Nor does the distinction between algorithmic formalism and
realism fully characterize the behaviors of computer scientists. In
practice, computer scientists are “diverse and ambivalent charac-
ters” [133] who blend formalist and realist methods, engaging in
“nuanced, contextualized, and re exive practices” [104] as they “con-
tinuously straddle the competing demands of formal abstraction
and empirical contingency” [115]. Some computer science sub elds
(such as CSCW [14]) have long histories of engaging with sociotech-
nical practices, while others (such as FAT*) are actively developing
such methods. We aim to highlight examples of realist-aligned
work to help shift such work from exception to standard practice.
Nonetheless, computer scientists recognize that the insights of STS
and critical algorithm studies fall beyond their own interpretive
frames [100]. Even within the FAT* community, critical evaluations
of the mathematization of fairness suggest the need for further
evolution from formalism towards realism [11, 52, 58, 67, 135].
Of course, a turn toward algorithmic realism would not remedy
or prevent every algorithmic harm. Computer scientists are just one
set of actors within larger sociotechnical systems that include other
people, institutions, policies, and pressures. Algorithmic realism
may do little directly to remedy the harms of algorithms deployed
through discriminatory public policies, by authoritarian regimes,
or under exploitative business models. A great deal of algorithmic
work is also done by people without formal computer science train-
ing. Algorithmic thinking presents a potent site for reform, however.
Computer science plays an inuential role in society, both directly
through the work of developing algorithmic interventions and in-
directly as algorithmic thinking shapes how scholars (both inside
and outside the eld), practitioners, and public o cials conceive
of social challenges and progress [16, 53, 125, 148]. For instance,
various public policies and business practices draw on algorithmic
reasoning as a way to gain legitimacy [53, 112, 156].
Following STS scholars such as Jasano [75] and Winner [149],
we aim to trace a middle path between technological determinism
and social determinism, exploring the ways in which algorithmic ar-
tifacts have politics. We see algorithmic realism not as distinct from
sociotechnical systems, but valuable precisely because it situates
algorithmic interventions within sociotechnical systems. Computer
scientists are not the only or the most important actors within
sociotechnical systems (nor should they be). Yet reforming such
systems requires that computer scientists recognize their position-
ality and reason about what roles they do (and should) have. Thus,
providing computer scientists with the epistemic capacity to nav-
igate the inherent socio-political dimensions of their work is an
essential component of sociotechnical reform.

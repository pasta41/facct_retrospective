
Social media monitoring by law enforcement is becoming com-
monplace, but little is known about what software packages for
it do. Through public records requests, we obtained log files from
the Corvallis (Oregon) Police Department’s use of social media
monitoring software called DigitalStakeout. These log files include
the results of proprietary searches by DigitalStakeout that were
running over a period of 13 months and include 7240 social media
posts. In this paper, we focus on the Tweets logged in this data and
consider the racial and ethnic identity (through manual coding) of
the users that are therein flagged by DigitalStakeout. We observe
differences in the demographics of the users whose Tweets are
flagged by DigitalStakeout compared to the demographics of the
Twitter users in the region, however, our sample size is too small
to determine significance. Further, the demographics of the Twitter
users in the region do not seem to reflect that of the residents of
the region, with an apparent higher representation of Black and
Hispanic people. We also reconstruct the keywords related to a
Narcotics report set up by DigitalStakeout for the Corvallis Police
Department and find that these keywords flag Tweets unrelated to
narcotics or flag Tweets related to marijuana, a drug that is legal
for recreational use in Oregon. Almost all of the keywords have a
common meaning unrelated to narcotics (e.g. broken, snow, hop,
high) that call into question the utility that such a keyword based
search could have to law enforcement.
As social media monitoring is increasingly used for law enforce-
ment purposes, racial biases in surveillance may contribute to ex-
isting racial disparities in law enforcement practices. We are hope-
ful that log files obtainable through public records request will
shed light on the operation of these surveillance tools. There are
challenges in auditing these tools: public records requests may go
unfulfilled even if the data is available, social media platforms may
not provide comparable data for comparison with surveillance data,
demographics can be difficult to ascertain from social media and
Institutional Review Boards may not understand how to weigh the
ethical considerations involved in this type of research. We include
in this paper a discussion of our experience in navigating these
issues.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
FAT* ’20, January 27–30, 2020, Barcelona, Spain
© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-6936-7/20/02. . . $15.00
https://doi.org/10.1145/3351095.3372841
CCS CONCEPTS
• Social and professional topics → Governmental surveil-
lance; Corporate surveillance; Race and ethnicity; • General
and reference → Empirical studies;
KEYWORDS
social media monitoring, surveillance, police, demographics, key-
words, audit
ACM Reference Format:
Glencora Borradaile, Brett Burkhardt, and Alexandria LeClerc. 2020. Whose
Tweets are Surveilled for the Police:, An Audit of a Social-Media Monitoring
Tool via Log Files. InConference on Fairness, Accountability, and Transparency
(FAT* ’20), January 27–30, 2020, Barcelona, Spain. ACM, New York, NY, USA,
14 pages. https://doi.org/10.1145/3351095.3372841
1 INTRODUCTION
Law enforcement use of social media monitoring software has
been in the news for several years, and usually it is not good
news. The ACLU of Northern California reported that MediaSonar,
used by the Fresno Police Department, encouraged police to track
#BlackLivesMatter and related hashtags to identify “threats to pub-
lic safety” [34]. After it was revealed that MediaSonar marketed
itself as a way for police to “avoid the warrant process,” Twitter
cut off the company’s access to their enterprise API [36]. Twitter
also cut SnapTrends’ API access after the release of details of law
enforcement use of their software; SnapTrends closed shop shortly
thereafter [15]. Geofeedia was notably used during the Freddie Gray
uprisings to “arrest [protesters] directly from the crowd” aided by
social media posts and face recognition technology [23]; shortly af-
ter this revelation from the ACLU of Northern California, Facebook,
Twitter and Instagram all revoked API access from Geofeedia [35].
Both SnapTrends and Geofeedia are known to have enabled “un-
dercover” accounts that befriend Facebook super-users in order to
bypass users’ privacy settings [15]. During a trial period of Digital-
Stakeout, an agent of the Oregon Department of Justice searched
for #BlackLivesMatter, discovered that an Oregon DOJ attorney
was tweeting support and wrote a memo describing the posts as
“possible threats towards law enforcement” – the agent who wrote
the memo was later found to be in violation of state law [14].
The usefulness of social media monitoring has been called into
question. Conarck reports that social media monitoring in Jack-
sonville, FL by Geofeedia “included largely protected free-speech
activity and useless miscellanea” [12]. Relevant to the monitoring
of social media in Corvallis, OR, in February 2018, an individual
was arrested for Tweets threatening a shooting on the Oregon
State University’s Corvallis campus. However, the Tweets were not
discovered through surveillance of social media but through an
anonymous tip line [43]. Indeed, our work echoes that of Conarck,
uncovering that DigitalStakeout uses simple keyword search, at
least on the topic of Narcotics, and that almost all the keywords
have benign drug meanings that uncover “useless miscellanea.”
Police increasingly utilize social media. A 2015 survey of over 500
US police departments found that 94% of agencies had used social
media in some capacity—to notify the public, recruit employees,
gather intelligence, manage reputations, or other. The survey found
that 89% of agencies had used social media tools to further criminal
investigations [24]. Further, a 2016 report by the Brennan Center for
Justice identified 151 local and state law enforcement agencies in
the United States that have subscribed to social media monitoring
services. These jurisdictions partner with a variety of private firms
that deliver the monitoring service, including Geofeedia, Media
Sonar, Snaptrends, Dataminr, DigitalStakeout, and Babel Street [40].
What is known about social media monitoring technology is mostly
gleaned from documents obtained through public records requests
but these documents are often limited to marketing and training
materials. Meanwhile, the technologies are proprietary, and details
of the underlying algorithms are unknown.
In this paper, we seek to understand how social media surveil-
lance software may place certain groups of users under undue
scrutiny. Pew Research reports on the racial and ethnic, gender
and age biases across the many social media platforms [1]. Sloan
and Morgan report further demographic differences (in terms of
gender, age, class and language) that exist among Twitter users as
to whether they opt to geotag their tweets [45]. We ask: Do these
biases combine to unduly focus attention on certain users? Does the
software introduce biases that cannot be explained by a disparity
in how different groups use social media? We find that the demo-
graphics of the users whose Tweets are flagged by DigitalStakeout
are representative of the demographics of the Twitter users in the
region, but may not reflect that of the residents of the region, with
an apparent higher representation of Black and Hispanic people.
To understand law enforcement monitoring of social media, we
made public records requests to agencies asking for logs from social
media monitoring tools. We show that it is possible to reverse
engineer the operation of keyword-based social media monitoring
using log files. We also show that we can audit the software [42],
using the limited log files, for potential demographic disparities
from the use of social media monitoring. Because the data size is
small and comes from a single jurisdiction, we are limited in the
scope of questions we can answer. However, this study provides a
proof of concept and highlights areas for future study.
1.1 Overview: From data to defining the
research questions
In the summer of 2017, we sent public records requests to 10 agen-
cies listed by the Brennan Center as having (had) access to Digi-
talStakeout: Allentown Police Department, Alpharetta City Police
Department, Corvallis Police Department, FortWorth Police Depart-
ment, Georgia Bureau of Investigation, Hillsboro County Sheriff’s
Office, Indiana State Police, Oregon State Police, Scottsdale Police
Department, and Yakima Police Department. We chose DigitalStake-
out as a case study because it is a social media monitoring software
package that was not reported to be subject to API restrictions by
social media platforms (as MediaSonar, SnapTrends and Geofeedia
were), is still actively used and had the largest number of listed
subscribing agencies in the Brennan Center report. Initially these
requests were not made with a specific research question in mind,
but more generally seeking to understand the use of social media
monitoring software. As part of the public records request, we asked
for “logs of searches that have been input into DigitalStakeout” and
“debug logs produced by DigitalStakeout.”
Several departments have claimed criminal investigatory ma-
terial exemptions to public records laws (for which we are still
seeking research exemptions to that exemption) and at least two
agencies did not have records to release: Oregon DOJ did not sub-
scribe to DigitalStakeout after their trial run (and now reports a
policy of not subscribing to social media monitoring software) and
the Yakima Police Department reports that their officers did not
use the software and no longer subscribe. The Corvallis Police De-
partment did furnish logs in the form of .csv files which consist of
7240 links to social media posts, with some additional meta-data.
We describe the data in more detail in Section 2.
Upon initial examination of the data, we observed that: more
people of color seemed to be represented in the collected social
media posts than in Corvallis, and the collected social media posts
largely did not seem to be relevant to law enforcement. These
observations lead to the research questions:
(1) Are the demographics of the social media users identified
by DigitalStakeout representative of social media users or of
the target population? (Section 5)
(2) How are the social media posts being identified by Digital-
Stakeout? (Section 6)
At this point, we sought guidance from our IRB on how to re-
sponsibly pursue these questions. We describe our procedure for
demographic coding in Section 3. An analysis of the racial and
ethnic demographics are given in Section 5. A look at the keywords
used to flag social media posts is given in Section 6. We describe
our navigation of the ethical issues of this work in Section 7.
1.
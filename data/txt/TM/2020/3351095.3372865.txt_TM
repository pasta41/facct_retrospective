
In 2015, Delhi Police announced plans for predictive policing. The
Crime Mapping, Analytics and Predictive System (CMAPS) would
be implemented in India’s capital, for live spatial hotspot mapping
of crime, criminal behavior patterns and suspect analysis. Four
years later, there is little known about the effect of CMAPS due
to the lack of public accountability mechanisms and large excep-
tions for law enforcement under India’s Right to Information Act.
Through an ethnographic study of Delhi Police’s data collection
practices, and analysing the institutional and legal reality within
which CMAPS will function, this paper presents one of the first
accounts of smart policing in India. Through our findings and dis-
cussion we show what kinds of biases are present within Delhi
Police’s data collection practices currently and how they translate
and transfer into initiatives like CMAPS. We further discuss what
the biases in CMAPS can teach us about future public sector deploy-
ment of socio-technical systems in India and other global South
geographies. We also offer methodological considerations for study-
ing AI deployments in non-western contexts. We conclude with a
set of recommendations for civil society and social justice actors to
consider when engaging with opaque systems implemented in the
public sector.
CCS CONCEPTS
• Social and professional topics → Governmental regulations;
Race and ethnicity; Cultural characteristics; • Computing method-
ologies → Reasoning about belief and knowledge.
KEYWORDS
Fairness-Aware Machine Learning, Predictive Policing, Interdisci-
plinary, Sociotechnical systems
ACM Reference Format:
Vidushi Marda and Shivangi Narayan. 2020. Data in New Delhi’s Predictive
Policing System. In FAT* ’20: Proceedings of ACM Conference on Fairness,
Accountability, and Transparency, January 27–30, 2020, Barcelona, Spain.
ACM, New York, NY, USA, 8 pages. https://doi.org/10.1145/3351095.3372865
∗Both authors contributed equally to this research.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
FAT* ’20, January 27–30, 2020, Barcelona, Spain
© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-6936-7/20/01. . . $15.00
https://doi.org/10.1145/3351095.3372865
1 INTRODUCTION
As of 2019, law enforcement agencies across India are in the pro-
cess of deploying machine learning systems for crime prevention,
criminal tracking, and better allocation of resources. In Chennai,
one of the major Indian metropolises with a population of 11 mil-
lion, facial recognition systems are deployed in crowded places to
identify criminals and individuals who “look suspicious” [18]. In
the south Indian state of Telangana (estimated population of 40
million) smart law enforcement has come to be deployed with a
view to create a “360 degree view” of citizens [28]. Elsewhere, in the
north Indian state of Punjab (estimated population of 30 million),
the Punjab Artificial Intelligence System received a Smart Policing
Award for its use of facial recognition in crime solving [30]. The Na-
tional Crime Records Bureau of India recently published a tender for
the Automated Face Recognition System which would be used for
“criminal identification, verification and its dissemination among
various police organizations and units across the country” [16]. One
of the first initiatives towards the use of machine learning (ML) in
law enforcement was pioneered by the Delhi Police. For context,
Delhi is a city with a population of close to 30 million people. It is
the national capital, and is also anecdotally referred to as the ‘rape
capital’ of India due to historically high records of violence against
women. This is important to understand to follow the larger safety
discourse in Delhi and why policing interventions of a certain kind
may gain public legitimacy. In 2015, Delhi police announced the
use of the Crime Mapping, Analysis and Mapping System (CMAPS),
a predictive policing system [20] that would access data directly
from the Dial 100 call centre to plot the geographic location of calls
and calculate crime hotspots.
The limitations and dangers of predictive policing have been
studied in jurisdictions like the United States and Europe. It is
well understood that these systems risk over-policing vulnerable
populations [15] and exacerbate problematic institutional biases
[14]. The implementation and quotidian experience of these systems
in the global South (or post-colonial) jurisdictions like India remain
to be studied. It is particularly crucial to study such deployments in
India at this juncture because of the ongoing efforts at wholesale
deployment of various ML technologies in all aspects of public
life in India with little to no meaningful consideration of potential
harms. In this paper, we study the process by which crime hotspot
mapping is currently carried out by Delhi Police, and the existing
infrastructure and data on which CMAPS will be developed. We
zoom in on what the “spatial distribution of crime” entails in New
Delhi, and also investigate the creation, collection and classification
of data. We draw on observational and unstructured interview data
to answer the following questions:
(1) What kinds of biases are present in police data currently,
and how do they arise?
(2) What kinds of social and political assumptions inform these
practices, and how do they find their way into predictive
policing systems like CMAPS?
(3) What can current data practices tell us about future tech
uses within the same institutional reality?
The paper offers four substantial contributions to existing lit-
erature in the field. Firstly, this paper is the first of its kind to
present a study of a predictive policing system from the Global
South. Operationalising findings from previous work by Seaver
[23] and Haraway [8], we analyse daily activities of human, insti-
tutional and societal actors, and situate our analysis of the system
within its local context, drawing from on-the-ground observation
and interviews. Second, we explore the extent and types of biases
that exist within Delhi’s crime hotspot mapping system. A signif-
icant component of studying predictive policing initiatives is to
study the data that trains these systems [6]. However, as Suresh
& Guttag [29] have argued earlier, the phrase “training data bias”
in the context of machine learning applications is too broad to be
useful. We use their framework to bring about a more granular
understanding of how current practices within Delhi Police influ-
ence technical systems like CMAPS. In doing so, we also present
new evidence which can be used to engage with similarly placed
predictive policing systems in India and beyond.
Third, law enforcement’s use of technology for maintaining law
and order is notoriously opaque - from secretive procurement prac-
tices, to deployment that is not subject or amenable to information
requests. Richardson et. al have explored the urgent need for ac-
countability mechanisms within predictive policing systems in the
United States [22]. In the context of New Delhi’s predictive policing
system, the first step towards accountability is peering into the
functioning of the system itself. Currently, the gap between media
coverage of new initiatives in re: law enforcement in India and an
understanding of how, where, when and by who those systems
are actually being used is huge. Our paper aims to bridge that gap.
Fourth, we provide an account of observed biases within policing
institutions and their transfer to technical systems that operate
within these formal structures. Policing is an institution histori-
cally known for its problematic practices, reflected in its data and
systems. By observing the link between historical practice and tech-
nical solutions, we avoid the “ripple effect trap” identified by Selbst
et. al [25] while at the same time demonstrating the importance
of analysing sociotechnical systems in the context that they are
designed, developed and deployed. In the absence of accountability
mechanisms and publicly available data, our research points to the
value in focusing on the institutional and human aspect of machine
learning in the public sector.
This paper proceeds as follows. Section 2 will provide a closer
look at the current status of predictive policing in New Delhi. Sec-
tion 3 describes our methodology for conducting research and field
work. Section 4 provides insights from our field work and walks the
reader through current data practices, Section 5 provides key points
of analysis and Section 6 concludes with reflections, learnings and
recommendations, and Section 7 reflects on limitations and future
research.

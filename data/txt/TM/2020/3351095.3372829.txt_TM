
A growing body of work shows that many problems in fairness,
accountability, transparency, and ethics in machine learning sys-
tems are rooted in decisions surrounding the data collection and
annotation process. In spite of its fundamental nature however, data
collection remains an overlooked part of the machine learning (ML)
pipeline. In this paper, we argue that a new specialization should
be formed within ML that is focused on methodologies for data
collection and annotation: efforts that require institutional frame-
works and procedures. Specifically for sociocultural data, parallels
can be drawn from archives and libraries. Archives are the longest
standing communal effort to gather human information and archive
scholars have already developed the language and procedures to
address and discuss many challenges pertaining to data collection
such as consent, power, inclusivity, transparency, and ethics & pri-
vacy. We discuss these five key approaches in document collection
practices in archives that can inform data collection in sociocultural
ML. By showing data collection practices from another field, we
encourage ML research to be more cognizant and systematic in
data collection and draw from interdisciplinary expertise.
CCS CONCEPTS
• Computing methodologies → Machine learning.
KEYWORDS
datasets, machine learning, ML fairness, data collection, sociocul-
tural data, archives
ACM Reference Format:
Eun Seo Jo and Timnit Gebru. 2020. Lessons from Archives: Strategies
for Collecting Sociocultural Data in Machine Learning. In Conference on
Fairness, Accountability, and Transparency (FAT* ’20), January 27–30, 2020,
Barcelona, Spain. ACM, New York, NY, USA, 11 pages. https://doi.org/10.
1145/3351095.3372829
1 INTRODUCTION
Data composition often determines the outcomes of machine learn-
ing (ML) systems and research. Haphazardly categorizing people in
the data used to train ML models can harm vulnerable groups and
propagate societal biases. Automated tools such as face recognition
software can expose target groups, especially in cases of power
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
FAT* ’20, January 27–30, 2020, Barcelona, Spain
© 2020 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-6936-7/20/01.
https://doi.org/10.1145/3351095.3372829
Figure 1: Article from LIFE magazine (Dec. 1941) with two
images advising identifiable phenotype differences between
Japanese and Chinese ("allies") groups with the intention to
spite Japanese Americans following the Japanese bombing
of Pearl Harbor.
imbalance where select institutions have exclusive access to data
and powerful models. Historically, biological phenotype traits have
been used to single out target groups in moments of public hostility
(Fig. 1), and similar use cases have been reported today with face
recognition technology [20, 44, 48].1 These use cases show the dan-
gers of creating large datasets annotated with people’s phenotypic
traits.
On the other hand, in applications such as automated melanoma
detection from skin images, it is important to have diverse training
data and perform disaggregated testing by various demographic
1©1941 The Picture Collection Inc. All rights reserved. Reprinted/Translated from LIFE
and published with permission of The Picture Collection Inc. Reproduction in any
manner in any language in whole or in part without written permission is prohibited.
LIFE and the LIFE logo are registered trademarks of TI Gotham Inc., used under license.
Table 1: Lessons fromArchives: summaries of approaches in archival and library sciences to some of themost important topics
in data collection, and how they can be applied in the machine learning setting.
Consent (1) Institute data gathering outreach programs to actively collect underrepresented data
(2) Adopt crowdsourcing models that collect open-ended responses from participants and give them options to
denote sensitivity and access
Inclusivity (1) Complement datasets with “Mission Statements” that signal commitment to stated concepts/topics/groups
(2) “Open” data sets to promote ongoing collection following mission statements
Power (1) Form data consortia where data centers of various sizes can share resources and the cost burdens of data
collection and management
Transparency (1) Keep process records of materials added to or selected out of dataset.
(2) Adopt a multi-layer, multi-person data supervision system.
Ethics & Privacy (1) Promote data collection as a full-time, professional career.
(2) Form or integrate existing global/national organizations in instituting standardized codes of ethics/conduct
and procedures to review violations
characteristics to ensure that all groups are accurately diagnosed.
The quest for large, representative datasets can raise questions of
informed consent. Keyes et al. have shown that benchmarks such as
those from theNational Institute of Standards and Technology in the
United States (NIST) consist of data from vulnerable populations
taken without consent [38]. Disaggregated testing also requires
gathering potentially sensitive information, and categorizing people
into various groups based on demographic information (e.g. gender,
age, race, skin type, ethnicity). Many times however, it is unclear
how or whether people should be categorized in the first place.
While it is important to represent people by their preferred means
of representation (e.g. gender identity), other times (such as when
documenting instances of discrimination), it may be important to
categorize them according to how they are perceived by society.
Although the manner in which data is gathered, annotated, and
used in ML has far reaching consequences, data collection has
not been examined with rigor. Holstein et al.’s 2019 summary of
critical needs for fair practice among industry ML practitioners
identifies the lack of an industry-wide standard for “fairness-aware
data collection” as an area for improvement across the field. The
lack of any systematic process for generating datasets has spurred
researchers to call it the “wild west” [28].
Recently, an increased focus has been given to data, especially
in terms of annotating various demographic characteristics for dis-
aggregated testing, gathering representative data, and providing
documentation pertaining to the data gathering and annotation
process [1, 21, 47]. However, this move only addresses part of the
problem. There are still open questions regarding power imbal-
ance, privacy, and other ethical concerns. As researchers uncover
more issues related to ML systems, many have started calling for
an interdisciplinary approach to understanding and tackling these
issues [58]. Likewise, we call on the ML community to take lessons
from other disciplines that have longer histories of addressing sim-
ilar concerns. In particular, we focus on archives, the oldest human
attempt to gather sociocultural data. We outline archives’ parallels
with data collection efforts in ML and inspiration in the language
and institutional approaches for solving these problems in ML. As
archives are institutions dealing primarily with documents and
photographs, these lessons are best applicable to subfields using
unstructured data, such as Natural Language Processing (NLP) and
Computer Vision (CV). Of course, archives are just one example of
a distant field we can learn from among a wide array of fields. By
showing the rigor applied to various aspects of the data collection
and annotation process in archives, an industry of its own, we hope
to convince the ML community that an interdisciplinary subfield
should be formed focused on data gathering, sharing, annotation,
ethics monitoring, and record-keeping processes.
As disciplines primarily concerned with documentation collec-
tion and information categorization, archival studies have come
across many of the issues related to consent, privacy, power im-
balance, and representation among other concerns that the ML
community is now starting to discuss. While ML research has been
conducted using various benchmarks without questioning the bi-
ases in datasets, motives associated with the institutions collecting
them, and how these traits shape downstream tasks, archives have
• an institutional mission statement that defines the concepts
or subgroups to collect data on
• full-time curators responsible for weighing the risks and
benefits of gathering different types of data and theoretical
frameworks for appraising collected data
• codes of conduct/ethics and a professional framework for
enforcing them
• standardized forms of documentation akin to what was pro-
posed in Datasheets for Datasets [21]
In addition, to address issues of representation, inclusivity and
power imbalance, archival sciences have promoted various collec-
tive efforts such as
• community based activism to ensure various cultures are
represented in the manner in which they would like to be
seen (e.g. Mukurtu2)
• data consortia for sharing data across institutions to reduce
cost of labor and infrastructure.
We frame our findings about archival strategies into 5 main
topics of concern in the fair ML community: consent, inclusivity,
power, transparency, and ethics & privacy. Table 1 summarizes the
approaches to these topics in archival studies and how they can be
2mukurtu.org
applied to ML. Our results show that archives have institutional
and procedural structures in place that regulate data collection,
annotation, and preservation that ML can draw from.
The rest of the paper is organized as follows. Section 2 gives
an overview of archives and their relevance to ML. Section 3 dis-
cusses the different levels of supervision in ML and archival data
collection. Section 4 discusses how data collection can be more
“interventionist”. Section 5 presents archival approaches to con-
sent, power, inclusivity, transparency and ethics & privacy and the
lessons we can draw from them. Section 6 enumerates how we
can implement these approaches at societal and individual levels.
Section 7 presents a data collection case study to illustrate how
these concepts can be applied in practice. Section 8 discusses the
limitations of parallels and applications on ML. Section 9 concludes
with open questions and challenges.

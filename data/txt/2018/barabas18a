Interventions over Predictions: Reframing the Ethical Debate for Actuarial Risk Assessment
Proceedings of Machine Learning Research 81:1–15, 2018 Conference on Fairness, Accountability, and Transparency
Chelsea Barabas cbarabas@media.mit.edu
Karthik Dinakar karthik@media.mit.edu
Joichi Ito joi@media.mit.edu
Madars Virza madars@mit.edu
MIT Media Lab, 75 Amherst St. E15-245, Cambridge, MA 02139, United States
Jonathan Zittrain a2jz@law.harvard.edu
Harvard University, Griswold 505, 1525 Massachusetts Avenue, Cambridge, MA 02138, United States
Editors: Sorelle A. Friedler and Christo Wilson
ABSTRACT
Actuarial risk assessments might be unduly
perceived as a neutral way to counteract
implicit bias and increase the fairness of
decisions made at almost every juncture
of the criminal justice system, from pre-
trial release to sentencing, parole and pro-
bation. In recent times these assessments
have come under increased scrutiny, as crit-
ics claim that the statistical techniques
underlying them might reproduce existing
patterns of discrimination and historical bi-
ases that are reflected in the data. Much
of this debate is centered around compet-
ing notions of fairness and predictive accu-
racy, resting on the contested use of vari-
ables that act as “proxies” for character-
istics legally protected against discrimina-
tion, such as race and gender.
We argue that a core ethical debate sur-
rounding the use of regression in risk as-
sessments is not simply one of bias or ac-
curacy. Rather, it’s one of purpose. If ma-
chine learning is operationalized merely in
the service of predicting individual future
crime, then it becomes difficult to break
cycles of criminalization that are driven by
the iatrogenic effects of the criminal jus-
tice system itself. We posit that machine
learning should not be used for prediction,
but rather to surface covariates that are fed
into a causal model for understanding the
social, structural and psychological drivers
of crime. We propose an alternative appli-
cation of machine learning and causal in-
ference away from predicting risk scores to
risk mitigation.
Keywords: causal inference, criminal jus-
tice, interventions, risk assessment tools
1 INTRODUCTION
In 2016, a team of investigative journalists from
ProPublica published an article (Angwin et al.,
2016) claiming that COMPAS, a proprietary risk
assessment tool that has been used in the U.S.
criminal justice system, was racially biased. The
article sparked a national debate about the ex-
panding use of algorithmic decision-making aids
in the courts. This debate is emblematic of a
much broader conversation around the appropri-
ate use of data and statistical methods in soci-
ety, in spheres as varied as health care, hous-
ing, employment and education. For example,
Selbst (Selbst, 2016) cites media debates on con-
sumer finance (Economist, 2017), employment
(Wang, 2017), housing (Biggs, 2016), health care
(Siwicki, 2017), and sentencing (Tashea, 2017).
While these issues are largely framed in terms
of new technology, driven by “big data” or “ar-
tificial intelligence,” the methods and tools in
question are often incremental iterations on much
older actuarial decision-making practices. This
is certainly the case for risk assessments, which
have existed in some form in the U.S. criminal
justice system since the 1920’s.
By placing the current debate around risk as-
sessment in a broader context, we can get a fuller
understanding of the way these actuarial tools
have evolved to achieve a varied set of social and
institutional agendas. The current debate around
risk assessment tends to characterize or implicitly
c© 2018 C. Barabas, K. Dinakar, J. Ito, M. Virza & J. Zittrain.
Interventions over Predictions:Reframing the Ethical Debate for Actuarial Risk Assessment
concede the purpose of these tools as fundamen-
tally predictive in nature. The more significant
power of data-driven risk assessment can be as
a broader diagnostic tool, one used to help prac-
titioners address risk as a dynamic, intervenable
phenomenon. When risk assessments are recast
in this light, we can ask whether or not regres-
sion and machine learning methods can help in
diagnosis and intervention, rather than predic-
tion. We make a case for why causal inference, a
statistical method designed explicitly to establish
a causal connection between a “treatment” and
an outcome of interest, provides a more desirable
framework for developing intervention-driven risk
assessments in the criminal justice system.
2 CURRENT DEBATES ON THE FAIRNESS
OF RISK ASSESSMENTS
Risk assessment tools have been adopted to as-
sist with a number of decision points through-
out the criminal justice system, from pretrial
release to post-conviction sentencing, probation
and parole. In spite of the tools’ growing influ-
ence over judicial or administrative decisions, de-
fendants rarely have an opportunity to probe or
challenge the recommendations the tools gener-
ate. While defendants are supplied with their
end scores, they are typically not entitled to ac-
cess the calculations or input data that were used
to calculate the final tabulation. Critics have
called for increased transparency surrounding the
development and administration of these tools,
arguing that the proprietary interests of assess-
ment developers should not take precedence over
a defendant’s right to due process in the courts
(Wexler, 2017; Angwin et al., 2016; Fennell and
Hall, 1980). In addition to transparency issues
related to proprietary software, a major focus
of recent scholarship has been on developing in-
terpretable machine learning models that enable
outside researchers to better scrutinize the un-
derlying logic of actuarial tools which are based
on machine learning (Zeng et al., 2017; Vellido
et al., 2012).
Others have focused on the particular ethical
challenges that arise during the administration
and interpretation of risk assessments. Although
risk assessments can be perceived – and some-
times marketed – as an objective means of over-
coming human bias in decision making, there
remain many ways that human discretion en-
ters into the formation and interpretation of risk
scores. Ethnographic work has shown that scores
are frequently misapplied and misinterpreted by
judges and practitioners (Hannah-Moffat, 2015).
Moreover, scholars have documented specific
strategies that administrators can use to shade
or manipulate end scores to reflect their precon-
ceptions of offender risk (Hannah-Moffat, 2015;
Hardy, 2014). There have also been multiple doc-
umented instances in which a risk or needs score
has been inappropriately referenced for a deci-
sion it was not intended to inform (for example,
a needs score that was intended to inform pro-
bation decisions being cited in judges’ sentencing
statements) (Wexler, 2017; Angwin et al., 2016).
At least one recent court ruling has emphasized
the importance of providing judges additional in-
formation about the limitations inherent in risk
score predictions (Roggensack, C.J. and Abra-
hamson, J., 2016). Others have called for more
work to be done in order to understand how risk
scores interact with the pre-existing biases and
beliefs of the individuals who rely on them (Fen-
nell and Hall, 1980).
Amidst all these issues, arguably the primary
focus of debate regarding the fairness of risk as-
sessments has centered around the specific meth-
ods and data used to develop statistically valid
predictions. Risk assessment is commonly char-
acterized as a predictive technology, one whose
value is measured by the degree to which they are
more accurate than the fallible human decision
makers they are designed to advise or supplant
(Kleinberg et al., 2017a). This characterization
stems in part from the fact that much of the re-
cent attention on risk assessments has centered
around their appropriate use in pretrial release
decisions (Angwin et al., 2016; Kleinberg et al.,
2017a; Flores et al., 2016).
In contrast to other stages of the criminal jus-
tice process, pretrial release is framed as a narrow
and fundamentally predictive task: risk assess-
ments are used to inform decisions about whom
to detain and whom to release before a trial date.
Increasingly, pretrial risk assessments are being
embraced as part of a larger effort to move away
from a “resource-based” approach of making re-
lease decisions, based on individuals’ ability to
post cash bail, to a “risk-based” approach that
centers on predicting one’s likelihood of engag-
ing in a specific set of undesirable behaviors,
such as failure to appear in court or to engage
in new criminal activity (Foundation, 2016; In-
stitute, 2017).
In this context, some scholars have framed the
value-add of risk assessment strictly in terms of
their ability to make predictions more accurately
than the judges meting out such decisions by
themselves (Kleinberg et al., 2017a). Because the
value-add of risk assessments has been framed
largely in terms of their predictive power, much
of the ethical debate surrounding them has fo-
cused on how to handle various forms of bias
in the face of less-than-accurate tools. Scholars
have identified numerous ways that statistically-
driven methods like machine learning can repro-
duce existing patterns of individual prejudice and
institutionalized bias. These mechanisms corre-
spond with different stages in the model design
process such as identifying the research question,
collecting training data, labeling examples within
the training set, feature selection and double-
encoding bias in proxies for protected classes
(Barocas and Selbst, 2016; Gong, 2016; Angwin
et al., 2016; Starr, 2014; Citron, 2016).
Others have focused specifically on bias in
model outcomes. Critics of risk assessment
have expressed concerns about the distribution of
inter-group inaccuracy in risk models. They em-
phasize the importance of predictive parity as an
explicit goal; that is, the systems we use should
not only be equally accurate, but also have sim-
ilar accuracy rates over all test groups (e.g. dif-
ferent racial groups or genders) to which they are
applied. These researchers have argued that risk
assessments are not that accurate to begin with,
and for the large percentage of outcomes that
is not accurate, disparate impact tends to fall
disproportionately across the population, along
racial lines (Angwin et al., 2016; Citron, 2016).
Yet proponents of risk assessment have ar-
gued that uneven distributions of false positives
and false negatives do not constitute a “biased”
model in a strictly technical sense. These individ-
uals contend that the most important consider-
ation regarding bias is whether or not the prob-
ability estimates provided by the algorithm are
well-calibrated, so that the algorithm performs in
a way that is equally accurate across all groups
(Flores et al., 2016; Skeem et al., 2016)
This debate has led to a broader discussion on
the inherent trade-offs in these competing notions
of fairness. Kleinberg et al. (Kleinberg et al.,
2017b) argue that, in general, no mechanism can
both achieve optimal accuracy, and optimal pre-
dictive parity, unless the base rates for the groups
are equal, or the algorithm in fact achieves per-
fect classification. In their excellent survey Berk.
et al: identify six kinds of fairness, and show that
not only these notions conflict with accuracy, but
also with one another (Berk et al., 2017).
This debate is now evolving to identify specific
trade-offs between things like predictive accuracy
and predictive parity across groups. This makes
sense when we frame the value of risk assessments
strictly in terms of their utility as a predictive
technology, whereby accuracy levels are often in
direct tension with these competing notions of
fairness. However, this framing of the issues es-
chews the fact that risk assessments are rarely
used just for predictive purposes. The majority
of risk assessments in use today are based on a
“risk-needs-responsivity” framework to inform a
broad range of decisions regarding effective pun-
ishment and treatment (Hannah-Moffat, 2005).
Such assessments are, and should be, fundamen-
tally diagnostic in nature, whereby risk is con-
ceptualized as a dynamic phenomenon that can
be lowered through a range of semi-personalized
interventions.
In the criminal justice system, risk assessments
play an integral role in shaping how practition-
ers understand and intervene in the lives of of-
fenders in the service of lowering future crime
rates. We conceptualize risk assessments as part
of an assemblage of practices and tools that give
rise to visibilities, or ways of viewing, individual
offenders and complex phenomena like criminal
behavior (Hardy, 2014). Risk assessments have
evolved over the last several decades to support
a diverse set of institutional goals and processes.
In the following section, we give a brief overview
of how risk assessments have evolved from a tool
used solely for prediction to one that is diagnostic
at its core. We then call into question whether
or not the statistical methods currently underly-
ing risk assessments, namely regression and, to
a limited extent, machine learning, are the ap-
propriate methods to use in the service of this
goal.
3. Risk assessments: predictive or
diagnostic tools?
The evolution of actuarial risk assessment has
been well documented by others, and is fre-
quently broken down into four generations of
tools (Andrews et al., 2006; Harcourt, 2015; Mon-
ahan and Skeem, 2016; Desmarais and Singh,
2013; Hannah-Moffat, 2013). The first genera-
tion of risk assessments emerged in the 1920’s
and were based largely on semi-structured clin-
ical evaluations that were carried out by skilled
professionals as part of an effort to identify reha-
bilitative treatment options for offenders. These
assessments were structured around a standard-
ized set of clinical items, but did not include a
statistical mechanism for validating scores and
decisions (Andrews et al., 2006).
First generation risk assessment tools fell out
of fashion in the 1970’s, as they were widely criti-
cized for being too subjective and having low lev-
els of predictive accuracy (Hannah-Moffat, 2013).
Also during this time, a “nothing works” mind-
set began to supplant the rehabilitative approach
that had dominated the correctional system dur-
ing the first half of the twentieth century (Mau-
rutto and Hannah-Moffat, 2006). In place of
treatment programs, approaches based on inca-
pacitation and other “law and order” measures
became the norm.
A second generation of assessment was opti-
mized and validated for predictive accuracy using
a new statistical method: regression modeling.
Regression modeling is particularly well-suited
for prediction-oriented assessment, because it en-
ables researchers to identify variables that are
predictive of an outcome of interest, without nec-
essarily having to understand why that factor is
significant. To this end, the second generation of
assessment focused almost exclusively on static
historical factors, such as age and criminal his-
tory. Such factors were considered desirable be-
cause they were perceived as both objective and
highly predictive (Maurutto and Hannah-Moffat,
2006). This marked a subtle shift in the values
and goals risk assessments were designed to sup-
port, away from semi-personalized treatment and
towards objective prediction. As a result, risk as-
sessments were reconfigured as a more simplistic
tool that relied heavily on prior criminal history
to predict future outcomes.
These changes marked a significant shift in
the way the justice system understood and re-
sponded to the notion of offender risk. While
earlier tools were designed to facilitate effec-
tive treatment, new statistical assessments were
based on a static notion of risk, one that was not
easily changed through intervention. These as-
sessments gave rise to what some scholars have
dubbed a “new penology,” whereby penal poli-
cies shifted away from rehabilitative interven-
tions to more administrative approaches to pop-
ulation management that rely almost exclusively
on incapacitation to mitigate risk (Feeley and Si-
mon, 1992). As Maurutto and Hannah-Moffat ar-
gue, when assessments pivot towards prediction,
rather than intervention, “risk is conceived of as a
negative strategy that incapacitates and manages
but never produces productive transformations”
(Maurutto and Hannah-Moffat, 2006). Since the
1970s, the shift towards standardized decision-
making and away from individualized treatment
accompanied a sharp increase in incarceration
rates (Harcourt, 2010).
These prediction-oriented risk assessments
were a part of a suite of tools and policies in-
troduced in the 1970’s and 80’s that relied heav-
ily on prior criminal history to predict and sys-
tematize interventions to prevent future crime.
Other policies included state and federal sentenc-
ing guidelines, which were ostensibly designed to
standardize decision making across jurisdictions
and minimize bias in sentencing. A growing body
of scholarship has linked these “colorblind” poli-
cies to trends in mass incarceration and growing
racial disparities in the criminal justice system.
(Van Cleve and Mayes; Schlesinger, 2011; Har-
court, 2015; Hamilton, 2015).
Scholars have argued that prediction-oriented
risk assessments produce a “ratchet effect” on
profiled populations, because they fail to take
into consideration the criminogenic nature of the
criminal justice system itself (Harcourt, 2015;
Hamilton, 2015). Studies have demonstrated di-
minishing returns on the use of incarceration as
a means of lowering crime (Zimring, 2006). In
fact, the ripple effects of incarceration, such as
the weakening of family ties and diminishing em-
ployment opportunities, can exacerbate the like-
lihood of future recidivism at both the individ-
ual and collective level (Cullen et al., 2011; De-
Fina and Hannon, 2010; Mitchell et al., 2017). As
Hamilton has argued, assessments that rely on a
static, prediction-oriented notion of risk can act
as a “self-fulfilling prophecy” that justifies and
widens the net of social control over marginal-
ized populations (Hamilton, 2015). When risk is
constituted as a static phenomenon, it can only
suggest what should not be done (i.e. release),
and gives little insight into what can be done to
improve outcomes (Beck, 1992).
By the 1980’s, critiques of this prediction-
oriented approach started to emerge, heralding
in the next iteration of assessment. Proponents
of evidence-based justice reform argued that risk
assessment should be reconfigured to help in the
effort of reducing the risk of recidivism and low-
ering incarceration rates. Risk assessments were
reframed as a way of effectively identifying and
allotting scarce resources to programs and inter-
ventions that were “proven” to work (Andrews
and Bonta, 2010; Andrews et al., 1990; Cullen
and Genderau, 2001; Etienne, 2009),
To this end, a third generation of actuar-
ial tools integrated factors that were conceived
as “criminogenic needs,” or intervenable factors
that are believed to impact one’s risk of recidi-
vating. These included a more diverse set of in-
puts, such as employment status and history of
substance abuse, which effectively reconstituted
risk as a dynamic phenomenon that could be in-
tervened upon (Andrews et al., 2006). While
many of these dynamic factors held less predic-
tive power than the static attributes included on
second generation tools, these needs factors were
desirable because they enabled criminal justice
practitioners to consider a broader set of treat-
ment options aimed at lowering risk.
Thus, predictive risk and intervenable needs
factors were combined into a hybrid risk/needs
model, one that used regression to identify sta-
tistically significant risk/needs factors. The key
difference between second and third generation
assessments, then, was the incorporation of these
less predictive, but dynamic, risk/needs factors
that could inform the selection of treatment inter-
ventions beyond incapacitation. By the 1990’s,
these efforts were further supplemented by fourth
generation tools that added “responsivity fac-
tors,” such as levels of intelligence, self-esteem,
and psychological disorders, in order to im-
prove response outcomes to treatment (Andrews
and Bonta, 2010). The risk-needs-responsivity
(RNR) framework has reasserted the authority of
a correctional treatment approach, one that en-
visions offenders as individuals capable of reform
through intervention.
Today risk assessments are used for two pri-
mary purposes, which Monahan and Skeem deem
“prediction-oriented” and “reduction-oriented”
approaches to assessment (Monahan and Skeem,
2016). Prediction-oriented assessments are used
to facilitate accurate and efficient prediction of
future recidivism, while reduction-oriented tools
are intended to inform treatment and supervision
plans. In recent years, we’ve seen a resurgence
of public interest in prediction-oriented assess-
ments, particularly at the pretrial stage where
release decisions are viewed as essentially a fore-
casting task. Yet we argue that even pretrial de-
cisions should be characterized as a moment of
intervention, rather than mere prediction. The
push to adopt pretrial assessments, like the Pub-
lic Safety Assessment, is tightly coupled with ef-
forts to eliminate cash bail, which empirical anal-
ysis has demonstrated to be ineffective at low-
ering near-term risks (failure to appear and new
criminal activity) and long-term recidivism rates.
For example, Gupta et.al show that high bail
amounts, which often result in pretrial detention,
drive a rise in long-term recidivism rates (Gupta
et al., 2016).
Bail is an ineffective pretrial intervention that
proponents of risk assessment would like to elim-
inate in the service of achieving better pretrial
outcomes. When framed in this way, the logi-
cal next question is not so much whether or not
judges make more accurate decisions when they
use risk assessments. Rather, we should be ask-
ing whether or not pretrial risk assessments effec-
tively support judges in making better decisions
about whom to release, and under what condi-
tions (i.e. how should the criminal justice sys-
tem intervene in an individual’s life to mitigate
specific, relevant risks). Thus, we argue that the
most socially beneficial use of risk assessments
should be centered around their utility as a di-
agnostic tool, at all stages of the criminal justice
life cycle. This is an important point because it
informs the goals and characteristics we strive to
achieve in the development of a fair and ethical
risk assessment tool.
In recent times, there has been a growing en-
thusiasm around the idea of using machine learn-
ing techniques to enhance the performance of
modern day assessments. However, these meth-
ods run the risk of swinging the trend of assess-
ment back towards prediction, rather than inter-
vention. New statistical techniques like machine
learning have garnered a lot of enthusiasm and, as
Kleinberg et al. have pointed out, this increased
enthusiasm and investment might unduly push
institutions to reframe their goals in a way that
is amenable to machine learning analysis (Klein-
berg et al., 2015).
Similar to regression, machine learning models
are well-suited to the task of identifying corre-
lational relationships across an even wider range
of variables, with the goal being to create assess-
ments that can predict risk with greater accuracy.
While earlier assessments were based on theories
in criminology, data mining enables the surfacing
of new patterns and trends that are “born from
the data,” without necessarily having a theoret-
ical explanation for why they emerge (Kitchin,
2014). As such, machine learning is touted as a
way of helping us identify patterns that we could
not have discovered by ourselves, in the service
of creating more predictive tools.
Yet, diagnostic practices do not map cleanly to
tools that use prediction-oriented methods, such
as regression and machine learning. While the
goals of risk assessment have expanded, the sta-
tistical methods used to identify risks and needs
have remained the same since their introduction
in second generation tools. This regression-based
methodology is ill-suited for the purpose of effec-
tive diagnosis and intervention of criminogenic
needs. When we use regression for intervention,
we run the risk of conflating correlational vari-
ables with causal ones, which gives rise to a range
of challenges.
In the following section, we argue that assess-
ments designed for intervention require a differ-
ent set of statistical techniques, ones that can
identify causal relationships between risk factors
and future crime. We outline key differences be-
tween regression, machine learning and causal in-
ference in order to make the case for moving away
from using regression and machine learning for
intervention-oriented assessment.
4. Regression vs. Machine
Learning vs. Causal Inference
Nothwithstanding the popular discourse on the
ethical use of risk assessments, the vast majority
of these tools do not use new statistical meth-
ods frequently associated with “artificial intelli-
gence,” such as machine learning. They are over-
whelmingly based on regression models. More-
over, the small number of tools that are currently
being developed using machine learning methods
should be characterized as an incremental, rather
than a transformational, innovation in the way
risk assessments have historically worked.
Regression analysis is widely used for purposes
of forecasting future events. The main goal of re-
gression is to identify a set of variables that are
predictive of a given outcome variable. This is
achieved by determining the optimal weights for
a given set of covariates, ones that are best pre-
dictive of the outcome variable of interest. This
is done through processes called model checking
and selection (Gelman, 2007), whereby statisti-
cal tests are run on each covariate to see how
significantly predictive they are of the outcome
variable . Covariates that are identified through
this process are correlational, not causal, of the
outcome variable. For example, prior arrest has
been found to be an important predictor of fu-
ture crime but does not shed light on the causal
drivers of criminal behavior. Regression based
models, while better suited for predicting risk
scores, are not well-equipped to answer causal
questions on interventional covariates. Tacking
on interventional covariates to a list of risk co-
variates and using regression models for risk pre-
diction suffers from three main drawbacks:
First, regression models for risk prediction are
blunt instruments that do not always contextual-
ize risk and intervenable factors specific to differ-
ent subgroups in the data (Greiner, 2008). Crit-
ics have pointed out that criminogenic needs in
risk assessments are treated as “universal,” even
though the theories and data on which they are
validated often skew heavily towards a white,
male population. Very little attention has been
given to validating these models on more diverse
populations, in spite of the fact that there is a
robust body of academic literature that captures
a variety of gendered and racialized pathways to
crime (Belknap, 2014; Chesney-Lind, 1989; Simp-
son, 1989). This has significant implications for
how we understand the predictive and diagnos-
tic potency of risk assessment tools for diverse
populations (Reisig et al., 2006). For example,
scholars have argued that covariates currently in-
cluded in many regression models for risk pre-
diction are limited to a narrow set of andro-
centric theories of criminogenic need, to the ex-
clusion of risk and interventional covariates spe-
cific to female defendants. The decision of which
covariates to add into the regression model is
largely driven by how accurate the model’s pre-
dictions are, not by well-posed questions around
how causal the covariates are, potentially exclud-
ing covariates that are core drivers of criminal
behavior for different subgroups in the popula-
tion. For example, some analyses of the LSI-
R risk assessment tool have shown that the co-
variates used for risk prediction are largely in-
formed by a male offender worldview, ignoring
well-established “pathways to crime” for women
(i.e. childhood sexual abuse, substance addic-
tion, and lack of employment) as a crucial in-
terventional class of covariates specific to women
(Reisig et al., 2006).
Second, the set of factors considered in RNR
assessments are typically constrained to a narrow
set of variables, ones which are amenable to indi-
vidualized treatment plans and are informed by
particular psychological and normative theories
of re-offending (Hannah-Moffat, 2011). Very lit-
tle consideration has been given to broader social
or structural drivers of crime. Indeed, influential
scholars of some of the most widely used risk as-
sessments in use today have explicitly discounted
the relevance of sociological factors, such as eth-
nicity and socioeconomic status, because those
factors are viewed as static and challenging to in-
tervene upon. These researchers claim that it is a
myth to think that the ”roots of crime are buried
deep in structured inequality,” arguing that psy-
chological factors, such as antisocial cognitive
patterns and beliefs, have demonstrated much
stronger statistical significance when it comes
to inter-individual variations in re-arrest within
the defendant population. (Andrews and Bonta,
2010; Prins and Reich, 2017).
Yet, as Prins and Reich have pointed out,
these scholars often conflate ”causes of crime”
with ”causes of individual differences in crime.”
(Prins and Reich, 2017). Such heavy empha-
sis on psycho-social factors may limit our ability
to understand the underlying drivers of criminal
activity at the population level, or ask harder
questions about why we see persistent disparities
in crime and arrest rates across certain popula-
tions and geographies (Prins and Reich, 2017).
As Hannah-Moffat has argued, in RNR assess-
ments an offender’s needs are stripped of their
broader social context, and are framed largely
in terms of poor choices or moral and psycho-
logical deficiencies that can be treated through
“re-education” at the individual level (Hannah-
Moffat, 2011). This approach tends to obfuscate
the significance of underlying factors that are
highly prevalent for the population of interest.
As Prins and Reich argue, if such structural fac-
tors are, ”nearly ubiquitous for individuals who
become involved in the criminal justice system,
we would not expect them to be predictive of
inter-individual variation in arrest” (Prins and
Reich, 2017).
The narrow theoretical focus of risk assess-
ments stems in part from the fact that regression
is ill-suited to test and differentiate competing
models of criminal behavior. This has led to a
fairly narrow conceptualization of criminogenic
need that is limited to attributes which demon-
strate a statistically significant relationship to fu-
ture recidivism rates in a regression model. Other
common sense needs factors for which a statisti-
cally significant relationship could not be estab-
lished, such as mental health, have been excluded
from these models.
Within a regression framework, one might ad-
dress this issue by identifying competing theories
of criminogenic behavior and running two differ-
ent regression models to see which one is more
predictive. But if two different regression models
were estimated using different guiding crimino-
genic theories for different subgroups in the pop-
ulation, one has to contend with the real possi-
bility of the models arriving at different risk pre-
dictions, leaving no principled way to choose the
prediction of one model over another.
Finally, it is challenging to differentiate inter-
mediate outcomes from covariates in a regression
based model sans a causal inference framework
(Greiner, 2008). This is important because with-
out establishing a causal relationship between a
given covariate to the risk of recidivism, we run
the risk of misinterpreting an intermediate out-
come as a causal driver of crime. This is deeply
significant if we are to use risk assessments as
the basis for identifying effective interventions to
address the underlying drivers of crime. Asso-
ciative relationships between covariates used in a
regression model and the outcome variable of in-
terest need not be causal; such covariates might
be misconstrued as an intermediate outcome that
is causal of criminal behavior. Prins and Re-
ich underline this important point by means of
a compelling example using a directed acyclic
graph. They show how intensive policing causes
more re-arrests and anti law-enforcement resent-
ment (“antisocial cognition”) at the same time.
While antisocial cognition might strongly predict
re-arrest, it is not typically a causal driver of re-
arrest. Intervening to tackle antisocial cognition
without addressing the root cause of excessive
and intensive policing will not reduce re-arrests
under such a model - antisocial cognition is itself
caused by increased intensive policing and must
not be misinterpreted as a causal driver of crime.
It is important to distinguish machine learning
from causal inference. Machine learning lever-
ages concepts of pattern recognition, prediction,
abstraction and generalization, while a causal in-
ference framework is based on estimating the ef-
fect of an intervention on a outcome variable of
interest. Machine learning algorithms leverage
the same principles as regression for predicting
an outcome variable, but do so by expanding
the set of covariates for prediction. In machine
learning, one wants to obtain a generalized model
that appropriately fits the data at hand. This
is achieved in machine learning using a variety
of advanced statistical techniques such as kernel
transformations and parameter sweeping, which
enable complex interactions between covariates
to be captured (but not necessarily understood)
for the purposes of increased predictive accuracy.
In a sense, machine learning treats prediction as
sacrosanct – it is not important why a given set
of covariates are predictive, so long as they are.
Machine learning algorithms used for predic-
tion of risk scores should be seen as incremen-
tal extensions of regression-based methods, ones
that will amplify, rather than mitigate, the chal-
lenges we describe above. Though the vast ma-
jority of risk prediction models are based on re-
gression, there has been an increased interest in
using contemporary “supervised” machine learn-
ing methods in this setting. In supervised ma-
chine learning, a given set of covariates, also re-
ferred to as features, are used in a model to pre-
dict the outcome variable of interest. An an-
alyst estimating a model to predict risk scores
has many types of algorithms to choose from.
Many of these algorithms use advanced statistical
methods to transform the space of input features
into a higher order space that is often difficult
to interpret, even by the analyst estimating the
model.
In a supervised machine learning driven pre-
diction setting, the principal focus is on achieving
reliable and accurate prediction. The question of
what constitutes the input space of features is
secondary to achieving the best predictions pos-
sible. Often a machine learning engineer will sim-
ply add or remove individual features, reestimate
a new model with the changed feature spaces and
check for the predictive performance of the model
(James, 2013). There is often no other ratio-
nale given for including and excluding individual
features. Similar to regression, the set of input
features are merely correlational and not causal
of the outcome variable. Recent work on inter-
pretable supervised learning algorithms for risk
score prediction in the criminal justice system at-
tempts to explain the logic used by the model in
computing the risk for a new defendant, but this
should be seen as incremental to current prac-
tices, as it fails to answer the question of which
features are causal drivers of criminal behavior.
Furthermore, such a supervised setting, even
with better model interpretability (Zeng et al.,
2017), is not a principled way of determining how
much a given variable needs to change to reduce
the risk of future crime. For example, deter-
mining number of hours of cognitive behavioral
therapy given to incarcerated individuals to ad-
dress their criminogenic psychopathology (a com-
mon intervenable variable) is difficult to compute
using these methods devoid a causal inference
framework. In short, without a causal inference
framework, contemporary supervised learning al-
gorithms used for risk prediction are not useful
for targeted intervention. The increased atten-
tion and excitement around machine learning and
artificial intelligence, coupled with the advanced
statistical techniques they make use of has given
them the veneer of appearing “scientific,” accom-
panied by descriptive language that often subtly
connotes causality, when in reality these models
do not even broach causality.
5. Towards a Causal Framework for
Risk Assessment
In contrast to regression and machine learning,
statistical causal inference (Imbens, 2015) is a
framework that is used to establish causal re-
lationships between covariates and the outcome
variable of interest. This is achieved through the
design of experimental conditions in which co-
variates are altered systematically to see if the
alteration produces effect changes in the outcome
variable. The key difference between causal infer-
ence and regression-like methods is the ability for
one to change values of a covariate for the pur-
pose of examining whether it causes the outcome
variable. Causal inference is best suited for the
design of interventions that reduce the risk of fu-
ture crime.
Yet regression, and to a limited extent predic-
tive machine learning, dominate the landscape
of risk assessments used for both prediction and
intervention. This gives rise to a series of chal-
lenges that limit the justice’s systems ability to
effectively intervene to lower the risk of recidi-
vism. A causal inference experiment produces
new data to be analyzed for the purpose of es-
tablishing causality, but in regression and ma-
chine learning, one is limited to historical data
that has already been captured, potentially ex-
cluding important variables crucial for effective
intervention.
Unlike regression and predictive supervised
machine learning models, a causal inference
framework is better suited to answer questions of
“what interventions work” in the criminal justice
system, particularly those aimed at decreasing
well-specified risks, such as recidivism and fail-
ure to appear in court. For example consider the
potential outcomes causal inference framework.
In this approach causality is inferred by ran-
domly assigning individuals or groups, referred to
as units, to an intervention or treatment. Each
unit subjected to a treatment may realize an out-
come of interest, and upon receiving no treatment
may realize an alternate outcome, also known as
the counter-factual. Randomly assigning units to
both the treatment and the control and compar-
ing the potential outcome after the application
of treatment and control gives a measure of the
causal effect of the chosen intervention.
When performed under an experimental set-
ting, this is known as a randomized control
trial (RCT) and is considered the gold stan-
dard for measuring the causal effects of a
given treatment, under a set of conditions for
a defined unit (Imbens, 2015). For example,
a randomized-controlled trial in Philadelphia
found that community-based low intensity su-
pervision program of low-risk offenders was more
effective than high-intensity law-enforcement su-
pervision in reducing new criminal activity of the
offenders (Barnes et al., 2010).
In the criminal justice system it may not al-
ways be possible to practically obtain a potential
outcome for both the treatment and the control
of the same unit. Beyond technical challenges
with the data, researchers may encounter resis-
tance from the legal profession, which has been
reticent to adopt rigorous empirical methods to
infer the effectiveness of interventions in the
criminal justice system. Greiner and Matthews
(Greiner and Matthews, 2016) point to the fact
that the first RCT’s in the medical and legal fields
were conducted around the same time, in the
early 1930s. Yet today, the legal field overwhelm-
ingly lags medical research in the use of scientific
causal methods to evaluate the effectiveness of
interventions.
Causal inference in cases where it is not pos-
sible to do an RCT is usually derived from ap-
plying the same concepts to observational data,
with donor pooling and other matching methods
to fill the counter-factual values for each unit
based on identifying similar units receiving the
two different interventions (Rubin, 2006). For
example, a recent observational study evaluated
the effectiveness of different forms of electronic
monitoring (EM) technologies for released defen-
dants in the state of Florida. Using propensity-
score matching to group unit (defendant) covari-
ates, the study found that while EM reduced new
criminal activity (NCA) across all demographics,
the decrease was the lowest for violent offenders
(Bales et al., 2010). In addition, electronic mon-
itoring was found to reduce NCA more than the
use of global-positioning system (GPS) monitor-
ing.
The potential outcomes model offers sev-
eral structural advantages over regression-based
methods for evaluating which interventions work
in the criminal justice system (Greiner, 2008).
First, one is able to measure the impact of
timing and duration of the applied intervention
in a causal inference framework, an advantage
severely lacking in regression-based methods. For
example, given the limited resources for behav-
ioral therapy in correctional settings, research
has shown that the timing of the initiation of be-
havioral therapy has an effect not only on prison
conduct of defendants, but also on the risk of re-
cidivism. In the potential outcomes framework,
a randomized experiment can test when it might
be a good time to initiate behavioral therapy as
an intervention (Duwe, 2017).
Second, random assignment of units to treat-
ments ensures a “balance” of the covariates,
thereby isolating the applied treatment as the
causal driver (or not). Third, causal inference
insists that the analyst carefully separates covari-
ates that are not impacted by the treatment from
intermediate outcomes that are indeed impacted
by the treatment. This has serious implications
for using risk assessments as a diagnostic tool,
especially for high-risk groups whose risk stems
from structural inequality.
This doesn’t mean that there is no room for
machine learning in the development of diagnos-
tic risk assessments. Unsupervised and semi-
supervised machine learning algorithms are well
suited for surfacing important causal questions
regarding highly correlational covariates. Such
causal inference questions are much better ad-
dressed by either performing inference on obser-
vational data, or even better, the design of a ran-
domized experiment when possible. For example,
Kim and Duwe show (Duwe and Kim, 2016) how
supervised machine learning models outperform
classical regression models for predicting recidi-
vism. Yet, these models are difficult to inter-
pret, even though they yield more accurate pre-
dictions. Rather than using machine learning for
prediction, these methods could be used to iden-
tify features that are highly predictive of recidi-
vism, in order to inform hypotheses on interven-
tions (and their timing) that can then be tested
using causal inference.
6. Implications and Conclusion
In recent times, predictive risk assessments have
garnered unprecedented interest, as individuals
from across the political spectrum seek to achieve
a diverse set of criminal justice reforms with
the help of data-driven actuarial tools. The
promise of these tools is frequently characterized
in terms of the affordances they offer with regard
to cutting-edge technological advances in predic-
tive data analysis, in fields such as machine learn-
ing. Risk assessments have been sold as an inno-
vative means of achieving efficiency, neutrality,
and fairness in a system that has been plagued
by the implicit bias of individual decision mak-
ers (i.e. judges) and flawed organizational risk
mitigation practices (i.e. money-bail) (Institute,
2017).
However, the reality is that most risk assess-
ments in use today are built using statistical
methods that are based on regression. Little has
changed since the 1970’s when the first statis-
tically validated actuarial tools were built using
regression algorithms. Even in instances where
new methods commonly associated with “artifi-
cial intelligence” are being developed for risk as-
sessments, these innovations are really incremen-
tal extensions of prior statistical methods used
for forecasting future criminal events.
Risk assessment has a long and rich history in
the criminal justice system. Yet, in current de-
bates surrounding the ethical use of these tools,
this larger historical context is often lost. Fair-
ness debates surrounding risk assessment end up
in conceptual cul-de-sacs, whereby trade-offs re-
garding things like “accuracy equity” and “pre-
dictive parity” are weighed in lieu of asking
deeper questions about what the purpose of these
tools is and should be in the first place (Flores
et al., 2016; Kleinberg et al., 2017b; Gong, 2016).
Those deeper questions include asking how ac-
tuarial tools might support or undermine crime
prevention interventions.
We argue that when risk assessments are used
primarily as a predictive technology, they fuel
harmful trends towards mass incarceration and
growing inequality in the justice system. Pre-
dictive risk assessments offer little guidance on
how to effectively intervene to lower risk. When
predictive accuracy is the primary metric along
which these technologies are evaluated, the sys-
tem misses opportunities to explore a deeper set
of questions surrounding the way its administra-
tors can use data as part of a reflexive practice
of testing hypotheses in the service of achieving
near and long term goals.
We argue for a shift away from predictive tech-
nologies, towards diagnostic methods that will
help us to understand the criminogenic effects of
the criminal justice system itself, as well as eval-
uate the effectiveness of interventions designed
to interrupt cycles of crime. In contrast to the
current emphasis on machine learning techniques
that offer no grounded way of understanding
the underlying drivers of crime, these methods
should be based in a more rigorous approach
that incorporates both qualitative and quantita-
tive data analysis.
To this end, we argue that risk assessments
should be conceived of as a diagnostic tool that
can be used to understand the underlying social,
economic and psychological drivers of crime. We
posit that causal inference offers the best frame-
work for pursuing these goals. More work should
be done to examine how these quantitative meth-
ods might be supplemented by more qualita-
tive practices of knowledge production. For ex-
ample, Paluck argues that ethnographic meth-
ods can enable researchers to move beyond aver-
age treatment effects, to more deeply understand
the underlying mechanisms of a causal effect via
causal inference (Paluck, 2010). Moreover, Elish
and boyd have pointed out that quantitative re-
searchers would benefit immensely from the rich
frameworks for reflexivity found in more quali-
tative data practices, such as ethnography (Elish
and danah boyd, 2017). This is of paramount im-
portance for data applications in the criminal jus-
tice system, where researchers should constantly
re-examine the way their research practices might
influence and warp the outcomes of their work.
Though causal inference through randomized
experiments has been touted as the gold stan-
dard for evaluating criminogenic interventions,
their practical application is much more sparse
(Weisburd, 2000; Greiner and Matthews, 2016).
A large scale survey of intervention evaluations
in the US criminal justice system found that only
16% of all interventions were evaluated using ran-
domized experiments (Sherman, 2006). Random-
ized experiments to infer causal relationships be-
tween interventions and recidivism are seen as
difficult to implement in practice, given resource
constraints in correctional facilities. Others have
raised ethical challenges around subjecting a vul-
nerable population to a control arm of a random-
ized experiment (Weisburd, 2000). These con-
cerns and challenges mirror challenges in medi-
cal research, where the testing of medical devices,
drugs and therapies can often have life and death
implications. Yet, there are well-established and
mature frameworks on ethical experimentation
and causal inference in clinical medicine. It is
inconceivable today to imagine the introduction
of a new drug without RCTs – the Food and
Drug Administration mandates a framework for
furnishing evidence of a new drug’s effectiveness
in four phases. Guidelines and rules for ethical
experimentation on patients from funding bod-
ies such as the National Institutes of Health,
combined with Institutional Review Board (IRB)
oversight at host institutions are the norm for
causal inference in medical research. Scholars
such as Greiner (Greiner and Matthews, 2016)
have cast the lack of causal inference in the law
as a problem of political will.
In the criminal justice system, many new in-
terventions, such as the timing, type and doses
of psychological therapy both within and out-
side of correctional facilities can be tested using
randomized experiments. In cases where a ran-
domized experiment is either not feasible or is
ethically fraught with serious potential risks, de-
riving causal inference from observational data
should be considered (Greiner, 2008). There is
a growing body of work that deploys observa-
tional methods in the field of criminal justice.
For instance, Dobbie, Goldin and Yang show
via quasi-experimental observational study de-
sign that pretrial detention weakens defendant’s
bargaining position in plea negotiations and a
conviction also reduces their future participation
in the the formal labor market (Dobbie et al.,
2016). Just in the last year, four other obser-
vational causal inference studies exploring the
downstream consequences of pretrial detention
were released (Gupta et al., 2016; Heaton et al.,
2017; Leslie and Pope, 2016; Stevenson, 2016).
In addition, Lum and Yang (Lum and Yang,
2005) have highlighted structural challenges that
also hamper the use of causal inference studies,
such as the lack of early mentorship available for
empirical criminology analysts interested in us-
ing these methods, as well as a shift of research
funding away from randomized experiments to
quick statistical analysis. The relative ease with
which most regression and supervised prediction
algorithms can be estimated makes them all the
more convenient to use. It’s no surprise that ma-
chine learning has gained momentum over causal
inference, at a time when convenience is com-
bined with the growing hype around the use of
machine learning to solve some of our most in-
tractable social problems. Nevertheless, careful
design of a causal inference setup, both experi-
mental and observational, offer significant bene-
fits for the process of discovering and validating
criminogenic interventions.
Data-driven tools provide an immense oppor-
tunity for us to pursue goals of fair punishment
and future crime prevention. But this requires
us to move away from merely tacking on inter-
venable variables to risk covariates for predic-
tive models, and towards the use of empirically-
grounded tools to help understand and respond
to the underlying drivers of crime, both individ-
ually and systemically.
Acknowledgments
The research leading to these results has received
funding from the Ethics and Governance of Arti-
ficial Intelligence Fund.
References**

D A Andrews, James Bonta, and R D
Hoge. Classification for effective rehabilitation.
Criminal Justice and Behavior, 17(1):19–52,
1990. doi: 10.1177/0093854890017001004.**

D A Andrews, James Bonta, and J Stephen
Wormith. The recent past and near future
of risk and/or need assessment. Crime &
Delinquency, 52(1):7–27, 2006. doi: 10.1177/
0011128705281756.**

D A Andrews and J Bonta. The Psychol-
ogy of Criminal Conduct. Anderson Publish-
ing. Lexis Nexis/Anderson Pub., 2010. ISBN
9781422463291.**

Julia Angwin, Jeff Larson, Surya Mattu, and
Lauren Kirchner. Machine bias: There’s soft-
ware used across the country to predict future
criminals. and it’s biased against blacks. ProP-
ublica, 2016.**

William Bales, Karen Mann, Thomas Blomberg,
Gerry Gaes, Kelle Barrick, Karla Dhungana,
and Brian McManus. Quantitative and qual-
itative assessment of electronic monitoring.
2010.**

Geoffrey C Barnes, Lindsay Ahlman, Charlotte
Gill, Lawrence W Sherman, Ellen Kurtz, and
Robert Malvestuto. Low-intensity community
supervision for low-risk offenders: a random-
ized, controlled trial. Journal of Experimental
Criminology, 6(2):159–189, 2010.**

Solon Barocas and Andrew D Selbst. Big data’s
disparate impact. California Law Review, 104,
2016. doi: 10.15779/Z38BG31.**

Ulrich Beck. Risk Society: Towards a New
Modernity. SAGE Publications Ltd, 1992.**

J Belknap. The Invisible Woman: Gender,
Crime, and Justice. Cengage Learning, 2014. ISBN 9781305175730.**

Richard Berk, Hoda Heidari, Shahin Jabbari,
Michael Kearns, and Aaron Roth. Fairness in
criminal justice risk assessments: The state of
the art. Working Paper 2017-1.0, University
of Pennsylvania, Department of Criminology,
2017. URL https://arxiv.org/abs/1703.
09207.**

John Biggs. Naborly lets landlords screen
tenants automagically, 2016. URL https:
//techcrunch.com/2016/08/15/naborly-
lets-landlords-screen-tenants-
automagically/.**

Meda Chesney-Lind. Girls’ crime and woman’s
place: Toward a feminist model of female delin-
quency. Crime & Delinquency, 35(1):5–29,
1989. doi: 10.1177/0011128789035001002.**

Danielle Citron. (un)fairness of risk scores
in criminal sentencing, 2016. URL https:
//www.forbes.com/sites/daniellecitron/
2016/07/13/unfairness-of-risk-scores-
in-criminal-sentencing/.**

Francis T Cullen and Paul Genderau. From
nothing works to what works: Changing pro-
fessional ideology in the 21st century. The
Prison Journal, 81(3):313–338, 2001. doi:
10.1177/0032885501081003002.**

Francis T Cullen, Cheryl Lero Jonson, and
Daniel S Nagin. Prisons do not reduce re-
cidivism. The Prison Journal, 91(3):48S–65S,
2011. doi: 10.1177/0032885511415224.**

Robert DeFina and Lance Hannon. For incapac-
itation, there is no time like the present: The
lagged effects of prisoner reentry on property
and violent crime rates. Social Science Re-
search, 39(6):1004–1014, 2010. doi: 10.1016/
j.ssresearch.2010.08.001.**

Sarah L Desmarais and Jay P Singh. Risk
assessment instruments validated and imple-
mented in correctional settings in the united
states. Technical report, The Council of State
Governments Justice Center, 2013.**

Will Dobbie, Jacob Goldin, and Crystal Yang.
The effects of pre-trial detention on conviction,
future crime, and employment: Evidence from
randomly assigned judges. Technical report,
National Bureau of Economic Research, 2016.**

Grant Duwe. Timing and sequence of cor-
rectional programming, 2017. URL http:
//www.crj.org/assets/2017/09/Timing-
and-Sequencing-of-Correctional-
Programming-Duwe.pdf.**

Grant Duwe and KiDeuk Kim. Sacrificing ac-
curacy for transparency in recidivism risk as-
sessment: The impact of classification method
on predictive performance. Corrections, 1(3):
155–176, 2016. doi: 10.1080/23774657.2016.
1178083.**

The Economist. Machine-learning promises
to shake up large swathes of finance,
2017. URL https://www.economist.com/
news/finance-and-economics/21722685-
fields-trading-credit-assessment-
fraud-prevention-machine-learning.**

M C Elish and danah boyd. Situating meth-
ods in the magic of big data and ai. Com-
munication Monographs, 0(0):1–24, 2017. doi:
10.1080/03637751.2017.1375130.**

Margareth Etienne. Legal and practical implica-
tions of evidence-based sentencing by judges.
Chapman Journal of Criminal Justice, 1:43–
60, 2009.**

Malcolm M Feeley and Jonathan Simon.
The new penology: Notes on the emerging
strategy of corrections and its implica-
tions. Criminology, 30:449–475, 1992. URL
http://scholarship.law.berkeley.edu/
facpubs/718/.**

Stephen A Fennell and William N Hall. Due
process at sentencing: An empirical and legal
analysis of the disclosure of presentence reports
in federal courts. Harvard Law Review, 93(8):
1613–1697, 1980. ISSN 0017811X.**

Anthony W Flores, Kristin Bechtel, and
Christopher T Lowenkamp. False positives,
false negatives, and false analyses: A rejoinder
to “machine bias: There’s software used across
the country to predict future criminals. and
it’s biased against blacks.”. Federal Probation
Journal, pages 38–46, September 2016. URL
http://www.uscourts.gov/statistics-
reports/publications/federal-
probation-journal/federal-probation-
journal-september-2016.**

Arnold Foundation. Results from the first six
months of the public safety assessmentcourt in
kentucky. Report, 2016.**

Andrew Gelman. Data analysis using regression
and multilevel/hierarchical models. Cambridge
University Press, Cambridge New York, 2007.
ISBN 978-0521686891.**

Abe Gong. Ethics for powerful algo-
rithms (2 of 4), July 2016. URL
https://medium.com/@AbeGong/ethics-
for-powerful-algorithms-2-of-3-
5bf750ce4c54.**

D James Greiner. Causal inference in civil rights
litigation. Harvard Law Review, 122(2):533–
598, 2008.**

D James Greiner and Andrea Matthews. Ran-
domized control trials in the united states legal
profession. Annual Review of Law and Social
Science, 12:295–312, 2016.**

Arpit Gupta, Christopher Hansman, and Ethan
Frenchman. The heavy costs of high bail: Evi-
dence from judge randomization. The Journal
of Legal Studies, 45(2):471–505, 2016.**

Melissa Hamilton. Back to the future: The
influence of criminal history on risk assess-
ment. Berkeley Journal of Criminal Law, 2015.
Forthcoming; SSRN ID: 2555878.**

Kelly Hannah-Moffat. Criminogenic needs and
the transformative risk subject: Hybridiza-
tions of risk/need in penality. Punishment &
Society, 7(1):29–51, 2005.**

Kelly Hannah-Moffat. Sacrosanct or flawed:
Risk, accountability and gender-responsive pe-
nal politics. Current Issues in Criminal Jus-
tice, 22:193–215, March 2011.**

Kelly Hannah-Moffat. Actuarial sentencing: An
“unsettled” proposition. Justice Quarterly, 30
(2):270–296, 2013. doi: 10.1080/07418825.
2012.682603.**

Kelly Hannah-Moffat. The uncertainties of risk
assessment: Partiality, transparency, and just
decisions. Federal Sentencing Reporter, 27(4):
244–247, April 2015. doi: 10.1525/fsr.2015.27.
4.244.**

Bernard E Harcourt. Risk as a proxy for race.
2010.**

Bernard E. Harcourt. Risk as a proxy for race:
The dangers of risk assessment. Federal Sen-
tencing Reporter, 27(4):237–243, April 2015.
doi: 10.1525/fsr.2015.27.4.237.**

Mark Hardy. Practitioner perspectives on risk:
Using governmentality to understand contem-
porary probation practice. European Jour-
nal of Criminology, 11(3):303–318, 2014. doi:
10.1177/1477370813495758.**

Paul Heaton, Sandra Mayson, and Megan
Stevenson. The downstream consequences of
misdemeanor pretrial detention. Stan. L. Rev.,
69:711, 2017.**

Guido Imbens. Causal inference for statistics, so-
cial, and biomedical sciences : an introduction.
Cambridge University Press, New York, 2015.
ISBN 978-0521885881.**

Pretrial Justice Institute. Pretrial risk assess-
ments can produce race-neutral results. Re-
port, 2017.**

Gareth James. An introduction to statistical
learning : with applications in R. Springer,
New York, NY, 2013. ISBN 978-1461471370.**

Rob Kitchin. Big data, new epistemologies
and paradigm shifts. Big Data & Society, 1
(1):2053951714528481, 2014. doi: 10.1177/
2053951714528481.**

Jon Kleinberg, Jens Ludwig, Sendhil Mul-
lainathan, and Ziad Obermeyer. Prediction
policy problems. American Economic Review,
105(5):491–95, May 2015. doi: 10.1257/aer.
p20151023.**

Jon Kleinberg, Himabindu Lakkaraju, Jure
Leskovec, Jens Ludwig, and Sendhil Mul-
lainathan. Human decisions and machine pre-
dictions. Working Paper 23180, National Bu-
reau of Economic Research, February 2017a.**

Jon Kleinberg, Sendhil Mullainathan, and Man-
ish Raghavan. Inherent trade-offs in the fair
determination of risk scores. In Proceedings of
the 8th Innovations in Theoretical Computer
Science Conference, ITCS ’17, 2017b.**

Emily Leslie and Nolan G Pope. The unintended
impact of pretrial detention on case outcomes:
Evidence from nyc arraignments. 2016.**

Cynthia Lum and Sue-Ming Yang. Why do eval-
uation researchers in crime and justice choose
non-experimental methods? Journal of Exper-
imental Criminology, 1(2):191–213, 2005.**

Paula Maurutto and Kelly Hannah-Moffat. As-
sembling risk and the restructuring of penal
control. The British Journal of Criminology,
46(3):438–454, 2006. doi: 10.1093/bjc/azi073.**

Ojmarrh Mitchell, Joshua C Cochran, Daniel P
Mears, and William D Bales. Examining
prison effects on recidivism: A regression dis-
continuity approach. Justice Quarterly, 34(4):
571–596, 2017.**

John Monahan and Jennifer L Skeem. Risk
assessment in criminal sentencing. Annual
Review of Clinical Psychology, 12(1):489–513,
2016. doi: 10.1146/annurev-clinpsy-021815-
092945.**

Elizabeth Levy Paluck. The promising integra-
tion of qualitative methods and field experi-
ments. The Annals of the American Academy
of Political and Social Science, 628:59–71,
2010.**

Seth J Prins and Adam Reich. Can we avoid
reductionism in risk reduction? Theoretical
Criminology, page 1362480617707948, 2017.
Michael D. Reisig, Kristy Holtfreter, and Merry
Morash. Assessing recidivism risk across
female pathways to crime. Justice Quar-
terly, 23(3):384–405, 2006. doi: 10.1080/
07418820600869152.**

Roggensack, C J  and Abrahamson, J. State of
wisconsin V Eric L Loomis, July 2016. URL
https://www.wicourts.gov/sc/opinion/
DisplayDocument.pdf?content=pdf&seqNo=
171690.**

Donald B Rubin. Matched sampling for causal
effects. Cambridge University Press, 2006.**

Traci Schlesinger. The failure of race neutral poli-
cies: How mandatory terms and sentencing en-
hancements contribute to mass racialized in-
carceration. Crime & Delinquency, 57(1):56–
81, 2011. doi: 10.1177/0011128708323629.**

Andrew D Selbst. Disparate impact in big data
policing. Georgia Law Review, 2016. Forth-
coming; SSRN ID: 2819182.**

Lawrence Sherman. Evidence-based crime pre-
vention. Routledge, London New York, 2006.
ISBN 978-0415401029.**

Sally S Simpson. Feminist theory, crime, and
justice. Criminology, 27(4):605–632, 1989.
ISSN 1745-9125. doi: 10.1111/j.1745-9125.
1989.tb01048.x.**

Bill Siwicki. Machine learning 101: The
healthcare opportunities are endless, 2017.
URL http://www.healthcareitnews.com/
news/machine-learning-101-healthcare-
opportunities-are-endless.**

Jennifer L Skeem, John Monahan, and Christo-
pher T Lowenkamp. Gender, risk assessment,
and sanctioning: The cost of treating women
like men. Working Paper 10, Virginia Public
Law and Legal Theory Research Paper Series,
2016.**

Sonja B Starr. Evidence-based sentencing and
the scientific rationalization of discrimination.
Stanford Law Review, 66, 2014.**

Megan Stevenson. Distortion of justice: How
the inability to pay bail affects case outcomes.
2016.**

Jason Tashea. Courts are using ai to sentence
criminals. that must stop now, 2017. URL
https://www.wired.com/2017/04/courts-
using-ai-sentence-criminals-must-
stop-now/.**

Nicole Gonzalez Van Cleve and Lauren Mayes.
Criminal justice through “colorblind” lenses:
A call to examine the mutual constitution of
race and criminal justice. Law & Social In-
quiry, 40(2). ISSN 1747-4469.**

Alfredo Vellido, José Mart́ın-Guerrero, and
Paulo J G  Lisboa. Making machine learning
models interpretable. 12:163–172, 01 2012.**

Tammy Wang. How machine learning will
shape the future of hiring, 2017. URL
https://www.linkedin.com/pulse/how-
machine-learning-shape-future-hiring-
tammy-wang.**

David Weisburd. Randomized experiments in
criminal justice policy: Prospects and prob-
lems. NCCD news, 46(2):181–193, 2000.**

Rebecca Wexler. Code of sielnce: How pri-
vate companies hide flaws in the software
that governments use to decide who goes
to prison and who gets out, 2017. URL
http://washingtonmonthly.com/magazine/
junejulyaugust-2017/code-of-silence/.**

Jiaming Zeng, Berk Ustun, and Cynthia Rudin.
Interpretable classification models for recidi-
vism prediction. Journal of the Royal Statis-
tical Society: Series A (Statistics in Society),
180(3):689–722, 2017. ISSN 1467-985X. doi:
10.1111/rssa.12227.**

Franklin E Zimring. The Great American Crime
Decline. Oxford University Press, 2006. doi:
10.1093/acprof:oso/9780195181159.001.0001.

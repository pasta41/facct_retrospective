Biases in Generative Art— A Causal Look from the Lens of Art
History
Ramya Srinivasan
Fujitsu Laboratories of America
Kanji Uchino
Fujitsu Laboratories of America
ABSTRACT
With rapid progress in artificial intelligence (AI), popularity of
generative art has grown substantially. From creating paintings to
generating novel art styles, AI based generative art has showcased a
variety of applications. However, there has been little focus concern-
ing the ethical impacts of AI based generative art. In this work, we
investigate biases in the generative art AI pipeline right from those
that can originate due to improper problem formulation to those
related to algorithm design. Viewing from the lens of art history, we
discuss the socio-cultural impacts of these biases. Leveraging causal
models, we highlight how current methods fall short in modeling
the process of art creation and thus contribute to various types of
biases. We illustrate the same through case studies, in particular
those related to style transfer. To the best of our knowledge, this is
the first extensive analysis that investigates biases in the generative
art AI pipeline from the perspective of art history. We hope our
work sparks interdisciplinary discussions related to accountability
of generative art.
CCS CONCEPTS
• Social and professional topics; •Computingmethodologies
→ Artificial intelligence;
KEYWORDS
generative art, style transfer, biases, AI, socio-cultural impacts
ACM Reference Format:
Ramya Srinivasan and Kanji Uchino. 2021. Biases in Generative Art— A
Causal Look from the Lens of Art History. In . ACM, New York, NY, USA,
11 pages.
1 INTRODUCTION
Generative art refers to art that in part or in whole has been created
by the use of an autonomous system [11]. In a broad sense, the
term “autonomous" can refer to any non-human system that can
determine features of an art work, such as use of smart materials,
mechanical processes, and chemical processes, to name a few. Com-
puter generated art, i.e. art generated by algorithms or computer
programs, is perhaps the most common form of generative art [63].
In fact, the terms "generative art" and "computer art" have been
used more or less interchangeably for a long time now [11, 63].
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
FAccT, March 3–10, 2021, Virtual Event, Canada, ,
© 2021 Association for Computing Machinery.
ACM ISBN ACM ISBN 978-1-4503-8309-7/21/03. . . $15.00
With the rapid advancement of deep learning, there has been
remarkable progress in AI based generative art. From creating hy-
brid images using attributes from multiple images to generating
cartoons from portraits, AI based generative art has exemplified
new and diverse applications [3, 25, 26, 45].
As a consequence, AI based generative art has become extremely
popular. In 2019, “Sotheby" auction house sold an AI generated art
work for 32000 pounds [55]. A little earlier in 2018, the auction
house “Christies" sold an AI generated art work for a staggering
432500 USD [15]. Institutions have also shown an increased interest
towards AI based generative art as evidenced by the number of
museum shows [7, 24]. There are also several apps and tools such as
[3, 20, 37] that have not only enhanced the popularity of AI based
generative art, but have also facilitated ease of use and accessibility
to end-users.
Figure 1: Example of bias in AIportraits app [2]—Skin color of ac-
tress Tessa Thompson (left) is lightened in the app’s portrait rendi-
tion (right), thus exhibiting racial bias. Image source [53].
Amidst this progress and popularity surge, experts across dis-
ciplines have voiced concerns regarding the consequences of gen-
erative art. For example, in [19], the authors reflect on the impact
of interfacing with art autonomously generated by non-human
creative agents. The authors argue that such art could widen the
divide between the human creator and the human audience, and
emphasize on the need to balance between automation and develop-
ment of humans’ creative potentials. Discussing whether computers
can replace human artists, the author in [34] argues that “art re-
quires human intent, inspiration, a desire to express something". The
author further adds that artistic creation is primarily a social act,
and concludes that computers cannot replace humans. In a simi-
lar vein, discussing whether machines can create art, the author
in [16] argues that the process of creating an art work is distinct
from the outcome, i.e. the artwork. Drawing from the theory of
philosophical aesthetics, the author states that when something is
created, something about inner self is expressed.
It has been argued that both art and technology are means
through which humans reveal their epistemic knowledge [42]. Such
knowledge could include societal values, cultures, beliefs, as well
as individual biases and prejudices. In the work [34], artist and
computer scientist Aaron Hertzman states “artworks are created
by a human-defined procedure", and further notes that computer
41
DOI: 10.1145/3442188.3445869
FAccT, March 3–10, 2021, Virtual Event, Canada, , Ramya Srinivasan and Kanji Uchino
Figure 2: Example of bias in learning artists’ styles. The affect con-
veyed by the original image (a) is lost in the “Van Gogh" version (b)
of [70]. This is contrary to Van Gogh’s style, see (c), a real artwork
by Van Gogh depicting red flowers in the field like in (a).
generated art can thus be biased. Even artists like David Young who
argue that machines create art on their own, acknowledge existen-
tial bias in generative art. In the essay Tabula Rasa [67], Young notes
that human biases in the form of preconceptions, irrationalities,
and emotions can easily get embedded into the data used to train
these generative art AI models. A recent notable example of bias
in generative art concerns a portrait generator app called “AIpor-
traits" [2]. It was pointed out that skin color of people of color was
lightened in the app’s portrait rendition [38, 53]. Figure 1 provides
an illustration of the same. Furthermore, AI algorithms are best
thought of as data-fitting procedures [12]. As the author in [34]
beautifully describes, these algorithms are “like tourists in a foreign
country that can repeat and combine phrases from the phrasebook,
but not truly understand the foreign language or culture".
Many types of latent biases in generative art, especially those
concerning art history, have not been analyzed in any of the past
studies. Further, socio-cultural impacts of biases in generative art
have not been investigated. We aim to address these issues in this
work. We motivate the problem with an illustration. Consider an
image-to-image translation model such as CycleGAN [70] which
has been used to create images across different artists’ “styles". Fig-
ure 2 (b) shows an example of “Van Gogh" version of a photograph
(Figure 2(a)) as rendered by the CycleGAN model. As can be seen,
the affect conveyed by the original image is lost in the “Van Gogh"
version: the red flowers, perhaps indicative of Spring are no longer
evident, instead a dry season is reflected.
The generated image seems quite contrary to Van Gogh’s take on
colors. “Green Ears of Wheat", an 1888 art work by Van Gogh serves
as an illustration to the point; see Figure 2 (c) [60]. As documented
in his letters to his sister Wilhelmina and artist Horace M. Livens,
Van Gogh mentions about how he emphasized colors [58], and how
by using bright contrasting colors he was able to infuse life in his
works: “ Poppies or red geraniums in vigorously green leaves - motif
in red and green. These are fundamentals, which one may subdivide
further, and elaborate, but quite enough to show you without the
help of a picture that there are colours which cause each other to
shine brilliantly, which form a couple, which complete each other
like man and woman”, [56, 57]. Thus, by merely using correlation
statistics to model the artist’s style, aspects such as emotion and
intent which are central to an art’s creation [16] are not taken into
account, thereby rendering a biased representation of the artist’s
“style" and also possibly stereotyping the artist in the process.
Such biases could potentially have long standing adverse socio-
cultural impacts. First, because of the inherent biases in training
data and algorithms, generative art could be embedded with racial
bias, gender bias, and other types of discrimination. Second, based
on their limited understanding, algorithms could stereotype artists’
style and not reflect their true cognitive abilities. This means aspects
such as artist’s intent and emotions are overlooked, thus potentially
conveying an opposite affect in the generated art. Third, historical
events and people may be depicted in a manner contrary to the
original times, thus contributing to a bias in understanding history
and thereby get in the way of authentically preserving cultural
heritage (illustrated in Sec. 6). These observations therefore compel
an analysis of generative art so as to uncover various types of biases.
1.1 Contributions
In this paper, we investigate biases in AI based generative art right
from those that can originate due to inappropriate problem formu-
lation to those that can be related to algorithm design. Viewing
from the lens of art history, we discuss the social-cultural impacts
of these biases. We advocate for the use of causal models [48] to
depict potential processes of art creation. We highlight how current
methods can fall short in modeling the process and thus contribute
to various biases such as selection bias and transportability bias
[10]. We illustrate the same through case studies that span various
art movements, artists, art media/material, genres, and geographies.
First, examples of biases that arise due to improper problem
formulation, namely, framing effect biases, are considered (Sec. 4).
After providing a background of causal models (Sec. 5), we discuss
case studies to demonstrate confounding biases in modeling artists’
styles (Sec. 6.1), followed by illustrations of selection bias (Sec. 6.2).
Biases in transferring artists styles, also known as transportability
biases, are discussed (Sec. 6.3). Transportability bias is demonstrated
by considering case studies that include both art movements that
are subtly different (e.g. modern art movements such as Cubism
and Futurism) and art movements across different time periods (e.g.
Modern art and Early Renaissance). Illustrations of biases in datasets
are provided in Sec. 7. A list of the case studies examined in the
paper can be found in Table 1. Our findings shed light on the various
inherent biases in generative art right from problem formulation
and datasets to algorithm design and data analysis. We also discuss
the socio-cultural repercussions of these biases (Sec. 8). To the best
of our knowledge, this is the first extensive analysis that investigates
biases in the generative art AI pipeline from the perspective of art
history. We hope our work triggers interdisciplinary discussions
concerning accountability of generative art, and sparks the design
of novel methods to address these issues.
1.2 Case study selection
We surveyed academic papers, online platforms, and apps that gen-
erate art using AI. In order to uncover potential biases from an art
historical perspective, from the surveyed list, we selected papers
and platforms that focused on simulating established art movements
and/or artists’ styles. Thus, papers such as [25] or platforms such
as [3] which focus on deviating from established styles to create
imaginary patterns are not included in our study. To demonstrate
various biases, we have considered state-of-the-art generative art
AI models [54, 70] and platforms/apps such as [2, 20, 29] that focus
on simulating established art movements and artists’ styles. The art
movements considered as part of case studies have been determined
42
Biases in Generative Art— A Causal Look from the Lens of Art History FAccT, March 3–10, 2021, Virtual Event, Canada, ,
CS Model Bias type Art Movements Artists Genres
1 [70] Confounding bias Post-Impressionism Vincent Van Gogh Landscape
2 [54] Selection bias Romanticism Gustave Dore Illustration
3 [2] Selection bias (racial bias) Renaissance Various artists Portraits
4 [70] Transportability bias Post-Impressionism Paul Cezanne Photo, Landscape
5 [20] Transportability bias Cubism, Futurism Fernand Leger, Gino Severini Genre art, battle painting
6 [20] Transportability bias Realism, Expressionism Mary Cassatt, Ernst Kirchner Portraits
7 [29] Transportability bias Renaissance, Expressionism, Clementine Hunter, Portrait, Sculpture
(racial bias) Folkart Desiderio da Settignano
8 [1] Transportability (gender) bias Renaissance Raphael, Piero di Cosimo Portraits
9 [2] Representational bias Renaissance Various artists Portraits
10 [54] Label bias Ukiyo-e Various artists Various genres
Table 1: Summary of Case Studies (CS) described in the paper. Note, there could be more than one type of bias associated with each CS. For
illustrative purposes, only one bias type is discussed in each CS. Model denotes the algorithm/platform listed under corresponding references.
based on the experimental set-ups reported in these state-of-the-art
AI models and platforms. These include Renaissance art, Modern art
(Cubism, Futurism, Impressionism, Expressionism, Post Impression-
ism and Romanticism), and Ukiyo-e art. It is to be noted that due to
the paucity of existing AI applications that study non-western art
forms, Ukiyo-e is the only non-western art form studied. The genres
span landscapes, portraits, battle paintings, genre art, sketches, and
illustrations. Art material considered includes woodblock prints,
engravings, paint, etc. The study includes artists across cultures
such as Black folk artist Clementine Hunter, American painter Mary
Cassatt, Dutch artist Van Gogh, French illustrator and sculptor Gus-
tave Dore, Italian artist Gino Severini, amongst others. In the next
section, we discuss work related to computer generated art.
2 AI FOR ART GENERATION
Computer generated art has a long history. In 1970’s, painter Harold
Cohen began exhibiting paintings generated by a program called
AARON [34]. By 1980s, several artists were using computer pro-
grams to create interactive experiences for the audience [34]. In
the 1990s, Flash, a tool for creating animations became popular [7].
Around the same time, Paul Haeberli introduced a paint program
whereby a user could quickly create a painting without needing
any technical skill [33]. In 2000s, tools like Processing [14] and
OpenFrameworks [69] allowed artists to make art using code.
As early as 2001, researchers in computer vision were training
computers to learn artists’ styles from examples [35]. Since 2012,
rapid advancement in deep learning has triggered a wide range of
models for AI based generative art. For example, [44? ] is an open
source tool released by Google that uses a convolutional neural
network (CNN) to understand what neural networks are doing
at each layer by creating dream-like appearances. Another CNN
architecture is the neural style transfer [26] work that allows to
blend content of one image into style of another image to create
new images. In [32], a recurrent neural network is proposed to
construct stroke-based drawings of common objects.
Recently, generative adversarial networks (GANs) [30] have be-
come popular for creating art. Creative adversarial networks [25]
proposed modifications to the GAN objective to make it creative
by maximizing deviation from established styles and minimizing
deviation from art distribution. In [70], the authors proposed a
method to translate styles across unpaired images and illustrated
its applicability in transferring artists’ styles. In [54], the authors
used conditional GANs to generate artworks.
There are many tools and apps to facilitate users to easily create
art. Using [2], users can transform a portrait in the style of famous
portraits. Photos can be converted into artworks using [37]. In an
application called GANbreeder, two images are combined to gener-
ate a new image [3]. The style of the input image is transformed
into another specified style in [20]. Cartoonify turns a photo into a
cartoon drawing leveraging Google’s “Draw This" [43].
Given that there are many tools to quickly create art, there is
an increased risk for generative art to be biased. With surging art
market [13] and pressing need for diversity and inclusiveness in
art [6], an analysis of bias in generative art becomes even more
pertinent. In a recent art project titled ‘Imagenet Roulette’ [17], AI
researcher Kate Crawford and artist Trevor Paglen exposed biases
in machine learning datasets. While there have been studies to
understand how humans perceive art [36] and to examine if there
is a perception bias towards art created by AI [51], there is little to
no extensive analysis concerning biases in generative art. In this
paper, we provide an extensive analysis of biases in art generated
autonomously by AI, looking from the perspective of art history.
Such an analysis is useful to understand machine related biases
independent of human biases, and is necessary to study scenarios
involving both human (artist) and machine bias. In the rest of this
paper, generative art refers to AI based generative art.
3 ART-HISTORICAL ASPECTS OF
ARTWORKS
In this section, we discuss various aspects pertaining to art history
based on which art works can be analyzed. Art historians employ a
number of ways to group world arts into systems of classification
[60]. These groupings are based on a set of qualities that are signifi-
cant. Such significant qualities could be related to specific approach
of an artist, material used to create art works, art movements, genre,
etc. We provide a brief account of some main aspects so as to aid in
understanding some types of biases that we illustrate in the paper.
43
FAccT, March 3–10, 2021, Virtual Event, Canada, , Ramya Srinivasan and Kanji Uchino
3.1 Art Movements
Art movements can be described as tendencies or styles in art
with a specific common philosophy influenced by various factors
such as cultures, geographies, political-dynastical markers, etc. and
followed by a group of artists during a specific period of time
[60]. Examples of art movements include Ancient Egyptian art,
Ancient Greek art, Medieval Art, Renaissance art, Modern art, etc.
Within each of these art movements, there are sub-categories based
on various factors. For example, modern art includes many sub-
categories such as Symbolism, Impressionism, Post-impressionism,
Cubism, Futurism, Pop-art, and so on. As an illustration, consider
Impressionism and Post-impressionism. Both movements origi-
nated in France, however Post-impressionism originated in reac-
tion to Impressionism. While Impressionism was characterized by
vibrant colors, spontaneous brush strokes, and urban life styles,
Post-Impressionism artists had their own individual styles to sym-
bolically display real subjects and their emotions [47]. Similarly,
each art movement is characterized by unique features that reflects
certain trends. Thus art movement is a dominant factor influencing
artists and artworks. Interested readers may refer to [60] where over
hundred sub-categories are listed across a dozen art movements.
3.2 Art material
Artworks can also be grouped based on the material and techniques
used in creating the art. Charcoal, enamel, mosaics, tapestry, paint,
and lithography are some examples of art materials. Artists use
different techniques to create artworks from different materials. For
example, mosaic is a coherent pattern or image in which each com-
ponent element is built up from small regular or irregular pieces
of substances such as stone, glass or ceramic, held in place by plas-
ter/mortar, entirely or predominantly covering a plane or curved
surface, even a three dimensional shape, and normally integrated
with its architectural context [22]. Mosaics were traditionally used
as decoration for floors and walls becoming very popular across the
Ancient RomanWorld. Different art movements saw the prevalence
of different materials. For example during the Renaissance period,
sculptures were made out of various materials like marble, white
stone, gold, etc. Thus, material and technique employed to create
art can influence the artist and the resulting artwork. An elaborate
list of various materials can be found in the WikiArt dataset [60].
3.3 Genre
Genre of an artwork is based on the depicted themes and objects. A
hierarchy of genres was developed in the 17𝑡ℎ century [23]. Accord-
ing to this hierarchy, history paintings, namely paintings depicting
scenes of important historical, mythological, and religious events,
were considered to be the top ranked genre and this was so until the
mid 19𝑡ℎ century. History paintings were usually large and typically
narrated a story such as a battle, allegory, or the like. Portraiture
was another prominent genre and these usually depicted royals,
aristocrats, and other important people in society. Portraiture had
to convey aesthetic aspects of the subject depicted, such as their
power, beauty, etc. In contrast, “genre painting" depicted scenes
from every day lives of ordinary people. Landscapes, animal paint-
ing, and still life painting are some other prominent genres. Abstract
or figurative art are the most common genres for contemporary
art [60]. An artist usually can work across different genre types,
however, art historians mark certain artists as representatives of a
particular genre. For example, Anthony van Dyck is recognized as a
portraitist, Alfred Sisley as a landscape painter, and Piet Mondrian
as an abstract artist – though each one of them worked in a number
of different genres [60]. Wikiart dataset provides an extensive list
of genres based on artists and artworks.
3.4 Artists
There are many aspects that characterize an artist’s “style". In addi-
tion to factors such as art movement, art material, and genre, an
artist’s style can be characterized by factors such as their cultural
backgrounds, their art lineage or schools (from whom they learned
or who influenced them), and other subjective aspects such as their
cognitive skills, beliefs, prejudices, and so on. Consider for example,
Paul Cezanne, one of the most popular artists in the history of
modern art. Although generally categorized as a Post-Impressionist
artist, Cezanne influenced several other art movements such as
Cubism and Fauvism. Some of his early pictures depict classical and
romantic themes with expressive brushwork and dark colors, while
later he is said to have adopted brighter colors drawing inspiration,
emotions, and memory to paint [59]. Cezanne himself remarked: “A
work of art which did not begin in emotion is not art". In his still-life
paintings, Cezanne began to address technical problems of form and
color by experimenting with subtly gradated tonal variations, or
“constructive brushstrokes,” to create dimension in the objects [59].
His artworks span a variety of genres and exhibit patterns from
multiple art movements marked by subtle cognitive aspects. Thus,
modeling artists’ style is not a straightforward computational task,
it entails many abstract elements that are hard to quantify. Yet, re-
searchers define “style" in ways that suit their model’s performance,
we discuss this issue next.
4 BIASES DUE TO PROBLEM FORMULATION
Biases can arise based on how a problem is defined and is formally
known as the framing effect bias [50]. Consider, for example, the
problem of style transfer in artworks. There are at least two different
notions of styles when it comes to artworks: one which is related
to the art movement, and another which is related to the artist.
As described in Section 3, there are many aspects to each of the
above notions of style. Yet researchers conveniently define style in
a manner that suits their model’s performance. This is a consistent
problem across several models. For example, in [54], the authors
claim that their model learns Ukiyo-e style since the generated
images are “yellowish" like Ukiyo-e artworks. In [70], a single model
is used to learn styles of artists and art movements. Like in [54],
the justification to have learned Ukiyo-e style seems to be based on
color features. Thus, “style" has been defined based on the color of
the generated art. Given that most Ukiyo-e works were woodblock
prints, it is thus natural for the generated art to be yellowish.
Ukiyo-e is a form of Japanese art. The works usually depicted
landscapes, tales from history, scenes from the Kabuki theatre, and
other aspects of everyday city life. Some unique characteristics
of Ukiyo-e included exaggerated foreshortening, asymmetry of
design, areas of flat (unshaded) colour, and imaginative cropping of
figures [64]. Foreshortening refers to the technique of depicting an
44
Biases in Generative Art— A Causal Look from the Lens of Art History FAccT, March 3–10, 2021, Virtual Event, Canada, ,
object or human body in a picture so as to produce an illusion of
projection or extension in space and to convey the notion of depth.
These characteristics are not captured in the examples depicted in
[54, 70]. Such drawbacks can also happen due to the model design
issues which we discuss in Section 6. Nevertheless, inappropriate
problem formulation can introduce and perpetuate biases across the
generative art AI pipeline. In the next section, we briefly describe
structural causal models that we leverage to analyze different biases.
5 STRUCTURAL CAUSAL MODELS
We advocate for the use of causal directed acyclic graphs (DAGs)
[48] to analyze some types of biases that are related to algorithm de-
sign and datasets. In Section 3, we saw that there are several aspects
relevant to an artwork and that these aspects could influence each
other in many ways. For example, art movement could influence the
choice of art material, the subject of a portrait could influence the
artist, and so on. DAGs help in visualizing such relationships. DAGs
also allow encoding of assumptions about data, model, and analysis,
and serve as a tool to test for various biases under such assumptions.
Researchers have leveraged causal models to discuss and develop
various notions of fairness [28, 40]. Causal models facilitate domain
experts such as art historians to encode their assumptions, and
hence serve as accessible data visualization and analysis tools. Based
on different expert opinions, there can be multiple assumptions.
Thus, there can be more than one DAG describing the relationship
of an artwork with the artist, genre, art movement, etc. Thus, using
multiple DAGs it is possible to analyze for biases under different
scenarios. We discuss basic concepts related to causal models, and
through case studies, illustrate the intuition behind using causal
models to analyze biases in generative art.
DAGs are visual graphs for encoding causal assumptions be-
tween the variables of interest. Specifically, the assumptions about
data are encoded by means of structural causal models (SCMs) [48].
A structural causal model𝑀 , consists of two sets of variables,𝑈 and
𝑉 , and a set 𝐹 of functions that determine or simulate how values
are assigned to each variable 𝑉𝑖 ∈ 𝑉 . The variables 𝑉 are observed
and variables𝑈 are unobserved. Variables𝑈 and 𝑉 constitute the
vertices of a causal graph 𝐺 and the directed edges between them
denote the various causal dependencies.
5.1 d-separation
Regardless of the functional form of the equations in the model (𝐹 ),
conditional independence relations can be obtained if the model
𝑀 satisfies certain criteria. 𝑑 − 𝑠𝑒𝑝𝑎𝑟𝑎𝑡𝑖𝑜𝑛 is a criterion for decid-
ing, from a given a causal graph, whether a set 𝑋 of variables is
independent of another set 𝑍 , given a third set 𝑌 . The idea is to
associate “dependence" with “connectedness" (i.e., the existence of
a connecting path) and “independence" with “unconnected-ness"
or “separation" [48]. Path here refers to any consecutive sequence
of edges, disregarding their direction.
Consider a three vertex graph consisting of vertices 𝑋 , 𝑌 , and 𝑍 .
There are three basic types of relations using which any pattern of
arrows in a DAG can be analyzed, these are depicted in Figure 3. The
leftmost graph (i) denotes a causal chain or that of a “mediation".
The effect of 𝑋 on 𝑍 is mediated through 𝑌 . In this case, given 𝑌
(i.e. conditioning on 𝑌 ), 𝑋 is independent of 𝑍 or 𝑌 is said to 𝑏𝑙𝑜𝑐𝑘
Figure 3: D-separation: Graph structures to illustrate conditional
independence. Please refer to Section 5.1 for details
the path from 𝑋 to 𝑍 . In the center graph (ii), 𝑌 is a common cause
of 𝑋 and 𝑍 . If unobserved, 𝑌 is a confounder as it causes spurious
correlations between 𝑋 and 𝑍 . Conditioned on 𝑌 , the path from
𝑋 to 𝑌 is blocked. In the rightmost graph (iii), 𝑌 is a collider as
two arrows enter into it. As such, the path from 𝑋 to 𝑌 is blocked.
However, conditioning on 𝑌 , the path will be unblocked. In general,
a set 𝑌 is admissible (or “sufficient”) for estimating the causal effect
of 𝑋 on 𝑍 if the following two conditions hold [48]:
• No element of 𝑌 is a descendant of 𝑋
• The elements of 𝑌 block all backdoor paths from 𝑋 to 𝑍—i.e.,
all paths that end with an arrow pointing to 𝑋 .
5.2 Interventions
An 𝑖𝑛𝑡𝑒𝑟𝑣𝑒𝑛𝑡𝑖𝑜𝑛 on a graph is denoted by the “𝑑𝑜" operator [48].
The 𝑑𝑜 operator corresponds to setting the intervened variable to a
specific value and removing the influence of other variables on it.
For example, in graph (ii) of Figure 3, 𝑑𝑜 (𝑋 = 𝑥) implies that the
variable 𝑋 is set to the value 𝑥 and the incoming arrow into 𝑋 is
removed. 𝑑𝑜 operator facilitates quantification of causal effects. For
example, in Figure 3 (ii), the expression 𝑃 (𝑍 |𝑑𝑜 (𝑋 = 𝑥)) quantifies
the causal effect of𝑋 on𝑍 . A set of rules referred to as 𝑑𝑜−𝑐𝑎𝑙𝑐𝑢𝑙𝑢𝑠
are always applicable in the context of interventions [48]. These
rules determine when it is possible to
• to add/delete observations in interventions,
• to exchange interventions and observations,
• to add/delete interventions
𝑑𝑜 − 𝑐𝑎𝑙𝑐𝑢𝑙𝑢𝑠 helps in rendering expressions free from “𝑑𝑜”. We are
now equipped to discuss algorithmic biases in generative art.
6 BIASES RELATED TO ALGORITHM
Bias can arise if the algorithm ignores the effect of unobserved
variables, overlooks domain specific differences, uses subsets of the
population for analysis, and so on. We discuss these in this section.
6.1 Confounding bias
Confounding bias originates from common causes that affect both
inputs and outputs [48]. We illustrate this bias through case studies.
6.1.1 Case Study 1: Modeling artists styles has been one of the
most common applications in generative art. As discussed in Section
3.4, several observed and unobserved abstract aspects constitute an
artist’s style. Revisiting example discussed in Figure 2, the problem
of modeling Van Gogh’s style can be viewed as estimating the
causal effect of Van Gogh on the artwork. Thus, the expression
𝑃 (𝐴𝑟𝑡𝑤𝑜𝑟𝑘 |𝑑𝑜 (𝐴𝑟𝑡𝑖𝑠𝑡)) models the style of the artist in the artwork
(Section 5.2). It is to be noted that the assumptions encoded through
45
FAccT, March 3–10, 2021, Virtual Event, Canada, , Ramya Srinivasan and Kanji Uchino
a DAG can vary from one expert opinion to another. However, these
varying opinions help to discover and test for biases under different
scenarios and in turn highlight the drawbacks of existing correlation
based methods such as [70] that do not take into account important
cultural and social aspects that influence an artist’s style.
Consider Figure 4 (i) that depicts one potential process of art
creation (note there could be several others based on assumptions
of domain experts, we consider one such for illustration). Here, the
variable 𝑋 denotes the artist, 𝑍 denotes the artwork,𝐺 is the genre,
𝑀 is the art material, and 𝐴 denotes the art movement. Accord-
ing to the assumptions encoded in this DAG, art material, genre,
and art movement are confounders influencing both the artist and
the artwork. Further, art movement influences the art material.
Let us assume that all of the confounders are observable. Under
these assumptions, in order to model the style of Van Gogh (i.e.
𝑃 (𝑍 |𝑑𝑜 (𝑋 = 𝑥))), we have to block the backdoor path from 𝑋 to 𝑍
(Section 5.1), so as to remove confounding bias.
Specifically, for graph (i) in Figure 4, the following equation
captures the causal effect of 𝑋 on 𝑍
𝑃 (𝑍 |𝑑𝑜 (𝑋 = 𝑥)) =∑
𝑔,𝑎,𝑚
𝑃 (𝑍 |𝑥,𝐺 = 𝑔,𝐴 = 𝑎,𝑀 =𝑚)𝑃 (𝐺 = 𝑔,𝐴 = 𝑎,𝑀 =𝑚) (1)
For the case study, 𝑑𝑜 (𝑋 = 𝑥) implies do(Artist=Van Gogh). The
summation
∑
𝑔,𝑎,𝑚 in Eq. 1 indicates that one has to consider all
possible art movements, art materials, and genres that the artist has
worked in order to model their style. The implication of finding a
sufficient set,𝐴,𝐺,𝑀 , is that stratifying on𝐴,𝐺,𝑀 is guaranteed to
remove all confounding bias relative to the causal effect of 𝑋 on 𝑍 .
Thus, modeling artist’s style requires knowledge about the causal
process governing the artwork’s creation. Models like [54, 70] that
do not consider the influence of confounders like art movement
are prone to omitted variable bias [66] and confounding bias. Art
movements were characterized by many socio-cultural and political
events and reflect the dynamic influence of these events on art. Thus
by ignoring this variable, there is a bias in capturing the artist’s
style, in understanding the art’s intent, and in representing culture.
Based on the DAG, the causal effect may or may not be identifiable.
Eq. (2) differs from the conditional distribution 𝑃 (𝑍 = 𝑧 |𝑋 = 𝑥),
and the difference between the two distributions, i.e. 𝑃 (𝑍 |𝑑𝑜 (𝑋 =
𝑥)) − 𝑃 (𝑍 = 𝑧 |𝑋 = 𝑥) defines confounding bias [10].
Figure 4 (i) depicted a scenario with no unobserved confounders.
In presence of unobserved confounders, causal effects are not iden-
tifiable. Consider Figure 4 (ii). Let 𝐸 represent emotions of the artist.
The dotted circle and lines denote the unobserved confounder 𝐸
and its influence on other variables. In this case, even knowing the
joint distribution of genre, art movement, and material 𝑃 (𝐴,𝐺,𝑀)
does not help in identifying Van Gogh’s style, i.e. 𝑃 (𝑍 |𝑑𝑜 (𝑋 = 𝑥))
is not identifiable. In general several subjective factors like prior
beliefs, emotions, cultural values, etc. can influence the artist and
the artwork. Thus in reality, the true style of any artist cannot be
accurately modeled. Even if confounding bias due to unobserved
factors is overlooked, there are other biases as discussed next.
Figure 4: (i): Confounding bias due to genre, material and artmove-
ments. (ii): Confounding bias due to artist’s unobserved emotions.
Figure 5: (i): Example of selection bias (ii): Illustration of CS 2, see
Section 6.2. (iii) Illustration of selection bias in datasets, see Section
7.1. Causal effect of𝑋 on 𝑍 is not identifiable across (i), (ii), and (iii)
6.2 Sample Selection bias
Sample selection bias (or selection bias for short) is the bias that
is induced by preferential selection of units for data analysis [10].
In a DAG, a special variable 𝑆 is used to denote the selection of
the variable in the analysis, 𝑆 = 1 indicating selection and 𝑆 = 0
indicating otherwise. Consider for example, Figure 5 (i). Here, 𝑋 →
𝑆 and 𝑍 → 𝑆 indicates that both inputs and outputs are selection
dependent (i.e. 𝑆 = 1 with respect to both 𝑋 and 𝑍 ). The case study
discussed below will further clarify these concepts.
6.2.1 Case Study 2. To illustrate selection bias, let us consider an
example described in the ArtGAN model [54]. The authors state
that their model is able to recognize artist Gustave Dore’s prefer-
ences as the generated images resonate with the dull color found
in Dore’s artworks. Mostly engravings were selected for analysis.
Graph (ii) in Figure 5 depicts a possible DAG for this case. Let 𝑋
denote Dore’s style. 𝑋 → 𝑆 depicts the selection of engravings in
the analysis. Further, as the authors mention, the generated images
are greyish due to the engravings considered, thus 𝑍 → 𝑆 , where
𝑍 denotes generated image. Additionally, there may be some unob-
served confounders that influence both 𝑋 and 𝑍 as denoted by the
bi-directional dotted arrow, and there may be some other Artgan
model variable 𝑉 that influences the nature of generated image 𝑍 ,
these are depicted in Figure 5 (ii).
In order to be able to recover the causal effect of 𝑋 on 𝑍 under
selection bias, [10] lists the conditions known as selection backdoor
criteria. Formally, let 𝑌 be a set of variables partitioned into two
groups 𝑌+ and 𝑌− such that 𝑌+ contains all non-descendants of 𝑋
46
Biases in Generative Art— A Causal Look from the Lens of Art History FAccT, March 3–10, 2021, Virtual Event, Canada, ,
and 𝑌− the descendants of 𝑋 , and let 𝐺𝑠 stand for the graph that
includes the selection mechanism 𝑆 . 𝑌 is said to satisfy the selection
backdoor criterion if the following conditions are true:
• (i) 𝑌+ blocks all backdoor paths from 𝑋 to 𝑍 in 𝐺𝑠
• (ii) 𝑋 and 𝑌+ block all paths between 𝑌− and 𝑍 in 𝐺𝑠
• (iii) 𝑋 and 𝑌 block all paths between 𝑆 and 𝑍 in 𝐺𝑠
• (iv) 𝑌 and 𝑌 ∪ (𝑋,𝑍 ) are measured.
In Figure 5 (ii), the path between 𝑆 and 𝑍 is not blocked due to the
presence of direct link between the two variables, thus condition
(iii) in selection backdoor criteria is not satisfied. Hence Dore’s
style cannot be recovered based on the engravings considered in
the analysis. In fact, in addition to engravings, Dore’s worked on
paintings. For example, landscapes such as ‘The Lost Cow’, paintings
such as ‘Little Red Riding Hood’, religious painting such as ‘The
Wrestle of Jacob’ are not greyish and exhibit colors reflective of the
genre. Thus, by merely selecting engravings for analysis, sample
selection bias is induced and style of Dore cannot be identified.
Note, the failure to capture Dore’s style in [54] can be additionally
attributed to other types of biases such as confounding bias, label
bias, and even framing effect bias. For the purpose of illustrating
selection bias, we have focused on describing selection bias only.
In general, there can be more than one type of bias in a case study.
6.2.2 Case Study 3: As an other example of selection bias, consider
the case of [2]. As illustrated in Figure 1, racial bias was evident in
this application. Figure 5 (ii) can also be used to describe this sce-
nario. Let𝑋 denote the set of input images selected for analysis and
let 𝑍 represent the generated images. Selection of Renaissance por-
traits of mostly white people was used in the analysis, thus 𝑋 → 𝑆 .
As evident, the generated images were portraits of fair skinned
people, thus 𝑍 → 𝑆 . Additionally, there could be unobserved con-
founders influencing both the input images𝑋 and generated images
𝑍 , and there may be model parameters 𝑉 influencing the gener-
ated images. As condition (iii) in selection backdoor criteria is not
satisfied, there is selection bias.
6.3 Transportability bias
Style transfer is a popular application in generative art. Various
works have demonstrated transferring across artists’ styles (e.g.
Cezanne to Monet) and across art media (e.g. photograph to paint-
ing). Learning models that can generalize across domains is com-
monly known as transfer learning in the deep learning community
and as transportability in the causality community. Transporta-
bility defines the conditions under which causal effects learned
in experimental studies can be transferred into to a new popula-
tion in which only observational studies can be conducted [49].
The differences between the populations of interest are expressed
through representations called as “selection diagrams”. To this end,
DAGs are augmented with a set, 𝑅, of “selection variables,” where
each member of 𝑅 corresponds to a mechanism by which the two
populations differ, and switching between the two populations
will be represented by conditioning on different values of these
𝑅 variables. 𝑅 variables locate the mechanisms where structural
discrepancies between the two domains are suspected to take place.
Transportability bias arises if causal effects cannot be transferred
across populations.
Figure 6: (i): An example Selection diagram (SD). (ii): SD for case
study 4 and 5. (iii) SD illustrating case study 10. Causal effect of 𝑋
on 𝑍 is not identifiable across all scenarios (i), (ii), and (iii)
The conditions under which causal effects can be transported are
listed in [9]. Formally, let 𝐷 be the selection diagram characteriz-
ing the two populations Π and Π∗ with observational distributions
𝑃 and 𝑃∗, and 𝑅 a set of selection variables in 𝐷 . The relation
𝑄 = 𝑃∗ (𝑧 |𝑑𝑜 (𝑥), 𝑦) is transportable from Π to Π∗ if and only if the
expression 𝑃 (𝑧 |𝑑𝑜 (𝑥), 𝑦, 𝑟 ) is reducible, using rules of do-calculus
[48] (Sec. 5.2), to an expression in which 𝑅 appears only as a condi-
tioning variable in do-free terms. Given a DAG, open source tools
like [8] can check for causal effects transportability automatically.
As an illustration, consider Figure 6 (i). Let the variable 𝑋 de-
note artist and 𝑍 denote the artwork. Suppose the variable 𝑌 is
an unobserved confounder denoting subjective emotions of the
artist. Between any two artists, this variable 𝑌 is bound to cause
differences and hence the selection variable 𝑅 is pointing to 𝑌 to
indicate this difference. For this DAG, the causal effect of 𝑋 on
𝑍 is not transportable or transferable across the two artists. For
illustrative purposes, we will ignore the differences due to unob-
served factors such as subjective emotions of artists and consider
differences in observed variables. There can still be transportability
bias as illustrated through the following case studies.
6.3.1 Case Study 4: In [70], a model that can transfer photograph
to an artist’s style is proposed, say photograph and Cezanne for
illustration. For simplicity, we consider only one genre say land-
scapes. The goal is to model Cezanne’s style in rendering the land-
scape corresponding to the photo. Consider Figure 6 (ii) which
illustrates one possible selection diagram for this case study. Let
𝑋 denote artist/photographer and let 𝑍 denote the artwork/photo.
Thus, there are two populations corresponding to the choice of 𝑋
and 𝑍 , i.e. photographer/photo, and artist/artwork. For the style
transfer problem, we want to be able to capture the causal effect of
the artist 𝑋 on the artwork 𝑍 using the photograph. The shaded
squares marked by the symbol 𝑅 are the selection variables and
are used to denote differences in the two populations [10]. Further,
there may other unobserved confounders. However, to illustrate
biases beyond the difference in unobserved confounders, we will
overlook such confounders in this case study.
The factors that influence an artist are different from those that
influence a photographer. For example, Cezanne could be influ-
enced by the art movement whereas the photographer may be
influenced by the photography trends. This distinction is indicated
by the selection variable 𝑅 pointing into 𝑋 . Further, the factors
that affect the artwork may be different in the two populations. A
47
FAccT, March 3–10, 2021, Virtual Event, Canada, , Ramya Srinivasan and Kanji Uchino
Figure 7: Center: “Propellers", a Cubist work by Fernand Leger. Right:
“Armoured Train in Action", a Futurism work by Gino Severini. Left:
translation of the center image according to the style of right im-
age by [20]. Movement, a key aspect of Futurism, is missing in the
translation. Image source: [60]
photograph may be subject to the camera characteristics, lighting,
and measurement errors, selection variable 𝑅 pointing to 𝑍 denotes
this difference. When the distinction is associated with the target
variable, i.e. 𝑍 in Figure 6 (ii), causal effects are not transportable
[9]. Thus, there will be transportability bias.
In fact, in post-impressionism, the art movement primarily as-
sociated with Cezanne, artists had their own individual styles. As
mentioned in [59], Cezanne concentrated on pictorial problems
of creating depth in his landscapes. He used an organized system
of layers to construct a series of horizontal planes, which build
dimension and draw the viewer into the landscape. This technique
is apparent in some of his works such as Mont Sainte-Victoire, the
Viaduct of the Arc River Valley and The Gulf of Marseille Seen from
L’Estaque [59]. In some of his works such as Gardanne, Cezanne
painted the landscape with intense volumetric patterns of geometric
rhythms most pronounced in the houses reflective of Cubism. The
generated images in [70] do not exhibit such geometric rhythms.
6.3.2 Case Study 5: In the previous case study, we analyzed bias
in the context of style transfer from one genre to another (from
photograph to landscape). As another illustration, let us consider
the problem of style transfer across art movements and genres.
In order to demonstrate transportability bias in this setting, we
consider DeepArt.io [20], an online platform that maps the style
of one image to the content of the other using a neural network
architecture [26]. We consider a case study that involves Cubism
and Futurism, two art movements in the modern art era. Both
these movements had many common aspects, yet they diverged in
subtle ways. Therefore, we find it to be an interesting case study
for analysis. Both Cubism and Futurism focus on representation
of objects from multiple perspectives/viewpoints and emphasize
on geometrical shapes. Cubism, is concerned with forms in static
relationships while Futurism is concerned with them in a kinetic
state. Futurism emphasized on objects and events that involved
movement such as wars, energy of nightclub, and so on [62]. As
such, we consider the following artworks for the case study.
“Propellers" (center image in Figure 7) was a 1918 Cubist art by
Fernand Leger. Leger was fascinated with technology, in particular
with propellers, and viewed them as objects of beauty holding them
close to sculptures [4]. Right image in Figure 7 is a 1915 Futurism
art by Gino Servini called “Armored Train in Action". Severini was
inspired by Cubism but was a member of Futurism. Futurism used
Figure 8: Center: “Miss Mary Ellison", a Realism artwork by Mary
Cassatt. Right: “Erna" , an Expressionism artwork by Ernst Ludwig
Kirchner. Left: translation of the center image according to the style
of right image by [20]. Distorted subjects, a key aspect of Expression-
ism is absent in the translation. Image source: [60]
art as a symbol for expressing political and social views. Severini
depicted aspects of war, movement, and modernity in this work.
Figure 6 (ii) can be a potential DAG for this case study, note,
there can be other DAGs based on assumptions. The differences
in Cubism and Futurism art movements combined with the differ-
ences in genre influences the artists differently and the artwork
differently. Also, there is the effect of unobserved factors such as
the artist’s emotions that influence the artist and the artwork. The
left most image in Figure 7 corresponds to the “Futurism version” of
Propellers. Kinetic patterns which is a distinct feature of Futurism, is
absent in the translated image. Given that the original image is that
of a mechanical object (propellers), a Futurism version of it should
have depicted the movement of the propellers much like in ‘Ar-
moured train in Action’ that shows the fractured landscape, which
accentuates the train’s force and momentum as it cuts through the
countryside [46]. Thus, there is bias in transferring styles.
6.3.3 Case Study 6: The previous case study encompassed style
transfer across art movements which were similar in many ways.
We now consider a case study involving style transfer between
Realism and Expressionism, two art movements that have marked
differences from one another. We consider common genre, namely
portraits across the two art movements. Thus, this case study serves
as a good test to see if style transfer from [20, 26] is effective given
that the difference between two styles is significant.
Realism focuses on representing subject matter truthfully, with-
out artificiality and avoiding implausible, exotic and supernatural
elements [60]. The center image in Figure 8 is an Realism portrait
by Mary Cassatt. Expressionists, on the other hand, used gestural
brushstrokes and distorted subjects to portray intense emotions
through their works. The right image in Figure 8 is an expression-
ism portrait by Ernst Ludwig Kirchner. As can be observed, the
facial features in the right image have been distorted (e.g. sharp
chin resulting in an almost triangular facial contour, pointed nose
and ears) to intensify emotions. The left image in Figure 8 is the
style translated version of the center image. Aesthetic innovations
typical of an avante-garde movement like Expressionism are not
evident in the style translated version. As Kirchner himself said, in
Expressionism, objective correctness of things is not emphasized
[52], rather a new appearance is created through radical distortions
of subjects to evoke intense emotional experiences. The style trans-
lated version is exactly as the original but for some color changes.
48
Biases in Generative Art— A Causal Look from the Lens of Art History FAccT, March 3–10, 2021, Virtual Event, Canada, ,
Figure 9: (i): “Black Matriarch", a Folkart by Clementine Hunter. (ii):
“Expressionismversion" of (i) by [29]. (iii): “Giovinetto", a Renaissance
sculpture by Desiderio da Settignano. (iv): “Expressionism version"
of (iii) by [29]. Face color of “Black Matriarch" is changed in the trans-
lation unlike in “Giovinetto", a white sculpture. Image source: [60]
The image neither exhibits any distorted features nor has gestu-
ral brushstrokes that portray intense emotions. Thus, the style
translation does not capture the subtleties of the Expressionism art
movement.
6.3.4 Case Study 7: As another case study to demonstrate biases
in “style" transfer, we consider “GoART" [29]. This app allows a
user to convert an uploaded photo into various styles spanning art
movements such as Byzantine, Expressionism, Cubism, Ukiyo-e,
and artists such as Van Gogh.We consider a 1970 folk art by Clemen-
tine Hunter titled “Black Matriarch" shown in Figure 9 (i). Figure 9
(ii) shows the “Expressionism" version of the “Black Matriarch" from
[29]. As can be noticed, the face is tinted in red. However, this kind
of effect is not pronounced in light colored faces. Consider Figure
9 (iii). This is an early Renaissance sculpture by Desiderio da Set-
tignano. The face in the “Expressionism" version of this sculpture
(Figure 9 (iv)) does not seem to have shades of red as significant as
in Figure 9 (ii). Similar results were observed with other styles such
as Byzantine wherein the face of “Black Matriarch" was tinted with
shades of blue while the fairer faces were not heavily tinted. There
is noticeable difference in the way faces are converted across styles
based on the color of the face, indicating potential racial biases.
6.3.5 Case Study 8: We consider Abacus.AI’s online tool that con-
verts a user uploaded photo into a different gender: male to female
and vice versa [1]. One of their demos shows translation of the
Renaissance painting of Mona Lisa into a masculine face. Thus, we
experimented with other Renaissance paintings. Figure 10 (i) is a
‘portrait of a man holding an apple’ by Raphael and Figure 10 (iii)
is a ‘portrait of a young man’ by Italian artist Piero di Cosimo [60].
Figure 10 (ii) and 10 (iv) are the gender translated versions of (i)
and (iii) by [1], both of which fail to identify the original paintings
as those of men. Young men with long hair were mistaken to be
women and thus the gender-translated versions of these images
depicted masculine faces with beards. In the Renaissance era, it was
common for young men to have long hair, often extending from
ears to shoulders. Thus, by not understanding the differences due
to culture across genders and age, men are being stereotyped as
having short hair and [1] thus exhibits transportability bias.
7 BIASES IN DATASETS
In this section, we discuss biases due to unrepresentative datasets
and due to inconsistencies in annotation.
Figure 10: (i) Portrait of a man by Raphael, (iii) Portrait of a young
man by Cosimo. (ii), (iv): Gender translations of (i) and (iii) respec-
tively. Young men with long hair were mistaken as women by [1]
7.1 Representational bias
The bias that arises because of having a dataset that is not repre-
sentative of the real world is referred to as representational bias.
This is a particular type of selection bias. Specifically in the con-
text of art datasets, there may be imbalances with respect to art
genres (e.g. large number of photographs vs few sculptures), artists
(e.g. mostly European artists vs few native artists), art movements
(large number of works concerning Renaissance and modern art
movements as opposed to others), and so on. The availability of
artworks is one of the main constraints in collecting a dataset that
is representative of the bygone times, but preferences of the dataset
curators can also play a role in contributing to bias.
7.1.1 Case Study 9: Consider [2] that was trained using about
45000 Renaissance portraits of mostly white people [38, 53]. Quite
naturally, the system performs poorly on dark skinned people. Faces
depicting different races, appearances, etc. have not been pooled
into the dataset, thus contributing to representational bias. This is
a particular instance of selection bias that has to do with dataset
curation. Algorithms trained using datasets with severe class imbal-
ances are bound to be biased. Figure 5 (iii) illustrates this. Suppose
𝑋 denotes artist and 𝑍 denotes artworks, then class imbalances
corresponds to 𝑍 → 𝑆 , i.e. type of artworks influences selection
into the dataset (in this case mostly white Renaissance portraits
were selected into the dataset). As condition (iii) fails in selection
backdoor criteria, there is representational bias.
7.2 Label bias
This type of bias is associated with the inconsistencies in the label-
ing process. Different annotators may have different preferences
which can get reflected in the labels created. A common instance
of label bias arises when different annotations could be used to
represent an artwork. For example, a scene with clouds may be
annotated as a “cloudscape" by some annotators and more generally
as a "landscape" by others.
Yet another type of label bias arises when subjective biases of
evaluators can affect labeling. “Confirmation bias" [50], a type of
human bias, is closely related to this type of label bias. For example,
in a task of annotating emotions associated with artworks, the labels
could be biased by the subjective preferences of annotators such as
their culture, beliefs, and introspective capabilities. Consider the
Behance Artistic Media dataset [65] which provides labels based
on emotions such as “happy", “scary", "peaceful", etc. Such labels
could be based on annotator’s beliefs, and can therefore be noisy.
49
FAccT, March 3–10, 2021, Virtual Event, Canada, , Ramya Srinivasan and Kanji Uchino
7.2.1 Case Study 10: To illustrate how annotation inconsistencies
can induce bias, consider the ArtGAN model [54]. This model uses
the label information to train the GAN’s discriminator. The authors
claim that by using labels pertaining to genre (cityscapes, por-
traits, etc.), art media (e.g. sketch and study, engraving), and style
(e.g. Ukiyo-e), they are able to generate images of those categories.
However, the annotations are not necessarily reliable indicators of
genres or styles. For example, “sketch and study" category includes
several other categories such as portraits, religious paintings, and
allegorical works to name a few. Figure 6 (iii) illustrates this bias. Let
Π and Π∗ denote the environments corresponding to two different
annotators. Suppose 𝑋 denotes art movement’s style (e.g. Ukiyo-e),
and 𝑍 is the artwork. Annotation inconsistencies across annota-
tors affects the artworks’ labels, this is indicated by the selection
variable 𝑅 pointing to 𝑍 . When there are differences in the target
variable (i.e. label of artworks), the causal effect of 𝑋 on 𝑍 is not
identifiable using the annotations provided [9]. Thus, a generative
model that leverages such labels in modeling style is prone to bias.
8 DISCUSSION
Art is much more than an aesthetic entity. As elaborated in [68], art
imparts “moral knowledge", i.e. knowledge about what ought to do
and not to do [31]. Art also enables “emphathic knowledge", some-
thing through which one can compare different views of the world
through direct experience [18]. Art initiates a conversation with
the public [19], it is a form of language that is not just a mimicry
but a symbolic transposition [41]. Art is ‘a form of technology that
contributes to knowledge production by exemplifying aspects of the
world that would otherwise go overlooked’ [31]. Thus given its pow-
erful impact in shaping moral and empathetic values, generative
art comes with the responsibility of creating art that respects and
upholds societal ethics. By coloring the face of the “Black Matri-
arch", [29] is not only depicting racial bias, but also inaccurate in its
representation of the art movement. As artist Edgar Degas remarks,
“Art is not just what you see but what you make others see". Thus,
generative art that does not promote diversity and inclusiveness
has the potential of creating and communicating unethical values.
Art reflects cognitive abilities of the artist [21]. Cognitive abili-
ties include perception, memory, emotions, and other latent aspects
about the artist. Generative art that is meant to create art in the
“style" of various artists must reflect and respect artist’s cognitive
abilities and not stereotype them based on any narrowly defined
metric. For example, often, “style of Van Gogh" is largely modeled
based on the brushstrokes in his rendition “Starry Nights" or based
on certain colors such as in [54]. Similarly, “style of Cezanne" in
[70] little reflects the variety of geometric patterns that were promi-
nent in his works. Needless to mention that cognitive aspects of the
artist are not considered. As discussed in Section 4 and 6, majority
of these issues arise due to framing effect bias and algorithmic bias.
Often style is defined and modeled in a way to suit the algorithm’s
performance. Not only are several important abilities and achieve-
ments of artists overlooked in the process of poor style modeling,
but also those pertaining to larger art movements are ignored. For
example, advanced techniques such as exaggerated foreshorten-
ing and perspective modeling that were typical of many Ukiyo-e
renditions are hardly visible in the generated versions [29, 70].
In a recent photo booth titled “Latent Face", latent vectors of
the styleGAN model were combined to generate "hypothetical chil-
dren" of subjects depicted in the original portraits [5]. While this
may have been an exploratory experiment, the task exemplifies
framing effect bias. Defining “children" as combination of latent
vectors is highly questionable. The latent vectors may or may not
have any reliable interpretation, and a very difficult and potentially
impossible problem of generating faces of hypothetical children is
conveniently framed as a simple task. There are also several ethical
concerns associated with such a framing given that people depicted
in the original portraits were not related or never had children.
Framing effect bias coupled with algorithmic bias contributes to
inaccurate knowledge about history. Artworks were often meant
to document important events in history such as wars, mytho-
logical events, political movements, etc. By wrongly modeling or
overlooking certain subtle aspects, generative art can contribute
to false perceptions about social, cultural and political aspects of
past times and hinder awareness about important historical events.
For example, as discussed in case study 5, in the Futurism artwork
“Armored Train in Action", artist Severini conveys his views on war
that was prevalent during the time. In fact, Futurism artists heavily
depicted their views of political events through patterns indicating
movement in the artworks. A generated style translation should
thus preserve such important characteristics of art movements, or
else they will be contributing to a bias in understanding history.
People have a propensity to favor suggestions from automated sys-
tems and to ignore contradictory information, even if it is correct.
This is called as “automation bias" [61]. Thus, people may give lit-
tle importance to historical evidence. Further, often, evaluation of
generative art is done by people (e.g. Amazon Mechanical Turk
workers) who do not necessarily possess domain knowledge. Thus,
even if generated art is not accurately representing cultural and
historical knowledge, people may endorse them.
Tutorials like [27] and [39] emphasize on the need to inspect the
design choices made by the creators of AI systems and the socio-
political contexts that shape their deployment. Can algorithms
accurately model artist’s “styles"? More broadly, is the defined prob-
lem even solvable? How can representative datasets and reliable
labels be created to address the defined problem? What are the
measurement biases in digitally capturing art? What are the socio-
cultural impacts of generative art? Does generative art promote
inclusiveness? Who should own responsibility for biases in genera-
tive art? These are just some questions that need to be analyzed.
Also, domain experts (e.g. art historians) should be involved in the
generative art pipeline to better inform the process of art creation.
9 CONCLUSIONS
In this paper, we investigated biases in the generative art AI pipeline
from the perspective of art history. Leveraging structural causal
models, we highlighted how current methods fall short in modeling
the process of art creation and illustrated instances of framing effect
bias, dataset bias, selection bias, confounding bias, and transporta-
bility bias. We also discussed the socio-cultural impacts of these
biases. We hope our work sparks inter-disciplinary dicussions and
inspires new directions concerning accountability of generative art.
50
Biases in Generative Art— A Causal Look from the Lens of Art History FAccT, March 3–10, 2021, Virtual Event, Canada, ,
REFERENCES
[1] Abacus.AI. 2020. Effortlessly embed cutting edge AI in your Applications. In
https://abacus.ai.
[2] AIportraits. 2020. AIportraits: The easiest way to make your portraits look
stunning. https://aiportraits.org (2020).
[3] Artbreeder. 2020. Artbreeder: Extend your Imagination.
https://www.artbreeder.com (2020).
[4] Christoph Asendorf. 1994. The Propeller and the Avant-Garde: Leger, Duchamp,
Brancusi. Fernand leger: The Rhythm of Modern Life (1994).
[5] Jason Bailey. 2019. Breeding Paintings With Machine Learning.
https://www.artnome.com/news/2019/8/25/breeding-paintings-with-machine-
learning (2019).
[6] Jason Bailey. 2020. 2020 Art Market Predictions.
https://www.artnome.com/news/2020/1/27/2020-art-market-predictions (2020).
[7] Jason Bailey. 2020. The tools of generative art from flash to neural net-
works. https://www.artnews.com/art-in-america/features/generative-art-tools-
flash-processing-neural-networks-1202674657/ (2020).
[8] Elias Bareinboim et al. 2020. Causal Fusion. In https://causalfusion.net.
[9] Elias Bareinboim and Judea Pearl. 2012. Transportability of Causal Effects:
Completeness Results. In AAAI.
[10] Elias Bareinboim and Judea Pearl. 2016. Causal inference and the data-fusion
problem. Proceedings of the National Academy of Sciences (2016).
[11] Margaret Boden and Ernest Edmonds. 2009. What is Generative Art. Digital
Creativity (2009).
[12] Rodney Brooks. 2017. The Seven Deadly Sins of AI Predictions. MIT Technology
Review (2017).
[13] McAndrew C. 2019. The art market. An Art Basel and UBS Report.
https://www.artbasel.com/about/initiatives/the-art-market (2019).
[14] Reas C and Fry B. 2007. Processing: a programming handbook for visual designers
and artists. MIT Press (2007).
[15] Christies. 2018. Is artificial intelligence set to become art’s next medium?
https://goo.gl/4LDZjX (2018).
[16] Mark Coeckelbergh. 2017. Can Machines Create Art? Philosophy and Technology
(2017).
[17] Kate Crawford and Trevor Paglen. 2019. Excavating AI: The Politics of Images in
Machine Learning Training Sets. https://www.excavating.ai (2019).
[18] Novitz D. 1987. Knowledge, Fiction, and Imagination. Temple University Press
(1987).
[19] Antonio Daniele and Yi-Zhe Song. 2019. AI+Art= Human. AAAI AI Ethics and
Society (2019).
[20] Deepart.io. 2020. Deepart.io. https://deepart.io (2020).
[21] E. Dissanayake. 2001. Where art comes from and Why. University of Washington
Press (2001).
[22] Katherine Dunbabin. 1999. Mosaics of the Greek and Roman World. Cambridge
University Press (1999).
[23] Anna Brzyski (Editor). 2007. Partisan Canons. Duke University Press (2007).
[24] Ahmed Elgammal. 2019. Faceless Portraits Transcending Time. HG Contem-
porary New York https://uploads.strikinglycdn.com/files/3e2cdfa0-8b8f-44ea-a6ca-
d12f123e3b0c/AICAN-HG-Catalogue-web.pdf (2019).
[25] Ahmed Elgammal, Bingchen Liu, Mohamed Elhoseiny, andMarianMazzone. 2017.
CAN: Creative Adversarial Networks, Generating "Art" by Learning About Styles
and Deviating from Style Norms. International Conference on Computational
Creativity (ICCC) (2017).
[26] Leon A. Gatys, Alexander S Ecker, and Matthias Bethge. 2016. Image Style
Transfer Using Convolutional Neural Networks. Computer Vision and Pattern
Recognition (2016).
[27] Timnit Gebru and Emily Denton. 2020. Tutorial on Fairness Accountability
Transparency and Ethics in Computer Vision. CVPR Tutorial (2020).
[28] Bruce Glymour and Jonathan Herington. 2019. Measuring the Biases that Matter.
FaccT (2019).
[29] GoART. 2020. GoART: AI Photo Effects. http://goart.fotor.com.s3-website-us-west-
2.amazonaws.com (2020).
[30] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-
Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative
adversarial nets. NeurIPS (2014).
[31] Tim Gorichanaz. 2020. Engaging with Public Art: An Exploration of the Design
Space. CHI (2020).
[32] David Ha and Douglas Eck. 2018. A Neural Representation of Sketch Drawings.
International Conference on Learning Representations (2018).
[33] Paul Haeberli. 1990. Paint By Numbers: Abstract Image Representations. SIG-
GRAPH (1990).
[34] Aaron Hertzmann. 2018. Can Computers create Art? Arts (2018).
[35] Aaron Hertzmann, C. Jacobs, N. Oliver, B. Curless, and D.H. Salesin. 2001. Image
Analogies. SIGGRAPH (2001).
[36] Joo-Wha Hong. 2018. Bias in Perception of Art Produced by Artificial Intelligence.
International Conference on Human Computer Interaction (2018).
[37] Instapainting. 2020. AI painter. https://www.instapainting.com/ai-painter (2020).
[38] Edward Ongweso Jr. 2019. Racial Bias in AI Isn’t Getting Better and Neither Are
Researchers’ Excuses. https://www.vice.com/en_us/article/8xzwgx/racial-bias-in-
ai-isnt-getting-better-and-neither-are-researchers-excuses (2019).
[39] Christine Kaeser-Chen, Elizabeth Dubois, Friederike Schuur, and Emanuel Moss.
2020. Positionality-aware machine learning: translation tutorial. FAccT Tutorial
(2020).
[40] Matt J. Kusner, Joshua R. Loftus, Chris Russell, and Ricardo Silva. 2017. Counter-
factual Fairness. NeurIPS (2017).
[41] A. Leroi-Gourhan. 1993. Gesture and Speech. MIT Press (1993).
[42] Heidegger M. 1977. The question concerning technology, and other essays.
Garland Publishing INC (1977).
[43] Dan Macnish. 2020. Draw this. https://danmacnish.com/drawthis/ (2020).
[44] Authur Miller. 2019. The Artist in the Machine The World of AI-Powered Cre-
ativity. MIT Press (2019).
[45] Alexander Mordvintsev, Christopher Olah, and Mike Tyka. 2015. Deep Dream.
https://github.com/google/deepdream (2015).
[46] MoMA: Musuem of Modern Art. 2020. Gino Severini: Armoured Train in Action.
In https://www.moma.org/collection/works/33837.
[47] Oxford Art Online. 2020. Impressionism and Post-Impressionism.
https://www.oxfordartonline.com/page/impressionism-and-post-
impressionism/impressionism-and-postimpressionism (2020).
[48] Judea Pearl. 2009. Causality: Models, Reasoning and Inference, 2nd Edition.
Cambridge University Press (2009).
[49] Judea Pearl and Elias Bareinboim. 2014. External Validity: From Do-Calculus to
Transportability Across Populations. Statistical Sciences (2014).
[50] Scott Plous. 1993. The psychology of judgment and decision making. Mc-Graw
Hill (1993).
[51] Martin Ragot, Nicolas Martin, and Salomé Cojean. 2020. AI-generated vs. Human
Artworks. A Perception Bias Towards Artificial Intelligence? CHI: Late Breaking
Work (2020).
[52] The Art Story. 2020. Ernst Ludwig Kirchner - Biography and Legacy. In
https://www.theartstory.org/artist/kirchner-ernst-ludwig/life-and-legacy/#nav.
[53] Morgan Sung. 2019. The AI Renaissance portrait generator isn’t great at painting
people of color. https://mashable.com/article/ai-portrait-generator-pocs/ (2019).
[54] Wei Ren Tan, Chee Seng Chan, Hernan Aguirre, and Kiyoshi Tanaka. 2017.
ArtGAN: Artwork Synthesis with Conditional Categorical GANs. ArXiV (2017).
[55] Value. 2019. AI Artwork Goes Up for Auction for 30, 000 at Sotheby’s.
https://en.thevalue.com/articles/sothebys-ai-memories-of-passersby (2019).
[56] Vincent van Gogh. 1886. Letter to Horace M. Livens, Translated by Robert
Harrison. http://www.webexhibits.org/vangogh/letter/17/459a.htm (1886).
[57] Vincent van Gogh. 1888. Letter to Wilhelmina van Gogh,
Translated by Translated by Mrs. Johanna van Gogh-Bonger.
http://www.webexhibits.org/vangogh/letter/18/W04.htm (1888).
[58] VanGoghGallery. 2020. VINCENT VAN GOGH: POPPIES.
https://www.vangoghgallery.com/misc/poppies.html (2020).
[59] James Voorhies). 2004. Paul Cézanne (1839–1906). Heilbrunn Timeline of Art
History (2004).
[60] Wikiart. 2020. Visual Art Encyclopedia. https://www.wikiart.org (2020).
[61] Wikipedia. 2020. Automation Bias. https://en.wikipedia.org/wiki/Automation_bias
(2020).
[62] Wikipedia. 2020. Futurism. https://en.wikipedia.org/wiki/Futurism (2020).
[63] Wikipedia. 2020. Generative Art. https://en.wikipedia.org/wiki/Generative_art
(2020).
[64] Wikipedia. 2020. Ukiyo-e. https://en.wikipedia.org/wiki/Ukiyo-e (2020).
[65] Michael J. Wilber, Chen Fang, Hailin Jin, Aaron Hertzmann, John Collomosse, and
Serge Belongie. 2017. BAM! The Behance Artistic Media Dataset for Recognition
Beyond Photography. ICCV (2017).
[66] Jeffrey M. Wooldridge. 2009. Omitted Variable Bias: The Simple Case. In Intro-
ductory Econometrics: A Modern Approach.
[67] David Young. 2019. Tabula Rasa: Rethinking the Intelligence of Machine Minds.
https://medium.com/@dkyy/tabula-rasa-b5f846e60859 (2019).
[68] James O. Young. 2001. Art and Knowledge. Routledge, London, UK (2001).
[69] Lieberman Z., Watson T., and Castro A et. al. 2009. Openframeworks.
https://goo.gl/41tycE (2009).
[70] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A. Efros. 2017. Unpaired
Image-to-Image Translation using Cycle-Consistent Adversarial Networks. ICCV
(2017).
51

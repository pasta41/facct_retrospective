A Statistical Test for Probabilistic Fairness
Bahar Taskesen
Ecole Polytechnique FÃ©dÃ©rale de Lausanne
Switzerland
bahar.taskesen@epfl.ch
Jose Blanchet
jose.blanchet@stanford.edu
Stanford University
USA
Daniel Kuhn
Ecole Polytechnique FÃ©dÃ©rale de Lausanne
Switzerland
daniel.kuhn@epfl.ch
Viet Anh Nguyen
Stanford University
USA
viet-anh.nguyen@stanford.edu
ABSTRACT
Algorithms are now routinely used to make consequential decisions
that affect human lives. Examples include college admissions, med-
ical interventions or law enforcement. While algorithms empower
us to harness all information hidden in vast amounts of data, they
may inadvertently amplify existing biases in the available datasets.
This concern has sparked increasing interest in fair machine learn-
ing, which aims to quantify andmitigate algorithmic discrimination.
Indeed, machine learning models should undergo intensive tests to
detect algorithmic biases before being deployed at scale. In this pa-
per, we use ideas from the theory of optimal transport to propose a
statistical hypothesis test for detecting unfair classifiers. Leveraging
the geometry of the feature space, the test statistic quantifies the
distance of the empirical distribution supported on the test samples
to the manifold of distributions that render a pre-trained classi-
fier fair. We develop a rigorous hypothesis testing mechanism for
assessing the probabilistic fairness of any pre-trained logistic classi-
fier, and we show both theoretically as well as empirically that the
proposed test is asymptotically correct. In addition, the proposed
framework offers interpretability by identifying the most favorable
perturbation of the data so that the given classifier becomes fair.
CCS CONCEPTS
â€¢ Applied computingâ†’ IT governance; Law; â€¢ Social and pro-
fessional topics â†’ Race and ethnicity; Geographic charac-
teristics; Sexual orientation; Gender; Age; â€¢ Theory of com-
putationâ†’Mathematical optimization.
KEYWORDS
fairness, algorithmic bias, equal opportunity, equalized odds,Wasser-
stein distance
ACM Reference Format:
Bahar Taskesen, Jose Blanchet, Daniel Kuhn, and Viet Anh Nguyen. 2021.
A Statistical Test for Probabilistic Fairness. In ACM Conference on Fairness,
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
FAccT â€™21, March 1â€“10, 2021, Virtual Event, Canada
Â© 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-8309-7/21/03. . . $15.00
https://doi.org/10.1145/3442188.3445927
Accountability, and Transparency (FAccT â€™21), March 1â€“10, 2021, Virtual
Event, Canada. ACM, New York, NY, USA, 18 pages. https://doi.org/10.1145/
3442188.3445927
1 INTRODUCTION
The past decade witnessed data and algorithms becoming an inte-
grative part of the human society. Recent technological advances
are now allowing us to collect and store an astronomical amount of
unstructured data, and the unprecedented computing power is en-
abling us to convert these data into decisional insights. Nowadays,
machine learning algorithms can uncover complex patterns in the
data to produce an exceptional performance that can match, or even
surpass, that of humans. These algorithms, as a consequence, are
proliferating in every corner of our lives, from suggesting us the
next vacation destination to helping us create digital paintings and
melodies. Machine learning algorithms are also gradually assisting
humans in consequential decisions such as deciding whether a stu-
dent is admitted to college, picking which medical treatment to be
prescribed to a patient, and determining whether a person is con-
victed. Arguably, these decisions impact radically many peopleâ€™s
lives, together with the future of their loved ones.
Algorithms are conceived and function following strict rules of
logic and algebra; it is hence natural to expect that machine learn-
ing algorithms deliver objective predictions and recommendations.
Unfortunately, in-depth investigations reveal the excruciating real-
ity that state-of-the-art algorithmic assistance is far from being free
of biases. For example, a predictive algorithm widely used in the
United States criminal justice system is more likely to misclassify
African-American offenders into the group of high recidivism risk
compared to white-Americans [12, 46]. The artificial intelligence
tool developed by Amazon also learned to penalize gender-related
keywords such as â€œwomenâ€™sâ€ in the profile screening process, and
thus may prefer to recommend hiring male candidates for soft-
ware development and technical positions [17]. Further, Googleâ€™s
ad-targeting algorithm displayed advertisements for higher-paying
executive jobs more often to men than to women [18].
There are several possible explanations for why cold, soulless
algorithms may trigger biased recommendations. First, the data
used to train machine learning algorithms may already encrypt hu-
man biases manifested in the data collection process. These biases
arise as the result of a suboptimal design of experiments, or from
historically biased human decisions that accumulate over centuries.
Machine-learned algorithms, which are apt to detect underlying
patterns from data, will unintentionally learn and maintain these
648
FAccT â€™21, March 1â€“10, 2021, Virtual Event, Canada Bahar Taskesen, Jose Blanchet, Daniel Kuhn, and Viet Anh Nguyen
existing biases [9, 43]. For example, secretary or primary school
teacher are professions which are predominantly taken by women,
thus, natural language processing systems are inclined to associate
female attributes to these jobs. Second, training a machine learn-
ing algorithm typically involves minimizing the prediction error
which privileges the majority populations over the minority groups.
Clinical trials, for instance, typically involve very few participants
from the minority groups such as indigenous people, and thus med-
ical interventions recommended by the algorithms may not align
perfectly to the characteristics and interests of patients from the
minority groups. Finally, even when the sensitive attributes are
not used in the training phase, strong correlations between the
sensitive attributes and the remaining variables in the dataset may
be exploited to generate unjust actions. For example, the sensitive
attribute of race can be easily inferred with high accuracy based
on common non-sensitive attributes such as the travel history of
passengers or the grocery shopping records of customers.
The pressing needs to redress undesirable algorithmic biases
have propelled the rising field of fair machine learning
1
. A building
pillar of this field involves the verification task: given a machine
learning algorithm, we are interested in verifying if this algorithm
satisfies a chosen criterion of fairness. This task is performed in
two steps: first, we choose an appropriate notion of fairness, then
the second step invokes a computational procedure, which may
or may not involve data, to decide if the chosen fairness criterion
is fulfilled. A plethora of criteria for fair machine learning were
proposed in the literature, many of them are motivated by philo-
sophical or sociological ideologies or legal constraints. For example,
anti-discrimination laws may prohibit making decisions based on
sensitive attributes such as age, gender, race or sexual orienta-
tion. Thus, a naÃ¯ve strategy, called fairness through unawareness,
involves removing all sensitive attributes from the training data.
However, this strategy seldom guarantees any fairness due to the
inter-correlation issues [27, 30], and thus potentially fails to gener-
ate inclusive outcomes [2, 6, 36, 41]. Other notions of fairness aim to
either promote individual fairness [21], prevent disparate treatment
[70] or avoid disparate mistreatment [23, 71] of the algorithms. To-
wards similar goals, notions of group fairness focus on reducing the
difference of favorable outcomes proportions among different sen-
sitive groups. Examples of group fairness notions include disparate
impact [70], demographic parity (statistical parity) [10, 21], equality
of opportunity [31] and equalized odds [31]. The notion of coun-
terfactual fairness [27] was also suggested as a measure of causal
fairness. Despite the abundance of available notions, there is un-
fortunately no general consensus on the most suitable measure to
serve as the industry standard. Moreover, except in trivial cases, it
is not possible for a machine learning algorithm to simultaneously
satisfy multiple notions of fairness [5, 37]. Therefore, the choice of
the fairness notion is likely to remain more an art than a science.
This paper focuses not on the normative approach to choosing
an ideal notion of machine learning fairness. We endeavor in this
paper to shed more light on the computational procedure to com-
plement the verification task. Concretely, we position ourselves in
the classification setting, which is arguably the most popular task
in machine learning. Moreover, we will focus on notions of group
1
Comprehensive surveys on fair machine learning can be found in [5, 13, 14, 44].
fairness, and we employ the framework of statistical hypothesis
test instead of algorithmic test.
Contributions. Our paper makes two concrete contributions to
the problem of fairness testing of machine learningâ€™s classifiers.
(1) We propose the Wasserstein projection framework to perform
statistical hypothesis test of group fairness for classification
algorithms. We derive in details the computation of the test
statistic and the limiting distribution when fairness is measured
using the probabilistic equality of opportunity and probabilistic
equalized odds criteria.
(2) We demonstrate that the Wasserstein projection hypothesis test-
ing paradigm is asymptotically correct and can exploit additional
information on the geometry of the feature space. Moreover,
we also show that this paradigm promotes transparency and
interpretability through the analysis of the most favorable dis-
tributions.
The remaining of the paper is structured as follows. In Section 2,
we introduce the general problem of statistical hypothesis test of
classification fairness, and depict the current landscape of fairness
testing in the literature. Section 3 details ourWasserstein projection
approach to this problem. Sections 4 and 5 apply the proposed
framework to test if a pre-trained logistic classifier satisfies the
fairness notion of probabilistic equal opportunity and probabilistic
equalized odds, respectively. Numerical experiments are presented
in Section 6 to empirically validate the correctness and demonstrate
the power of our proposed paradigm. Section 7 concludes the paper
with outlooks on the broader impact of our Wasserstein projection
hypothesis testing approach.
All technical proofs are relegated to the Appendix.
2 STATISTICAL TESTING FRAMEWORK FOR
FAIRNESS AND LITERATURE REVIEW
We consider throughout this paper a generic binary classification
setting. Let X = Rğ‘‘ and Y = {0, 1} be the space of feature inputs
and label outputs of interest. We assume that there is a single
sensitive attribute corresponding to each data point and its space is
denoted byA = {0, 1}. A probabilistic classifier is represented by a
functionâ„(Â·) : X â†’ [0, 1] that outputs for each given sample ğ‘¥ âˆˆ X
the probability that ğ‘¥ belongs to the positive class. The deterministic
classifier predicts class 1 if â„(ğ‘¥) â‰¥ ğœ and class 0 otherwise, where
ğœ âˆˆ [0, 1] is a classification threshold. Note that the function â„
depends only on the feature ğ‘‹ , but not on the sensitive attribute ğ´,
thus predicting ğ‘Œ using â„ satisfies fairness through unawareness.
The central goal of this paper is to provide a statistical test to
detect if a classifier â„ fails to satisfy a prescribed notion of machine
learning fairness. A statistical hypothesis test can be cast with the
null hypothesis being
H0: the classifier â„ is fair,
against the alternative hypothesis being
H1: the classifier â„ is not fair.
In this paper, we focus on statistical notions of group fairness, which
are usually defined using conditional probabilities. A prevalent
notion of fairness in machine learning is the criterion of equality of
649
A Statistical Test for Probabilistic Fairness FAccT â€™21, March 1â€“10, 2021, Virtual Event, Canada
opportunity
2
, which requires that the true positive rate are equal
between subgroups.
Definition 2.1 (Equal opportunity [31]). A classifier â„(Â·) : X â†’
[0, 1] satisfies the equal opportunity criterion relative to Q if
Q(â„(ğ‘‹ ) â‰¥ ğœ |ğ´ = 1, ğ‘Œ = 1) = Q(â„(ğ‘‹ ) â‰¥ ğœ |ğ´ = 0, ğ‘Œ = 1),
where ğœ is the classification threshold.
Another popular criterion of machine learning fairness is the
equalized odds, which is more stringent than the equality of op-
portunity: it requires that the positive outcome is conditionally
independent of the sensitive attributes given the true label.
Definition 2.2 (Equalized odds [31]). A classifierâ„(Â·) : X â†’ [0, 1]
satisfies the equalized odds criterion relative to Q if
Q(â„(ğ‘‹ ) â‰¥ğœ |ğ´=1,ğ‘Œ =ğ‘¦)=Q(â„(ğ‘‹ ) â‰¥ğœ |ğ´=0,ğ‘Œ =ğ‘¦) âˆ€ğ‘¦ âˆˆY,
where ğœ is the classification threshold.
Notice that the criteria of fairness presented in Definitions 2.1
and 2.2 are dependent on the distribution Q: a classifier â„ can be
fair relative to a distribution Q1, but it may become unfair with
respect to another distribution Q2 â‰  Q1. If we denote by P the true
population distribution that governs the random vector (ğ‘‹,ğ´,ğ‘Œ ),
then it is imperative and reasonable to test for group fairness with
respect to P. For example, to test for the equality of opportunity,
we can reformulate a two-sample equal conditional mean test of
the null hypothesis
H0 : EP [1â„ (ğ‘‹ ) â‰¥ğœ |ğ´ = 1, ğ‘Œ = 1] = EP [1â„ (ğ‘‹ ) â‰¥ğœ |ğ´ = 0, ğ‘Œ = 1],
and one can potentially employ a Welchâ€™s ğ‘¡-test with proper adjust-
ment for the randomness of the sample size. Unfortunately, deriving
the test becomes complicated when the null hypothesis involves an
equality of multi-dimensional quantities, which arises in the case
of equalized odds, due to the complication of the covariance terms.
Variations of the permutation tests were also proposed to detect
discriminatory behaviour of machine learning algorithms following
the same formulation of the one-dimensional two-sample equal-
ity of conditional mean test [19, 66]. However, these permutation
tests follow a black-box mechanism and are unable to be gener-
alized to multi-dimensional tests. Tests based on group fairness
notions can also be accomplished using an algorithmic approach
as in [19, 29, 35, 57].
From a broader perspective, deriving tests for fairness is an active
area of research, and many testing procedures have been recently
proposed to test for individual fairness [34, 68], for counterfactual
fairness [6, 27] and diverse other criteria [3, 66, 67].
Literature related to optimal transport. Optimal transport is
a long-standing field that dates back to the seminal work of Gas-
pard Monge [45]. In the past few years, it has attracted signif-
icant attention in the machine learning and computer science
communities thanks to the availability of fast approximation al-
gorithms [4, 8, 16, 20, 28]. Optimal transport is particularly suc-
cessful in various learning tasks, notably generative mixture mod-
els [38, 49], image processing [1, 24, 39, 50, 63], computer vision
and graphics [51, 52, 56, 61, 62], clustering [32], dimensionality
reduction [11, 25, 55, 58, 59], domain adaptation [15, 47], signal
2
We use two terms â€œequality of opportunityâ€ and â€œequal opportunityâ€ interchangeably.
processing [65] and data-driven distributionally robust optimiza-
tion [7, 26, 40, 72]. Recent comprehensive survey on optimal trans-
port and its applications can be found in [38, 53].
In the context of fair classification, ideas from optimal transport
have been used to construct fair logistic classifier [64], to detect
classifiers that does not obey group fairness notions, or to ensure
fairness by pre-processing [29], to learn a fair subspace embedding
that promotes fair classification [69], to test individual fairness [68],
or to construct a counterfactual test [6].
3 WASSERSTEIN PROJECTION FRAMEWORK
FOR STATISTICAL TEST OF FAIRNESS
We hereby provide a fresh alternative to the testing problem of
machine learning fairness. On that purpose, for a given classifier â„,
we define abstractly the following set of distributions
Fâ„ = {Q âˆˆ P : the classifier â„ is fair relative to Q} , (1)
where P denotes the space of all distributions on X Ã— A Ã— Y.
Intuitively, the set Fâ„ contains all probability distributions under
which the classifier â„ satisfies the prescribed notion of fairness. It is
trivial to see that ifFâ„ contains the true data-generating distribution
P, then the classifier â„ is fair relative to P. Thus, we can reinterpret
the hypothesis test of fairness using the hypotheses
H0: P âˆˆ Fâ„ , H1: P âˆ‰ Fâ„ .
Testing the inclusion of P in Fâ„ is convenient if P is endowed with
a distance. In this paper, we equip P with the Wasserstein distance.
Definition 3.1 (Wasserstein distance). The type-2 Wasserstein
distance between two probability distributions Q and Qâ€² supported
on Î is defined as
W(Qâ€²,Q) = min
ğœ‹ âˆˆÎ  (Qâ€²,Q)
âˆš
Eğœ‹ [ğ‘ (b â€², b)2],
where the setÎ (Qâ€²,Q) contains all joint distributions of the random
vectors b â€² âˆˆ Î and b âˆˆ Î under which b â€² and b have marginal
distributions Qâ€² and Q, respectively, and ğ‘ : Î Ã— Î â†’ [0,âˆ]
constitutes a lower semi-continuous ground metric.
The type-2 Wasserstein distance
3
is a special instance of the
optimal transport. The squared Wasserstein distance between Qâ€²
and Q can be interpreted as the cost of moving the distribution
Qâ€² to Q, where ğ‘ (b â€², b) is the cost of moving a unit mass from b â€²
to b . Being a distance on P, W is symmetric, non-negative and
vanishes to zero if Qâ€² = Q. The Wasserstein distance is hence an
attractive measure to identify if P belongs to Fâ„ . Using this insight,
the hypothesis test for fairness has the equivalent representation
H0: infQâˆˆFâ„ W(P,Q) = 0, H1: infQâˆˆFâ„ W(P,Q) > 0.
Even though P remains elusive to our knowledge, we are given
access to a set of i.i.d test samples {(ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– )}ğ‘ğ‘–=1
generated from
the true distribution P. Thus we can rely on the empirical value
inf
QâˆˆFâ„
W( Ë†Pğ‘ ,Q),
which is the distance from the empirical distribution supported on
the samples
Ë†Pğ‘ =
âˆ‘ğ‘
ğ‘–=1
ğ›¿ (ğ‘¥ğ‘– ,ğ‘ğ‘– ,?Ì‚?ğ‘– ) to the set Fâ„ . To perform the test,
it is sufficient to study the limiting distribution of the test statistic
using proper scaling under the null hypothesisH0. The outcome of
3
From this point, we omit the term â€œtype-2â€ for brevity.
650
FAccT â€™21, March 1â€“10, 2021, Virtual Event, Canada Bahar Taskesen, Jose Blanchet, Daniel Kuhn, and Viet Anh Nguyen
the test is determined by comparing the test statistic to the quantile
value of the limiting distribution at a chosen level of significant
ğ›¼ âˆˆ (0, 1).
Advantages. The Wasserstein projection framework to hypothesis
testing that we described above offers several advantages over the
existing methods.
(1) Geometric flexibility: The definition of the Wasserstein distance
implies that there exists a joint ground metric ğ‘ on the space of
the features, the sensitive attribute and the label. If the modelers
or the regulators possess any structural information on an ap-
propriate metric on Î = X Ã— A Ã—Y, then this information can
be exploited in the testing procedure. Thus, the Wasserstein pro-
jection framework equips the users with an additional freedom
to inject prior geometric information into the statistical test.
(2) Mutivariate generalizability: Certain notions of fairness, such
as equalized odds, are prescribed using multiple equalities of
conditional expectations. TheWasserstein projection framework
encapsulates these equalities simultaneously in the definition of
the set Fâ„ , and provides a joint test of these equalities without
the hassle of decoupling and testing individual equalities as
being done in the currently literature.
(3) Interpretability: If we denote by Qâ˜… the projection of the empir-
ical distribution
Ë†Pğ‘ onto the set of distributions Fâ„ , i.e.,
Qâ˜… = arg min
QâˆˆFâ„
W( Ë†Pğ‘ ,Q),
then Qâ˜… encodes the minimal perturbation to the empirical sam-
ples so that the classifier â„ becomes fair. The distribution Qâ˜… is
thus termed the most favorable distribution, and examining Qâ˜…
can reveal the underlying mechanism and explain the outcome
of the hypothesis test. The accessibility to Qâ˜… showcases the
expressiveness of the Wasserstein projection framework.
Whilst theoretically sound and attractive, there are three poten-
tial difficulties with the Wasserstein projection approach to statis-
tical test of fairness. First, to project
Ë†Pğ‘ onto the set Fâ„ , we need
to solve an infinite-dimensional optimization problem, which is
inherently difficult. Second, for many notions of machine learning
fairness such as the equality of opportunity and the equalized odds,
the corresponding set Fâ„ in (1) is usually prescribed using nonlinear
constraints. For example, if we consider the equal opportunity cri-
terion in Definition 2.1, then the set Fâ„ can be re-expressed using a
fractional function of the probability measure as
Fâ„ =ï£±ï£´ï£´ï£²ï£´ï£´ï£³
Q âˆˆ P such that
Q(â„(ğ‘‹ ) â‰¥ ğœ,ğ´ = 1, ğ‘Œ = 1)
Q(ğ´ = 1, ğ‘Œ = 1) =
Q(â„(ğ‘‹ ) â‰¥ ğœ,ğ´ = 0, ğ‘Œ = 1)
Q(ğ´ = 0, ğ‘Œ = 1)
ï£¼ï£´ï£´ï£½ï£´ï£´ï£¾ .
Apart from involving nonlinear constraints, it is easy to verify that
the set Fâ„ is also non-convex, which amplifies the difficulty of
computing the projection onto Fâ„ . Finally, the limiting distribution
of the test statistic is difficult to analyze due to the discontinuity
of the probability function at the set {ğ‘¥ âˆˆ X : â„(ğ‘¥) = ğœ}. The
asymptotic analysis with this discontinuity is of a combinatorial
nature, and is significantly more problematic than the asymptotic
analysis of smooth quantities.
While these difficulties may be overcome via various ways, in
this paper we choose the following combination of remedies. First,
we will use a relaxed notion of fairness termed probabilistic fairness,
which was originally introduced in [54]. Second, when computing
the Wasserstein distances between distributions on X Ã—A Ã—Y, we
use
ğ‘
(
(ğ‘¥ â€², ğ‘â€², ğ‘¦â€²), (ğ‘¥, ğ‘,ğ‘¦)
)
= âˆ¥ğ‘¥ âˆ’ ğ‘¥ â€²âˆ¥ + âˆ|ğ‘ âˆ’ ğ‘â€² | + âˆ|ğ‘¦ âˆ’ ğ‘¦â€² | (2)
as the ground metric, where âˆ¥ Â· âˆ¥ is a norm on Rğ‘‘ . This case corre-
sponds to having an absolute trust in the label and in the sensitive
attribute of the training samples. This absolute trust restriction is
common in the literature of fair machine learning [64, 68].
We now briefly discuss the advantage of using the ground met-
ric of the form (2). Denote by ğ‘ âˆˆ R |A |Ã—|Y |++ the array of the true
marginals of (ğ´,ğ‘Œ ), in particular, ğ‘ğ‘ğ‘¦ = P(ğ´ = ğ‘,ğ‘Œ = ğ‘¦) for all
ğ‘ âˆˆ A and ğ‘¦ âˆˆ Y. Further, let ğ‘ğ‘ âˆˆ R |A |Ã—|Y |++ be the array of the
empirical marginals of (ğ´,ğ‘Œ ) under the empirical measure
Ë†Pğ‘ , that
is, ğ‘ğ‘ğ‘ğ‘¦ = Ë†Pğ‘ (ğ´ = ğ‘,ğ‘Œ = ğ‘¦) for all ğ‘ âˆˆ A and ğ‘¦ âˆˆ Y. Through-
out this paper, we assume that the empirical marginals are proper,
that is, ğ‘ğ‘ğ‘ğ‘¦ âˆˆ (0, 1) for any (ğ‘,ğ‘¦) âˆˆ A Ã— Y. We define temporar-
ily the simplex set Î” B {ğ‘ âˆˆ R |A |Ã—|Y |++ :
âˆ‘
ğ‘âˆˆA,ğ‘¦âˆˆY ğ‘ğ‘ğ‘¦ = 1}.
Subsequently, for any marginals ğ‘ âˆˆ Î”, we define the marginally-
constrained set of distributions
Fâ„ (ğ‘) â‰œ
{
Q âˆˆ P :
â„ is fair relative to Q
Q(ğ´ = ğ‘,ğ‘Œ = ğ‘¦) = ğ‘ğ‘ğ‘¦ âˆ€(ğ‘,ğ‘¦) âˆˆ A Ã— Y
}
.
Using these notations, one can readily verify that Fâ„ = âˆªğ‘âˆˆÎ”Fâ„ (ğ‘) .
Moreover, the next result asserts that in order to compute the pro-
jection of
Ë†Pğ‘ onto Fâ„ , to suffices to project onto the marginally-
constrained set Fâ„ (ğ‘ğ‘ ).
Lemma 3.2 (Projection with marginal restrictions). Suppose that
the ground metric is chosen as in (2). If a measure Q âˆˆ Fâ„ satisfies
W( Ë†Pğ‘ ,Q) < âˆ, then Q âˆˆ Fâ„ (ğ‘ğ‘ ).
A useful consequence of Lemma 3.2 is that
inf
QâˆˆFâ„
W( Ë†Pğ‘ ,Q) = inf
QâˆˆFâ„ (ğ‘ğ‘ )
W( Ë†Pğ‘ ,Q), (3)
where the feasible set of the problem on the right-hand side is the
marginally-constrained set Fâ„ (ğ‘ğ‘ ) using the empirical marginals
ğ‘ğ‘ . For two notions of probabilistic fairness that we will explore in
this paper, projecting
Ë†Pğ‘ onto Fâ„ (ğ‘ğ‘ ) is arguably easier than onto
Fâ„ . Thus, this choice of ground metric improves the tractability
when computing the test statistic.
Third, and finally, we will focus on the logistic regression setting,
which is one of the most popular classification methods [33]. In this
setting, the conditional probability P[ğ‘Œ = 1|ğ‘‹ = ğ‘¥] is modelled by
the sigmoid function â„ğ›½ (ğ‘¥) = (1 + exp(âˆ’ğ›½âŠ¤ğ‘¥))âˆ’1, where ğ›½ âˆˆ Rğ‘‘
is the regression parameter. Moreover, a classifier with ğ›½ = 0, is
trivially fair. Thus, it suffices to consider ğ›½ â‰  0.
Notations. We use âˆ¥ Â· âˆ¥âˆ— to denote the dual norm of âˆ¥ Â· âˆ¥. For any
integer ğ‘ , we define [ğ‘ ] B {1, 2, . . . , ğ‘ }. Given ğ‘ test samples
(ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– )ğ‘ğ‘–=1
, we use Iğ‘¦ â‰œ {ğ‘– âˆˆ [ğ‘ ] : ğ‘¦ğ‘– = ğ‘¦} to denote the index
set of observations with label ğ‘¦. The parameters _ğ‘– are defined as
âˆ€ğ‘– âˆˆ [ğ‘ ] : _ğ‘– =
ï£±ï£´ï£´ï£´ï£´ï£´ï£²ï£´ï£´ï£´ï£´ï£´ï£³
(ğ‘ğ‘
11
)âˆ’1
if (ğ‘ğ‘– , ğ‘¦ğ‘– ) = (1, 1),
âˆ’(ğ‘ğ‘
01
)âˆ’1
if (ğ‘ğ‘– , ğ‘¦ğ‘– ) = (0, 1),
(ğ‘ğ‘
10
)âˆ’1
if (ğ‘ğ‘– , ğ‘¦ğ‘– ) = (1, 0),
âˆ’(ğ‘ğ‘
00
)âˆ’1
if (ğ‘ğ‘– , ğ‘¦ğ‘– ) = (0, 0) .
(4)
651
A Statistical Test for Probabilistic Fairness FAccT â€™21, March 1â€“10, 2021, Virtual Event, Canada
4 TESTING FAIRNESS FOR PROBABILISTIC
EQUAL OPPORTUNITY CRITERION
In this section, we use the ingredients introduced in the previous
section to concretely construct a statistical test for the fairness of a
logistic classifier â„ğ›½ . Specifically, we will employ the probabilistic
equal opportunity criterion which was originally proposed in [54].
Definition 4.1 (Probabilistic equal opportunity criterion [54]). A
logistic classifier â„ğ›½ : X â†’ [0, 1] satisfies the probabilistic equal-
ized opportunity criteria relative to a distribution Q if
EQ [â„ğ›½ (ğ‘‹ ) |ğ´ = 1, ğ‘Œ = 1] = EQ [â„ğ›½ (ğ‘‹ ) |ğ´ = 0, ğ‘Œ = 1] .
The probabilistic equal opportunity criterion, which serves as
a surrogate for the equal opportunity criterion in Definition 2.1,
depends on the smooth and bounded sigmoid function â„ğ›½ but is
independent of the classification threshold ğœ . Motivated by [42],
we empirically illustrate in Figure 1 that the probabilistic surrogate
provides a good approximation of the equal opportunity criterion.
Figure 1a plots the absolute difference of the classification probabil-
ities |P(â„(ğ‘‹ ) â‰¥ 1
2
|ğ´ = 1, ğ‘Œ = 1) âˆ’P(â„(ğ‘‹ ) â‰¥ 1
2
|ğ´ = 0, ğ‘Œ = 1) |, while
Figure 1b plots the absolute difference of the sigmoid expectations
|EP [â„(ğ‘‹ ) |ğ´ = 1, ğ‘Œ = 1]âˆ’EP [â„(ğ‘‹ ) |ğ´ = 0, ğ‘Œ = 1] |. One may observe
that the regions of ğ›½ so that the absolute differences fall close to
zero are similar in both plots. This implies that a logistic classifier
â„ğ›½ which is equal opportunity fair is also likely to be probabilistic
equal opportunity fair, and vice versa.
2 0 2
2
2
1
0
1
2
1
0.0
0.2
0.4
(a) Equal opportunity
2 0 2
2
2
1
0
1
2
1
0.2
0.4
(b) Probabilistic equal opportunity
Figure 1: Comparison of fairness notions for ğ‘‘ = 2 and
â„ğ›½ (ğ‘¥) = 1/(1 + exp( 1
3
âˆ’ ğ›½1ğ‘¥1 âˆ’ ğ›½2ğ‘¥2)).
We use the superscript â€œoppâ€ to emphasize that fairness is mea-
sured using the probabilistic equal opportunity criterion. Conse-
quentially, the set of distributions F opp
â„ğ›½
that makes the logistic
classifier â„ğ›½ fair is
F opp
â„ğ›½
=
{
Q âˆˆ P such that :
EQ [â„ğ›½ (ğ‘‹ ) |ğ´ = 1, ğ‘Œ = 1]=EQ [â„ğ›½ (ğ‘‹ ) |ğ´ = 0, ğ‘Œ = 1]
}
.
The statistical hypothesis test to verify whether the classifier â„ğ›½ is
fair is formulated with the null and alternative hypotheses
Hopp
0
: P âˆˆ F opp
â„ğ›½
, Hopp
1
: P âˆ‰ F opp
â„ğ›½
.
The remainder of this section unfolds as follows. In Section 4.1,
we delineate the computation of the projection of
Ë†Pğ‘ onto F opp
â„ğ›½
.
Section 4.2 studies the limiting distribution of the test statistic,
while Section 4.3 examines the most favorable distribution.
4.1 Wasserstein Projection
Lemma 3.2 suggests that it is sufficient to consider the projection
onto the marginally-constrained set F opp
â„ğ›½
(ğ‘ğ‘ ), where ğ‘ğ‘ is the
empirical marginals of the empirical distribution
Ë†Pğ‘ . In particular,
F opp
â„ğ›½
(ğ‘ğ‘ ) is
F opp
â„ğ›½
(ğ‘ğ‘ )
=
ï£±ï£´ï£´ï£²ï£´ï£´ï£³
Q âˆˆ P such that :
(ğ‘ğ‘
11
)âˆ’1EQ [â„ğ›½ (ğ‘‹ )1(1,1)(ğ´,ğ‘Œ )]= (ğ‘ğ‘01
)âˆ’1EQ [â„ğ›½ (ğ‘‹ )1(0,1)(ğ´,ğ‘Œ )]
Q(ğ´ = ğ‘,ğ‘Œ = ğ‘¦)=ğ‘ğ‘ğ‘ğ‘¦ âˆ€(ğ‘,ğ‘¦) âˆˆ A Ã— Y
ï£¼ï£´ï£´ï£½ï£´ï£´ï£¾,
where the equality follows from the law of conditional expectation.
Notice that the set F opp
â„ğ›½
(ğ‘ğ‘ ) is prescribed using linear constraints
of Q, and thus it is more amenable to optimization than the set
F opp
â„ğ›½
. It is also more convenient to work with the squared distance
function R whose input is the empirical distribution
Ë†Pğ‘ and its
corresponding vector of empirical marginals ğ‘ğ‘ by
Ropp ( Ë†Pğ‘ , ğ‘ğ‘ ) Bï£±ï£´ï£´ï£²ï£´ï£´ï£³
inf W(Q, Ë†Pğ‘ )2
s.t. EQ [â„ğ›½ (ğ‘‹ ) ((ğ‘ğ‘11
)âˆ’1
1(1,1)(ğ´,ğ‘Œ )âˆ’(ğ‘ğ‘01
)âˆ’1
1(0,1)(ğ´,ğ‘Œ ))]=0
EQ [1(ğ‘,ğ‘¦) (ğ´,ğ‘Œ )] = ğ‘ğ‘ğ‘ğ‘¦ âˆ€(ğ‘,ğ‘¦) âˆˆ A Ã— Y .
Notice that the constraints of the above infimum problem are linear
in the measure Q, but the functions inside the expectation opera-
tors are possibly nonlinear functions of ğ‘ğ‘ . Using the equivalent
characterization (3), the following relation holds
inf
QâˆˆFopp
â„ğ›½
W( Ë†Pğ‘ ,Q) = inf
QâˆˆFopp
â„ğ›½
(ğ‘ğ‘ )
W( Ë†Pğ‘ ,Q) =
âˆš
Ropp ( Ë†Pğ‘ , ğ‘ğ‘ ) .
We now proceed to show how computing the projection can be
reduced to solving a finite-dimensional optimization problem.
Proposition 4.2 (Dual reformulation). The squared projection
distance Ropp ( Ë†Pğ‘ , ğ‘ğ‘ ) equals to the optimal value of the following
finite-dimensional optimization problem
sup
ğ›¾ âˆˆR
1
ğ‘
âˆ‘
ğ‘–âˆˆI1
inf
ğ‘¥ğ‘– âˆˆX
{
âˆ¥ğ‘¥ğ‘– âˆ’ ğ‘¥ğ‘– âˆ¥2 + ğ›¾_ğ‘–â„ğ›½ (ğ‘¥ğ‘– )
}
. (5)
While Proposition 4.2 asserts that computing the squared pro-
jection distance Ropp ( Ë†Pğ‘ , ğ‘ğ‘ ) is equivalent to solving a finite-
dimensional problem, unfortunately, this saddle point problem is
in general difficult. Indeed, because â„ğ›½ is non-convex, even finding
the optimal inner solution ğ‘¥â˜…
ğ‘–
for a fixed value of the outer variable
ğ›¾ âˆˆ R is generally NP-hard [48]. The situation can be partially
alleviated if âˆ¥ Â· âˆ¥ is an Euclidean norm on Rğ‘‘ .
Lemma 4.3 (Univariate reduction). Suppose that âˆ¥ Â· âˆ¥ is the Eu-
clidean norm on Rğ‘‘ , we have
Ropp ( Ë†Pğ‘ , ğ‘ğ‘ ) =
sup
ğ›¾ âˆˆR
1
ğ‘
âˆ‘
ğ‘–âˆˆI1
min
ğ‘˜ğ‘– âˆˆ[0, 1
8
]
ğ›¾2_2
ğ‘– âˆ¥ğ›½ âˆ¥
2
2
ğ‘˜2
ğ‘– +
ğ›¾_ğ‘–
1 + exp(ğ›¾_ğ‘– âˆ¥ğ›½ âˆ¥2
2
ğ‘˜ğ‘– âˆ’ ğ›½âŠ¤ğ‘¥ğ‘– )
.
(6)
The proof of Lemma 4.3 follows trivially from application of
Lemma B.1 to reformulate the inner infimum problems for each
652
FAccT â€™21, March 1â€“10, 2021, Virtual Event, Canada Bahar Taskesen, Jose Blanchet, Daniel Kuhn, and Viet Anh Nguyen
ğ‘– âˆˆ I1. Lemma 4.3 offers a significant reduction in the computa-
tional complexity to solve the inner subproblems of (5). Instead
of optimizing over ğ‘‘-dimensional vector ğ‘¥ğ‘– , the representation in
Lemma 4.3 suggests that it suffices to search over a 1-dimensional
space for ğ‘˜ğ‘– . While the objective function is still non-convex in ğ‘˜ğ‘– ,
we can perform a grid search over a compact interval to find the
optimal solution for ğ‘˜ğ‘– to high precision. The grid search operations
can also be parallelized across the index ğ‘– thanks to the indepen-
dent structure of the inner problems. Furthermore, the objective
function of the supremum problem is a point-wise minimum of
linear, thus concave, functions of ğ›¾ . Hence, the outer problem is a
concave maximization problem in ğ›¾ , which can be solved using a
golden section search algorithm.
4.2 Limiting Distribution
Wenow characterize the limit properties ofRopp ( Ë†Pğ‘ , ğ‘ğ‘ ). The next
theorem assert that the limiting distribution is of the chi-square
type.
Theorem 4.4 (Limiting distribution â€“ Probabilistic equal opportu-
nity). Suppose that (ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– ) are i.i.d. samples from P. Under the
null hypothesisHopp
0
, we have
ğ‘ Ã— Ropp ( Ë†Pğ‘ , ğ‘ğ‘ ) ğ‘‘.âˆ’â†’ \ ğœ’2
1
,
where ğœ’2
1
is a chi-square distribution with 1 degree of freedom,
\ =
(
EP
[âˆ‡â„ğ›½ (ğ‘‹ ) (1(1,1) (ğ´,ğ‘Œ )ğ‘11
âˆ’
1(0,1) (ğ´,ğ‘Œ )
ğ‘01
)2
âˆ—
])âˆ’1
ğœ2
1
ğ‘2
01
ğ‘2
11
with ğœ2
1
= Cov(ğ‘1), and ğ‘1 is the random variable
ğ‘1 = â„ğ›½ (ğ‘‹ )
(
ğ‘011(1,1) (ğ´,ğ‘Œ ) âˆ’ ğ‘111(0,1) (ğ´,ğ‘Œ )
)
+ 1(0,1) (ğ´,ğ‘Œ )EP [1(1,1) (ğ´,ğ‘Œ )â„ğ›½ (ğ‘‹ )]
âˆ’ 1(1,1) (ğ´,ğ‘Œ )EP [1(0,1) (ğ´,ğ‘Œ )â„ğ›½ (ğ‘‹ )] .
Construction of the hypothesis test. Based on the result of The-
orem 4.4, the statistical hypothesis test proceeds as follows. Let
[
opp
1âˆ’ğ›¼ denote the (1 âˆ’ ğ›¼) Ã— 100% quantile of \ ğœ’2
1
, where ğ›¼ âˆˆ (0, 1) is
the predetermined significance level. By Theorem 4.4, the statistical
decision has the form
RejectHopp
0
if ğ‘ 
opp
ğ‘
> [
opp
1âˆ’ğ›¼ ,
with
ğ‘ 
opp
ğ‘
= ğ‘ Ã— Ropp ( Ë†Pğ‘ , ğ‘ğ‘ ) .
The limiting distribution \ ğœ’2
1
is nonpivotal because \ depends on
the true distribution P. Luckily, because the quantile function of
\ ğœ’2
1
is continuous in \ , if Ë†\ğ‘ is a consistent estimator of \ then it
is also valid to use the quantile of
Ë†\ğ‘ ğœ’2
1
for the purpose of testing.
We thus proceed to discuss a consistent estimator
Ë†\ğ‘ constructed
from the available data. First, notice that ğ‘ğ‘
01
and ğ‘ğ‘
11
are consistent
estimator for ğ‘01 and ğ‘11. Similarly, the law of large numbers asserts
that the denominator term in the definition of \ can be estimated
by the sample average
EP
[âˆ‡â„ğ›½ (ğ‘‹ ) (1(1,1) (ğ´,ğ‘Œ )ğ‘11
âˆ’
1(0,1) (ğ´,ğ‘Œ )
ğ‘01
)2
âˆ—
]
â‰ˆ ğ‘‡ğ‘ =
âˆ¥ğ›½ âˆ¥2âˆ—
ğ‘
ğ‘âˆ‘
ğ‘–=1
â„ğ›½ (ğ‘¥ğ‘– )2(1âˆ’â„ğ›½ (ğ‘¥ğ‘– ))2
(
1(1,1)(ğ‘ğ‘– , ğ‘¦ğ‘– )
(ğ‘ğ‘
11
)2
+
1(0,1)(ğ‘ğ‘– , ğ‘¦ğ‘– )
(ğ‘ğ‘
01
)2
)
.
Under the null hypothesisHopp
0
,ğ‘1 hasmean 0. The sample average
estimate of ğœ2
1
is ğœ2
1
â‰ˆ (?Ì‚?ğ‘ )2 with
(?Ì‚?ğ‘
1
)2 =
1
ğ‘
ğ‘âˆ‘
ğ‘–=1
[
â„ğ›½ (ğ‘¥ğ‘– )
(
ğ‘011(1,1) (ğ‘ğ‘– , ğ‘¦ğ‘– ) âˆ’ ğ‘111(0,1) (ğ´,ğ‘Œ )
)
+ 1(0,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
( ğ‘âˆ‘
ğ‘—=1
1(1,1) (ğ‘ ğ‘— , ğ‘¦ ğ‘— )â„ğ›½ (ğ‘¥ ğ‘— )
)
(7)
âˆ’ 1(1,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
( ğ‘âˆ‘
ğ‘—=1
1(0,1) (ğ‘ ğ‘— , ğ‘¦ ğ‘— )â„ğ›½ (ğ‘¥ ğ‘— )
) ]2
.
Using a nested arguments involving the continuous mapping theo-
rem and Slutskyâ€™s theorem, the estimator
Ë†\ğ‘ =
(?Ì‚?ğ‘
1
)2
ğ‘‡ğ‘ (ğ‘ğ‘
01
)2 (ğ‘ğ‘
11
)2
is consistent for \ . Let the corresponding (1 âˆ’ ğ›¼) Ã— 100% quantile
of the random variable
Ë†\ğ‘ ğœ’2
1
be [Ì‚
opp
1âˆ’ğ›¼ . The statistical test decision
using the plug-in consistent estimate becomes
RejectHopp
0
if ğ‘ 
opp
ğ‘
> [Ì‚
opp
1âˆ’ğ›¼ .
4.3 Most Favorable Distributions
We now discuss the construction of the most favorable distribution
Qâ˜…, the projection of the empirical distribution
Ë†Pğ‘ onto the set
F opp
â„ğ›½
. Intuitively,Qâ˜… is the distribution closest to
Ë†Pğ‘ that makesâ„ğ›½
a fair classifier under the equal opportunity criterion. If âˆ¥ Â· âˆ¥ is the
Euclidean norm, the information about Qâ˜… can be recovered from
the optimal solution of problem (6) by the result of the following
lemma.
Lemma 4.5 (Most favorable distribution). Suppose that âˆ¥ Â· âˆ¥ is
the Euclidean norm. Let ğ›¾â˜… be the optimal solution of problem (6),
and for any ğ‘– âˆˆ I1, let ğ‘˜â˜…ğ‘– be a solution of the inner minimization
of (6) with respect to ğ›¾â˜…. Then the most favorable distribution
Qâ˜… = arg min
QâˆˆFopp
â„ğ›½
W( Ë†Pğ‘ ,Q) is a discrete distribution of the form
Qâ˜… =
1
ğ‘
( âˆ‘
ğ‘–âˆˆI0
ğ›¿ (ğ‘¥ğ‘– ,ğ‘ğ‘– ,?Ì‚?ğ‘– ) +
âˆ‘
ğ‘–âˆˆI1
ğ›¿ (ğ‘¥ğ‘–âˆ’ğ‘˜â˜…ğ‘– ğ›¾â˜…_ğ‘–ğ›½,ğ‘ğ‘– ,?Ì‚?ğ‘– )
)
.
By using the result of Lemma 4.3, it is easy to verify that Qâ˜…
satisfies W(Qâ˜…, Ë†Pğ‘ )2 = Ropp ( Ë†Pğ‘ , ğ‘ğ‘ ). Moreover, one can also
show that Qâ˜… âˆˆ F opp
â„ğ›½
. These two observations imply that Qâ˜… is
the projection of
Ë†Pğ‘ onto F opp
â„ğ›½
. The detailed proof is omitted.
Lemma 4.5 suggests that in order to obtain the most favorable
distribution, it suffices to perturb only the data points with positive
label. This is intuitively rational because the notion of probabilistic
equality of opportunity only depends on the positive label, and thus
the perturbation with a minimal energy requirement should only
653
A Statistical Test for Probabilistic Fairness FAccT â€™21, March 1â€“10, 2021, Virtual Event, Canada
move sample points with ğ‘¦ğ‘– = 1. When the underlying geometry
is the Euclidean norm, the optimal perturbation of the point ğ‘¥ğ‘– is
to move it along a line dictated by ğ›½ with a scaling factor ğ‘˜â˜…
ğ‘–
ğ›¾â˜…_ğ‘– .
Notice that _ğ‘– defined in (4) are of opposite signs between samples
of different sensitive attributes, which implies that it is optimal to
perturb ğ‘¥ğ‘– in opposite directions dependent on whether ğ‘ğ‘– = 0 or
ğ‘ğ‘– = 1. This is, again, rational because moving points in opposite
direction brings the clusters of points closer to the others, which
reduces the discrepancy in the expected value of â„ğ›½ (ğ‘‹ ) between
subgroups.
As a final remark, we note that Qâ˜… is not necessarily unique.
This is because of the non-convexity of the inner problem over ğ‘˜ğ‘–
in (6), which leads to the non-uniqueness of the optimal solution
ğ‘˜â˜…
ğ‘–
(see Appendix B and Figure 5).
5 TESTING FAIRNESS FOR PROBABILISTIC
EQUALIZED ODDS CRITERION
In this section, we extend the Wasserstein projection framework to
the statistical test of probabilistic equalized odds for a pre-trained
logistic classifier.
Definition 5.1 (Probabilistic equalized odds criterion [54]). A lo-
gistic classifier â„ğ›½ (Â·) : X â†’ [0, 1] satisfies the probabilistic equal-
ized odds criteria relative to Q if
EQ [â„ğ›½ (ğ‘‹ ) |ğ´ = 1, ğ‘Œ = ğ‘¦] = EQ [â„ğ›½ (ğ‘‹ ) |ğ´ = 0, ğ‘Œ = ğ‘¦] âˆ€ğ‘¦ âˆˆ Y .
The notion of probabilistic equalized odds requires that the con-
ditional expectation of â„ğ›½ to be independent of ğ´ for any label
subgroup, thus it is more stringent than the probabilistic equal
opportunity studied in the previous section. We use the superscript
â€œoddâ€ in this section to emphasize on this specific notion of fairness.
The definition of the probabilistic equalized odds prescribes the
following set of distributions
F odd
â„ğ›½
=
ï£±ï£´ï£´ï£²ï£´ï£´ï£³
Q âˆˆ P such that :
EQ [â„ğ›½ (ğ‘‹ ) |ğ´ = 1, ğ‘Œ = 1] = EQ [â„ğ›½ (ğ‘‹ ) |ğ´ = 0, ğ‘Œ = 1]
EQ [â„ğ›½ (ğ‘‹ ) |ğ´ = 1, ğ‘Œ = 0] = EQ [â„ğ›½ (ğ‘‹ ) |ğ´ = 0, ğ‘Œ = 0]
ï£¼ï£´ï£´ï£½ï£´ï£´ï£¾.
Correspondingly, the Wasserstein projection hypothesis test for
probabilisitc equalized odds can be formulated as
Hodd
0
: P âˆˆ F odd
â„ğ›½
, Hodd
1
: P âˆ‰ F odd
â„ğ›½
.
In the sequence, we study the projection onto the manifold F odd
â„ğ›½
in Section 5.1. Section 5.2 examines the asymptotic behaviour of
the test statistic, and we close this section by studying the most
favorable distribution Qâ˜… in Section 5.3.
5.1 Wasserstein Projection
Following a similar strategy as in Section 4, we define the set
F odd
â„ğ›½
(ğ‘ğ‘ )
=
ï£±ï£´ï£´ï£´ï£´ï£´ï£²ï£´ï£´ï£´ï£´ï£´ï£³
Q âˆˆ P such that :
(ğ‘ğ‘
11
)âˆ’1EQ [â„ğ›½ (ğ‘‹ )1(1,1)(ğ´,ğ‘Œ )]= (ğ‘ğ‘01
)âˆ’1EQ [â„ğ›½ (ğ‘‹ )1(0,1)(ğ´,ğ‘Œ )]
(ğ‘ğ‘
10
)âˆ’1EQ [â„ğ›½ (ğ‘‹ )1(1,0)(ğ´,ğ‘Œ )]= (ğ‘ğ‘00
)âˆ’1EQ [â„ğ›½ (ğ‘‹ )1(0,0)(ğ´,ğ‘Œ )]
Q(ğ´ = ğ‘,ğ‘Œ = ğ‘¦)=ğ‘ğ‘ğ‘ğ‘¦ âˆ€(ğ‘,ğ‘¦) âˆˆ A Ã— Y
ï£¼ï£´ï£´ï£´ï£´ï£´ï£½ï£´ï£´ï£´ï£´ï£´ï£¾
,
and the squared distance function
Rodd ( Ë†Pğ‘ , ğ‘ğ‘ ) =ï£±ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£²ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£³
inf W(Q, Ë†Pğ‘ )2
s.t. EQ [â„ğ›½ (ğ‘‹ ) ((ğ‘ğ‘11
)âˆ’1
1(1,1)(ğ´,ğ‘Œ )âˆ’(ğ‘ğ‘01
)âˆ’1
1(0,1)(ğ´,ğ‘Œ ))]=0
EQ [â„ğ›½ (ğ‘‹ ) ((ğ‘ğ‘10
)âˆ’1
1(1,0)(ğ´,ğ‘Œ )âˆ’(ğ‘ğ‘00
)âˆ’1
1(0,0)(ğ´,ğ‘Œ ))]=0
EQ [1(ğ‘,ğ‘¦) (ğ´,ğ‘Œ )]=ğ‘ğ‘ğ‘ğ‘¦ âˆ€(ğ‘,ğ‘¦) âˆˆ A Ã— Y .
The equivalent relation (3) suggests that the projection onto the set
of distributions F odd
â„ğ›½
satisfies
inf
QâˆˆFodd
â„ğ›½
W( Ë†Pğ‘ ,Q) = inf
QâˆˆFodd
â„ğ›½
(ğ‘ğ‘ )
W( Ë†Pğ‘ ,Q) =
âˆš
Rodd ( Ë†Pğ‘ , ğ‘ğ‘ ) .
The squared distance Rodd ( Ë†Pğ‘ , ğ‘ğ‘ ) can be computed by solving
the saddle point problem in the following proposition.
Proposition 5.2 (Dual reformulation). The squared projection
distance Rodd ( Ë†Pğ‘ , ğ‘ğ‘ ) equals to the optimal value of the following
finite-dimensional optimization problem
sup
ğ›¾ âˆˆR,Z âˆˆR
1
ğ‘
ğ‘âˆ‘
ğ‘–=1
inf
ğ‘¥ğ‘– âˆˆX
{
âˆ¥ğ‘¥ğ‘–âˆ’ğ‘¥ğ‘– âˆ¥2+(ğ›¾_ğ‘–11 (ğ‘¦ğ‘– ) + Z_ğ‘–10 (ğ‘¦ğ‘– ))â„ğ›½ (ğ‘¥ğ‘– )
}
.
(8)
To complete this section, we now discuss an efficient way to
compute Rodd ( Ë†Pğ‘ , ğ‘ğ‘ ). The next lemma reveals that computing
Rodd ( Ë†Pğ‘ , ğ‘ğ‘ ) can be decomposed into two subproblems of similar
structure.
Lemma 5.3 (Univariate reduction). We have
Rodd ( Ë†Pğ‘ , ğ‘ğ‘ ) = Ropp ( Ë†Pğ‘ , ğ‘ğ‘ ) +ğ‘ˆğ‘ ,
whereğ‘ˆğ‘ is computed as
ğ‘ˆğ‘ = sup
Z âˆˆR
1
ğ‘
âˆ‘
ğ‘–âˆˆI0
inf
ğ‘¥ğ‘– âˆˆX
{
âˆ¥ğ‘¥ğ‘– âˆ’ ğ‘¥ğ‘– âˆ¥2 + Z_ğ‘–â„ğ›½ (ğ‘¥ğ‘– )
}
.
Furthermore, if âˆ¥ Â· âˆ¥ is the Euclidean norm on Rğ‘‘ , then
ğ‘ˆğ‘ =
sup
Z âˆˆR
1
ğ‘
ï£±ï£´ï£´ï£²ï£´ï£´ï£³
âˆ‘
ğ‘–âˆˆI0
min
ğ‘˜ğ‘– âˆˆ[0, 1
8
]
Z 2_2
ğ‘– âˆ¥ğ›½ âˆ¥
2
2
ğ‘˜2
ğ‘– +
Z_ğ‘–
1 + exp(Z_ğ‘– âˆ¥ğ›½ âˆ¥2
2
ğ‘˜ğ‘–âˆ’ğ›½âŠ¤ğ‘¥ğ‘– )
ï£¼ï£´ï£´ï£½ï£´ï£´ï£¾ .
(9)
Notice that problem (9) has a similar structure to problem (6):
the mere difference is that the summation in the objective function
of (9) runs over the index set I0 = {ğ‘– âˆˆ [ğ‘ ] : ğ‘¦ğ‘– = 0} instead of
I1 in (6). Solving for ğ‘ˆğ‘ thus incurs the same computational com-
plexity as, and can also be performed in parallel with, computing
Ropp ( Ë†Pğ‘ , ğ‘ğ‘ ).
5.2 Limiting Distribution
The next result asserts that the squared projection distance Rodd
has the ğ‘‚ (ğ‘âˆ’1) convergence rate.
654
FAccT â€™21, March 1â€“10, 2021, Virtual Event, Canada Bahar Taskesen, Jose Blanchet, Daniel Kuhn, and Viet Anh Nguyen
Theorem 5.4 (Limiting distribution â€“ Probabilistic equalized odds).
Suppose that (ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– ) are i.i.d. samples from P. Under the null
hypothesisHodd
0
, we have
ğ‘ Ã— Rodd ( Ë†Pğ‘ , ğ‘ğ‘ ) ğ‘‘.âˆ’â†’
sup
ğ›¾,Z
{
ğ›¾ğ»1 + Zğ»0+
EP
[(ğ›¾Z )âŠ¤(ğ‘âˆ’1
11
1(1,1) (ğ´,ğ‘Œ )âˆ’ğ‘âˆ’1
01
1(0,1) (ğ´,ğ‘Œ )
ğ‘âˆ’1
10
1(1,0) (ğ´,ğ‘Œ )âˆ’ğ‘âˆ’1
00
1(0,0) (ğ´,ğ‘Œ )
)
âˆ‡â„ğ›½ (ğ‘‹ )
2
âˆ—
]}
,
where âˆ‡â„ğ›½ (ğ‘‹ ) = â„ğ›½ (ğ‘‹ ) (1âˆ’â„ğ›½ (ğ‘‹ )ğ›½ , andğ»ğ‘¦ = N(0, ğœ2
ğ‘¦)/(ğ‘1ğ‘¦ğ‘0ğ‘¦)
with ğœ2
ğ‘¦ = Cov(ğ‘ğ‘¦), and ğ‘ğ‘¦ are random variables
ğ‘ğ‘¦ = â„ğ›½ (ğ‘‹ )
(
ğ‘0ğ‘¦1(1,ğ‘¦) (ğ´,ğ‘Œ ) âˆ’ ğ‘1ğ‘¦1(0,ğ‘¦) (ğ´,ğ‘Œ )
)
+ 1(0,ğ‘¦) (ğ´,ğ‘Œ )EP [1(1,ğ‘¦) (ğ´,ğ‘Œ )â„ğ›½ (ğ‘‹ )]
âˆ’ 1(1,ğ‘¦) (ğ´,ğ‘Œ )EP [1(0,ğ‘¦) (ğ´,ğ‘Œ )â„ğ›½ (ğ‘‹ )] .
Construction of the hypothesis test. Contrary to the explicit
chi-square limiting distribution for the probabilistic equal oppor-
tunity fairness in Theorem 4.4, the limiting distribution for the
probabilistic equalized odds fairness is not available in closed form.
Nevertheless, the limiting distribution in this case can be obtained
by sampling ğ»0 and ğ»1 and solving a collection of optimization
problems for each sample. Notice that the objective function of the
supremum problem presented in Theorem 5.4 is continuous in ğ»1
and ğ»0, one thus can define
?Ì‚?ğ‘¦ = N(0, ?Ì‚?2
ğ‘¦)/(ğ‘ğ‘1ğ‘¦ğ‘
ğ‘
0ğ‘¦),
where ?Ì‚?2
ğ‘¦ is the sample average estimate of ğœ2
ğ‘¦ , which can be com-
puted using an equation similar to (7). The limiting distribution
can be computed by solving the optimization problem with plug-in
values
sup
ğ›¾,Z
{
ğ›¾?Ì‚?1 + Z ?Ì‚?0+
E
Ë†Pğ‘
[ 
(
ğ›¾
Z
)âŠ¤((ğ‘ğ‘
11
)âˆ’1
1(1,1)(ğ´,ğ‘Œ )âˆ’(ğ‘ğ‘01
)âˆ’1
1(0,1)(ğ´,ğ‘Œ )
(ğ‘ğ‘
10
)âˆ’1
1(1,0)(ğ´,ğ‘Œ )âˆ’(ğ‘ğ‘00
)âˆ’1
1(0,0)(ğ´,ğ‘Œ )
)
âˆ‡â„ğ›½ (ğ‘‹ )

2
âˆ—
]}
.
Notice that the expectation in taken over the empirical distribution
Ë†Pğ‘ , and can be written as a finite sum. The last optimization prob-
lem can be solved efficiently using quadratic programming for any
realization of ?Ì‚?1 and ?Ì‚?0. The objective values can be collected to
compute the (1 âˆ’ ğ›¼) Ã— 100%-quantile estimate [Ì‚odd
1âˆ’ğ›¼ of the limiting
distribution. The statistical test decision using the plug-in estimate
becomes
RejectHodd
0
if ğ‘ odd
ğ‘
> [Ì‚odd
1âˆ’ğ›¼ ,
where ğ‘ odd
ğ‘
= ğ‘ Ã— Rodd ( Ë†Pğ‘ , ğ‘ğ‘ ).
5.3 Most Favorable Distributions
If the feature space X is endowed with an Euclidean norm, then the
most favorable distributionQâ˜…, defined in this section as the projec-
tion of
Ë†Pğ‘ onto F odd
â„ğ›½
, can be constructed by exploiting Lemma 5.3.
Lemma 5.5 (Most favorable distribution). Suppose that âˆ¥ Â· âˆ¥ is
the Euclidean norm. Let ğ›¾â˜… and Zâ˜… be the optimal solution of
problems (6) and (9), respectively. For any ğ‘– âˆˆ I1, let ğ‘˜â˜…ğ‘– be the
solution of the inner minimization of (6) with respect to ğ›¾â˜…, and
for any ğ‘– âˆˆ I0, let ğ‘˜â˜…ğ‘– be a solution of the inner minimization
of (9) with respect to Zâ˜…. Then the most favorable distribution
Qâ˜… = arg min
QâˆˆFodd
â„ğ›½
W( Ë†Pğ‘ ,Q) is a discrete distribution of the form
Qâ˜… =
1
ğ‘
( âˆ‘
ğ‘–âˆˆI0
ğ›¿ (ğ‘¥ğ‘–âˆ’ğ‘˜â˜…ğ‘– Zâ˜…_ğ‘–ğ›½,ğ‘ğ‘– ,?Ì‚?ğ‘– ) +
âˆ‘
ğ‘–âˆˆI1
ğ›¿ (ğ‘¥ğ‘–âˆ’ğ‘˜â˜…ğ‘– ğ›¾â˜…_ğ‘–ğ›½,ğ‘ğ‘– ,?Ì‚?ğ‘– )
)
.
The proof of Lemma 5.5 follows from verifying that Qâ˜… âˆˆ F odd
â„ğ›½
and that W(Qâ˜…, Ë†Pğ‘ )2 = Rodd ( Ë†Pğ‘ , ğ‘ğ‘ ) using Lemma 5.3, the de-
tailed proof is omitted. For probabilistic equalized odds, the most
favorable distribution Qâ˜… alters the locations of both ğ‘– âˆˆ I0 and
ğ‘– âˆˆ I1. The directions of perturbation are dependent on _ğ‘– , which
is determined using (4). Notice that _ğ‘– carry opposite signs corre-
sponding to whether ğ‘ğ‘– = 0 or ğ‘ğ‘– = 1, thus the perturbations will
move ğ‘¥ğ‘– in opposite directions based on the value of the sensitive
attribute ğ‘ğ‘– .
6 NUMERICAL EXPERIMENT
All experiments are run on an Intel Xeon based cluster composed
of 287 compute nodes each with 2 Skylake processors running at
2.3 GHz with 18 cores each. We only use 2 nodes of this cluster
and all optimization problems are implemented in Python version
3.7.3. In all experiments, we use the 2-norm to measure distances
in the feature space. Moreover, we focus on the hypothesis test of
probabilistic equal opportunity, and thus theWasserstein projection,
the limiting distribution and the most favorable distribution follow
from the results presented in Section 4.
6.1 Validation of the Hypothesis Test
We now demonstrate that our proposed Wasserstein projection
framework for statistical test of fairness is a valid, or asymptotically
correct, test. We consider a binary classification setting in which
X is 2-dimensional feature space. The true distribution P has true
marginal values ğ‘ğ‘ğ‘¦ being
ğ‘11 = 0.2, ğ‘01 = 0.1, ğ‘10 = 0.3, ğ‘00 = 0.4.
Moreover, conditioning on (ğ´,ğ‘Œ ), the feature ğ‘‹ follows a Gaussian
distribution of the form
ğ‘‹ |ğ´ = 1, ğ‘Œ = 1 âˆ¼ N([6, 0], [3.5, 0; 0, 5]),
ğ‘‹ |ğ´ = 0, ğ‘Œ = 1 âˆ¼ N([âˆ’2, 0], [5, 0; 0, 5]),
ğ‘‹ |ğ´ = 1, ğ‘Œ = 0 âˆ¼ N([6, 0], [3.5, 0; 0, 5]),
ğ‘‹ |ğ´ = 0, ğ‘Œ = 0 âˆ¼ N([âˆ’4, 0], [5, 0; 0, 5]).
The true distribution P is thus a mixture of Gaussian, and under this
specification, a simple algebraic calculation indicates that a logistic
classifier with ğ›½ = (0, 1)âŠ¤ is fair with respect to the probabilistic
equal opportunity criterion in Definition 4.1. We thus focus on
verifying fairness for this specific classifier. In the first experiment,
we empirically validate Theorem 4.4. To this end, we generate
ğ‘ âˆˆ {100, 500} i.i.d. samples from P to be used as the test data,
and then calculate the squared projection distance Ropp ( Ë†Pğ‘ , ğ‘ğ‘ )
using Proposition 4.2. The process is repeated 2,000 times to obtain
an empirical estimate of the distribution of ğ‘ Ã— Ropp ( Ë†Pğ‘ , ğ‘ğ‘ ).
655
A Statistical Test for Probabilistic Fairness FAccT â€™21, March 1â€“10, 2021, Virtual Event, Canada
0 10 20 30 40 50
100 Ã— opp( 100, p100)
0.0
0.2
0.4
0.6
D
en
si
ty
(a) ğ‘ = 100
0 10 20 30 40 50
500 Ã— opp( 500, p500)
0.0
0.2
0.4
0.6
D
en
si
ty
(b) ğ‘ = 500
0 10 20 30 40 50
100 Ã— opp( 100, p100)
0.7
0.8
0.9
1.0
C
um
ul
at
iv
e 
di
st
ri
bu
tio
n
(c) ğ‘ = 100
0 10 20 30 40 50
500 Ã— opp( 500, p500)
0.7
0.8
0.9
1.0
C
um
ul
at
iv
e 
di
st
ri
bu
tio
n
(d) ğ‘ = 500
Figure 2: Empirical distribution of ğ‘ Ã—Ropp ( Ë†Pğ‘ , ğ‘ğ‘ ) taken over 2,000 replications (histogram) versus the limiting distribution
\ ğœ’2
1
(blue curve) with different sample sizes ğ‘ . Fig. 2a-2b are density plots, Fig. 2c-2d are cumulative distribution plots.
We also generate another set of one million i.i.d. samples from
P to estimate the limiting distribution \ ğœ’2
1
. Figure 2 shows that
the empirical distribution of ğ‘ Ã— Ropp ( Ë†Pğ‘ , ğ‘ğ‘ ) converges to the
limiting distribution \ ğœ’2
1
as ğ‘ increases.
The second set of experiments aims to show that our proposed
Wasserstein projection hypothesis test is asymptotically valid. We
generate ğ‘ âˆˆ {100, 500, 1000} i.i.d. samples from P and calculate the
test statistic ğ‘ Ã— Ropp ( Ë†Pğ‘ , ğ‘ğ‘ ). The same data is used to estimate
Ë†\ğ‘ and compute the (1âˆ’ğ›¼)Ã—100%-quantile of
Ë†\ğ‘ ğœ’2
1
to perform the
quantile based test as laid out in Section 4.2. We repeat this proce-
dure for 2,000 replications to keep track of the rejection projection
at different significant values of ğ›¼ âˆˆ {0.5, 0.3, 0.1, 0.05, 0.01}. Table 1
summarizes the rejection probabilities of Wasserstein projection
tests for equal opportunity criterion under the null hypothesis
Hopp
0
. We can observe that at sample size ğ‘ > 100, the rejection
probability is close to the desired level ğ›¼ , which empirically vali-
dates our testing procedure.
ğ‘ = 100 ğ‘ = 500 ğ‘ = 1000 ğ›¼
0.511 0.4905 0.5 0.50
0.282 0.2895 0.299 0.30
0.048 0.0895 0.093 0.10
0.007 0.0425 0.0405 0.05
0.0 0.0065 0.005 0.01
Table 1: Comparison of the null rejection probabilities of
probabilistic equal opportunity tests with different signifi-
cance levels ğ›¼ and test sample sizes ğ‘ .
6.2 Most Favorable Distribution Analysis
In this section, we visualize the most favorable distribution Qâ˜…
from Lemma 4.5 for a vanilla logistic regression classifier with
weight ğ›½ = (0.4, 0.12)âŠ¤. We simply generate 28 samples with equal
subgroup proportions to form the empirical distribution
Ë†Pğ‘ . To find
the support of Qâ˜…, we solve problem (6), whose optimizer dictates
the transportation plan of each sample ğ‘¥ğ‘– . Figure 3 visualizes the
original test samples that forms
Ë†Pğ‘ , along with the most favorable
distribution Qâ˜…. Green lines in the figure represent how samples
are perturbed. As we are testing for the probabilistic notion of
equal opportunity, only the samples with positive label ğ‘¦ğ‘– = 1
Figure 3: Visualization of themost favorable distributionQâ˜…
for a logistic classifier with weight ğ›½ = (0.4, 0.12)âŠ¤. The black
arrow indicates the vector ğ›½ . Colors represent class, while
symbolic shapes encode the sensitive values. The green lines
show the transport plan of the empirical test samples from
their original positions (indicated with transparent colors)
to their ultimate destinations (with non-transparent colors).
presented in blue are perturbed in order to obtain Qâ˜…. Furthermore,
we observe that the positively-labeled test samples are transported
along the axis directed by ğ›½ (black arrow). Moreover, the samples
with different sensitive attributes, represented by different shapes,
move in opposite direction so that they get closer to each other,
which reduces the discrepancy in the expected value of â„ğ›½ (ğ‘‹ )
between the relevant subgroups.
6.3 The COMPAS Dataset
COMPAS (Correctional Offender Management Profiling for Alter-
native Sanctions)
4
is a commercial tool used by judges and parole
officers for scoring criminal defendantâ€™s likelihood of recidivism.
The COMPAS dataset is used by the COMPAS algorithm to com-
pute the risk score of reoffending for defendants, and also contains
the criminal records within 2 years after the decision. The dataset
consists of 6,172 samples with 10 attributes including gender, age
category, race, etc. We concentrate on the subset of the data with
violent recidivism, and we use race (African-American and Cau-
casian) as the sensitive attribute. We split 70% of the COMPAS data
to train a Tikhonov-regularized logistic classifier, with the tuning
penalty parameter _ chosen in the range from 0 to 100 with 50
4
https://www.propublica.org/datastore/dataset/compas-recidivism-risk-score-data-
and-analysis
656
FAccT â€™21, March 1â€“10, 2021, Virtual Event, Canada Bahar Taskesen, Jose Blanchet, Daniel Kuhn, and Viet Anh Nguyen
0 20 40 60 80 100
0
10
20
30
40
50
60
70
St
at
is
tic
 v
al
ue
0.635
0.640
0.645
0.650
0.655
0.660
0.665
0.670
Ac
cu
ra
cy
0.95 N Ã— opp( N, pN) Test accuracy
Figure 4: Test statistic and accuracy of Tikhonov regularized
logistic regression on test data with rejection threshold [Ì‚0.95.
equi-distant points. The remaining 30% of the data is used as the
test samples for auditing.
Figure 4 demonstrates the relation between the accuracy and
the degree of fairness with respect to the regularization parameter
_. Strong regularization penalty (high values of _) results in small
values of the test statistic, but the classifier has low test accuracy. On
the contrary, weak penalization leads to undesirable fairness level
but higher prediction accuracy. The pink dashed line in Figure 4
shows the rejection threshold of the Wasserstein projection test at
significance level ğ›¼ = 0.05 for varying value of the regularization
parameter _. We can observe that the Wasserstein projection test
recommends a rejection of the null hypothesis Hopp
0
for a wide
range of _. Only at _ sufficiently large that the test fails to reject
the null hypothesis.
7 CONCLUDING REMARKS AND BROADER
IMPACT
In this paper, we propose a statistical hypothesis test for group
fairness of classification algorithms based on the theory of opti-
mal transport. Our test statistic relies on computing the projection
distance from the empirical distribution supported on the test sam-
ples to the manifold of distributions that renders the classifier fair.
When the notion of fairness is chosen to be either the probabilistic
equal opportunity or the probabilistic equalized odds, we show that
the projection can be computed efficiently. We provide the limit-
ing distribution of the test statistic and show that our Wasserstein
projection test is asymptotically correct. Our proposed test also
offers the flexibility to incorporate the geometric information of
the feature space into testing procedure. Finally, analyzing the most
favorable distribution can help interpreting the reasons behind the
outcome of the test.
The Wasserstein projection hypothesis test is the culmination
of a benevolent motivation and effort, and it aims to furnish the
developers, the regulators and the general public a quantitative
method to verify certain notions of fairness in the classification
setting. At the same time, we acknowledge the risks and limitations
of the results presented in this paper.
First, it is essential to keep in mind that this paper focuses
on probabilistic notions of fairness, in particular, we provide the
Wasserstein statistical test for probabilistic equality of opportunity
and probabilistic equalized odds. Probabilistic notions are only ap-
proximations of the original definitions, and the employment of
probabilistic notions are solely for the technical purposes. Due to
the sensitivity of the test result on the choice of fairness notions, a
test that is designed for probabilistic notions may not be applicable
to test for original notions of fairness due to the interplay with
the threshold ğœ and the radical difference of both the test statistic
and the limiting distribution. If a logistic classifier â„ğ›½ is rejected
using our framework for probabilistic equal opportunity, it does
not necessarily imply that the classifier â„ğ›½ fails to satisfy the equal
opportunity criterion, and vice versa. The same argument holds
when we test for probabilistic equalized odds.
Second, the outcome of the Wasserstein projection test is de-
pendent on the choice of the underlying metric on the feature, the
sensitive attribute and the label spaces. Indeed, the test outcome
can change if we switch the metric of the feature space, for example,
from the Euclidean norm to a 1-norm. In the scope of this paper,
we do not study how sensitive the test outcome is with respect to
the choice of the metric, nor can we make any recommendation
on the optimal choice of the metric. Nevertheless, it is reasonable
to recommend that the metric should be chosen judiciously, and
the action of tuning the metric in order to obtain favorable test
outcome should be prohibited.
Third, to simplify the computation, we have assumed absolute
trust on the sensitive attributes and the label. The users of our test
should be mindful if there is potential corruption to these values.
Moreover, our test is constructed under the assumption that there
is no missing values in the test data. This assumption, unfortu-
nately, may not hold in real-world implementations. Constructing
statistical test which is robust to adversarial attacks and missing
data using the Wasserstein projection framework is an interesting
research direction.
Fourth, the statistical test in this paper is for a simple null hy-
pothesis. In practice, the regulators may be interested in a relaxed
fairness test in which the difference of the conditional expectations
is upper bounded by a fixed positive constant ğœ– . The extension of
the Wasserstein hypothesis testing framework for a composite null
hypothesis is non-trivial, thus we leave this idea for future study.
Finally, any auditing process for algorithmic fairness can become
a dangerous tool if it falls into the hand of unqualified or vicious
inspectors. The results in this paper are developed to broaden our
scientific understanding, and we recommend that the test and its
outcomes should be used as an informative reference, but not as
an absolute certification to promote any particular classifier or as a
justification for any particular classification decision.
We thus sincerely recommend that the tools proposed in this
paper be exercised with utmost consideration.
ACKNOWLEDGMENTS
Research supported by the Swiss National Science Foundation un-
der NCCR Automation, grant agreement 51NF40_180545. Material
in this paper is based upon work supported by the Air Force Of-
fice of Scientific Research under award number FA9550-20-1-0397.
Additional support is gratefully acknowledged from NSF grants
1915967, 1820942, 1838676, and also from the China Merchant Bank.
Finally, we would like to thank Nian Si andMichael Sklar for helpful
comments and discussions.
657
A Statistical Test for Probabilistic Fairness FAccT â€™21, March 1â€“10, 2021, Virtual Event, Canada
REFERENCES
[1] David Alvarez-Melis, Tommi S Jaakkola, and Stefanie Jegelka. 2017. Structured
optimal transport. arXiv preprint arXiv:1712.06199 (2017).
[2] Solon Barocas and Andrew D Selbst. 2016. Big dataâ€™s disparate impact. California
Law Review 104 (2016), 671â€“732.
[3] Rachel KE Bellamy, Kuntal Dey, Michael Hind, Samuel C Hoffman, Stephanie
Houde, Kalapriya Kannan, Pranay Lohia, Jacquelyn Martino, Sameep Mehta,
Aleksandra Mojsilovic, et al. 2018. AI Fairness 360: An extensible toolkit for
detecting, understanding, and mitigating unwanted algorithmic bias. arXiv
preprint arXiv:1810.01943 (2018).
[4] Jean-David Benamou, Guillaume Carlier, Marco Cuturi, Luca Nenna, and Gabriel
PeyrÃ©. 2015. Iterative Bregman projections for regularized transportation prob-
lems. SIAM Journal on Scientific Computing 37, 2 (2015), A1111â€“A1138.
[5] Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, and Aaron Roth.
2018. Fairness in criminal justice risk assessments: The state of the art. Sociological
Methods & Research (2018), 0049124118782533.
[6] Emily Black, Samuel Yeom, and Matt Fredrikson. 2020. FlipTest: fairness testing
via optimal transport. In Proceedings of the 2020 Conference on Fairness, Account-
ability, and Transparency. 111â€“121.
[7] Jose Blanchet, Yang Kang, and KarthyekMurthy. 2019. RobustWasserstein profile
inference and applications to machine learning. Journal of Applied Probability
56, 3 (2019), 830â€“857.
[8] Mathieu Blondel, Vivien Seguy, and Antoine Rolet. 2018. Smooth and sparse op-
timal transport. In International Conference on Artificial Intelligence and Statistics.
880â€“889.
[9] Joy Buolamwini and Timnit Gebru. 2018. Gender shades: Intersectional accu-
racy disparities in commercial gender classification. In Conference on Fairness,
Accountability and Transparency. 77â€“91.
[10] Toon Calders and Sicco Verwer. 2010. Three naive Bayes approaches for
discrimination-free classification. Data Mining and Knowledge Discovery 21,
2 (2010), 277â€“292.
[11] Elsa Cazelles, Vivien Seguy, JÃ©rÃ©mie Bigot, Marco Cuturi, and Nicolas Papadakis.
2018. Geodesic PCA versus log-PCA of histograms in the Wasserstein space.
SIAM Journal on Scientific Computing 40, 2 (2018), B429â€“B456.
[12] Alexandra Chouldechova. 2017. Fair prediction with disparate impact: A study
of bias in recidivism prediction instruments. Big Data 5, 2 (2017), 153â€“163.
[13] Alexandra Chouldechova and Aaron Roth. 2020. A snapshot of the frontiers of
fairness in machine learning. Commun. ACM 63, 5 (2020), 82â€“89.
[14] Sam Corbett-Davies, Emma Pierson, Avi Feller, Sharad Goel, and Aziz Huq. 2017.
Algorithmic decision making and the cost of fairness. In Proceedings of the 23rd
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.
797â€“806.
[15] Nicolas Courty, RÃ©mi Flamary, Devis Tuia, and Alain Rakotomamonjy. 2016.
Optimal transport for domain adaptation. IEEE transactions on pattern analysis
and machine intelligence 39, 9 (2016), 1853â€“1865.
[16] Marco Cuturi. 2013. Sinkhorn Distances: Lightspeed Computation of Optimal
Transport. In Advances in Neural Information Processing Systems. 2292â€“2300.
[17] Jeffrey Dastin. 2018. Amazon scraps secret AI recruiting tool that showed bias
against women. San Fransico, CA: Reuters. Retrieved on October 9 (2018), 2018.
[18] Amit Datta, Michael Carl Tschantz, and Anupam Datta. 2015. Automated ex-
periments on ad privacy settings: A tale of opacity, choice, and discrimination.
Proceedings on Privacy Enhancing Technologies 2015, 1 (2015), 92â€“112.
[19] Cyrus DiCiccio, Sriram Vasudevan, Kinjal Basu, Krishnaram Kenthapadi, and
DeepakAgarwal. 2020. Evaluating fairness using permutation tests. In Proceedings
of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data
Mining. 1467â€“1477.
[20] Pavel Dvurechensky, Alexander Gasnikov, and Alexey Kroshnin. 2018. Compu-
tational optimal transport: Complexity by accelerated gradient descent is better
than by Sinkhornâ€™s algorithm. arXiv preprint arXiv:1802.04367 (2018).
[21] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard
Zemel. 2012. Fairness through awareness. In Proceedings of the 3rd innovations in
theoretical computer science conference. 214â€“226.
[22] Mahyar Fazlyab, Manfred Morari, and George J. Pappas. 2019. Safety Verification
and Robustness Analysis of Neural Networks via Quadratic Constraints and
Semidefinite Programming. arXiv preprint arXiv:1903.01287 (2019).
[23] Michael Feldman, Sorelle A. Friedler, John Moeller, Carlos Scheidegger, and
Suresh Venkatasubramanian. 2015. Certifying and Removing Disparate Impact.
In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining. 259â€“268.
[24] Sira Ferradans, Nicolas Papadakis, Gabriel PeyrÃ©, and Jean-FranÃ§ois Aujol. 2014.
Regularized discrete optimal transport. SIAM Journal on Imaging Sciences 7, 3
(2014), 1853â€“1882.
[25] RÃ©mi Flamary, Marco Cuturi, Nicolas Courty, and Alain Rakotomamonjy. 2018.
Wasserstein discriminant analysis. Machine Learning 107, 12 (2018), 1923â€“1945.
[26] Rui Gao, Xi Chen, and Anton J Kleywegt. 2017. Wasserstein distributional robust-
ness and regularization in statistical learning. arXiv preprint arXiv:1712.06050
(2017).
[27] Sahaj Garg, Vincent Perot, Nicole Limtiaco, Ankur Taly, Ed H Chi, and Alex
Beutel. 2019. Counterfactual fairness in text classification through robustness. In
Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society. 219â€“226.
[28] Aude Genevay, Marco Cuturi, Gabriel PeyrÃ©, and Francis Bach. 2016. Stochastic
optimization for large-scale optimal transport. In Advances in Neural Information
Processing Systems. 3440â€“3448.
[29] Paula Gordaliza, Eustasio Del Barrio, Gamboa Fabrice, and Jean-Michel Loubes.
2019. Obtaining Fairness using Optimal Transport Theory. In Proceedings of the
36th International Conference on Machine Learning. 2357â€“2365.
[30] Nina Grgic-Hlaca, Muhammad Bilal Zafar, Krishna P Gummadi, and Adrian
Weller. 2016. The case for process fairness in learning: Feature selection for fair
decision making. In NIPS Symposium on Machine Learning and the Law, Vol. 1. 2.
[31] Moritz Hardt, Eric Price, Eric Price, and Nati Srebro. 2016. Equality of Opportunity
in Supervised Learning. In Advances in Neural Information Processing Systems 29.
3315â€“3323.
[32] Nhat Ho, Xuan Long Nguyen, Mikhail Yurochkin, Hung Hai Bui, Viet Huynh, and
Dinh Phung. 2017. Multilevel clustering via Wasserstein means. In Proceedings
of the 34th International Conference on Machine Learning-Volume 70. JMLR. org,
1501â€“1509.
[33] David W Hosmer Jr, Stanley Lemeshow, and Rodney X Sturdivant. 2013. Applied
Logistic Regression. John Wiley & Sons.
[34] Philips George John, Deepak Vijaykeerthy, and Diptikalyan Saha. 2020. Verifying
Individual Fairness in Machine Learning Models. In Conference on Uncertainty in
Artificial Intelligence. PMLR, 749â€“758.
[35] Nathan Kallus, Xiaojie Mao, and Angela Zhou. 2019. Assessing algorithmic
fairness with unobserved protected class using data combination. arXiv preprint
arXiv:1906.00285 (2019).
[36] Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, and Ashesh Rambachan. 2018.
Algorithmic fairness. In AEA Papers and Proceedings, Vol. 108. 22â€“27.
[37] Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan. 2016. Inherent
trade-offs in the fair determination of risk scores. arXiv preprint arXiv:1609.05807
(2016).
[38] Soheil Kolouri, Se Rim Park, Matthew Thorpe, Dejan Slepcev, and Gustavo K
Rohde. 2017. Optimal mass transport: Signal processing and machine-learning
applications. IEEE signal processing magazine 34, 4 (2017), 43â€“59.
[39] Soheil Kolouri and Gustavo K Rohde. 2015. Transport-based single frame super
resolution of very low resolution face images. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition. 4876â€“4884.
[40] Daniel Kuhn, Peyman Mohajerin Esfahani, Viet Anh Nguyen, and Soroosh
Shafieezadeh-Abadeh. 2019. Wasserstein distributionally robust optimization:
Theory and applications in machine learning. In Operations Research & Manage-
ment Science in the Age of Analytics. INFORMS, 130â€“166.
[41] Zachary Lipton, Julian McAuley, and Alexandra Chouldechova. 2018. Does
mitigating MLâ€™s impact disparity require treatment disparity?. In Advances in
Neural Information Processing Systems. 8125â€“8135.
[42] Michael Lohaus, MichaÃ«l Perrot, and Ulrike von Luxburg. 2020. Too Relaxed to
Be Fair. In International Conference on Machine Learning.
[43] Arjun K Manrai, Birgit H Funke, Heidi L Rehm, Morten S Olesen, Bradley A
Maron, Peter Szolovits, David M Margulies, Joseph Loscalzo, and Isaac S Kohane.
2016. Genetic misdiagnoses and the potential for health disparities. New England
Journal of Medicine 375, 7 (2016), 655â€“665.
[44] Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram
Galstyan. 2019. A survey on bias and fairness in machine learning. arXiv preprint
arXiv:1908.09635 (2019).
[45] Gaspard Monge. 1781. MÃ©moire sur la thÃ©orie des dÃ©blais et des remblais. Histoire
de lâ€™AcadÃ©mie Royale des Sciences de Paris (1781).
[46] MultiMedia LLC. 2016 (accessed June 4, 2020). Machine Bias. Avail-
able at https://www.propublica.org/article/machine-bias-risk-assessments-in-
criminal-sentencing.
[47] Zak Murez, Soheil Kolouri, David Kriegman, Ravi Ramamoorthi, and Kyungnam
Kim. 2018. Image to image translation for domain adaptation. In Proceedings of
the IEEE Conference on Computer Vision and Pattern Recognition. 4500â€“4509.
[48] Katta G Murty and Santosh N Kabadi. 1985. Some NP-complete problems in
quadratic and nonlinear programming. Technical Report.
[49] XuanLong Nguyen. 2013. Convergence of latent mixing measures in finite and
infinite mixture models. The Annals of Statistics 41, 1 (2013), 370â€“400.
[50] Nicolas Papadakis and Julien Rabin. 2017. Convex Histogram-Based Joint Image
Segmentation with Regularized Optimal Transport Cost. Journal of Mathematical
Imaging and Vision 59, 2 (2017), 161â€“186.
[51] Ofir Pele andMichaelWerman. 2008. A linear time histogrammetric for improved
sift matching. In European conference on computer vision. Springer, 495â€“508.
[52] O. Pele and M. Werman. 2009. Fast and robust Earth Moverâ€™s Distances. In
2009 IEEE 12th International Conference on Computer Vision. 460â€“467. https:
//doi.org/10.1109/ICCV.2009.5459199
[53] Gabriel PeyrÃ© and Marco Cuturi. 2019. Computational optimal transport. Foun-
dations and TrendsÂ® in Machine Learning 11, 5-6 (2019), 355â€“607.
[54] Geoff Pleiss, Manish Raghavan, FelixWu, Jon Kleinberg, and Kilian QWeinberger.
2017. On fairness and calibration. In Advances in Neural Information Processing
658
FAccT â€™21, March 1â€“10, 2021, Virtual Event, Canada Bahar Taskesen, Jose Blanchet, Daniel Kuhn, and Viet Anh Nguyen
Systems. 5680â€“5689.
[55] Antoine Rolet, Marco Cuturi, and Gabriel PeyrÃ©. 2016. Fast dictionary learning
with a smoothedWasserstein loss. InArtificial Intelligence and Statistics. 630â€“638.
[56] Yossi Rubner, Carlo Tomasi, and Leonidas J Guibas. 2000. The earth moverâ€™s
distance as a metric for image retrieval. International journal of computer vision
40, 2 (2000), 99â€“121.
[57] Pedro Saleiro, Benedict Kuester, Loren Hinkson, Jesse London, Abby Stevens, Ari
Anisfeld, Kit T Rodolfa, and Rayid Ghani. 2018. Aequitas: A bias and fairness
audit toolkit. arXiv preprint arXiv:1811.05577 (2018).
[58] Bernhard Schmitzer. 2016. A sparse multiscale algorithm for dense optimal
transport. Journal of Mathematical Imaging and Vision 56, 2 (2016), 238â€“259.
[59] Vivien Seguy and Marco Cuturi. 2015. Principal geodesic analysis for probability
measures under the optimal transport metric. In Advances in Neural Information
Processing Systems. 3312â€“3320.
[60] James E Smith. 1995. Generalized Chebychev inequalities: Theory and applica-
tions in decision analysis. Operations Research 43, 5 (1995), 807â€“825.
[61] Justin Solomon, Fernando De Goes, Gabriel PeyrÃ©, Marco Cuturi, Adrian Butscher,
Andy Nguyen, Tao Du, and Leonidas Guibas. 2015. ConvolutionalWasserstein dis-
tances: Efficient optimal transportation on geometric domains. ACM Transactions
on Graphics (TOG) 34, 4 (2015), 66.
[62] Justin Solomon, Raif Rustamov, Leonidas Guibas, and Adrian Butscher. 2014.
Earth moverâ€™s distances on discrete surfaces. ACM Transactions on Graphics
(TOG) 33, 4 (2014), 67.
[63] Guillaume Tartavel, Gabriel PeyrÃ©, and Yann Gousseau. 2016. Wasserstein loss
for image synthesis and restoration. SIAM Journal on Imaging Sciences 9, 4 (2016),
1726â€“1755.
[64] Bahar Taskesen, Viet AnhNguyen, Daniel Kuhn, and Jose Blanchet. 2020. A Distri-
butionally Robust Approach to Fair Classification. arXiv preprint arXiv:2007.09530
(2020).
[65] Matthew Thorpe, Serim Park, Soheil Kolouri, Gustavo K Rohde, and Dejan SlepÄev.
2017. A Transportation ğ¿ğ‘ Distance for Signal Analysis. Journal of mathematical
imaging and vision 59, 2 (2017), 187â€“210.
[66] Florian Tramer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, Jean-Pierre
Hubaux, Mathias Humbert, Ari Juels, and Huang Lin. 2017. FairTest: Discovering
unwarranted associations in data-driven applications. In 2017 IEEE European
Symposium on Security and Privacy (EuroS&P). IEEE, 401â€“416.
[67] JamesWexler, Mahima Pushkarna, Tolga Bolukbasi, MartinWattenberg, Fernanda
ViÃ©gas, and Jimbo Wilson. 2019. The what-if tool: Interactive probing of machine
learning models. IEEE transactions on visualization and computer graphics 26, 1
(2019), 56â€“65.
[68] Songkai Xue, Mikhail Yurochkin, and Yuekai Sun. 2020. Auditing ML Models for
Individual Bias and Unfairness. arXiv preprint arXiv:2003.05048 (2020).
[69] Mikhail Yurochkin, Amanda Bower, and Yuekai Sun. 2020. Training individually
fair ML models with sensitive subspace robustness. In International Conference
on Learning Representations.
[70] Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P
Gummadi. 2017. Fairness beyond disparate treatment & disparate impact: Learn-
ing classification without disparate mistreatment. In Proceedings of the 26th
International Conference on World Wide Web. 1171â€“1180.
[71] Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P
Gummadi. 2017. Fairness constraints: Mechanisms for fair classification. AISTATS
(2017).
[72] C. Zhao and Y. Guan. 2018. Data-driven risk-averse stochastic optimization with
Wasserstein metric. Operations Research Letters 46, 2 (2018), 262 â€“ 267.
A APPENDIX - PROOFS
A.1 Proofs of Section 2
Proof of Lemma 3.2. Because the fairness constraints are sim-
ilar in both sets Fâ„ and Fâ„ (ğ‘ğ‘ ), it thus suffice to verify that Q
satisfies the marginal conditions Q(ğ´ = ğ‘,ğ‘Œ = ğ‘¦) = ğ‘ğ‘ğ‘ğ‘¦ for all
(ğ‘,ğ‘¦) âˆˆ A Ã— Y. By the definition of the Wasserstein distance and
the ground metric ğ‘ , there exists a coupling ğœ‹ such that
W( Ë†Pğ‘ ,Q)2 = Eğœ‹ [(âˆ¥ğ‘‹ â€² âˆ’ ğ‘‹ âˆ¥ + âˆ|ğ´â€² âˆ’ğ´| + âˆ|ğ‘Œ â€² âˆ’ ğ‘Œ |)2]
and themarginal distribution of ğœ‹ are
Ë†Pğ‘ andQ, respectively. By the
law of total probability and because
Ë†Pğ‘ is an empirical distribution,
we can write ğœ‹ = ğ‘âˆ’1
âˆ‘ğ‘
ğ‘–=1
ğ›¿ (ğ‘¥ğ‘– ,ğ‘ğ‘– ,?Ì‚?ğ‘– ) âŠ— Qğ‘– , where Qğ‘– denotes the
conditional distributions of (ğ‘‹,ğ´,ğ‘Œ ) given (ğ‘‹ â€², ğ´â€², ğ‘Œ â€²) = (ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– )
for all ğ‘– âˆˆ [ğ‘ ].
Suppose without any loss of generality that there exists a tuple
(ğ‘,ğ‘¦) âˆˆ A Ã— Y such that Q(ğ´ = ğ‘,ğ‘Œ = ğ‘¦) > ğ‘ğ‘ğ‘ğ‘¦ . This means
Q(ğ´ = ğ‘,ğ‘Œ = ğ‘¦) = 1
ğ‘
ğ‘âˆ‘
ğ‘–=1
Qğ‘– (ğ´ = ğ‘,ğ‘Œ = ğ‘¦)
>
1
ğ‘
ğ‘âˆ‘
ğ‘–=1
1(ğ‘,ğ‘¦) (ğ‘ğ‘– , ğ‘¦ğ‘– ).
This implies that theremust exist an index ğ‘–â˜… âˆˆ [ğ‘ ] with (ğ‘ğ‘–â˜…, ğ‘¦ğ‘–â˜…) â‰ 
(ğ‘,ğ‘¦), and that
Qğ‘–â˜… (ğ´ = ğ‘,ğ‘Œ = ğ‘¦) > 0.
However, this further implies that
W( Ë†Pğ‘ ,Q)2 =
1
ğ‘
ğ‘âˆ‘
ğ‘–=1
EQğ‘– [(âˆ¥ğ‘¥ğ‘– âˆ’ ğ‘‹ âˆ¥ + âˆ|ğ‘ğ‘– âˆ’ğ´| + âˆ|ğ‘¦ğ‘– âˆ’ ğ‘Œ |)
2]
â‰¥ 1
ğ‘
EQğ‘–â˜… [(âˆ¥ğ‘¥ğ‘–â˜… âˆ’ ğ‘‹ âˆ¥ + âˆ|ğ‘ğ‘–â˜… âˆ’ğ´| + âˆ|ğ‘¦ğ‘–â˜… âˆ’ ğ‘Œ |)
2]
â‰¥ 1
ğ‘
Qğ‘–â˜… (ğ´ = ğ‘,ğ‘Œ = ğ‘¦) (âˆ(ğ‘ğ‘–â˜… âˆ’ ğ‘) + âˆ(ğ‘¦ğ‘–â˜… âˆ’ ğ‘¦))2
= âˆ,
where the equality follows from the decomposition of ğœ‹ using the
law of total probability and the first inequality follows because the
transportation cost is nonnegative. This contradicts the fact that
W( Ë†Pğ‘ ,Q) < âˆ. â–¡
A.2 Proofs of Section 4
Before proving Proposition 4.2, we first prove a preparatory lemma
that verifies the Slater condition of the conic optimization problem.
To shorten the notation, we write b = (ğ‘‹,ğ´,ğ‘Œ ) and denote Î =
X Ã— A Ã— Y, ÎÌ‚ğ‘ = {(ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– )}ğ‘ğ‘–=1
. We assume that ğ‘ â‰¥ 2 and
Ë†bğ‘– = (ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– ) are distinct. We useM+ (Î Ã— ÎÌ‚ğ‘ ) to denote the set
of all nonnegative measures on Î Ã— ÎÌ‚ğ‘ .
Lemma A.1 (Slater condition - Probabilistic equal opportunity).
Suppose that ğ›½ â‰  0, ğ‘ğ‘
11
âˆˆ (0, 1) and ğ‘ğ‘
01
âˆˆ (0, 1). Define the function
ğ‘“ğ›½ (ğ‘‹,ğ´,ğ‘Œ ) â‰œ
1
ğ‘ğ‘
11
â„ğ›½ (ğ‘‹ )1(1,1) (ğ´,ğ‘Œ ) âˆ’
1
ğ‘ğ‘
01
â„ğ›½ (ğ‘‹ )1(0,1) (ğ´,ğ‘Œ ),
and let ğ‘“ be a vector-valued function ğ‘“ : Î Ã— ÎÌ‚ğ‘ â†’ Rğ‘+1
ğ‘“ (b, b â€²) =
Â©Â­Â­Â­Â­Â­Â«
1
Ë†bğ‘–
(b â€²)
.
.
.
1
Ë†bğ‘
(b â€²)
ğ‘“ğ›½ (b)
ÂªÂ®Â®Â®Â®Â®Â¬
.
Then we have
Â©Â­Â­Â­Â­Â«
1/ğ‘
.
.
.
1/ğ‘
0
ÂªÂ®Â®Â®Â®Â¬
âˆˆ int
{
Eğœ‹ [ğ‘“ (b, b â€²)] : ğœ‹ âˆˆ M+ (Î Ã— ÎÌ‚ğ‘ )
}
.
Proof of Lemma A.1. It suffices to show that for any
ğ‘ âˆˆ
(
1
2ğ‘
,
3
2ğ‘
)ğ‘
Ã—
(
âˆ’1
4
,
1
4
)
,
659
A Statistical Test for Probabilistic Fairness FAccT â€™21, March 1â€“10, 2021, Virtual Event, Canada
there exists a nonnegative measure ğœ‹ âˆˆ M+ (ÎÃ— ÎÌ‚ğ‘ ) such that ğ‘ =
Eğœ‹ [ğ‘“ (b, b â€²)]. We will verify this claim by constructing ğœ‹ explicitly.
To this end, define the following locations
ğ‘¥ğ‘ğ‘¦ âˆˆ X âˆ€(ğ‘,ğ‘¦) âˆˆ A Ã— Y,
and set ğœ‹ âˆˆ M+ (Î Ã— ÎÌ‚ğ‘ ) explicitly as
ğœ‹ (b = (ğ‘¥ğ‘ğ‘– ?Ì‚?ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– ), b
â€² = (ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– )) = ğ‘ğ‘– ,
and ğœ‹ is 0 everywhere else. By construction, one can verify that
Eğœ‹ [1 Ë†bğ‘–
(b â€²)] = ğ‘ğ‘– for all ğ‘– âˆˆ [ğ‘ ]. If we define the following index
sets Iğ‘ğ‘¦ = {ğ‘– âˆˆ [ğ‘ ] : ğ‘ğ‘– = ğ‘,ğ‘¦ğ‘– = ğ‘¦}, then
Eğœ‹ [ğ‘“ğ›½ (b)] = (ğ‘ğ‘11
)âˆ’1â„ğ›½ (ğ‘¥11)
âˆ‘
ğ‘–âˆˆI11
ğ‘ğ‘– âˆ’ (ğ‘ğ‘01
)âˆ’1â„ğ›½ (ğ‘¥01)
âˆ‘
ğ‘–âˆˆI01
ğ‘ğ‘– .
It now remains to find the locations of ğ‘¥11 and ğ‘¥01 to balance the
above equation. We have the following two cases.
(1) Suppose that ğ‘ğ‘+1 â‰¥ 0. In this case, choose ğ‘¥01 âˆˆ X such that
â„ğ›½ (ğ‘¥01) = 1
6
. The condition Eğœ‹ [ğ‘“ğ›½ (b)] = ğ‘ğ‘+1 requires that
â„ğ›½ (ğ‘¥11) =
ğ‘ğ‘+1 + 1
6
(ğ‘ğ‘
01
)âˆ’1
âˆ‘
ğ‘–âˆˆI01
ğ‘ğ‘–
(ğ‘ğ‘
11
)âˆ’1
âˆ‘
ğ‘–âˆˆI11
ğ‘ğ‘–
.
Because ğ‘ğ‘+1 â‰¥ 0 and ğ‘ğ‘– are strictly positive, the term on the
right hand side is strictly positive. Moreover, we have
(ğ‘ğ‘
01
)âˆ’1
âˆ‘
ğ‘–âˆˆI01
ğ‘ğ‘– <
3
2
and (ğ‘ğ‘
11
)âˆ’1
âˆ‘
ğ‘–âˆˆI11
ğ‘ğ‘– >
1
2
for any feasible value of ğ‘ğ‘– , which implies that
0 <
ğ‘ğ‘+1 + 1
6
(ğ‘ğ‘
01
)âˆ’1
âˆ‘
ğ‘–âˆˆI01
ğ‘ğ‘–
(ğ‘ğ‘
11
)âˆ’1
âˆ‘
ğ‘–âˆˆI11
ğ‘ğ‘–
<
1
4
+ 1
4
1
2
= 1.
This implies the existence of ğ‘¥11 âˆˆ X so that Eğœ‹ [ğ‘“ğ›½ (b)] = ğ‘ğ‘+1.
(2) Suppose thatğ‘ğ‘+1 < 0. In this case, we can chooseğ‘¥11 âˆˆ X such
that â„ğ›½ (ğ‘¥11) = 1
6
. A similar argument as in the previous case
implies the existence of ğ‘¥01 âˆˆ X such that Eğœ‹ [ğ‘“ğ›½ (b)] = ğ‘ğ‘+1.
Combining the two cases leads to the postulated results. â–¡
We are now ready to prove Proposition 4.2.
Proof of Proposition 4.2. For the purpose of this proof, we
define the function _ : A Ã—Y â†’ R as
_(ğ‘,ğ‘¦) =
1(1,1) (ğ‘,ğ‘¦)
ğ‘ğ‘
11
âˆ’
1(0,1) (ğ‘,ğ‘¦)
ğ‘ğ‘
01
. (10)
By definition of the squared distance function Ropp
, we have
Ropp ( Ë†Pğ‘ , ğ‘ğ‘ )
=
ï£±ï£´ï£´ï£´ï£´ï£´ï£²ï£´ï£´ï£´ï£´ï£´ï£³
inf
QâˆˆP
W( Ë†Pğ‘ ,Q)2
s.t. (ğ‘ğ‘
11
)âˆ’1EQ [â„ğ›½ (ğ‘‹ )1(1,1) (ğ´,ğ‘Œ )]
= (ğ‘ğ‘
01
)âˆ’1EQ [â„ğ›½ (ğ‘‹ )1(0,1) (ğ´,ğ‘Œ )]
Q(ğ´ = ğ‘,ğ‘Œ = ğ‘¦) = ğ‘ğ‘ğ‘ğ‘¦ âˆ€ğ‘ âˆˆ A, ğ‘¦ âˆˆ Y
=
ï£±ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£²ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£³
inf
ğœ‹
Eğœ‹ [ğ‘
(
(ğ‘‹ â€², ğ´â€², ğ‘Œ â€²), (ğ‘‹,ğ´,ğ‘Œ )
)
2]
s.t. ğœ‹ âˆˆ P((X Ã— A Ã— Y) Ã— (X Ã— A Ã—Y))
Eğœ‹ [ğ‘“ğ›½ (ğ‘‹,ğ´,ğ‘Œ )] = 0
ğœ‹ (ğ´ = ğ‘,ğ‘Œ = ğ‘¦) = ğ‘ğ‘ğ‘ğ‘¦ âˆ€ğ‘ âˆˆ A, ğ‘¦ âˆˆ Y
Eğœ‹ [1(ğ‘¥ğ‘– ,ğ‘ğ‘– ,?Ì‚?ğ‘– ) (ğ‘‹ â€², ğ´â€², ğ‘Œ â€²)] = 1/ğ‘ âˆ€ğ‘– âˆˆ [ğ‘ ],
where the function ğ‘“ğ›½ is defined as
ğ‘“ğ›½ (ğ‘¥, ğ‘,ğ‘¦) â‰œ (ğ‘ğ‘11
)âˆ’1â„ğ›½ (ğ‘¥)1(1,1) (ğ‘,ğ‘¦) âˆ’ (ğ‘ğ‘01
)âˆ’1â„ğ›½ (ğ‘¥)1(0,1) (ğ‘,ğ‘¦)
= â„ğ›½ (ğ‘¥)_(ğ‘,ğ‘¦), (11)
andP(S) denotes the set of all joint probabilitymeasures supported
on S. Because of the infinity individual cost on A and Y by the
definition of cost in (2), any joint measure ğœ‹ with finite objective
value should satisfies ğœ‹ (ğ´ = ğ‘,ğ‘Œ = ğ‘¦) = Ë†Pğ‘ (ğ´â€² = ğ‘,ğ‘Œ â€² = ğ‘¦) = ğ‘ğ‘ğ‘ğ‘¦
for any ğ‘ âˆˆ A and ğ‘¦ âˆˆ Y. Thus, the set of constraints ğœ‹ (ğ´ = ğ‘,ğ‘Œ =
ğ‘¦) = ğ‘ğ‘ğ‘ğ‘¦ can be eliminated without alternating the optimization
problem. We thus have
Ropp ( Ë†Pğ‘ , ğ‘ğ‘ )
=
ï£±ï£´ï£´ï£´ï£´ï£´ï£²ï£´ï£´ï£´ï£´ï£´ï£³
inf
ğœ‹
Eğœ‹ [ğ‘
(
(ğ‘‹ â€², ğ´â€², ğ‘Œ â€²), (ğ‘‹,ğ´,ğ‘Œ )
)
2]
s.t. ğœ‹ âˆˆ P((X Ã— A Ã— Y) Ã— (X Ã— A Ã—Y))
Eğœ‹ [ğ‘“ğ›½ (ğ‘‹,ğ´,ğ‘Œ )] = 0
Eğœ‹ [1(ğ‘¥ğ‘– ,ğ‘ğ‘– ,?Ì‚?ğ‘– ) (ğ‘‹ â€², ğ´â€², ğ‘Œ â€²)]=1/ğ‘ âˆ€ğ‘– âˆˆ [ğ‘ ] .
To shorten the notations, we use Î = X Ã— A Ã— Y and ÎÌ‚ğ‘ =
{(ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– )}. Moreover, define the vector ğ‘ and the vector-valued
Borel measurable function on Î Ã— ÎÌ‚ğ‘ as
ğ‘ =
Â©Â­Â­Â­Â­Â«
0
1/ğ‘
.
.
.
1/ğ‘
ÂªÂ®Â®Â®Â®Â¬
ğ‘“ (b, b â€²) =
Â©Â­Â­Â­Â­Â­Â«
ğ‘“ğ›½ (b)
1
Ë†bğ‘–
(b â€²)
.
.
.
1
Ë†bğ‘
(b â€²)
ÂªÂ®Â®Â®Â®Â®Â¬
.
By using the introduced notation, we can reformulate the above
optimization problem as
inf
{
Eğœ‹ [ğ‘ (b, b â€²)2] : ğœ‹ âˆˆ M+ (Î Ã— ÎÌ‚ğ‘ ),Eğœ‹ [ğ‘“ (b, b â€²)] = ğ‘
}
which is a problem of moments. By Lemma A.1, the above optimiza-
tion problem satisfies the Slater condition, thus the strong duality
result [60, Section 2.2] implies that
Ropp ( Ë†Pğ‘ , ğ‘ğ‘ )
=
ï£±ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£²ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£³
sup
1
ğ‘
ğ‘âˆ‘
ğ‘–=1
ğ‘ğ‘–
s.t. ğ‘ âˆˆ Rğ‘ , ğ›¾ âˆˆ R
ğ‘âˆ‘
ğ‘–=1
ğ‘ğ‘–1(ğ‘¥ğ‘– ,ğ‘ğ‘– ,?Ì‚?ğ‘– ) (ğ‘¥
â€², ğ‘â€², ğ‘¦â€²) âˆ’ ğ›¾ ğ‘“ğ›½ (ğ‘¥, ğ‘,ğ‘¦)
â‰¤ ğ‘
(
(ğ‘¥ â€², ğ‘â€², ğ‘¦â€²), (ğ‘¥, ğ‘,ğ‘¦)
)
2
âˆ€(ğ‘¥, ğ‘,ğ‘¦), (ğ‘¥ â€², ğ‘â€², ğ‘¦â€²) âˆˆ X Ã— A Ã—Y .
(12)
Note that the problem in (12) can be equivalently represented asï£±ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£²ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£³
sup
1
ğ‘
ğ‘âˆ‘
ğ‘–=1
ğ‘ğ‘–
s.t. ğ‘ âˆˆ Rğ‘ , ğ›¾ âˆˆ R
ğ‘ğ‘– âˆ’ ğ›¾ ğ‘“ğ›½ (ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– ) â‰¤ ğ‘
(
(ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– ), (ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– )
)
2
âˆ€(ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– ) âˆˆ X Ã— A Ã—Y,âˆ€ğ‘– âˆˆ [ğ‘ ]
= sup
ğ›¾ âˆˆR
1
ğ‘
ğ‘âˆ‘
ğ‘–=1
inf
ğ‘¥ğ‘– âˆˆX
{
âˆ¥ğ‘¥ğ‘– âˆ’ ğ‘¥ğ‘– âˆ¥2 + ğ›¾ ğ‘“ğ›½ (ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– )
}
. (13)
660
FAccT â€™21, March 1â€“10, 2021, Virtual Event, Canada Bahar Taskesen, Jose Blanchet, Daniel Kuhn, and Viet Anh Nguyen
Because ğ‘“ğ›½ has the form (11), we have the equivalent problem
sup
ğ›¾ âˆˆR
1
ğ‘
ğ‘âˆ‘
ğ‘–=1
inf
ğ‘¥ğ‘– âˆˆX
{
âˆ¥ğ‘¥ğ‘– âˆ’ ğ‘¥ğ‘– âˆ¥2 + ğ›¾_(ğ‘ğ‘– , ğ‘¦ğ‘– )â„ğ›½ (ğ‘¥ğ‘– )
}
.
For any ğ‘– âˆˆ I0, _(ğ‘ğ‘– , ğ‘¦ğ‘– ) = 0, and in this case we have the optimal
solution of ğ‘¥ğ‘– satisfies ğ‘¥
â˜…
ğ‘–
= ğ‘¥ğ‘– . As a consequence, the summation
collapses to a partial sum over I1. This observation completes the
proof. â–¡
Proof of Theorem 4.4. Leveraging equation (13), we can ex-
press
Ropp ( Ë†Pğ‘ , ğ‘ğ‘ ) =
sup
ğ›¾
E
Ë†Pğ‘
[
inf
Î”
ğ›¾â„ğ›½ (ğ‘‹ + Î”)
(
1(1,1) (ğ´,ğ‘Œ )
ğ‘ğ‘
11
âˆ’
1(0,1) (ğ´,ğ‘Œ )
ğ‘ğ‘
01
)
+ âˆ¥Î”âˆ¥2
]
.
We define
ğ»ğ‘ â‰œ
1
âˆš
ğ‘
ğ‘âˆ‘
ğ‘–=1
â„ğ›½ (ğ‘¥ğ‘– )
(
1(1,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
ğ‘ğ‘
11
âˆ’
1(0,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
ğ‘ğ‘
01
)
,
and using this expression we can reformulate Ropp ( Ë†Pğ‘ , ğ‘ğ‘ ) as
sup
ğ›¾
{
1
âˆš
ğ‘
ğ›¾ğ»ğ‘ + E
Ë†Pğ‘
[
inf
Î”
ğ›¾ [â„ğ›½ (ğ‘‹ + Î”) âˆ’ â„ğ›½ (ğ‘‹ )]Ã—(
1(1,1) (ğ´,ğ‘Œ )
ğ‘ğ‘
11
âˆ’
1(0,1) (ğ´,ğ‘Œ )
ğ‘ğ‘
01
)
+ âˆ¥Î”âˆ¥2
]}
.
Because â„ğ›½ is a sigmoid function, it is differentiable, and by the
fundamental theorem of calculus, we have for any ğ‘¥ âˆˆ X,
â„ğ›½ (ğ‘¥ + Î”) âˆ’ â„ğ›½ (ğ‘¥) =
âˆ«
1
0
âˆ‡â„ğ›½ (ğ‘¥ + ğ‘¡Î”) Â· Î”dğ‘¡,
where Â· represents the inner product on Rğ‘‘ . By applying variable
transformations ğ›¾ â† ğ›¾
âˆš
ğ‘ and Î”â† Î”
âˆš
ğ‘ , we have
ğ‘ Ã— Ropp ( Ë†Pğ‘ , ğ‘ğ‘ )
= sup
ğ›¾
{
ğ›¾ğ»ğ‘ + E
Ë†Pğ‘
[
inf
Î”
ğ›¾
âˆ«
1
0
âˆ‡â„ğ›½
(
ğ‘‹ + ğ‘¡ Î”
âˆš
ğ‘
)
Â· Î”dğ‘¡(
1(1,1) (ğ´,ğ‘Œ )
ğ‘ğ‘
11
âˆ’
1(0,1) (ğ´,ğ‘Œ )
ğ‘ğ‘
01
)
+ âˆ¥Î”âˆ¥2
]}
= sup
ğ›¾
{
ğ›¾ğ»ğ‘ + 1
ğ‘
ğ‘âˆ‘
ğ‘–=1
inf
Î”ğ‘–
ğ›¾
âˆ«
1
0
âˆ‡â„ğ›½
(
ğ‘¥ğ‘– + ğ‘¡
Î”ğ‘–âˆš
ğ‘
)
Â· Î”ğ‘–dğ‘¡ Ã—(
1(1,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
ğ‘ğ‘
11
âˆ’
1(0,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
ğ‘ğ‘
01
)
+ âˆ¥Î”ğ‘– âˆ¥2
}
,
where the second equality follows by the definition of the empirical
distribution
Ë†Pğ‘ . For any values of ğ‘ğ‘
01
> 0 and ğ‘ğ‘
11
> 0, we have
for any ğ›¾ â‰  0,
P
(ğ›¾âˆ‡â„ğ›½ (ğ‘‹ )
(
1(1,1) (ğ´,ğ‘Œ )
ğ‘ğ‘
11
âˆ’
1(0,1) (ğ´,ğ‘Œ )
ğ‘ğ‘
01
)
âˆ—
= 0
)
= P
(
(ğ‘ğ‘
11
)âˆ’1
1(1,1) (ğ´,ğ‘Œ ) = (ğ‘ğ‘01
)âˆ’1
1(0,1) (ğ´,ğ‘Œ )
)
= P(ğ‘Œ = 0) < 1,
which implies that
P
(ğ›¾âˆ‡â„ğ›½ (ğ‘‹ )
(
1(1,1) (ğ´,ğ‘Œ )
ğ‘ğ‘
11
âˆ’
1(0,1) (ğ´,ğ‘Œ )
ğ‘ğ‘
01
)
âˆ—
> 0
)
> 0.
This coincides with Assumption A4 in [7]. Using the same argument
as in the proof of [7, Theorem 3], we can show that the optimal
solution for ğ›¾ and Î”ğ‘– belong to a compact set with high probability.
Moreover, we have
1(1,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
ğ‘ğ‘
11
âˆ’
1(0,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
ğ‘ğ‘
01
=
1(1,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
ğ‘11
(1 âˆ’ ğ‘œP (1)) âˆ’
1(0,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
ğ‘01
(1 âˆ’ ğ‘œP (1)) ,
and thus
ğ‘ Ã— Ropp ( Ë†Pğ‘ , ğ‘ğ‘ )
= sup
ğ›¾
{
ğ›¾ğ»ğ‘ + 1
ğ‘
ğ‘âˆ‘
ğ‘–=1
inf
Î”ğ‘–
ğ›¾
âˆ«
1
0
âˆ‡â„ğ›½
(
ğ‘¥ğ‘– + ğ‘¡
Î”ğ‘–âˆš
ğ‘
)
Â· Î”ğ‘–dğ‘¡ Ã—(
1(1,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
ğ‘11
âˆ’
1(0,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
ğ‘01
)
+ âˆ¥Î”ğ‘– âˆ¥2 + ğ‘œP (1)
}
.
In the next step, fix any tuple (ğ‘,ğ‘¦) âˆˆ A Ã— Y, and denote the
following constant
ğ‘€1 = |ğ‘âˆ’1
11
1(1,1) (ğ‘,ğ‘¦) âˆ’ ğ‘âˆ’1
01
1(0,1) (ğ‘,ğ‘¦) |.
We find
âˆ¥ [âˆ‡â„ğ›½ (ğ‘¥ + Î”) âˆ’ âˆ‡â„ğ›½ (ğ‘¥)] (ğ‘âˆ’1
11
1(1,1) (ğ‘,ğ‘¦) âˆ’ ğ‘âˆ’1
01
1(0,1) (ğ‘,ğ‘¦))âˆ¥âˆ—
=|â„ğ›½ (ğ‘¥ + Î”) âˆ’ â„ğ›½ (ğ‘¥) âˆ’ â„ğ›½ (ğ‘¥ + Î”)2 + â„ğ›½ (ğ‘¥)2 |âˆ¥ğ›½ âˆ¥âˆ—ğ‘€1
â‰¤(|â„ğ›½ (ğ‘¥ + Î”) âˆ’ â„ğ›½ (ğ‘¥) | + |â„ğ›½ (ğ‘¥ + Î”)2 âˆ’ â„ğ›½ (ğ‘¥)2 |) âˆ¥ğ›½ âˆ¥âˆ—ğ‘€1 .
Because the sigmoid function is slope-restricted in the interval
[0, 1] [22, Proposition 2], we have
0 â‰¤
â„ğ›½ (ğ‘¥ + Î”) âˆ’ â„ğ›½ (ğ‘¥)
ğ›½âŠ¤Î”
â‰¤ 1,
which implies that
|â„ğ›½ (ğ‘¥ + Î”) âˆ’ â„ğ›½ (ğ‘¥) | â‰¤ |ğ›½âŠ¤Î”| â‰¤ âˆ¥ğ›½ âˆ¥âˆ—âˆ¥Î”âˆ¥,
where the second inequality follows from HÃ¶lder inequality. Using
a similar argument, we have
|â„ğ›½ (ğ‘¥ + Î”)2 âˆ’ â„ğ›½ (ğ‘¥)2 | = â‰¤ (â„ğ›½ (ğ‘¥ + Î”) + â„ğ›½ (ğ‘¥)) |â„ğ›½ (ğ‘¥ + Î”) âˆ’ â„ğ›½ (ğ‘¥) |
â‰¤ 2âˆ¥ğ›½ âˆ¥âˆ—âˆ¥Î”âˆ¥.
Combining these inequalities, we conclude that
âˆ¥ [âˆ‡â„ğ›½ (ğ‘¥ + Î”) âˆ’ âˆ‡â„ğ›½ (ğ‘¥)] (ğ‘âˆ’1
11
1(1,1) (ğ‘,ğ‘¦) âˆ’ ğ‘âˆ’1
01
1(0,1) (ğ‘,ğ‘¦))âˆ¥2
â‰¤ 3âˆ¥ğ›½ âˆ¥2âˆ—ğ‘€1âˆ¥Î”âˆ¥,
661
A Statistical Test for Probabilistic Fairness FAccT â€™21, March 1â€“10, 2021, Virtual Event, Canada
and thus Assumption 6â€™ in [7] is satisfied. If ğ»ğ‘ ğ‘‘.âˆ’â†’ ğ‘ for some
random variable ğ‘ , then [7, Lemma 4] asserts that
ğ‘ Ã— Ropp ( Ë†Pğ‘ , ğ‘ğ‘ )
ğ‘‘.âˆ’â†’ sup
ğ›¾ âˆˆR
{
ğ›¾ğ‘ âˆ’ ğ›¾2
4
EP
[âˆ‡â„ğ›½ (ğ‘‹ ) (1(1,1) (ğ´,ğ‘Œ )ğ‘11
âˆ’
1(0,1) (ğ´,ğ‘Œ )
ğ‘01
)2
âˆ—
]}
=
(
EP
[âˆ‡â„ğ›½ (ğ‘‹ ) (1(1,1) (ğ´,ğ‘Œ )ğ‘11
âˆ’
1(0,1) (ğ´,ğ‘Œ )
ğ‘01
)2
âˆ—
])âˆ’1
ğ‘ 2,
where the equality sign follows from the fact that for any realization
of ğ‘ , the optimal solution of ğ›¾ is
ğ›¾â˜…(ğ‘ )= 2ğ‘
EP
[âˆ‡â„ğ›½ (ğ‘‹ ) (1(1,1) (ğ´,ğ‘Œ )ğ‘11
âˆ’ 1(0,1) (ğ´,ğ‘Œ )
ğ‘01
)2
âˆ—
] .
We now study the limit distribution ğ‘ . In the next step, we study
the limit of ğ»ğ‘
.
ğ»ğ‘
=
1
âˆš
ğ‘
ğ‘âˆ‘
ğ‘–=1
â„ğ›½ (ğ‘¥ğ‘– )
(
1(1,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
ğ‘ğ‘
11
âˆ’
1(0,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
ğ‘ğ‘
01
)
=
1
ğ‘ğ‘
11
ğ‘ğ‘
01
Ã— 1
âˆš
ğ‘
ğ‘âˆ‘
ğ‘–=1
â„ğ›½ (ğ‘¥ğ‘– )
(
ğ‘ğ‘
01
1(1,1) (ğ‘ğ‘– , ğ‘¦ğ‘– ) âˆ’ ğ‘ğ‘11
1(0,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
)
=
1
ğ‘ğ‘
11
ğ‘ğ‘
01
Ã—
(
1
âˆš
ğ‘
ğ‘âˆ‘
ğ‘–=1
â„ğ›½ (ğ‘¥ğ‘– )
(
ğ‘011(1,1) (ğ‘ğ‘– , ğ‘¦ğ‘– ) âˆ’ ğ‘111(0,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
)
+
âˆš
ğ‘ (ğ‘ğ‘
01
âˆ’ ğ‘01)
1
ğ‘
ğ‘âˆ‘
ğ‘–=1
1(1,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )â„ğ›½ (ğ‘¥ğ‘– )
âˆ’
âˆš
ğ‘ (ğ‘ğ‘
11
âˆ’ ğ‘11)
1
ğ‘
ğ‘âˆ‘
ğ‘–=1
1(0,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )â„ğ›½ (ğ‘¥ğ‘– )
)
By Slutskyâ€™s theorem, we have
âˆš
ğ‘ (ğ‘ğ‘
01
âˆ’ ğ‘01)Ã—
1
ğ‘
ğ‘âˆ‘
ğ‘–=1
(
1(1,1) (ğ‘ğ‘– , ğ‘¦ğ‘– ) â„ğ›½ (ğ‘¥ğ‘– ) âˆ’ EP [1(1,1) (ğ´,ğ‘Œ )â„ğ›½ (ğ‘‹ )]
)
= ğ‘œP (1),
âˆš
ğ‘ (ğ‘ğ‘
11
âˆ’ ğ‘11)Ã—
1
ğ‘
ğ‘âˆ‘
ğ‘–=1
(
1(0,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )â„ğ›½ (ğ‘¥ğ‘– ) âˆ’ EP [1(0,1) (ğ´,ğ‘Œ ) â„ğ›½ (ğ‘‹ )]
)
= ğ‘œP (1).
Under the null hypothesisHopp
0
, we have
ğ»ğ‘
=
1
ğ‘ğ‘
11
ğ‘ğ‘
01
Ã—
[
1
âˆš
ğ‘
ğ‘âˆ‘
ğ‘–=1
â„ğ›½ (ğ‘¥ğ‘– )
(
ğ‘011(1,1) (ğ‘ğ‘– , ğ‘¦ğ‘– ) âˆ’ ğ‘111(0,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
)
+
âˆš
ğ‘
(
1
ğ‘
ğ‘âˆ‘
ğ‘–=1
1(0,1) (ğ‘ğ‘– , ğ‘¦ğ‘– ) âˆ’ ğ‘01
)
EP [1(1,1) (ğ´,ğ‘Œ )â„ğ›½ (ğ‘‹ )]
âˆ’
âˆš
ğ‘
(
1
ğ‘
ğ‘âˆ‘
ğ‘–=1
1(1,1) (ğ‘ğ‘– , ğ‘¦ğ‘– ) âˆ’ ğ‘11
)
EP [1(0,1) (ğ´,ğ‘Œ )â„ğ›½ (ğ‘‹ )]
]
+ ğ‘œP (1)
=
1
ğ‘ğ‘
11
ğ‘ğ‘
01
Ã—
[
1
âˆš
ğ‘
ğ‘âˆ‘
ğ‘–=1
â„ğ›½ (ğ‘¥ğ‘– )
(
ğ‘011(1,1) (ğ‘ğ‘– , ğ‘¦ğ‘– ) âˆ’ ğ‘111(0,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
)
+ 1
âˆš
ğ‘
ğ‘âˆ‘
ğ‘–=1
(
1(0,1) (ğ‘ğ‘– , ğ‘¦ğ‘– ) âˆ’ ğ‘01
)
EP [1(1,1) (ğ´,ğ‘Œ )â„ğ›½ (ğ‘‹ )]
âˆ’ 1
âˆš
ğ‘
ğ‘âˆ‘
ğ‘–=1
(
1(1,1) (ğ‘ğ‘– , ğ‘¦ğ‘– ) âˆ’ ğ‘11
)
EP [1(0,1) (ğ´,ğ‘Œ )â„ğ›½ (ğ‘‹ )]
]
+ ğ‘œP (1)
ğ‘‘.âˆ’â†’ ğ‘,
where ğ‘ âˆ¼ 1
ğ‘11ğ‘01
N(0, ğœ2), ğœ2 = Cov(ğ‘ ), where ğ‘ is defined as in
the theorem statement. Defining \ completes the proof. â–¡
A.3 Proofs of Section 5
The proof of Proposition 5.2 necessitates the following preparatory
lemma. We use the same notations with Lemma A.1.
Lemma A.2 (Slater condition - Probabilistic equalized odds). Sup-
pose that ğ›½ â‰  0 and ğ‘ğ‘ğ‘ğ‘¦ âˆˆ (0, 1) for all (ğ‘,ğ‘¦) âˆˆ A Ã— Y. Define the
functions
ğ‘“ğ›½ (ğ‘‹,ğ´,ğ‘Œ ) â‰œ
1
ğ‘ğ‘
11
â„ğ›½ (ğ‘‹ )1(1,1) (ğ´,ğ‘Œ ) âˆ’
1
ğ‘ğ‘
01
â„ğ›½ (ğ‘‹ )1(0,1) (ğ´,ğ‘Œ ),
ğ‘”ğ›½ (ğ‘‹,ğ´,ğ‘Œ ) â‰œ
1
ğ‘ğ‘
10
â„ğ›½ (ğ‘‹ )1(1,0) (ğ´,ğ‘Œ ) âˆ’
1
ğ‘ğ‘
00
â„ğ›½ (ğ‘‹ )1(0,0) (ğ´,ğ‘Œ ),
and let ğ‘“ be a vector-valued function ğ‘“ : Î Ã— ÎÌ‚ğ‘ â†’ Rğ‘+2
ğ‘“ (b, b â€²) =
Â©Â­Â­Â­Â­Â­Â­Â­Â«
1
Ë†bğ‘–
(b â€²)
.
.
.
1
Ë†bğ‘
(b â€²)
ğ‘“ğ›½ (b)
ğ‘”ğ›½ (b)
ÂªÂ®Â®Â®Â®Â®Â®Â®Â¬
Then we have
Â©Â­Â­Â­Â­Â­Â­Â«
1/ğ‘
.
.
.
1/ğ‘
0
0
ÂªÂ®Â®Â®Â®Â®Â®Â¬
âˆˆ int
{
Eğœ‹ [ğ‘“ (b, b â€²)] : ğœ‹ âˆˆ M+ (Î Ã— ÎÌ‚ğ‘ )
}
.
Proof of Lemma A.2. It suffices to show that for any
ğ‘ âˆˆ
(
1
2ğ‘
,
3
2ğ‘
)ğ‘
Ã—
(
âˆ’1
4
,
1
4
)
2
,
662
FAccT â€™21, March 1â€“10, 2021, Virtual Event, Canada Bahar Taskesen, Jose Blanchet, Daniel Kuhn, and Viet Anh Nguyen
there exists a nonnegative measure ğœ‹ âˆˆ M+ (Î Ã— ÎÌ‚ğ‘ ) such that
ğ‘ = Eğœ‹ [ğ‘“ (b, b â€²)]. The proof follows a similar argument as that of
Lemma A.1 by noticing that
Eğœ‹ [ğ‘”ğ›½ (b)] = (ğ‘ğ‘10
)âˆ’1â„ğ›½ (ğ‘¥10)
âˆ‘
ğ‘–âˆˆI10
ğ‘ğ‘– âˆ’ (ğ‘ğ‘00
)âˆ’1â„ğ›½ (ğ‘¥00)
âˆ‘
ğ‘–âˆˆI00
ğ‘ğ‘– ,
and the specification of ğ‘¥10 and ğ‘¥00 can be achieved using similar
steps. â–¡
Proof of Proposition 5.2. To ease the exposition, we let the
function Î› : A Ã—Y â†’ R2
be defined as
Î›(ğ‘,ğ‘¦) =
(
(ğ‘ğ‘
11
)âˆ’1
1(1,1) (ğ‘,ğ‘¦) âˆ’ (ğ‘ğ‘01
)âˆ’1
1(0,1) (ğ‘,ğ‘¦)
(ğ‘ğ‘
10
)âˆ’1
1(1,0) (ğ‘,ğ‘¦) âˆ’ (ğ‘ğ‘00
)âˆ’1
1(0,0) (ğ‘,ğ‘¦)
)
.
Moreover, we define ğ‘“ğ›½ as in (11), and additionally define ğ‘”ğ›½ as
ğ‘”ğ›½ (ğ‘¥, ğ‘,ğ‘¦) = (ğ‘ğ‘10
)âˆ’1â„ğ›½ (ğ‘¥)1(1,0) (ğ‘,ğ‘¦) âˆ’ (ğ‘ğ‘00
)âˆ’1â„ğ›½ (ğ‘¥)1(0,0) (ğ‘,ğ‘¦) .
From the definition of Rodd ( Ë†Pğ‘ , ğ‘ğ‘ ), we have
Rodd ( Ë†Pğ‘ , ğ‘ğ‘ )
=
ï£±ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£²ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£³
inf
QâˆˆP
W( Ë†Pğ‘ ,Q)2
s.t. (ğ‘ğ‘
11
)âˆ’1EQ [â„ğ›½ (ğ‘‹ )1(1,1) (ğ´,ğ‘Œ )]
= (ğ‘ğ‘
01
)âˆ’1EQ [â„ğ›½ (ğ‘‹ )1(0,1) (ğ´,ğ‘Œ )]
(ğ‘ğ‘
10
)âˆ’1EQ [â„ğ›½ (ğ‘‹ )1(1,0) (ğ´,ğ‘Œ )]
= (ğ‘ğ‘
00
)âˆ’1EQ [â„ğ›½ (ğ‘‹ )1(0,0) (ğ´,ğ‘Œ )]
Q(ğ´ = ğ‘,ğ‘Œ = ğ‘¦) = ğ‘ğ‘ğ‘ğ‘¦ âˆ€ğ‘ âˆˆ A, ğ‘¦ âˆˆ Y
=
ï£±ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£²ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£³
inf
ğœ‹
Eğœ‹ [ğ‘
(
(ğ‘‹ â€², ğ´â€², ğ‘Œ â€²), (ğ‘‹,ğ´,ğ‘Œ )
)
2]
s.t. ğœ‹ âˆˆ P((X Ã— A Ã— Y) Ã— (X Ã— A Ã—Y))
Eğœ‹ [ğ‘“ğ›½ (ğ‘‹,ğ´,ğ‘Œ )] = 0
Eğœ‹ [ğ‘”ğ›½ (ğ‘‹,ğ´,ğ‘Œ )] = 0
ğœ‹ (ğ´ = ğ‘,ğ‘Œ = ğ‘¦) = ğ‘ğ‘ğ‘ğ‘¦ âˆ€ğ‘ âˆˆ A, ğ‘¦ âˆˆ Y
Eğœ‹ [1(ğ‘¥ğ‘– ,ğ‘ğ‘– ,?Ì‚?ğ‘– ) (ğ‘‹ â€², ğ´â€², ğ‘Œ â€²)] = 1/ğ‘ âˆ€ğ‘– âˆˆ [ğ‘ ] .
To shorten the notations, we use Î = X Ã— A Ã— Y and ÎÌ‚ğ‘ =
{(ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– )}. Moreover, define the vector ğ‘ and the vector-valued
Borel measurable function on Î Ã— ÎÌ‚ğ‘ as
ğ‘ =
Â©Â­Â­Â­Â­Â­Â­Â«
0
0
1/ğ‘
.
.
.
1/ğ‘
ÂªÂ®Â®Â®Â®Â®Â®Â¬
ğ‘“ (b, b â€²) =
Â©Â­Â­Â­Â­Â­Â­Â­Â«
ğ‘“ğ›½ (b)
ğ‘”ğ›½ (b)
1
Ë†bğ‘–
(b â€²)
.
.
.
1
Ë†bğ‘
(b â€²)
ÂªÂ®Â®Â®Â®Â®Â®Â®Â¬
.
By using the introduced notation, we can reformulate the above
optimization problem as
inf
{
Eğœ‹ [ğ‘ (b, b â€²)2] : ğœ‹ âˆˆ M+ (Î Ã— ÎÌ‚ğ‘ ),Eğœ‹ [ğ‘“ (b, b â€²)] = ğ‘
}
which is a problem of moments. By Lemma A.2, the above optimiza-
tion problem satisfies the Slater condition, thus the strong duality
result [60, Section 2.2] implies that
Rodd ( Ë†Pğ‘ , ğ‘ğ‘ )
=
ï£±ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£²ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£³
sup
1
ğ‘
ğ‘âˆ‘
ğ‘–=1
ğ‘ğ‘–
s.t. ğ‘ âˆˆ Rğ‘ , ğ›¾ âˆˆ R, Z âˆˆ R
ğ‘âˆ‘
ğ‘–=1
ğ‘ğ‘–1(ğ‘¥ğ‘– ,ğ‘ğ‘– ,?Ì‚?ğ‘– ) (ğ‘¥
â€², ğ‘â€², ğ‘¦â€²) âˆ’ ğ›¾ ğ‘“ğ›½ (ğ‘¥, ğ‘,ğ‘¦) âˆ’ Zğ‘”ğ›½ (ğ‘¥, ğ‘,ğ‘¦)
â‰¤ ğ‘
(
(ğ‘¥ â€², ğ‘â€², ğ‘¦â€²), (ğ‘¥, ğ‘,ğ‘¦)
)
2
âˆ€(ğ‘¥, ğ‘,ğ‘¦), (ğ‘¥ â€², ğ‘â€², ğ‘¦â€²) âˆˆ X Ã— A Ã—Y
=
ï£±ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£²ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£³
sup
1
ğ‘
ğ‘âˆ‘
ğ‘–=1
ğ‘ğ‘–
s.t. ğ‘ âˆˆ Rğ‘ , ğ›¾ âˆˆ R, Z âˆˆ R
ğ‘ğ‘– âˆ’ ğ›¾ ğ‘“ğ›½ (ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– ) âˆ’ Zğ‘”ğ›½ (ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– )
â‰¤ ğ‘
(
(ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– ), (ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– )
)
2
âˆ€(ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– ) âˆˆ X Ã— A Ã—Y,âˆ€ğ‘– âˆˆ [ğ‘ ]
= sup
ğ›¾,Z
1
ğ‘
ğ‘âˆ‘
ğ‘–=1
inf
ğ‘¥ğ‘– âˆˆX
{
âˆ¥ğ‘¥ğ‘– âˆ’ ğ‘¥ğ‘– âˆ¥2 + ğ›¾ ğ‘“ğ›½ (ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– ) + Zğ‘”ğ›½ (ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– )
}
,
By definition of ğ‘“ğ›½ , ğ‘”ğ›½ and the parameters _ğ‘– , we have
ğ›¾ ğ‘“ğ›½ (ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– ) + Zğ‘”ğ›½ (ğ‘¥ğ‘– , ğ‘ğ‘– , ğ‘¦ğ‘– ) = (ğ›¾_ğ‘–11 (ğ‘¦ğ‘– ) + Z_ğ‘–10 (ğ‘¦ğ‘– ))â„ğ›½ (ğ‘¥ğ‘– ) .
The proof is complete. â–¡
Proof of Lemma 5.3. Because [ğ‘ ] = I0 âˆª I1, we can write
Rodd ( Ë†Pğ‘ , ğ‘ğ‘ )
= sup
ğ›¾ âˆˆR
1
ğ‘
âˆ‘
ğ‘–âˆˆI1
inf
ğ‘¥ğ‘– âˆˆX
{
âˆ¥ğ‘¥ğ‘– âˆ’ ğ‘¥ğ‘– âˆ¥2 + ğ›¾_ğ‘–â„ğ›½ (ğ‘¥ğ‘– )
}
+ sup
Z âˆˆR
1
ğ‘
âˆ‘
ğ‘–âˆˆI0
inf
ğ‘¥ğ‘– âˆˆX
{
âˆ¥ğ‘¥ğ‘– âˆ’ ğ‘¥ğ‘– âˆ¥2 + Z_ğ‘–â„ğ›½ (ğ‘¥ğ‘– )
}
.
Note that the first supremum coincides with Ropp ( Ë†Pğ‘ , ğ‘ğ‘ ), and the
second supremum is ğ‘ˆğ‘ . Under the Euclidean norm assumption,
we can use Lemma B.1 to reformulate the inner infimum problems
forğ‘ˆğ‘ , which leads to (9). â–¡
Proof of Theorem 5.4. By applying a similar duality argument
as in the proof of Theorem 4.4, we can reformulate Rodd ( Ë†Pğ‘ , ğ‘ğ‘ )
as
Rodd ( Ë†Pğ‘ , ğ‘ğ‘ )
=sup
ğ›¾,Z
E
Ë†Pğ‘
ï£®ï£¯ï£¯ï£¯ï£¯ï£°inf
Î”
ï£±ï£´ï£´ï£²ï£´ï£´ï£³
ğ›¾â„ğ›½ (ğ‘‹ + Î”)
(1(1,1) (ğ´,ğ‘Œ )
ğ‘ğ‘
11
âˆ’ 1(0,1) (ğ´,ğ‘Œ )
ğ‘ğ‘
01
)
+Zâ„ğ›½ (ğ‘‹ + Î”)
(1(1,0) (ğ´,ğ‘Œ )
ğ‘ğ‘
10
âˆ’ 1(0,0) (ğ´,ğ‘Œ )
ğ‘ğ‘
00
)
+ âˆ¥Î”âˆ¥2
ï£¼ï£´ï£´ï£½ï£´ï£´ï£¾
ï£¹ï£ºï£ºï£ºï£ºï£»
= sup
ğ›¾,Z
{
1
âˆš
ğ‘
(Zğ»ğ‘
0
+ ğ›¾ğ»ğ‘
1
)+
E
Ë†Pğ‘
ï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£°inf
Î”
Â©Â­Â­Â­Â«
ğ›¾ [â„ğ›½ (ğ‘‹ + Î”) âˆ’ â„ğ›½ (ğ‘‹ )]
(1(1,1) (ğ´,ğ‘Œ )
ğ‘ğ‘
11
âˆ’ 1(0,1) (ğ´,ğ‘Œ )
ğ‘ğ‘
01
)
+Z [â„ğ›½ (ğ‘‹ + Î”) âˆ’ â„ğ›½ (ğ‘‹ )]
(1(1,0) (ğ´,ğ‘Œ )
ğ‘ğ‘
10
âˆ’ 1(0,0) (ğ´,ğ‘Œ )
ğ‘ğ‘
00
)
+âˆ¥Î”âˆ¥2
ÂªÂ®Â®Â®Â¬
ï£¹ï£ºï£ºï£ºï£ºï£ºï£ºï£»
ï£¼ï£´ï£´ï£´ï£´ï£½ï£´ï£´ï£´ï£´ï£¾
663
A Statistical Test for Probabilistic Fairness FAccT â€™21, March 1â€“10, 2021, Virtual Event, Canada
with the random variables ğ»ğ‘
0
and ğ»ğ‘
1
being defined as
ğ»ğ‘
0
â‰œ
1
âˆš
ğ‘
ğ‘âˆ‘
ğ‘–=1
â„ğ›½ (ğ‘¥ğ‘– )
(1(1,0) (ğ‘ğ‘– , ğ‘¦ğ‘– )
ğ‘ğ‘
10
âˆ’
1(0,0) (ğ‘ğ‘– , ğ‘¦ğ‘– )
ğ‘ğ‘
00
)
,
ğ»ğ‘
1
â‰œ
1
âˆš
ğ‘
ğ‘âˆ‘
ğ‘–=1
â„ğ›½ (ğ‘¥ğ‘– )
(1(1,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
ğ‘ğ‘
11
âˆ’
1(0,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
ğ‘ğ‘
01
)
.
Notice that the condition
P
( (
ğ›¾1
ğ›¾0
)âŠ¤
Î›(ğ´,ğ‘Œ )âˆ‡â„ğ›½ (ğ‘‹ )

âˆ—
> 0
)
> 0
is satisfied for any (ğ›¾0, ğ›¾1) â‰  0. Using the same argument as in the
proof of [7, Theorem 3], we can show that the optimal solution
for ğ›¾ , Z and Î”ğ‘– belong to a compact set with high probability. As
ğ‘ğ‘ğ‘¦ âˆ’ ğ‘ğ‘ğ‘¦ = ğ‘œP (1) for any (ğ‘,ğ‘¦) âˆˆ A Ã— Y, we have
ğ‘ Ã— Rodd ( Ë†Pğ‘ , ğ‘ğ‘ )
= sup
ğ›¾,Z
{
ğ›¾ğ»ğ‘
1
+ Zğ»ğ‘
0
+ 1
ğ‘
ğ‘âˆ‘
ğ‘–=1
inf
Î”ğ‘–
ğ›¾
âˆ«
1
0
âˆ‡â„ğ›½
(
ğ‘¥ğ‘– + ğ‘¡
Î”ğ‘–âˆš
ğ‘
)
Â· Î”ğ‘–dğ‘¡ Ã—(
ğ›¾
Z
)âŠ¤ (
ğ‘âˆ’1
11
1(1,1) (ğ‘ğ‘– , ğ‘¦ğ‘– ) âˆ’ ğ‘âˆ’1
01
1(0,1) (ğ‘ğ‘– , ğ‘¦ğ‘– )
ğ‘âˆ’1
10
1(1,0) (ğ‘ğ‘– , ğ‘¦ğ‘– ) âˆ’ ğ‘âˆ’1
00
1(0,0) (ğ‘ğ‘– , ğ‘¦ğ‘– )
)
+ âˆ¥Î”ğ‘– âˆ¥2 + ğ‘œP (1)
}
.
Using a similar argument, we can bound
âˆ¥ [âˆ‡â„ğ›½ (ğ‘¥ + Î”) âˆ’ âˆ‡â„ğ›½ (ğ‘¥)] (ğ‘âˆ’1
10
1(1,0) (ğ‘,ğ‘¦) âˆ’ ğ‘âˆ’1
00
1(0,0) (ğ‘,ğ‘¦))âˆ¥2
â‰¤ 3âˆ¥ğ›½ âˆ¥2âˆ—ğ‘€0âˆ¥Î”âˆ¥
for some constantğ‘€0, and thus Assumption 6â€™ in [7] is satisfied. If
ğ»ğ‘
0
ğ‘‘.âˆ’â†’ ğ»0 and ğ»ğ‘
1
ğ‘‘.âˆ’â†’ ğ»1 for some random variables ğ»0 and ğ»1,
then [7, Lemma 4] asserts that
ğ‘ Ã— Rodd ( Ë†Pğ‘ , ğ‘ğ‘ ) ğ‘‘.âˆ’â†’
sup
ğ›¾,Z
{ğ›¾ğ»1 + Zğ»0+
EP
[(ğ›¾
Z
)âŠ¤(
ğ‘âˆ’1
11
1(1,1) (ğ´,ğ‘Œ )âˆ’ğ‘âˆ’1
01
1(0,1) (ğ´,ğ‘Œ )
ğ‘âˆ’1
10
1(1,0) (ğ´,ğ‘Œ )âˆ’ğ‘âˆ’1
00
1(0,0) (ğ´,ğ‘Œ )
)
âˆ‡â„ğ›½ (ğ‘‹ )
2
âˆ—
]}
.
Using the same limiting argument as in the proof of Theorem 4.4,
we have the characterization of ğ»1 and ğ»0 as in the statement of
the theorem. â–¡
B APPENDIX - AUXILIARY RESULT
The following lemma is used repeatedly to prove Lemmas 4.3
and 5.3.
Lemma B.1. For any ğœ” âˆˆ R, ğ‘¥ âˆˆ Rğ‘ and ğ›½ âˆˆ Rğ‘ , we have
inf
ğ‘¥ âˆˆRğ‘
âˆ¥ğ‘¥ âˆ’ ğ‘¥ âˆ¥2
2
+ ğœ”
1 + exp(âˆ’ğ›½âŠ¤ğ‘¥)
= min
ğ‘˜âˆˆ[0, 1
8
]
ğœ”2âˆ¥ğ›½ âˆ¥2
2
ğ‘˜2 + ğœ”
1 + exp(âˆ’ğ›½âŠ¤ğ‘¥ + ğ‘˜ğœ” âˆ¥ğ›½ âˆ¥2
2
)
. (14)
Proof of Lemma B.1. Any ğ‘¥ âˆˆ Rğ‘ can be written using the
orthogonal decomposition as ğ‘¥ = ğ‘¥ âˆ’ ğ‘˜ğœ”ğ›½ âˆ’ ğ‘˜ â€²ğ›½âŠ¥ for some ğ‘˜ âˆˆ R,
ğ‘˜ â€² âˆˆ R and ğ›½âŠ¥ perpendicular to ğ›½ , that is, ğ›½âŠ¤ (ğ›½âŠ¥) = 0. Optimizing
over ğ‘¥ is equivalent to jointly optimizing over ğ‘˜ , ğ‘˜ â€² and ğ›½âŠ¥ as
inf âˆ¥ğ‘˜ğœ”ğ›½ + ğ‘˜ â€²ğ›½âŠ¥âˆ¥2
2
+ ğœ”
1 + exp(âˆ’ğ›½âŠ¤ğ‘¥ + ğ‘˜ğœ” âˆ¥ğ›½ âˆ¥2
2
)
s.t. ğ‘˜ âˆˆ R, ğ‘˜ â€² âˆˆ R, ğ›½âŠ¥ âˆˆ Rğ‘ , ğ›½âŠ¤ (ğ›½âŠ¥) = 0.
After extending the norm, and by noticing that the optimal solution
in ğ‘˜ â€² and ğ›½âŠ¥ should satisfy ğ‘˜ â€²ğ›½âŠ¥ = 0, the above optimization
problem is equivalent to
inf ğ‘˜2ğœ”2âˆ¥ğ›½ âˆ¥2
2
+ ğœ”
1 + exp(âˆ’ğ›½âŠ¤ğ‘¥ + ğ‘˜ğœ” âˆ¥ğ›½ âˆ¥2
2
)
s.t. ğ‘˜ âˆˆ R.
Let ğ¿(ğ‘˜) be the objective function of the above optimization prob-
lem, we have
âˆ‡ğ‘˜ğ¿(ğ‘˜) = 2ğœ”2âˆ¥ğ›½ âˆ¥2
2
ğ‘˜ âˆ’
ğœ”2âˆ¥ğ›½ âˆ¥2
2
exp(âˆ’ğ›½âŠ¤ğ‘¥ + ğ‘˜ğœ” âˆ¥ğ›½ âˆ¥2
2
)
(1 + exp(âˆ’ğ›½âŠ¤ğ‘¥ + ğ‘˜ğœ” âˆ¥ğ›½ âˆ¥2
2
))2
= ğœ”2âˆ¥ğ›½ âˆ¥2
2
(2ğ‘˜ âˆ’ ğœ (ğ‘˜) (1 âˆ’ ğœ (ğ‘˜))) ,
where for the purpose of this proof, we define ğœ (ğ‘˜) as
ğœ (ğ‘˜) â‰œ 1
1 + exp(âˆ’ğ›½âŠ¤ğ‘¥ + ğ‘˜ğœ” âˆ¥ğ›½ âˆ¥2
2
)
âˆˆ (0, 1).
Notice that ğœ (ğ‘˜) (1âˆ’ğœ (ğ‘˜)) âˆˆ (0, 1
4
) for any value of ğ‘˜ âˆˆ R. Because
âˆ‡ğ‘˜ğ¿(ğ‘˜) is continuous inğ‘˜ ,âˆ‡ğ‘˜ğ¿(ğ‘˜) â‰¤ 0 for anyğ‘˜ â‰¤ 0, andâˆ‡ğ‘˜ğ¿(ğ‘˜) â‰¥
0 for any ğ‘˜ â‰¥ 1
8
, one can conclude that there exists an optimal
solution ğ‘˜â˜… that lies in the compact range [0, 1
8
]. This completes
the proof. â–¡
Let ğ¿(ğ‘˜) be the objective function of the optimization prob-
lem (14). Figure 5 visualizes several instances of ğ¿(ğ‘˜) for differ-
ent values of inputs ğ›½, ğ‘¥ and ğœ” . Note that ğ¿(ğ‘˜) is non-convex in ğ‘˜ ,
and the optimizer of ğ¿(ğ‘˜) is not necessarily unique as indicated in
Figure 5d.
C APPENDIX - NUMERICAL RESULTS
We use the synthetic experiment from [71] to generate unfairness
landscapes provided in Figure 1. We set the true distributions of
the class labels P(ğ‘Œ = 0) = P(ğ‘Œ = 1) = 1/2, and conditioning on ğ‘Œ ,
the feature ğ‘‹ has
ğ‘‹ |ğ‘Œ = 1 âˆ¼ N([2; 2], [5, 1; 1, 5]),
ğ‘‹ |ğ‘Œ = 0 âˆ¼ N([âˆ’2;âˆ’2], [10, 1; 1, 3]).
Then, we draw sensitive attribute of each sample ğ‘¥ from a Bernoulli
distribution, that is
P(ğ´=1|ğ‘‹ =ğ‘¥ â€²)=ğ‘ğ‘‘ ğ‘“ (ğ‘¥ â€² |ğ‘Œ =1)/(ğ‘ğ‘‘ ğ‘“ (ğ‘¥ â€² |ğ‘Œ =1) + ğ‘ğ‘‘ ğ‘“ (ğ‘¥ â€² |ğ‘Œ =0)),
where ğ‘¥ â€² = [cos(ğœ‹/4), sin(ğœ‹/4); sin(ğœ‹/4), cos(ğœ‹/4)]ğ‘¥ is a rotated
version of the feature vector ğ‘¥ and ğ‘ğ‘‘ ğ‘“ (Â·|ğ‘Œ = ğ‘¦) is the Gaussian
probability density function of ğ‘‹ given ğ‘Œ = ğ‘¦.
664
FAccT â€™21, March 1â€“10, 2021, Virtual Event, Canada Bahar Taskesen, Jose Blanchet, Daniel Kuhn, and Viet Anh Nguyen
0.00 0.02 0.04 0.06 0.08 0.10 0.12
k
18
19
20
21
22
L(
k)
(a) ğ›½ = (0, 1)âŠ¤, ğ‘¥ = (âˆ’2, 10)âŠ¤, ğœ” =17.6
0.00 0.02 0.04 0.06 0.08 0.10 0.12
k
4
6
8
10
12
L(
k)
(b) ğ›½ = (âˆ’5, 5)âŠ¤, ğ‘¥ = (3, 5)âŠ¤, ğœ” =4
0.00 0.02 0.04 0.06 0.08 0.10 0.12
k
2
4
6
8
10
12
14
L(
k)
(c) ğ›½ = (âˆ’6, 5)âŠ¤, ğ‘¥ = (3, 5)âŠ¤, ğœ” =4
0.00 0.02 0.04 0.06 0.08 0.10 0.12
k
4
5
6
7
8
9
10
11
12
L(
k)
(d) ğ›½ = (âˆ’4.7, 5)âŠ¤, ğ‘¥ = (3, 5)âŠ¤, ğœ” =4
Figure 5: Plots of ğ¿(ğ‘˜) with respect to ğ‘˜ for different values of ğ›½, ğ‘¥ and ğœ” .
665

Censorship of Online Encyclopedias: Implications for NLP
Models
Eddie Yangâˆ—
z5yang@ucsd.edu
University of California, San Diego
La Jolla, California
Margaret E. Robertsâˆ—
meroberts@ucsd.edu
University of California, San Diego
La Jolla, California
ABSTRACT
While artificial intelligence provides the backbone for many tools
people use around the world, recent work has brought to attention
that the algorithms powering AI are not free of politics, stereo-
types, and bias. While most work in this area has focused on the
ways in which AI can exacerbate existing inequalities and discrim-
ination, very little work has studied how governments actively
shape training data. We describe how censorship has affected the
development of Wikipedia corpuses, text data which are regularly
used for pre-trained inputs into NLP algorithms. We show that
word embeddings trained on Baidu Baike, an online Chinese ency-
clopedia, have very different associations between adjectives and
a range of concepts about democracy, freedom, collective action,
equality, and people and historical events in China than its reg-
ularly blocked but uncensored counterpart â€“ Chinese language
Wikipedia. We examine the implications of these discrepancies by
studying their use in downstreamAI applications. Our paper shows
how government repression, censorship, and self-censorship may
impact training data and the applications that draw from them.
CCS CONCEPTS
â€¢ Computing methodologies â†’ Supervised learning by clas-
sification; â€¢ Information systems â†’ Content analysis and
feature selection; â€¢ Social and professional topics â†’ Politi-
cal speech.
KEYWORDS
word embeddings, censorship, training data, machine learning
ACM Reference Format:
Eddie Yang and Margaret E. Roberts. 2021. Censorship of Online Encyclo-
pedias: Implications for NLPModels. InConference on Fairness, Accountabil-
ity, and Transparency (FAccT â€™21), March 3â€“10, 2021, Virtual Event, Canada.
ACM,NewYork, NY, USA, 12 pages. https://doi.org/10.1145/3442188.3445916
1 INTRODUCTION
Natural language processing (NLP) as a branch of artificial intelli-
gence provides the basis for many tools people around the world
âˆ—Both authors contributed equally to this research.
FAccT â€™21, March 3â€“10, 2021, Virtual Event, Canada
ACM ISBN 978-1-4503-8309-7/21/03.
https://doi.org/10.1145/3442188.3445916
use daily. NLP impacts how firms provide products to users, con-
tent individuals receive through search and social media, and how
individuals interact with news and emails. Despite the growing im-
portance of NLP algorithms in shaping our lives, recently scholars,
policymakers, and the business community have raised the alarm
of how gender and racial biases may be baked into these algo-
rithms. Because they are trained on human data, the algorithms
themselves can replicate implicit and explicit human biases and
aggravate discrimination [6, 8, 39]. Additionally, training data that
over-represents a subset of the population may do a worse job at
predicting outcomes for other groups in the population [13].When
these algorithms are used in real world applications, they can per-
petuate inequalities and cause real harm.
While most of the work in this area has focused on bias and
discrimination, we bring to light another way in which NLP may
be affected by the institutions that impact the data that they feed
off of. We describe how censorship has affected the development
of online encyclopedia corpuses that are often used as training
data for NLP algorithms. The Chinese government has regularly
blocked Chinese languageWikipedia from operating in China, and
mainland Chinese Internet users are more likely to use an alterna-
tive Wikipedia-like website, Baidu Baike. The institution of cen-
sorship has weakened Chinese language Wikipedia, which is now
several times smaller than Baidu Baike, and made Baidu Baike -
which is subject to pre-censorship - an attractive source of train-
ing data. Using methods from the literature on gender discrimina-
tion in word embeddings, we show that Chinese word embeddings
trained with the same method but separately on these two cor-
puses reflect the political censorship of these corpuses, treating the
concepts of democracy, freedom, collective action, equality, people
and historical events in China significantly differently.
After establishing that these two corpuses reflect different word
associations, we demonstrate the potential real-world impact of
training data politics by using the two sets of word embeddings in
a transfer learning task to classify the sentiment of news headlines.
We find that models trained on the same data but using different
pre-trained word embeddings make significantly different predic-
tions of the valence of headlines containing words pertaining to
freedom, democracy, elections, collective action, social control, po-
litical figures, the CCP, and historical events. These results suggest
that censorship could have downstream effects on AI applications,
which merit future research and investigation.
Our paper proceeds as follows.We first describe the background
of how Wikipedia corpuses came to be used as training data for
word embeddings and how censorship impacts these corpuses. Sec-
ond, we describe our results of howword associations fromWikipedia
and Baidu Baike word embeddings differ on concepts that pertain
537
This work is licensed under a Creative Commons Attribution International 4.0 License.
FAccT â€™21, March 3â€“10, 2021, Virtual Event, Canada Yang and Roberts
to democracy, equality, freedom, collective action and historical
people and events in China. Last, we show that these embeddings
have downstream implications for AI models using a sentiment
prediction task.
2 PRE-TRAINEDWORD EMBEDDINGS AND
WIKIPEDIA CORPUSES
NLP algorithms rely on numerical representations of text as a basis
for modeling the relationship between that text and an outcome.
Many NLP algorithms use â€œword embeddingsâ€ to represent text,
where each word in a corpus is represented as a k-dimensional
vector that encodes the relationship between that word and other
words through the distance between them in k-dimensional space.
Words that frequently co-occur are closer in space. Popular algo-
rithms such as Glove [30] and Word2Vec [24] are used to estimate
embeddings for any given corpus of text. The word embeddings
are then used as numerical representations of input texts, which
are then related through a statistical classifier to an outcome.
In comparison to other numerical representations of text, word
embeddings are useful because they communicate the relationships
between words. The bag-of-words representation of text, which
represents each word as simply being included or not included in
the text, does not encode the relationship between words â€“ each
word is equidistant from the other. Word embeddings, on the other
hand, communicates to the model which words tend to co-occur,
thus providing the model with information that words like â€œpurseâ€
and â€œhandbagâ€ as more likely substitutes than â€œpurseâ€ and â€œair-
planeâ€.
Word embeddings are also useful because they can be pre-trained
on large corpuses of text like Wikipedia or Common Crawl, and
these pre-trained embeddings can then be used as an initial layer in
applications that may have less training data. Pre-trained word em-
beddings have been shown to achieve higher accuracy faster [31].
While training on large corpuses is expensive, companies and re-
search groups have made available pre-trained word embeddings
â€“ typically on large corpuses like Wikipedia or Common Crawl â€“
that can then be downloaded and used in any application in that
language.1
The motivation behind using pre-trained word embeddings is
that they can reflect how words are commonly used in a particu-
lar language. Indeed, Spirling and Rodriguez [36] show that pre-
trained word embeddings do surprisingly well on a â€œTuring testâ€
where human coders often cannot distinguish between closewords
produced by the embeddings and those produced by other humans.
To this end, Wikipedia corpuses are commonly selected to train
word embeddings because they are user-generated, open-source,
cover a wide range of topics, and are very large.2
At the same time as pre-trained embeddings have become pop-
ular for computer scientists in achieving better performance for
NLP tasks, some scholars have pointed to potential harms these
1For example, Facebookâ€™s provides word embeddings in 294 languages trained on
Wikipedia (https://fasttext.cc/docs/en/pretrained-vectors.html [5].
2A Google Scholar search of â€œpre-trained word embeddingsâ€ and Wikipedia returns
over 2,000 search results as of January 2021.
embeddings could create by encoding existing biases into the rep-
resentation. The primary concern is that embeddings replicate ex-
isting human biases and stereotypes in language and using them in
downstream applications can perpetuate these biases (see Sun et al.
[37] for a review). Caliskan et al. [8] show that word embeddings
reflect human biases, in that associations of words in trained word
embeddings mirror implicit association tests. Using simple analo-
gies within word embeddings, Bolukbasi et al. [6], Garg et al. [14],
and Manzini et al. [23] show that word embeddings can encode
racial and gender stereotypes. While these word associations can
be of interest to social science researchers, they may cause harm if
used in downstream tasks [3, 29].
More generally, research in machine learning has been criti-
cized for not paying enough attention to the origin of training
datasets and the social processes that generate them [15]. Imbal-
ances in the content of training data have been shown to create
differential error rates across groups in areas ranging from com-
puter vision to speech recognition [40, 41]. Some scholars have
argued that training datasets should be representative of the pop-
ulation that the algorithm is applied to [35].
3 CENSORSHIP OF CHINESE LANGUAGE
WIKIPEDIA AND IMPLICATIONS FOR
CHINESE LANGAUGE NLP
We consider another mechanism through which institutional and
societal forces impact the corpuses that are used to train word em-
beddings: government censorship. While we use the example of
online encyclopedias and word embeddings to make our point, its
implications are much more general. Government censorship of
social media, news, and websites directly affects large corpuses of
text by blocking usersâ€™ access, deleting individualmessages, adding
content through propaganda, or inducing self-censorship through
intimidation and laws [11, 19, 20, 22, 25, 32, 34].
While Wikipediaâ€™s global reach makes it an attractive corpus
for training models in many different languages, Wikipedia has
also been periodically censored by many governments, including
Iran, China, Uzbekistan, and Turkey [10]. China has had the most
extensive and long-lasting censorship of Wikipedia. Chinese lan-
guage Wikipedia has been blocked intermittently ever since it was
first established in 2001. Since May 19, 2015, all of Chinese lan-
guage Wikipedia has been blocked by the Great Firewall of China
[27, 44]. More recently, not just Chinese language Wikipedia, but
all language versions of Wikipedia have been blocked from main-
land China [2].
Censorship has weakened Chinese language Wikipedia by de-
creasing the size of its audience. Pan and Roberts [28] estimate that
the block of Chinese language Wikipedia in 2015 decreased page
views of the website by around 3 million views per day. Zhang and
Zhu [48] use the 2005 block of Wikipedia to show that the block
decreased views of Chinese language Wikipedia, which in turn
decreased user contributions to Wikipedia not only from blocked
users in mainland China, but also from unblocked users what had
fewer incentives to contribute after the block. While mainland Chi-
nese Internet users can access Chinese language Wikipedia with a
Virtual Private Network (VPN), evidence suggests that very few do
[9, 32].
538
Censorship of Online Encyclopedias FAccT â€™21, March 3â€“10, 2021, Virtual Event, Canada
Censorship of Chinese languageWikipedia has strengthened its
unblocked substitute, Baidu Baike. A similar Wikipedia-like web-
site, Baidu Baike as of 2019 boasted 16 million entries, 16 times
larger than Chinese language Wikipedia [46]. Yet, as with all com-
panies operating in China, Baidu Baike is subject to internal cen-
sorship that impacts whether and how certain entries are written.
While edits to Chinese languageWikipedia pages are posted imme-
diately, any edits to Baidu Baike pages go through pre-publication
review. While editors of Wikipedia can be anonymous, editors of
Baidu Baike must register their real names. Additional scrutiny is
given to sensitive pages, such as national leaders, political figures,
political information, and the military, where Baidu Baike regula-
tions stipulate that only government media outlets such as Xinhua
and Peopleâ€™s Daily can be used as sources.3
Pre-censorship of Baidu Baike affects the types of pages avail-
able on Baidu Baike and the way these pages are written. While
itâ€™s impossible to knowwithout an internal list the extent to which
missing pages in Baidu Baike are a direct result of government cen-
sorship, a substantial list of historical events covered on Chinese
language Wikipedia including â€œJune 4th Incidentâ€ and â€œDemoc-
racy Wallâ€ and well-known activists such as Chen Guangcheng
andWuâ€™erkaixi have no Baidu Baike page [26]. For example, when
we attempted to create entries on Baidu Baike such as â€œJune Fourth
Movementâ€ or â€œWuâ€™erkaixi,â€ we were automatically returned an er-
ror.
Perhaps because of the size difference between the two corpuses,
increasingly researchers developing cutting edgeChinese langauge
NLP models are drawing on the Baidu Baike corpus [38, 43]. Baidu
Baike word embeddings have been shown to perform better on
certain tasks [21]. Here, we assess the downstream implications
of this choice on the representation of democratic concepts, social
control, and historical events and figures. First, we follow Caliskan
et al. [8] to compare the distance between these concepts and a list
of adjectives and sentiment words.Then, we show the downstream
consequences of the choice of corpus on a predictive task of the
sentiment of headlines.
4 DISTANCE FROM DEMOCRACY:
COMPARISON BETWEEN BAIDU BAIKE
ANDWIKIPEDIA EMBEDDINGS
In this section, we consider the differences in word associations
amongword embeddings trainedwith Chinese languageWikipedia
and Baidu Baike. We use word embeddings made available by Li
et al. [21].4 Li et al. [21] train 300-dimensional word embeddings
on both Baidu Baike and Chinese language Wikipedia using the
same algorithm,Word2Vec [24]. For a benchmark, we also compare
these two sets of embeddings to embeddings trained on articles
from the Peopleâ€™s Daily from 1947-2016, the Chinese governmentâ€™s
mouthpiece.5
To evaluate word associations, we follow Caliskan et al. [8] and
Rodman [33] to compare the distance between a set of target words
3See instructions at: https://baike.baidu.com/item/%E7%99%BE%E5%BA%A6%E7%
99%BE%E7%A7%91%EF%BC%9A%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99.
4https://github.com/Embedding/Chinese-Word-Vectors
5Also trained by Li et al. [21] and made available at https://github.com/Embedding/
Chinese-Word-Vectors.
and attribute words to establish their relationships in each embed-
ding space. Figure 1 gives a simplified graphical representation of
the evaluation procedure in a 2-dimensional space. In this simple
example, we might be interested in the position of a target word
â€“ a concept we are interested in â€“ relative to a positive attribute
word and a negative attribute word. For example, we can evalu-
ate whether democratic concepts are represented more positively
or negatively by comparing the angle between the vector for the
target word â€œDemocracyâ€ (in black) and a positive attribute word
â€œStabilityâ€ as well as a negative attribute word â€œChaosâ€ (both in
blue).
Figure 1: Example of Word Embedding Comparison
In Figure 1, â€œDemocracyâ€ in word embedding A has a more pos-
itive connotation than in word embedding B, because the relative
position of the word â€œDemocracyâ€ in embedding A with respect
to the positive attribute word â€œStabilityâ€ and the negative attribute
word â€œChaosâ€ is closer to the positive attribute word than â€œDemoc-
racyâ€ is in embedding B. To minimize the particularities of a single
word and hence the variability of the result, we repeat this eval-
uation procedure across multiple target words representing the
same concept (e.g. democracy) and compare them with multiple
attribute words. In the next sections, we explain how we select
target words, attribute words, how we pre-process the embedding
space, and our results.
4.1 Identifying Target Words
We begin by delineating the categories of interest. In general, there
are two broad categories we are interested in: 1) democratic politi-
cal concepts and ideas and 2) known targets of propaganda. Based
on past work, we know entries that fall under these categories have
been the target of content control on Baidu Baike [26].Additionally,
the first category captures ideas that we think are normatively de-
sirable but discouraged in China.The second category captures the
extent that the embeddings are consistent with propaganda.
For the first category, we include
(1) Democratic values, in particular freedom and equality of
rights.
(2) Procedures of democracy, in particular features pertaining
to elections.
(3) Channels for voicing preferences in the form of collective
actions such as protests and petitions.
For the second category, we include
(1) Social control, especially concepts related to repression and
surveillance.
(2) The Chinese Communist Party (CCP) and related features.
539
FAccT â€™21, March 3â€“10, 2021, Virtual Event, Canada Yang and Roberts
(3) Significant historical events in China that involved the CCP,
such as the Cultural Revolution.
(4) Important figures who are extolled by the CCP.
(5) Figures who are denounced by the CCP, such as political
dissenters.
For each of these categories, we do not want to select only one
target word of interest, but rather a group of related words that
all cover the same concept. We select a group of target words that
â€œrepresentâ€this category as follows:
(1) For categories other than historical events and negative fig-
ures, we first select a Chinese word that most closely repre-
sents the category of interest.6 For example, for the category
of procedures of democracy, the Chinese word â€œelectionâ€ is
selected.
(2) We then calculate the cosine similarity of the representative
word with all other words from the word embedding spaces
(Wikipedia & Baidu Baike).
(3) From each corpus, we select 50 words that are closest to the
representative word (words with the highest cosine similar-
ity).
(4) Of the 100 words closest to the representative word for each
category, we include all words that could be thought to be
synonymous or a subset of the more general category. We
drop those that are domain specific; for example, of thewords
for the category of procedures of democracy, we dropped
the word â€Japanese Dietâ€, which is specific to the Japanese
political system.
(5) For categories on historical events and negative figures, we
simply used the name of the person or of the historical event.
(6) The full list of words for each category is presented in Ap-
pendix D.
We opt for the data-driven approach in (3) and (4) to select target
words in order to limit researcher degree of freedom. Furthermore,
the selection of representative words in (1) and the pruning of syn-
onyms in (4) were done by three native Chinese speakers to ensure
the selected words provide good coverage of how the categories of
interest are discussed in the Chinese context.
4.2 Selecting Attribute Words
We use two strategies for selecting attribute words. First, we draw
on the literature on propaganda in China to select a set of positive
and negative words that would be consistent with what we know
about CCP propaganda narratives. As scholars of propaganda have
pointed out, the CCP has actively tried to promote the image of it-
self and Chinaâ€™s political system as stable and prosperous, while
characterizing Western democratic systems as chaotic and in eco-
nomic decline [1, 7, 47]. Therefore, for our first set of words, which
we call â€œPropaganda AttributesWords,â€ positive words include syn-
onyms of stability and prosperity, while negative attribute words
include synonyms of chaos, decline, and instability. The full list for
the set of propaganda attribute words is presented in Appendix E.
For the second set of words, we are interested in whether the
target words are more generally evaluated differently between the
6We asked three Chinese speakers to independently come up with the representative
words and had them agree on a single word for each category. This step was done
before analysis was performed.
two corpuses. To test this, we make use of a dictionary of evalua-
tive words specifically designed for Chinese natural language pro-
cessing [42]. The dictionary codes whether an evaluative word is
positive, negative, or neutral. We follow the preprocessing instruc-
tions byWang and Ku [42] by dropping all neutral words and only
using the list of positive and negative evaluative words. A sample
of the set of evaluative words is presented in Appendix F. For sub-
sequent discussions, we refer to this list of attribute words as the
â€œEvaluative Attribute Words.â€
4.3 Pre-processing Word Embedding Spaces
There are two notable challenges when comparing different word
embeddings. One, word embeddings produced by stochastic algo-
rithms such as Word2Vec will embed words in non-aligned spaces
defined by different basis vectors. This precludes naive compari-
son of word distances across distinct corpuses [17, 33]. If the cen-
troids of the two word embeddings are different, then using co-
sine similarity (i.e. the cosine of the angle between two vectors) to
compare word associations across different corpuses can yield un-
interpretable result. Figure 2 presents a simplified example of this
problem. One word embedding, by virtue of being further away
from the origin, yields a smaller angle between the two vectors,
even though the relative positions of the two vectors in the two
word embeddings are the same.
To solve this problem, we standardize the basis vectors of each
word embeddings by subtracting the means and dividing by the
standard deviations of the basis vectors, so that each word embed-
ding is centered around the origin with dimension length 1.
Figure 2: Nonalignment between Two Word Embeddings
Another problem is that word embeddings trained on different
corpuses can have different vocabulary. This precludes us from
comparing words that appear in one word embedding but are not
present in the otherword embedding. Because of this, we only keep
the intersection of the vocabularies of word embeddings. As a re-
sult, six target words were dropped in the comparison between
Wikipedia- and Baidu Baike-trained word embeddings and five tar-
get words were dropped in the comparison between Wikipedia-
and Peopleâ€™s Daily-trained word embeddings.
540
Censorship of Online Encyclopedias FAccT â€™21, March 3â€“10, 2021, Virtual Event, Canada
4.4 Expectations
We expect ideas that are normatively appealing but discouraged in
China to be portrayed more negatively in Baidu Baike. We expect
figures who are denounced by the CCP to be portrayed more nega-
tively in Baidu Baike. On the other hand, we expect categories that
are targets of positive propaganda to be portrayed more positively
in Baidu Baike. Overall, we expect that censorship and curation of
Baidu Baike will mean that the words we are interested in will be
treated similarly in Baidu Baike and state media outletThe Peopleâ€™s
Daily. A summary of our theoretical expectations is presented in
Table 1 below.
Table 1: Theoretical Expections
Category Sign
Freedom âˆ’
Democracy âˆ’
Election âˆ’
Collective Action âˆ’
Negative Figures âˆ’
Social Control +
Surveillance +
CCP +
Historical Events +
Positive Figures +
Note: Negative sign indicates Baidu Baike and Peopleâ€™s Daily are
less favorable than Wikipedia and positive sign indicates that
Baidu Baike and Peopleâ€™s Daily are more favorable thanWikipedia.
4.5 Limitations
Through this design, we test whether there are differences between
word embeddings trained onChinese languageWikipedia and those
trained on Baidu Baike in topics where there is evidence of cen-
sorship on Baidu Baike. While we think the evidence we produce
is suggestive that censorship impacts the placement of the word
embeddings, we cannot isolate the effect of censorship outside of
other differences that may exist between Baidu Baike and Chi-
nese language Wikipedia. Isolating the effect of censorship is dif-
ficult in part because censorshipâ€™s influence is pervasive, affect-
ing the content not only through pre-publication review, but also
likely through the propensity for individuals to become editors and
the information that they have and are willing to contribute. This
makes it very difficult to establish a counterfactual of what the con-
tent on Baidu Baike would have looked like without censorship.
We believe Chinese language Wikipedia is the closest approxima-
tion to this counterfactual.
4.6 Results
Following Caliskan et al. [8], we use a randomization test with one-
sided p-value to compare how words in each category are repre-
sented in Wikipedia, Baidu Baike and Peopleâ€™s Daily.
Formally, let ğ‘‹ğ‘– , ğ‘– âˆˆ ğ‘, ğ‘ be the set of word vectors for the target
words from embedding ğ‘ and ğ‘ respectively. Let ğ´ğ‘– , ğµğ‘– , ğ‘– âˆˆ ğ‘, ğ‘
Table 2: Wikipedia vs. Baidu Baike
Propaganda Attributes Evaluative Attributes
effect size p-value effect size p-value
Freedom -0.62 0.01 0.06 0.60
Democracy -0.50 0.05 -0.56 0.03
Election -0.27 0.13 -0.33 0.05
Collective Action -0.66 0.00 -0.09 0.34
Negative Figures -0.91 0.00 0.50 0.99
Social Control 0.70 0.04 0.68 0.01
Surveillance 0.09 0.32 0.73 0.00
CCP 1.05 0.02 1.39 0.00
Historical Events 0.14 0.19 0.27 0.01
Positive Figures 0.59 0.00 1.17 0.00
be the two sets of word vectors for the attribute words, with ğ´ be-
ing the set of positive attributes and ğµ being the set of negative
attributes. Subscript ğ‘– again denotes the embedding that the word
vectors are from. Let cos( Â®ğ‘, Â®ğ‘) denote the cosine of the angle be-
tween vectors Â®ğ‘ and Â®ğ‘. The test statistic is
ğ‘ ğ‘– (ğ‘‹,ğ´, ğµ) =
âˆ‘
ğ‘–âˆˆğ‘
ğ‘  (ğ‘¥ğ‘– , ğ´ğ‘– , ğµğ‘– ) âˆ’
âˆ‘
ğ‘–âˆˆğ‘
ğ‘  (ğ‘¥ğ‘– , ğ´ğ‘– , ğµğ‘– )
where
ğ‘  (ğ‘¡, ğ´, ğµ) = meanğ‘âˆˆğ´ cos(Â®ğ‘¡, Â®ğ‘) âˆ’meanğ‘âˆˆğµ cos(Â®ğ‘¡, Â®ğ‘)
Let Î© denotes the set of all possible randomization realizations
of assignment of word vector ğ‘¥ to embedding ğ‘– âˆˆ {ğ‘,ğ‘}. The one-
sided p-value of the permutation test is
Prğ‘– [ğ‘ ğœ” âˆˆÎ© (ğ‘‹,ğ´, ğµ) > ğ‘ ğ‘– (ğ‘‹,ğ´, ğµ)]
We present the effect size of the difference in word associations
across word embeddings, defined as
meanğ‘–âˆˆğ‘ğ‘  (ğ‘¥ğ‘– , ğ´ğ‘– , ğµğ‘– ) âˆ’meanğ‘–âˆˆğ‘ğ‘  (ğ‘¥ğ‘– , ğ´ğ‘– , ğµğ‘– )
std.devğ‘–ğ‘  (ğ‘¥ğ‘– , ğ´ğ‘– , ğµğ‘– )
Conventional cutoffs for small, medium, and large effect sizes are
0.2, 0.5, and 0.8, respectively.The comparisons betweenWikipedia
and Baidu Baike word embeddings and between Wikipedia and
Peopleâ€™s Daily word embeddings are presented in Table 2 and Table
3 respectively.
Across most categories and for both sets of attribute words, the
differences in word embeddings are in line with our theoretical ex-
pectations. Table 2 indicates that for categories Freedom, Democ-
racy, Election, Collective Action, and Negative Figures, word em-
beddings trained with Baidu Baike display a more negative con-
notation than embeddings trained with Wikipedia. For categories
Social Control, Surveillance, CCP, and Historical Events, word em-
beddings trained with Baidu Baike display a more positive conno-
tation than embeddings trained with Wikipedia. The effect sizes
indicate substantial differences for target words that are related to
democracy and those that are targets of propaganda. This is con-
sistent across both set of attribute words and across the two com-
parisons. In Table 3 we show that the effect sizes when comparing
Wikipedia and Baidu Baike are similar to comparing Wikipedia
with the government publication The Peopleâ€™s Daily.
541
FAccT â€™21, March 3â€“10, 2021, Virtual Event, Canada Yang and Roberts
Table 3: Wikipedia vs. Peopleâ€™s Daily
Propaganda Attributes Evaluative Attributes
effect size p-value effect size p-value
Freedom -0.29 0.11 -0.51 0.01
Democracy -0.40 0.09 -0.97 0.00
Election -0.43 0.04 -0.91 0.00
Collective Action -0.81 0.00 -0.10 0.34
Negative Figures 0.44 0.91 -0.06 0.41
Social Control 0.82 0.01 0.58 0.03
Surveillance 0.31 0.06 0.84 0.00
CCP 1.39 0.00 1.22 0.00
Historical Events 0.29 0.08 0.22 0.04
Positive Figures 1.51 0.00 1.29 0.00
While most categories accord with our expectations, one in par-
ticular deserves further explanation. Negative figures, including
activists and dissidents who the CCP denounces, are only more
significantly associated with negative words on Baidu Baike and
Peopleâ€™s Daily in one instance and even have a positive effect size
comparing Baidu Baike to Wikipedia in Table 2. It is likely that be-
cause of censorship there is very little information about these fig-
ures in the Baidu Baike and Peopleâ€™s Daily corpuses, so their word
embeddings do not show strong relationships with the attribute
words. To examine this, we used Google Search to count the num-
ber of pages on Chinese language Wikipedia and Baidu Baike that
link to each negative figure. Out of 18 negative figures, Chinese lan-
guage Wikipedia has more page links to two thirds of them, even
though Chinese languageWikipedia is 16 times smaller.Therefore,
the uncertainty around the result we have for negative figures may
be a result of lack of information about these individuals in Baidu
Baike.
5 APPLICATION: SENTIMENT ANALYSIS OF
NEWS HEADLINES
In this section, we demonstrate that the differences we detected
in word embeddings have tangible effect on downstream machine
learning tasks. To do this, we make use of the pre-trained word
embeddings on each of the different corpuses as inputs in a larger
machine learning model that automatically labels the sentiment
polarity of news headlines. We chose the automated classification
of news headlines because machine learning based on news head-
lines is used in recommendation systems for social media news
feeds and news aggregators, as well as for analysts using auto-
mated classification of news to make stock price and economic pre-
dictions.7 We show that using the pre-trained word embeddings
from Baidu Baike and Chinese language Wikipedia with identical
training data produces sentiment predictions for news headlines
that differ systematically across our categories of interest.
7For example, EquBot https://equbot.com/.
5.1 Data and Method
We imagine a scenario where the task is to label the sentiment of
news headlines where the model is trained on a large, general sam-
ple of news headlines. We then examine the performance of this
model on an oversample of headlines that include our target words.
This allows us to evaluate how a general news sentiment classifier
performs on words that are politically valanced in China, varying
the origin of the pre-trained embeddings, but holding constant the
sentiment labels in the training and test sets.
For the training set, we randomly select 5,000 headlines from the
TNEWSdataset.TheTNEWSdataset contains 73,360 Chinese news
headlines of various categories.8 It is part of the Chinese Language
Understanding Evaluation (CLUE) Benchmark and is widely used
as the training data for Chinese news classification models. For
each of the randomly selected 5,000 headlines, we label each news
headline as positive, negative, or neutral in line with the general
sentiment of the headline. For our training set from the TNEWS
dataset, we have 1,861 headlines with positive sentiment, 781 with
negative sentiment, and 2,342 with neutral sentiment.9
For the test set, we collect Chinese news headlines that contain
any of our target words from Google News. For each of the target
words, we collect up to 100 news headlines. Because some target
words yield only a handful of news headlines, we collected 12,669
news headlines in total, out of 182 target words. Data collection
was done in July and August of 2020. Using the exact same coding
scheme as the training set, we label these headlines as positive, neg-
ative, or neutral.The test set contains 5,291 headlines with positive
sentiment, 3,913 with negative sentiment, and 3,424 with neutral
sentiment.10
We preprocess the news headlines by removing punctuation,
numbers, special characters, the names of the news agency (if they
appear on the headline), and duplicated headlines. To convert the
news headlines into input for machine learning models, we first
use a Chinese word segmentation tool to segment each news head-
line into a sequence of words. We then look up the word embed-
ding for each word in the sequence. Following a conventional ap-
proach, we take the average of the pre-trained word embeddings
of the words in a given news headline to represent each headline.
Any word that does not have a corresponding word embedding in
the Word2Vec models is dropped. This leaves us with three differ-
ent representations of the headlines: one for Baidu Baike, one for
Chinese language Wikipedia, and one for the Peopleâ€™s Daily.
With each of these three different representations of the text
based on different pre-trained embeddings, we train three machine
learningmodels â€“Naive Bayes (NB), support vectormachines (SVM)
and TextCNN [18]. For eachmodel, we use identical training labels,
from the TNEWS dataset.11 This yields a total of nine models, with
three for each pre-trained word embeddings. Each trained model is
then used to predict sentiment labels on the test set. Because of the
8For more details about the TNEWS dataset, see Appendix.
916 duplicated news headlines are dropped, resulting in 4,984 headlines in total.
1041 duplicated news headlines are dropped, resulting in 12,628 headlines in total.
11Because headlines with neutral labels are more noisy and given the difficulty of
training a three-class classifier with limited training data, we report results in the
main text based on models that are trained with only positive and negative headlines.
We report results with neutral headlines included in the Appendix. Our substantive
conclusions are largely intact.
542
Censorship of Online Encyclopedias FAccT â€™21, March 3â€“10, 2021, Virtual Event, Canada
stochastic nature of TextCNN, the TextCNN results are averaged
over 10 runs for each model.
We compare different trained models of the same architecture
(NB, SVM, or TextCNN) by looking at the mis-classifications for
each category of targetwords. Intuitively, amodel that is pre-disposed
to associate more positive words with a certain category of head-
lines will have more false-positives (e.g. negative headlines mis-
classified as positive), whereas a model that is pre-disposed to asso-
ciate more negative words with a certain category of headlines will
have more false-negatives (e.g. positive headlines mis-classified as
negative).
Because the overall mis-classification rate may differ for head-
lines of different target words, we use a linear mixed effects model
to compare the different embeddings, allowing headlines of differ-
ent target words to have different intercepts. More formally, let
ğ¿ğ‘– ğ‘— be a list of ğ‘ human-labeled sentiment scores for headlines
containing target word ğ‘– in category ğ‘— . Let ğ¿ğ‘ğ‘– ğ‘— and ğ¿ğ‘ğ‘– ğ‘— be the pre-
dicted sentiment scores frommodel ğ‘ andğ‘ for the same headlines.
We estimate the linear mixed effects model for each category ğ‘— of
news headlines by
ğ‘¦ ğ‘— = ğ›¼ğ‘– ğ‘— + ğ‘‹ ğ‘— ğ›½ ğ‘— + ğœ– ğ‘— (1)
where the outcome variable ğ‘¦ ğ‘— is a 2ğ‘ Ã— 1 vector of difference
in classifications against human labels,
( ğ¿ğ‘ğ‘— âˆ’ğ¿ğ‘—
ğ¿ğ‘ğ‘— âˆ’ğ¿ğ‘—
)
. ğ›¼ğ‘– ğ‘— is a 2ğ‘ Ã— 1
vector of random intercepts corresponding to headlines of each
target word ğ‘– in category ğ‘— . ğ‘‹ ğ‘— is an indicator variable for model ğ‘
(as opposed to ğ‘) and ğ›½ ğ‘— is the coefficient of interest.
5.2 Results
Before turning to the results of the impact of pre-trained embed-
dings on the predicted classifications of the model, we report the
overall accuracy of each of the models on the test set in Table 4.
Overall, TextCNN performs the best out of the three models. How-
ever, within models no set of pre-trained word embeddings per-
forms better than the other â€“ they all perform quite similarly.
Table 4: Model Accuracy in Test Set
Model Accuracy
Naive Bayes
Baidu Baike 76.83
Wikipedia 76.29
SVM
Baidu Baike 77.12
Wikipedia 76.68
TextCNN
Baidu Baike 82.84
Wikipedia 81.60
Even though the selection of pre-trained embeddings does not
seem to impact overall accuracy, the pre-trained embeddings do
influence the false positive and false negative rates of different cat-
egories of headlines. In Table 5 we show the comparison of Baidu
Baike andWikipedia, where Baidu Baike is model ğ‘ andWikipedia
is model ğ‘. This meansğ‘‹ ğ‘— from Equation 1 is 1 for category ğ‘— if the
model were trained with Baidu Baike word embeddings and 0 for
Wikipedia. A negative coefficient indicates that on average Baidu
Baike rates this category more negatively than Wikipedia. A pos-
itive coefficient indicates that on average Baidu Baike rates this
category as more positive than Wikipedia.
Table 5: Baidu Baike vs. Wikipedia
Naive Bayes SVM TextCNN
estimate p-value estimate p-value estimate p-value
Freedom -0.13 0.00 -0.06 0.00 -0.04 0.04
Democracy -0.08 0.00 -0.05 0.04 -0.04 0.06
Election -0.11 0.00 -0.06 0.03 -0.02 0.48
Collective Action -0.13 0.00 -0.07 0.00 -0.05 0.01
Negative Figures -0.04 0.03 0.00 0.96 -0.01 0.54
Social Control 0.03 0.12 0.00 0.93 0.03 0.13
Surveillance -0.01 0.68 -0.01 0.80 0.00 0.91
CCP 0.03 0.21 0.01 0.65 0.03 0.05
Historical Events -0.04 0.04 0.01 0.75 -0.02 0.26
Positive Figures 0.06 0.00 0.06 0.00 0.06 0.00
The results are largely consistent with what we found in Section
4. Overwhelmingly, Wikipedia predicts headlines that contain tar-
get words in the categories of freedom, democracy, election, and
collective action to be more positive. In contrast, Baidu Baike pre-
dicts headlines that contain target words of figures that the CCP
views positively to be more positive. The exceptions to our expec-
tations are the categories of social control, surveillance, CCP, and
historical events, where we cannot reject the null of no difference
between the two corpuses, although they do not go against our
expectations. We find similar results for the comparison between
Peopleâ€™s Daily and Chinese language Wikipedia, in Table 6.
Table 6: Peopleâ€™s Daily vs. Wikipedia
Naive Bayes SVM TextCNN
estimate p-value estimate p-value estimate p-value
Freedom -0.22 0.00 -0.08 0.00 -0.12 0.00
Democracy -0.14 0.00 -0.06 0.02 -0.07 0.00
Election -0.13 0.00 -0.01 0.62 -0.04 0.12
Collective Action -0.19 0.00 -0.05 0.05 -0.06 0.00
Negative Figures 0.01 0.78 0.01 0.72 -0.05 0.01
Social Control 0.05 0.00 0.01 0.66 0.01 0.63
Surveillance -0.04 0.11 -0.02 0.34 -0.03 0.22
CCP 0.07 0.00 0.00 0.82 0.02 0.24
Historical Events -0.01 0.77 0.02 0.29 -0.01 0.44
Positive Figures 0.13 0.00 0.04 0.00 0.06 0.00
To provide intuition, Figure 3 shows examples of headlines la-
beled differently betweenmodel trainedwith Baidu Baike pre-trained
embeddings and model trained with Chinese language Wikipedia
in our test set. The model trained with Baidu Baike pre-trained
word embedding labeled â€œTsai Ing-wen: Hope Hong Kong Can En-
joy Democracy as Taiwan Doesâ€ as negative, while Wikipedia and
humans labeled this headline as positive. The difference in these
predictions do not stem from the training data â€“ which is the same
543
FAccT â€™21, March 3â€“10, 2021, Virtual Event, Canada Yang and Roberts
â€“ or the model â€“ which is the same. Instead, the associations made
within the pre-trained word embeddings drive these differences.
Example 1:è”¡è‹±æ–‡:ç›¼å°æ¹¾äº«æœ‰çš„æ°‘ä¸»è‡ªç”±é¦™æ¸¯ä¹Ÿå¯ä»¥æœ‰
Tsai Ing-wen: Hope Hong Kong Can Enjoy Democracy as Taiwan
Does
Baidu Baike Label: - Wikipedia Label: + Human Label: +
Example 2:å°æ€æ–‡åŒ–å¸­å·æ¬§ç¾è‡ªç”±åè¢«è‡ªç”±è¯¯?
Cancel Culture Spreading through the Western World, Is It the
Fault of Freedom?
Baidu Baike Label: - Wikipedia Label: + Human Label: -
Example 3:å…±äº§æš´æ”¿å½•:æŠ—ç¾æ´æœçœŸç›¸
Communist Tyranny: The Truth about Chinese Involvement in
the Korean War
Baidu Baike Label: + Wikipedia Label: - Human Label: -
Example 4:é¦™æ¸¯ã€Šå›½å®‰æ³•ã€‹ï¼šä¸­å›½é©»æ¸¯éƒ¨é˜Ÿå¸ä»¤å¼ºç¡¬è¡¨æ€ç»´ç¨³
Hong Kong Security Law: PLA Hong Kong Garrison Commander
Takes Tough Stance in Support of Stability Maintenance
Baidu Baike Label: + Wikipedia Label: - Human Label: -
Figure 3: Examples of Headlines Labeled Differently
By Naive Bayes Models Trained with Baidu Baike and
Wikipedia
6 CONCLUSION
The extensive use of censorship in China means that the Chinese
government is in the dominant position to shape the political con-
tent of large Chinese language corpuses. Even though corpuses
like Chinese language Wikipedia exist outside of the Great Fire-
wall, they are significantly weakened by censorship, as shown by
the smaller size of Chinese language Wikipedia in comparison to
Baidu Baike. While more work would need to be done to under-
stand how these discrepancies affects users of any particular appli-
cation, we showed in this paper that political differences reflective
of censorship exist between two of the corpuses commonly used to
train Chinese language NLP. While our work focuses on word em-
beddings, the discrepancies we uncovered likely affect other pre-
trained NLP models as well, such as BERT [12] and ERNIE [38].
Furthermore, these political differences present a pathway through
which political censorship can have downstream effects on appli-
cations that may not themselves be political but that rely on NLP,
from predictive text and article recommendation systems to social
media news feeds and algorithms that flag disinformation.
The literature in computer science has taken on the problem of
bias in training data by looking for ways to de-bias it â€“ for exam-
ple, through data augmentation [49], de-biasing word embeddings
[6], and adversarial learning [45].12 However, it is unclear how
to think about de-biasing attitudes toward democracy, freedom,
surveillance, and social control. What does unbiased look like in
12Although methods for de-biasing have also been shown to often be inadequate [4,
16].
these circumstances, and how would one test it? The only way we
can think about an unbiased training set in this circumstance is
one where certain ideas are not automatically precluded from be-
ing included in any given corpus. But knowing what perspectives
have been omitted is difficult to determine and correct after the
fact.
ACKNOWLEDGMENTS
This work is partially supported by the National Science Founda-
tion under Grant No.:Ëœ0001738411.Thanks to Guanwei Hu, Yucong
Li, and Zoey Jialu Xu for their excellent research assistance. We
thankMichelle Torres, Allan Dafoe, and Jeffrey Ding for their help-
ful comments on this work.
REFERENCES
[1] 2016. No News is Bad News. The Economist (2016). https://www.economist.
com/china/2016/02/04/no-news-is-bad-news
[2] 2019. Wikipedia blocked in China in All Languages. BBC News (2019). https:
//www.bbc.com/news/technology-48269608
[3] Solon Barocas and Andrew D Selbst. 2016. Big dataâ€™s disparate impact. Calif. L.
Rev. 104 (2016), 671.
[4] Su Lin Blodgett, Solon Barocas, Hal DaumÃ© III, and Hanna Wallach. 2020. Lan-
guage (Technology) is Power: A Critical Survey of â€œBiasâ€ in NLP. arXiv preprint
arXiv:2005.14050 (2020).
[5] Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. En-
richingWord Vectors with Subword Information. Transactions of the Association
for Computational Linguistics 5 (2017), 135â€“146.
[6] Tolga Bolukbasi, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, and
Adam T Kalai. 2016. Man is to computer programmer as woman is to home-
maker? debiasing word embeddings. In Advances in neural information process-
ing systems. 4349â€“4357.
[7] Anne-Marie Brady. 2015. Authoritarianism Goes Global (II): Chinaâ€™s Foreign
Propaganda Machine. Journal of Democracy 26, 4 (2015), 51â€“59.
[8] Aylin Caliskan, Joanna J Bryson, and Arvind Narayanan. 2017. Semantics de-
rived automatically from language corpora contain human-like biases. Science
356, 6334 (2017), 183â€“186.
[9] Yuyu Chen and David Y. Yang. 2019. The Impact of Media Censorship: 1984 or
Brave New World? American Economic Review 109, 6 (2019).
[10] Justin Clark, Robert Faris, and Rebekah Heacock Jones. 2017. Analyzing Acces-
sibility of Wikipedia Projects Around the World. Berkman Klein Center Research
Publication 2017-4 (2017).
[11] Ronald Deibert, John Palfrey, Rafal Rohozinski, Jonathan Zittrain, and Jan-
ice Gross Stein. 2008. Access Denied: The Practice and Policy of Global Internet
Filtering. MIT Press, Cambridge.
[12] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:
Pre-training of deep bidirectional transformers for language understanding.
arXiv preprint arXiv:1810.04805 (2018).
[13] Julia Dressel and Hany Farid. 2018. The accuracy, fairness, and limits of predict-
ing recidivism. Science advances 4, 1 (2018), eaao5580.
[14] Nikhil Garg, Londa Schiebinger, Dan Jurafsky, and James Zou. 2018. Word em-
beddings quantify 100 years of gender and ethnic stereotypes. Proceedings of the
National Academy of Sciences 115, 16 (2018), E3635â€“E3644.
[15] R Stuart Geiger, Kevin Yu, Yanlai Yang, Mindy Dai, Jie Qiu, Rebekah Tang, and
Jenny Huang. 2020. Garbage in, garbage out? Do machine learning application
papers in social computing report where human-labeled training data comes
from?. In Proceedings of the 2020 Conference on Fairness, Accountability, and
Transparency. 325â€“336.
[16] Hila Gonen and Yoav Goldberg. 2019. Lipstick on a Pig: Debiasing Methods
Cover up Systematic Gender Biases in Word Embeddings But do not Remove
Them. In Proceedings of the 2019 Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technologies, Volume
1 (Long and Short Papers). 609â€“614.
[17] William L Hamilton, Jure Leskovec, and Dan Jurafsky. 2016. Diachronic Word
Embeddings Reveal Statistical Laws of Semantic Change. In Proceedings of the
54th Annual Meeting of the Association for Computational Linguistics (Volume 1:
Long Papers). 1489â€“1501.
[18] Yoon Kim. 2014. Convolutional Neural Networks for Sentence Classification.
In Proceedings of the 2014 Conference on Empirical Methods in Natural Language
Processing (EMNLP). 1746â€“1751.
[19] Gary King, Jennifer Pan, andMargaret E Roberts. 2013. How censorship in China
allows government criticism but silences collective expression. American Politi-
cal Science Review (2013), 326â€“343.
544
Censorship of Online Encyclopedias FAccT â€™21, March 3â€“10, 2021, Virtual Event, Canada
[20] Gary King, Jennifer Pan, and Margaret E Roberts. 2017. How the Chinese gov-
ernment fabricates social media posts for strategic distraction, not engaged ar-
gument. American Political Science Review 111, 3 (2017), 484â€“501.
[21] Shen Li, Zhe Zhao, Renfen Hu, Wensi Li, Tao Liu, and Xiaoyong Du. 2018. Ana-
logical Reasoning on Chinese Morphological and Semantic Relations. In Proceed-
ings of the 56th Annual Meeting of the Association for Computational Linguistics
(Volume 2: Short Papers). 138â€“143.
[22] Rebecca MacKinnon. 2012. Consent of the Networked: TheWorldwide Struggle For
Internet Freedom. Basic Books, New York.
[23] ThomasManzini, Lim Yao Chong, AlanWBlack, and Yulia Tsvetkov. 2019. Black
is to Criminal as Caucasian is to Police: Detecting and Removing Multiclass Bias
in Word Embeddings. In Proceedings of the 2019 Conference of the North Ameri-
can Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers). 615â€“621.
[24] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013.
Distributed representations of words and phrases and their compositionality. In
Advances in neural information processing systems. 3111â€“3119.
[25] Evgeny Morozov. 2011. The Net Delusion: The Dark Side of Internet Freedom.
PublicAffairs, New York.
[26] Jason Ng. 2013. Whoâ€™s the Boss? The difficulties of identifying censor-
ship in an environment with distributed oversight A large-scale compar-
ison of Wikipedia China with Hudong and Baidu Baike. Citizen Lab
(2013). https://citizenlab.ca/2013/08/a-large-scale-comparison-of-wikipedia-
china-with-hudong-and-baidu-baike/
[27] Daniel Oberhaus. 2017. Wikipediaâ€™s Switch to HTTPS Has Successfully Fought
Government Censorship. Motherboard (2017). https://bit.ly/2T5aEWm
[28] Jennifer Pan and Margaret E. Roberts. 2019. Censorshipâ€™s Effect on Incidental
Exposure to Information: Evidence from Wikipedia. SAGE Open (2019).
[29] Orestis Papakyriakopoulos, Simon Hegelich, Juan Carlos Medina Serrano, and
Fabienne Marco. 2020. Bias in word embeddings. In Proceedings of the 2020 Con-
ference on Fairness, Accountability, and Transparency. 446â€“457.
[30] Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove:
Global vectors for word representation. In Proceedings of the 2014 conference on
empirical methods in natural language processing (EMNLP). 1532â€“1543.
[31] Ye Qi, Devendra Sachan, Matthieu Felix, Sarguna Padmanabhan, and Graham
Neubig. 2018. When and Why Are Pre-Trained Word Embeddings Useful for
Neural Machine Translation?. In Proceedings of the 2018 Conference of the North
American Chapter of the Association for Computational Linguistics: Human Lan-
guage Technologies, Volume 2 (Short Papers). 529â€“535.
[32] Margaret E. Roberts. 2018. Censored: Distraction and Diversion Inside Chinaâ€™s
Great Firewall. Princeton University Press, Princeton.
[33] Emma Rodman. 2019. A Timely Intervention: Tracking the Changing Meanings
of Political Concepts with Word Vectors. Political Analysis (2019), 1â€“25.
[34] Sergey Sanovich, Denis Stukal, and Joshua A Tucker. 2018. Turning the virtual
tables: Government strategies for addressing online opposition with an applica-
tion to Russia. Comparative Politics 50, 3 (2018), 435â€“482.
[35] Shreya Shankar, Yoni Halpern, Eric Breck, James Atwood, Jimbo Wilson, and D
Sculley. 2017. No Classification without Representation: Assessing Geodiversity
Issues in Open Data Sets for the Developing World. stat 1050 (2017), 22.
[36] Arthur Spirling and P Rodriguez. 2019. Word embeddings: What works, what
doesnâ€™t, and how to tell the difference for applied research. (2019).
[37] Tony Sun, Andrew Gaut, Shirlyn Tang, Yuxin Huang, Mai ElSherief, Jieyu Zhao,
Diba Mirza, Elizabeth Belding, Kai-Wei Chang, and William Yang Wang. 2019.
Mitigating Gender Bias in Natural Language Processing: Literature Review. Pro-
ceedings of the 57th Annual Meeting of the Association for Computational Linguis-
tics (2019). https://doi.org/10.18653/v1/p19-1159
[38] Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin
Tian, Danxiang Zhu, Hao Tian, and Hua Wu. 2019. Ernie: Enhanced representa-
tion through knowledge integration. arXiv preprint arXiv:1904.09223 (2019).
[39] Latanya Sweeney. 2013. Discrimination in online ad delivery. Queue 11, 3 (2013),
10â€“29.
[40] Rachael Tatman. 2017. Gender and dialect bias in YouTubeâ€™s automatic captions.
In Proceedings of the First ACL Workshop on Ethics in Natural Language Process-
ing. 53â€“59.
[41] Antonio Torralba and Alexei A Efros. 2011. Unbiased look at dataset bias. In
CVPR 2011. IEEE, 1521â€“1528.
[42] Shih-Ming Wang and Lun-Wei Ku. 2016. ANTUSD: A large Chinese sentiment
dictionary. In Proceedings of the Tenth International Conference on Language Re-
sources and Evaluation (LRECâ€™16). 2697â€“2702.
[43] Junqiu Wei, Xiaozhe Ren, Xiaoguang Li, Wenyong Huang, Yi Liao, Yasheng
Wang, Jiashu Lin, Xin Jiang, Xiao Chen, andQun Liu. 2019. NEZHA: Neural con-
textualized representation for chinese language understanding. arXiv preprint
arXiv:1909.00204 (2019).
[44] Victoria Baranetsky Welinder, Yana and Brandon Black. 2015. Securing Access
toWiki-media Sites with HTTPS. Wikimedia Blog (2015). https://diff.wikimedia.
org/2015/06/12/securing-wikimedia-sites-with-https/
[45] Brian Hu Zhang, Blake Lemoine, and Margaret Mitchell. 2018. Mitigating un-
wanted biases with adversarial learning. In Proceedings of the 2018 AAAI/ACM
Conference on AI, Ethics, and Society. 335â€“340.
[46] Jane Zhang. 2019. How Baidu built an encyclopedia with 16 times
more Chinese entries than Wikipedia. South China Morning Post (2019).
https://www.scmp.com/tech/big-tech/article/3038402/how-baidu-baike-has-
faced-against-wikipedia-build-worlds-largest
[47] Xiaodong Zhang and Mark Boukes. 2019. How Chinaâ€™s flagship news program
framesâ€œthe Westâ€: Foreign news coverage of CCTVâ€™s Xinwen Lianbo before
and during Xi Jinpingâ€™s presidency. Chinese Journal of Communication 12, 4
(2019), 414â€“430.
[48] Xiaoquan Michael Zhang and Feng Zhu. 2011. Group size and incentives to
contribute: A natural experiment at Chinese Wikipedia. American Economic
Review 101, 4 (2011), 1601â€“15.
[49] Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang.
2018. Gender Bias in Coreference Resolution: Evaluation and Debiasing Meth-
ods. In Proceedings of the 2018 Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technologies, Volume
2 (Short Papers). 15â€“20.
545
FAccT â€™21, March 3â€“10, 2021, Virtual Event, Canada Yang and Roberts
A ADDITIONAL SENTIMENT ANALYSIS
RESULTS
A.1 Model Accuracy on Validation Set
In training the TextCNN models, we held out 20% of our train-
ing set as a validation set. The validation set was used to assess
the quality of the models during training. The model with the best
accuracy on the validation set in each run was selected as the out-
putted model. A.1 reports the average accuracy (over 10 runs) of
the models on the validation sets.
Table A.1: Model Accuracy on Validation Sets
2-class
Baidu Baike 90.29
Wikipedia 89.65
Peopleâ€™s Daily 92.64
3-class
Baidu Baike 67.44
Wikipedia 66.07
Peopleâ€™s Daily 67.80
Note: â€œ2-classâ€ classification means that the training and validation
sets contain only negative and positive headlines. â€œ3-classâ€ classi-
fication additionally has neutral headlines included.
A.2 Sentiment Analysis Results with Neutral
Headlines Included
Table A.2: Model Accuracy
Model Accuracy
Naive Bayes
Baidu Baike 56.42
Wikipedia 55.63
Peopleâ€™s Daily 57.79
SVM
Baidu Baike 55.53
Wikipedia 55.29
Peopleâ€™s Daily 54.71
TextCNN
Baidu Baike 61.71
Wikipedia 60.89
Peopleâ€™s Daily 58.55
Table A.3: Wikipedia vs. Baidu Baike
Naive Bayes SVM TextCNN
estimate p-value estimate p-value estimate p-value
Freedom -0.11 0.00 -0.06 0.00 -0.03 0.12
Democracy -0.08 0.00 -0.04 0.04 -0.02 0.23
Election -0.09 0.00 0.00 0.87 -0.01 0.62
Collective Action -0.10 0.00 -0.06 0.00 0.00 0.89
Negative Figures -0.05 0.00 -0.01 0.47 0.03 0.02
Social Control 0.01 0.59 0.03 0.08 0.03 0.04
Surveillance -0.06 0.00 -0.05 0.00 0.01 0.51
CCP 0.05 0.00 0.03 0.01 0.04 0.01
Historical Events -0.04 0.02 -0.01 0.66 0.02 0.05
Positive Figures 0.08 0.00 0.07 0.00 0.08 0.00
Table A.4: Wikipedia vs. Peopleâ€™s Daily
Naive Bayes SVM TextCNN
estimate p-value estimate p-value estimate p-value
Freedom -0.17 0.00 -0.07 0.00 -0.05 0.01
Democracy -0.13 0.00 -0.07 0.00 -0.06 0.00
Election -0.13 0.00 0.00 0.93 -0.01 0.53
Collective Action -0.15 0.00 -0.06 0.00 -0.02 0.22
Negative Figures -0.02 0.17 0.00 0.96 0.01 0.32
Social Control 0.05 0.00 0.02 0.22 0.00 0.97
Surveillance -0.01 0.61 -0.04 0.02 -0.01 0.56
CCP 0.04 0.01 0.04 0.00 0.03 0.02
Historical Events -0.01 0.53 0.00 0.78 0.03 0.00
Positive Figures 0.10 0.00 0.06 0.00 0.10 0.00
A.3 Sentiment Analysis Results Comparing
Baidu Baike and Peopleâ€™s Daily
A.5 reports the results comparing models trained on Baidu Baike
and those trained on Peopleâ€™s Daily, where Baidu Baike is model
ğ‘ and Peopleâ€™s Daily is model ğ‘. A positive coefficient means that
on average Peopleâ€™s Daily model rates a given category more pos-
itively than Baidu Baike.
A.6 reports results from the same comparison but with head-
lines with neutral labels included in the training and test sets.
Table A.5: Baidu Baike vs. Peopleâ€™s Daily (2-class)
Naive Bayes SVM TextCNN
estimate p-value estimate p-value estimate p-value
Freedom -0.09 0.00 -0.02 0.48 -0.07 0.00
Democracy -0.05 0.05 -0.01 0.68 -0.02 0.29
Election -0.03 0.31 0.04 0.08 -0.02 0.36
Collective Action -0.06 0.01 0.02 0.28 -0.01 0.57
Negative Figures 0.05 0.02 0.01 0.69 -0.04 0.04
Social Control 0.03 0.09 0.01 0.72 -0.02 0.27
Surveillance -0.03 0.25 -0.02 0.49 -0.02 0.24
CCP 0.04 0.04 0.00 0.82 -0.01 0.33
Historical Events 0.04 0.07 0.01 0.46 0.01 0.72
Positive Figures 0.07 0.00 -0.01 0.35 0.00 0.92
546
Censorship of Online Encyclopedias FAccT â€™21, March 3â€“10, 2021, Virtual Event, Canada
Table A.6: Baidu Baike vs. Peopleâ€™s Daily (3-class)
Naive Bayes SVM TextCNN
estimate p-value estimate p-value estimate p-value
Freedom -0.07 0.00 -0.01 0.64 -0.02 0.21
Democracy -0.06 0.01 -0.03 0.17 -0.04 0.04
Election -0.04 0.07 0.00 0.93 0.00 0.88
Collective Action -0.06 0.00 0.00 0.84 -0.02 0.26
Negative Figures 0.03 0.07 0.01 0.44 -0.02 0.20
Social Control 0.04 0.02 -0.01 0.59 -0.03 0.04
Surveillance 0.05 0.00 0.01 0.55 -0.02 0.20
CCP -0.01 0.63 0.01 0.46 0.00 0.73
Historical Events 0.03 0.06 0.00 0.88 0.01 0.36
Positive Figures 0.02 0.01 -0.01 0.34 0.01 0.12
B FURTHER DETAILS ON THE TNEWS
DATASET
The TNEWS Dataset comprises of 73,360 Chinese news headlines
from Toutiao, a Chinese news and information content platform.
The dataset contains news headlines from 15 categories: story, cul-
ture, entertainment, sports, finance, house, car, education, technol-
ogy, military, travel, world, stock, agriculture and gaming.
The TNEWS dataset is part of the Chinese Language Under-
standing Evaluation (CLUE) Benchmark, which serves as a com-
mon repository of datasets used to test the accuracy of trained
models. (For an equivalent of CLUE in English, see GLUE: https:
//gluebenchmark.com/). Because the length of a news headline is
usually short, the TNEWS dataset is widely used as either training
or testing data for machine learning models that tackle short-text
classification tasks. Given that the downstream task we are inter-
ested in is the classification of news headlines, the TNEWS dataset
serves as the ideal source of data in our case.
The TNEWS dataset is split into a training set (53,360 headlines),
a validation set (10,000 headlines) and a test set (10,100 headlines).
For our purpose, we pooled the three sets and randomly selected
5,000 news headlines from the pooled set. Because the news head-
lines are not labeled according to sentiment in the dataset, weman-
ually labeled the sentiment of the headlines in our selected subset.
Each headline is labeled by two independent coders of native Chi-
nese speaker and any conflict in labeling is resolved.
C LIST OF TARGETWORDS
Freedom (è‡ªç”±) = {è‡ªç”± (freedom),è¨€è®ºè‡ªç”± (freedom of speech),
é›†ä¼šè‡ªç”± (freedom of assembly),æ–°é—»è‡ªç”± (freedom of the press),
ç»“ç¤¾è‡ªç”± (freedom of association),è‡ªç”±æƒ (right to freedom),æ°‘
ä¸»è‡ªç”± (democracy and freedom), è‡ªç”±è¨€è®º (free speech), åˆ›ä½œ
è‡ªç”± (creative freedom), å©šå§»è‡ªä¸» (marital autonomy), è‡ªç”±æ°‘
ä¸» (freedom and democracy),è‡ªç”±å¸‚åœº (free market),è‡ªå†³ (self-
determination), è‡ªå†³æƒ (right to self-determination), ç”Ÿè€Œè‡ªç”±
(born free),è‡ªç”±è‡ªåœ¨ (free),è‡ªç”±é€‰æ‹© (freedom of choice),è‡ªç”±
æ€æƒ³ (freedom of thought), å…¬æ°‘è‡ªç”± (civil liberties), è‡ªç”±ç«äº‰
(free competition),å®—æ•™è‡ªç”± (freedom of religion),è‡ªç”±ä»·æ ¼ (free
price)}
Election (é€‰ä¸¾) = {é€‰ä¸¾ (election), ç›´æ¥é€‰ä¸¾ (direct election), è®®
ä¼šé€‰ä¸¾ (parliamentary election),é—´æ¥é€‰ä¸¾ (indirect election),ç›´
é€‰ (direct election),æ¢å±Šé€‰ä¸¾ (general election),æ°‘é€‰ (democrat-
ically elected), æŠ•ç¥¨é€‰ä¸¾ (voting), å…¨æ°‘å…¬å†³ (referendum), æ€»ç»Ÿ
å¤§é€‰ (presidential election), å¤§é€‰ (election), æ™®é€‰ (universal suf-
frage),å…¨æ°‘æŠ•ç¥¨ (referendum),æ°‘ä¸»é€‰ä¸¾ (democratic election)}
Democracy (æ°‘ä¸») = {æ°‘ä¸» (democracy),è‡ªç”±æ°‘ä¸» (freedom and
democracy),æ°‘ä¸»è‡ªç”± (democracy and freedom),æ°‘ä¸»åˆ¶åº¦ (demo-
cratic system), æ°‘ä¸»åŒ– (democratization), ç¤¾ä¼šæ°‘ä¸»ä¸»ä¹‰ (social
democracy),æ°‘ä¸»è¿åŠ¨ (democratic movement),æ°‘ä¸»ä¸»ä¹‰ (democ-
racy) ,æ°‘ä¸»æ”¹é© (democratic reform),æ°‘ä¸»åˆ¶ (democratic system),
æ°‘ä¸»é€‰ä¸¾ (demoratic election),æ°‘ä¸»æƒåŠ› (democratic rights),å¤š
å…šåˆ¶ (multi-party system),æ°‘ä¸»æ³•åˆ¶ (democracy and rule of law),
æ°‘ä¸»æƒåˆ© (democratic rights)}
Social Control (ç»´ç¨³) = {ç»´ç¨³ (social control), å¤„çª (emergency
handling),ç¤¾ä¼šæ²»å®‰ (public security),åææ€– (counter-terrorism),
å…¬å®‰å·¥ä½œ (police work),é¢„é˜²çŠ¯ç½ª (crime prevention),æ”¶å®¹å®¡æŸ¥
(arrest and investigation),æ²»å®‰å·¥ä½œ (public security work),å¤§æ’
æŸ¥ (inspections), æ‰«é»„æ‰“é (combating pornography and illegal
publications),æ¥è®¿ (petition reception),åé‚ªæ•™ (anti-cult)}
Surveillance (ç›‘æ§) = {ç›‘æ§ (surveillance), ç›‘æµ‹ (monitor), ç›‘è§†
(surveillance), ç®¡æ§ (control), ç›‘çœ‹ (monitor), ç›‘è§†ç³»ç»Ÿ (surveil-
lance system),æˆªå¬ (tapping),ç›‘æ§ä¸­å¿ƒ (surveillance center),æƒ…
æŠ¥æœåŠ¡ (intelligence service), æ’æŸ¥ (inspection), ç›‘è§†å™¨ (surveil-
lance equipment), æƒ…æŠ¥æœé›† (intelligence collection), é—´è°å«æ˜Ÿ
(reconnaissance satellite) , ç®¡ç†ç½‘ç»œ (internet control), ç›‘æ§å™¨
(surveillance equipment), ç›‘æ§ç«™ (surveillance center), ç›‘æ§å®¤
(surveillance center),æ•°æ®é‡‡é›† (data collection)}
Collective Action (æŠ—è®®) = {æŠ—è®® (protest),ç¤ºå¨ (demonstration),
ç¤ºå¨æ¸¸è¡Œ (demonstration; march), ç¤ºå¨æŠ—è®® ( demonstration;
protest),æ¸¸è¡Œç¤ºå¨ (demonstration; march),é™åç¤ºå¨ (sit-in),ç»
é£ŸæŠ—è®® (hunger strike), è¯·æ„¿ (petition), ç¤ºå¨è¿åŠ¨ (demonstra-
tion),æ¸¸è¡Œ (demonstration; march),ç½¢æ•™ (strike),é™å (sit-in),é›†
ä¼šæ¸¸è¡Œ (demonstration; assembly),ç½¢è¯¾ (strike),ç­¾åè¿åŠ¨ (signa-
ture campaign)}
Positive Figures (å…šå’Œå›½å®¶) = {æ¯›æ³½ä¸œ (Mao Zedong), æ±Ÿæ³½æ°‘
(Jiang Zemin), èƒ¡é”¦æ¶› (Ju Jintao), ä¹ è¿‘å¹³ (Xi Jinping), å‘¨æ©æ¥
(Zhou Enlai),æœ±ï¿½åŸº (Zhu Rongji),æ¸©å®¶å® (Wen Jiabao),æå…‹å¼º
(Li Keqiang),é‚“å°å¹³ (Deng Xiaoping),æ›¾åº†çº¢ (Zeng Qinghong),
åå›½é”‹ (Hua Guofeng),æé¹ (Li Peng),æ¨å°šæ˜† (Yang Shangkun),
è°·ç‰§ (Gu Mu),å´é‚¦å›½ (Wu Bangguo),æå²šæ¸… (Li Lanqing),çºªç™»
å¥ (Ji Dengkui),ä¹”çŸ³ (Qiao Shi),é‚¹å®¶å (Zou Jiahua),æç‘ç¯ (Li
Ruihuan),ä¿æ­£å£° (Yu Zhengsheng),å¼ é«˜ä¸½ (ZhangHaoli),ç”°çºªäº‘
(Tian Jiyun),å›è‰¯ç‰ (Hui Liangyu),ææºæ½® (Li Yuanchao),è´¾åº†æ—
(Jia Qinglin),å§šä¾æ— (Yao Yilin),å¼ ç«‹æ˜Œ (Zhang Lichang),å°‰å¥è¡Œ
(Wei Jianxing),å§œæ˜¥äº‘ (Jiang Chunyun),æé“æ˜  (Li Tieying),ç‹å…†
å›½ (Wang Zhaoguo),ç½—å¹² (Luo Gan),åˆ˜é–åŸº (Liu Jingji),æ¨æ±å²±
(Yang Rudai),ç‹å…‰è‹± (Wang Guangying),å½­ä½©äº‘ (Peng Peiyun),
åˆ˜äº‘å±± (Liu Yunshan),ä¸å…³æ ¹ (Ding Guangen),å½­çœŸ (Peng Zhen),
èƒ¡å¯ç«‹ (Hu Qili),æ›¾åŸ¹ç‚ (Zeng Peiyan),ä½•ä¸œæ˜Œ (He Dongchang)}
Negative Figures = {æ—å½ª (Lin Biao),ç‹æ´ªæ–‡ (Wang Hongwen),å¼ 
æ˜¥æ¡¥ (ZhangChunqiao),æ±Ÿé’ (JiangQing),å§šæ–‡å…ƒ (YaoWenyuan),
åˆ˜æ™“æ³¢ (Liu Xiaobo), ä¸¹å¢å˜‰æª ( Tenzin Gyatso), ææ´ªå¿— ( Li
547
FAccT â€™21, March 3â€“10, 2021, Virtual Event, Canada Yang and Roberts
Hongzhi), é™ˆæ°´æ‰ (Chen Shui-bian), é»„ä¹‹é”‹ (Joshua Wong), é»
æ™ºè‹± (Jimmy Lai),è‰¾æœªæœª (Ai Weiwei),æç™»è¾‰ (Lee Teng-hui),æ
æŸ±é“­ (Martin Lee),ä½•ä¿Šä» (Albert Ho),é™ˆæ–¹å®‰ç”Ÿ (Anson Chan),
è¾¾èµ– (Dalai Lama),é™ˆå…‰è¯š (Chen Guangcheng),æ»•å½ª (Teng Biao),
é­äº¬ç”Ÿ (Wei Jingsheng),é²å½¤ (Bao Tong)}
CCP (ä¸­å›½å…±äº§å…š) = {å…šä¸­å¤® (central committee), ä¸­å›½å…±äº§å…š
(CCP), å…šæ”¯éƒ¨ (party branch), ä¸­å…±ä¸­å¤® (central committee), å…±
é’å›¢ (CCP youth league),å…±é’å›¢ä¸­å¤® (youth league central com-
mittee),å…šå§” (party committee),ä¸­å¤®å…šæ ¡ (central party school)}
Historical Events = {æŠ—æ—¥æˆ˜äº‰ (Anti-Japanese War), è§£æ”¾æˆ˜äº‰
(Chinaâ€™s War of Liberation),æŠ—ç¾æ´æœ (the War to resist U.S. Ag-
gression and Aid Korea), æ”¹é©å¼€æ”¾ (Reform and Opening up),
é¦™æ¸¯å›å½’ (Hong Kong reunification), é•¿å¾ (Long March), ä¸‰å¤§
æˆ˜å½¹ (Three Great Battles in the Second Civil War), ç§‹æ”¶èµ·ä¹‰
(Autumn Harvest Uprising), å—æ˜Œèµ·ä¹‰ (Nanchang Uprising), æ¾³
é—¨å›å½’ (Transfer of sovereignty over Macau),å¿—æ„¿å†› (Volunteer
Army),åœŸåœ°æ”¹é© (Land Reform), å…­å›› (June Fourth Movement),
éµä¹‰ä¼šè®® (Zunyi Conference),ä¹äºŒå—å·¡ (Dengâ€™s Southern Tour
in 1992), å¹¿å·èµ·ä¹‰ (Guangzhou Uprising), è¥¿è—å’Œå¹³è§£æ”¾ (An-
nexation of Tibet),äº•å†ˆå±±ä¼šå¸ˆ (Jinggangshan Huishi),ç™¾å›¢å¤§æˆ˜
(Hundred Regiments Offensive),æ–‡é© (Cultural Revolution),æ–‡åŒ–
å¤§é©å‘½ (Cultural Revolution),å¤§è·ƒè¿› (Great Leap Forward),å››äºº
å¸® (Gang of Four),è§£æ”¾å†œå¥´ (Serfs Emancipation)}
D LISTS OF PROPAGANDA ATTRIBUTE
WORDS
Positive Adjectives = {ç¨³å®š,ç¹è£,å¯Œå¼º,å¹³ç¨³,å¹¸ç¦,æŒ¯å…´,å‘å±•,
å…´æ—º,æ˜Œç››,å¼ºç››,ç¨³å½“,å®‰å®š,å±€åŠ¿ç¨³å®š,å®‰å®šå›¢ç»“,é•¿æ²»ä¹…å®‰,å®‰
å±…ä¹ä¸š}
Negative Adjectives = {åŠ¨è¡,è¡°è½,éœ‡è¡,è´«ç˜ ,ä¸å¹¸,è¡°é€€,è§æ¡,
è´¥è½,æ²¡è½,è¡°è´¥,æ‘‡æ‘†,ä¸ç¨³,æ—¶å±€åŠ¨è¡,é¢ æ²›æµç¦»,åŠ¨è¡ä¸å®‰,æ°‘
ä¸èŠç”Ÿ}
E EXAMPLES OF EVALUATIVE ATTRIBUTE
WORDS
Positive Evaluative = {æƒ…æŠ•æ„åˆ,ç²¾é€‰,ä¸¥æ ¼éµå®ˆ,æœ€æ ¹æœ¬,ç¡®æœ‰å¿…
è¦,é‡é•‡,ç›´æ¥æ¥ç®¡,æ”¶è·,æ€æƒ³æ€§,å‡éœ€å‚åŠ ,å¯ç”¨äº,å½“ä½ è½å,
åŒæ„æ¥å—,å±…å† ,æ„ŸåŒ–,å®Œç¾æ¼”å‡º,æ€¥æ¬²,å¤šå…ƒåœ°ç†ç¯å¢ƒ,å½¢å½±ä¸ç¦»
çš„æœ‹å‹,ä¸€ä¸¾å‡»è´¥, â€¦}
Negative Evaluative = {é‡‘èæ³¢åŠ¨, ç§‘ä»¥, ç•¸å‹, å‘.. å¼€æª, ç ´ç¢å®¶
åº­,æ’¬åŠ¨,å¤´çš®å‘éº»,é¢ è¦†,è¿Ÿç–‘,è¡€æ·‹æ·‹åœ°,é©±èµ¶,å¹²çš„å¥½äº‹,è´£éª‚
ä¸ä¼‘,ç”Ÿç¡¬,ï¿½èš€,æ‹‰å›,èµ°å¤±çš„å®¶ç•œ,ç‡ƒçœ‰ä¹‹æ€¥,å–·æº…,è¿å, â€¦}
For the full list of evaluative words from the augmented NTU
sentiment dictionary (ANTUSD), see https://academiasinicanlplab.
github.io/#resources.
548

A Statistical Test for Probabilistic Fairness Algorithms are now routinely used to make consequential decisions that affect human lives Examples include college admissions medical interventions or law enforcement While algorithms empower us to harness all information hidden in vast amounts of data they may inadvertently amplify existing biases in the available datasets This concern has sparked increasing interest in fair machine learning which aims to quantify and mitigate algorithmic discrimination Indeed machine learning models should undergo intensive tests to detect algorithmic biases before being deployed at scale In this paper we use ideas from the theory of optimal transport to propose a statistical hypothesis test for detecting unfair classifiers Leveraging the geometry of the feature space the test statistic quantifies the distance of the empirical distribution supported on the test samples to the manifold of distributions that render a pre-trained classifier fair We develop a rigorous hypothesis testing mechanism for assessing the probabilistic fairness of any pre-trained logistic classifier and we show both theoretically as well as empirically that the proposed test is asymptotically correct In addition the proposed framework offers interpretability by identifying the most favorable perturbation of the data so that the given classifier becomes fair CONCEPTS Applied computing IT governance Law Social and professional topics Race and ethnicity Geographic characteristics Sexual orientation Gender Age Theory of computation Mathematical optimization KEYWORDS fairness algorithmic bias equal opportunity equalized odds Wasserstein distance INTRODUCTION The past decade witnessed data and algorithms becoming an integrative part of the human society Recent technological advances are now allowing us to collect and store an astronomical amount of unstructured data and the unprecedented computing power is enabling us to convert these data into decisional insights Nowadays machine learning algorithms can uncover complex patterns in the data to produce an exceptional performance that can match or even surpass that of humans These algorithms as a consequence are proliferating in every corner of our lives from suggesting us the next vacation destination to helping us create digital paintings and melodies Machine learning algorithms are also gradually assisting humans in consequential decisions such as deciding whether a student is admitted to college picking which medical treatment to be prescribed to a patient and determining whether a person is convicted Arguably these decisions impact radically many peoples lives together with the future of their loved ones Algorithms are conceived and function following strict rules of logic and algebra it is hence natural to expect that machine learning algorithms deliver objective predictions and recommendations Unfortunately in-depth investigations reveal the excruciating reality that state-of-the-art algorithmic assistance is far from being free of biases For example a predictive algorithm widely used in the United States criminal justice system is more likely to misclassify African-American offenders into the group of high recidivism risk compared to white-Americans The artificial intelligence tool developed by Amazon also learned to penalize gender-related keywords such as womens in the profile screening process and thus may prefer to recommend hiring male candidates for software development and technical positions Further Googles ad-targeting algorithm displayed advertisements for higher-paying executive jobs more often to men than to women There are several possible explanations for why cold soulless algorithms may trigger biased recommendations First the data used to train machine learning algorithms may already encrypt human biases manifested in the data collection process These biases arise as the result of a suboptimal design of experiments or from historically biased human decisions that accumulate over centuries Machine-learned algorithms which are apt to detect underlying patterns from data will unintentionally learn and maintain these existing biases For example secretary or primary school teacher are professions which are predominantly taken by women thus natural language processing systems are inclined to associate female attributes to these jobs Second training a machine learning algorithm typically involves minimizing the prediction error which privileges the majority populations over the minority groups Clinical trials for instance typically involve very few participants from the minority groups such as indigenous people and thus medical interventions recommended by the algorithms may not align perfectly to the characteristics and interests of patients from the minority groups Finally even when the sensitive attributes are not used in the training phase strong correlations between the sensitive attributes and the remaining variables in the dataset may be exploited to generate unjust actions For example the sensitive attribute of race can be easily inferred with high accuracy based on common non-sensitive attributes such as the travel history of passengers or the grocery shopping records of customers The pressing needs to redress undesirable algorithmic biases have propelled the rising field of fair machine learning A building pillar of this field involves the verification task given a machine learning algorithm we are interested in verifying if this algorithm satisfies a chosen criterion of fairness This task is performed in two steps first we choose an appropriate notion of fairness then the second step invokes a computational procedure which may or may not involve data to decide if the chosen fairness criterion is fulfilled A plethora of criteria for fair machine learning were proposed in the literature many of them are motivated by philosophical or sociological ideologies or legal constraints For example anti-discrimination laws may prohibit making decisions based on sensitive attributes such as age gender race or sexual orientation Thus a na√Øve strategy called fairness through unawareness involves removing all sensitive attributes from the training data However this strategy seldom guarantees any fairness due to the inter-correlation issues and thus potentially fails to generate inclusive outcomes Other notions of fairness aim to either promote individual fairness prevent disparate treatment or avoid disparate mistreatment of the algorithms Towards similar goals notions of group fairness focus on reducing the difference of favorable outcomes proportions among different sensitive groups Examples of group fairness notions include disparate impact demographic parity statistical parity equality of opportunity and equalized odds The notion of counterfactual fairness was also suggested as a measure of causal fairness Despite the abundance of available notions there is unfortunately no general consensus on the most suitable measure to serve as the industry standard Moreover except in trivial cases it is not possible for a machine learning algorithm to simultaneously satisfy multiple notions of fairness Therefore the choice of the fairness notion is likely to remain more an art than a science This paper focuses not on the normative approach to choosing an ideal notion of machine learning fairness We endeavor in this paper to shed more light on the computational procedure to complement the verification task Concretely we position ourselves in the classification setting which is arguably the most popular task in machine learning Moreover we will focus on notions of group Comprehensive surveys on fair machine learning can be found in fairness and we employ the framework of statistical hypothesis test instead of algorithmic test Contributions Our paper makes two concrete contributions to the problem of fairness testing of machine learnings classifiers We propose the Wasserstein projection framework to perform statistical hypothesis test of group fairness for classification algorithms We derive in details the computation of the test statistic and the limiting distribution when fairness is measured using the probabilistic equality of opportunity and probabilistic equalized odds criteria We demonstrate that the Wasserstein projection hypothesis testing paradigm is asymptotically correct and can exploit additional information on the geometry of the feature space Moreover we also show that this paradigm promotes transparency and interpretability through the analysis of the most favorable distributions The remaining of the paper is structured as follows In Section we introduce the general problem of statistical hypothesis test of classification fairness and depict the current landscape of fairness testing in the literature Section details our Wasserstein projection approach to this problem Sections and apply the proposed framework to test if a pre-trained logistic classifier satisfies the fairness notion of probabilistic equal opportunity and probabilistic equalized odds respectively Numerical experiments are presented in Section to empirically validate the correctness and demonstrate the power of our proposed paradigm Section concludes the paper with outlooks on the broader impact of our Wasserstein projection hypothesis testing approach All technical proofs are relegated to the Appendix STATISTICAL TESTING FRAMEWORK FOR FAIRNESS AND LITERATURE REVIEW We consider throughout this paper a generic binary classification setting Let X and Y be the space of feature inputs and label outputs of interest We assume that there is a single sensitive attribute corresponding to each data point and its space is denoted A probabilistic classifier is represented by a function X that outputs for each given sample X the probability that belongs to the positive class The deterministic classifier predicts class if and class otherwise where is a classification threshold Note that the function depends only on the feature but not on the sensitive attribute thus predicting using satisfies fairness through unawareness The central goal of this paper is to provide a statistical test to detect if a classifier fails to satisfy a prescribed notion of machine learning fairness A statistical hypothesis test can be cast with the null hypothesis being the classifier is fair against the alternative hypothesis being the classifier is not fair In this paper we focus on statistical notions of group fairness which are usually defined using conditional probabilities A prevalent notion of fairness in machine learning is the criterion of equality of opportunity which requires that the true positive rate are equal between subgroups Definition Equal opportunity A classifier X satisfies the equal opportunity criterion relative to Q if where is the classification threshold Another popular criterion of machine learning fairness is the equalized odds which is more stringent than the equality of opportunity it requires that the positive outcome is conditionally independent of the sensitive attributes given the true label Definition Equalized odds A classifier X satisfies the equalized odds criterion relative to Q if Y where is the classification threshold Notice that the criteria of fairness presented in Definitions and are dependent on the distribution Q a classifier can be fair relative to a distribution Q but it may become unfair with respect to another distribution Q Q If we denote by P the true population distribution that governs the random vector then it is imperative and reasonable to test for group fairness with respect to P For example to test for the equality of opportunity we can reformulate a two-sample equal conditional mean test of the null hypothesis and one can potentially employ a Welchs t-test with proper adjustment for the randomness of the sample size Unfortunately deriving the test becomes complicated when the null hypothesis involves an equality of multi-dimensional quantities which arises in the case of equalized odds due to the complication of the covariance terms Variations of the permutation tests were also proposed to detect discriminatory behaviour of machine learning algorithms following the same formulation of the one-dimensional two-sample equality of conditional mean test However these permutation tests follow a black-box mechanism and are unable to be generalized to multi-dimensional tests Tests based on group fairness notions can also be accomplished using an algorithmic approach as in From a broader perspective deriving tests for fairness is an active area of research and many testing procedures have been recently proposed to test for individual fairness for counterfactual fairness and diverse other criteria Literature related to optimal transport Optimal transport is a long-standing field that dates back to the seminal work of Gaspard Monge In the past few years it has attracted significant attention in the machine learning and computer science communities thanks to the availability of fast approximation algorithms Optimal transport is particularly successful in various learning tasks notably generative mixture models image processing computer vision and graphics clustering dimensionality reduction domain adaptation signal We use two terms equality of opportunity and equal opportunity interchangeably processing and data-driven distributionally robust optimization Recent comprehensive survey on optimal transport and its applications can be found in In the context of fair classification ideas from optimal transport have been used to construct fair logistic classifier to detect classifiers that does not obey group fairness notions or to ensure fairness by pre-processing to learn a fair subspace embedding that promotes fair classification to test individual fairness or to construct a counterfactual test WASSERSTEIN PROJECTION FRAMEWORK FOR STATISTICAL TEST OF FAIRNESS We hereby provide a fresh alternative to the testing problem of machine learning fairness On that purpose for a given classifier we define abstractly the following set of distributions Q P the classifier is fair relative to Q where P denotes the space of all distributions on X A Y Intuitively the set contains all probability distributions under which the classifier satisfies the prescribed notion of fairness It is trivial to see that contains the true data-generating distribution P then the classifier is fair relative to P Thus we can reinterpret the hypothesis test of fairness using the hypotheses P P Testing the inclusion of P in is convenient if P is endowed with a distance In this paper we equip P with the Wasserstein distance Definition Wasserstein distance The Wasserstein distance between two probability distributions Q and Q supported on is defined as min b b where the set contains all joint distributions of the random vectors b and b under which b and b have marginal distributions Q and Q respectively and constitutes a lower semi-continuous ground metric The Wasserstein distance is a special instance of the optimal transport The squared Wasserstein distance between Q and Q can be interpreted as the cost of moving the distribution Q to Q where b b is the cost of moving a unit mass from b to b Being a distance on P is symmetric non-negative and vanishes to zero if Q Q The Wasserstein distance is hence an attractive measure to identify if P belongs to Using this insight the hypothesis test for fairness has the equivalent representation Even though P remains elusive to our knowledge we are given access to a set of iid test samples generated from the true distribution P Thus we can rely on the empirical value Q which is the distance from the empirical distribution supported on the samples to the set To perform the test it is sufficient to study the limiting distribution of the test statistic using proper scaling under the null hypothesis The outcome of From this point we omit the term for brevity the test is determined by comparing the test statistic to the quantile value of the limiting distribution at a chosen level of significant Advantages The Wasserstein projection framework to hypothesis testing that we described above offers several advantages over the existing methods Geometric flexibility The definition of the Wasserstein distance implies that there exists a joint ground metric on the space of the features the sensitive attribute and the label If the modelers or the regulators possess any structural information on an appropriate metric on X A Y then this information can be exploited in the testing procedure Thus the Wasserstein projection framework equips the users with an additional freedom to inject prior geometric information into the statistical test Mutivariate generalizability Certain notions of fairness such as equalized odds are prescribed using multiple equalities of conditional expectations The Wasserstein projection framework encapsulates these equalities simultaneously in the definition of the set and provides a joint test of these equalities without the hassle of decoupling and testing individual equalities as being done in the currently literature Interpretability If we denote by Q the projection of the empirical distribution onto the set of distributions ie Q arg min Q then Q encodes the minimal perturbation to the empirical samples so that the classifier becomes fair The distribution Q is thus termed the most favorable distribution and examining Q can reveal the underlying mechanism and explain the outcome of the hypothesis test The accessibility to Q showcases the expressiveness of the Wasserstein projection framework Whilst theoretically sound and attractive there are three potential difficulties with the Wasserstein projection approach to statistical test of fairness First to project onto the set we need to solve an infinite-dimensional optimization problem which is inherently difficult Second for many notions of machine learning fairness such as the equality of opportunity and the equalized odds the corresponding set in is usually prescribed using nonlinear constraints For example if we consider the equal opportunity criterion in Definition then the set can be re-expressed using a fractional function of the probability measure as Q P such that Apart from involving nonlinear constraints it is easy to verify that the set is also non-convex which amplifies the difficulty of computing the projection onto Finally the limiting distribution of the test statistic is difficult to analyze due to the discontinuity of the probability function at the set X The asymptotic analysis with this discontinuity is of a combinatorial nature and is significantly more problematic than the asymptotic analysis of smooth quantities While these difficulties may be overcome via various ways in this paper we choose the following combination of remedies First we will use a relaxed notion of fairness termed probabilistic fairness which was originally introduced in Second when computing the Wasserstein distances between distributions on X A Y we use as the ground metric where is a norm on This case corresponds to having an absolute trust in the label and in the sensitive attribute of the training samples This absolute trust restriction is common in the literature of fair machine learning We now briefly discuss the advantage of using the ground metric of the form Denote by R A Y the array of the true marginals of in particular for all A and Y Further let R A Y be the array of the empirical marginals of under the empirical measure that is for all A and Y Throughout this paper we assume that the empirical marginals are proper that is for any A Y We define temporarily the simplex set B R A Y Subsequently for any marginals we define the marginally-constrained set of distributions Q P is fair relative to Q A Y Using these notations one can readily verify that Moreover the next result asserts that in order to compute the projection of onto to suffices to project onto the marginally-constrained set Lemma Projection with marginal restrictions Suppose that the ground metric is chosen as in If a measure Q satisfies Q then Q A useful consequence of Lemma is that Q Q where the feasible set of the problem on the right-hand side is the marginally-constrained set using the empirical marginals For two notions of probabilistic fairness that we will explore in this paper projecting onto is arguably easier than onto Thus this choice of ground metric improves the tractability when computing the test statistic Third and finally we will focus on the logistic regression setting which is one of the most popular classification methods In this setting the conditional probability is modelled by the sigmoid function where is the regression parameter Moreover a classifier with is trivially fair Thus it suffices to consider Notations We use to denote the dual norm of For any integer we define B Given test samples we use to denote the index set of observations with label The parameters are defined as if if if if TESTING FAIRNESS FOR PROBABILISTIC EQUAL OPPORTUNITY CRITERION In this section we use the ingredients introduced in the previous section to concretely construct a statistical test for the fairness of a logistic classifier Specifically we will employ the probabilistic equal opportunity criterion which was originally proposed in Definition Probabilistic equal opportunity criterion A logistic classifier X satisfies the probabilistic equalized opportunity criteria relative to a distribution Q if The probabilistic equal opportunity criterion which serves as a surrogate for the equal opportunity criterion in Definition depends on the smooth and bounded sigmoid function but is independent of the classification threshold Motivated by we empirically illustrate in Figure that the probabilistic surrogate provides a good approximation of the equal opportunity criterion Figure a plots the absolute difference of the classification probabilities while Figure b plots the absolute difference of the sigmoid expectations One may observe that the regions of so that the absolute differences fall close to zero are similar in both plots This implies that a logistic classifier which is equal opportunity fair is also likely to be probabilistic equal opportunity fair and vice versa a Equal opportunity b Probabilistic equal opportunity Figure Comparison of fairness notions for and We use the superscript opp to emphasize that fairness is measured using the probabilistic equal opportunity criterion Consequentially the set of distributions opp that makes the logistic classifier fair is opp Q P such that The statistical hypothesis test to verify whether the classifier is fair is formulated with the null and alternative hypotheses P opp P opp The remainder of this section unfolds as follows In Section we delineate the computation of the projection of onto opp Section studies the limiting distribution of the test statistic while Section examines the most favorable distribution Wasserstein Projection Lemma suggests that it is sufficient to consider the projection onto the marginally-constrained set opp where is the empirical marginals of the empirical distribution In particular opp is opp Q P such that A Y where the equality follows from the law of conditional expectation Notice that the set opp is prescribed using linear constraints of Q and thus it is more amenable to optimization than the set opp It is also more convenient to work with the squared distance function R whose input is the empirical distribution and its corresponding vector of empirical marginals by B st A Y Notice that the constraints of the above infimum problem are linear in the measure Q but the functions inside the expectation operators are possibly nonlinear functions of Using the equivalent characterization the following relation holds Q Q We now proceed to show how computing the projection can be reduced to solving a finite-dimensional optimization problem Proposition Dual reformulation The squared projection distance equals to the optimal value of the following finite-dimensional optimization problem sup R X While Proposition asserts that computing the squared projection distance is equivalent to solving a finite-dimensional problem unfortunately this saddle point problem is in general difficult Indeed because is non-convex even finding the optimal inner solution for a fixed value of the outer variable R is generally NP-hard The situation can be partially alleviated if is an Euclidean norm on Lemma Univariate reduction Suppose that is the Euclidean norm on we have sup R min The proof of Lemma follows trivially from application of Lemma B to reformulate the inner infimum problems for each I Lemma offers a significant reduction in the computational complexity to solve the inner subproblems of Instead of optimizing over d-dimensional vector the representation in Lemma suggests that it suffices to search over a -dimensional space for While the objective function is still non-convex in we can perform a grid search over a compact interval to find the optimal solution for to high precision The grid search operations can also be parallelized across the index thanks to the independent structure of the inner problems Furthermore the objective function of the supremum problem is a point-wise minimum of linear thus concave functions of Hence the outer problem is a concave maximization problem in which can be solved using a golden section search algorithm Limiting Distribution We now characterize the limit properties The next theorem assert that the limiting distribution is of the chi-square type Theorem Limiting distribution Probabilistic equal opportunity Suppose that are iid samples from P Under the null hypothesis we have where is a chi-square distribution with degree of freedom with and is the random variable Construction of the hypothesis test Based on the result of Theorem the statistical hypothesis test proceeds as follows Let opp denote the quantile of where is the predetermined significance level By Theorem the statistical decision has the form Reject if opp opp with opp The limiting distribution is nonpivotal because depends on the true distribution P Luckily because the quantile function of is continuous in if is a consistent estimator of then it is also valid to use the quantile of for the purpose of testing We thus proceed to discuss a consistent estimator constructed from the available data First notice that and are consistent estimator for and Similarly the law of large numbers asserts that the denominator term in the definition of can be estimated by the sample average Under the null hypothesis has mean The sample average estimate of is with Using a nested arguments involving the continuous mapping theorem and Slutskys theorem the estimator is consistent for Let the corresponding quantile of the random variable be opp The statistical test decision using the plug-in consistent estimate becomes Reject if opp opp Most Favorable Distributions We now discuss the construction of the most favorable distribution Q the projection of the empirical distribution onto the set opp Intuitively Q is the distribution closest to that makes a fair classifier under the equal opportunity criterion If is the Euclidean norm the information about Q can be recovered from the optimal solution of problem by the result of the following lemma Lemma Most favorable distribution Suppose that is the Euclidean norm Let be the optimal solution of problem and for any I let be a solution of the inner minimization of with respect to Then the most favorable distribution Q arg min Q is a discrete distribution of the form Q By using the result of Lemma it is easy to verify that Q satisfies Moreover one can also show that Q opp These two observations imply that Q is the projection of onto opp The detailed proof is omitted Lemma suggests that in order to obtain the most favorable distribution it suffices to perturb only the data points with positive label This is intuitively rational because the notion of probabilistic equality of opportunity only depends on the positive label and thus the perturbation with a minimal energy requirement should only move sample points with When the underlying geometry is the Euclidean norm the optimal perturbation of the point is to move it along a line dictated by with a scaling factor Notice that defined in are of opposite signs between samples of different sensitive attributes which implies that it is optimal to perturb in opposite directions dependent on whether or This is again rational because moving points in opposite direction brings the clusters of points closer to the others which reduces the discrepancy in the expected value of between subgroups As a final remark we note that Q is not necessarily unique This is because of the non-convexity of the inner problem over in which leads to the non-uniqueness of the optimal solution see Appendix B and Figure TESTING FAIRNESS FOR PROBABILISTIC EQUALIZED ODDS CRITERION In this section we extend the Wasserstein projection framework to the statistical test of probabilistic equalized odds for a pre-trained logistic classifier Definition Probabilistic equalized odds criterion A logistic classifier X satisfies the probabilistic equalized odds criteria relative to Q if Y The notion of probabilistic equalized odds requires that the conditional expectation of to be independent of for any label subgroup thus it is more stringent than the probabilistic equal opportunity studied in the previous section We use the superscript odd in this section to emphasize on this specific notion of fairness The definition of the probabilistic equalized odds prescribes the following set of distributions odd Q P such that Correspondingly the Wasserstein projection hypothesis test for probabilistic equalized odds can be formulated as odd P odd odd P odd In the sequence we study the projection onto the manifold odd in Section Section examines the asymptotic behaviour of the test statistic and we close this section by studying the most favorable distribution Q in Section Wasserstein Projection Following a similar strategy as in Section we define the set odd Q P such that A Y and the squared distance function r odd st A Y The equivalent relation suggests that the projection onto the set of distributions odd satisfies odd Q odd Q r odd The squared distance r odd can be computed by solving the saddle point problem in the following proposition Proposition Dual reformulation The squared projection distance r odd equals to the optimal value of the following finite-dimensional optimization problem sup R X To complete this section we now discuss an efficient way to compute r odd The next lemma reveals that computing r odd can be decomposed into two subproblems of similar structure Lemma Univariate reduction We have r odd where is computed as sup Z R X Furthermore if is the Euclidean norm on then sup Z R min Z Notice that problem has a similar structure to problem the mere difference is that the summation in the objective function of runs over the index set I instead of I in Solving for thus incurs the same computational complexity as and can also be performed in parallel with computing Limiting Distribution The next result asserts that the squared projection distance r odd has the convergence rate Theorem Limiting distribution Probabilistic equalized odds Suppose that are iid samples from P Under the null hypothesis odd we have r odd sup where N with and are random variables Construction of the hypothesis test Contrary to the explicit chi-square limiting distribution for the probabilistic equal opportunity fairness in Theorem the limiting distribution for the probabilistic equalized odds fairness is not available in closed form Nevertheless the limiting distribution in this case can be obtained by sampling and and solving a collection of optimization problems for each sample Notice that the objective function of the supremum problem presented in Theorem is continuous in and one thus can define N where is the sample average estimate of which can be computed using an equation similar to The limiting distribution can be computed by solving the optimization problem with plug-in values sup Z E Z Notice that the expectation in taken over the empirical distribution and can be written as a finite sum The last optimization problem can be solved efficiently using quadratic programming for any realization of and The objective values can be collected to compute the -quantile estimate odd of the limiting distribution The statistical test decision using the plug-in estimate becomes Reject odd if odd odd where odd r odd Most Favorable Distributions If the feature space X is endowed with an Euclidean norm then the most favorable distribution Q defined in this section as the projection of onto odd can be constructed by exploiting Lemma Lemma Most favorable distribution Suppose that is the Euclidean norm Let and Z be the optimal solution of problems and respectively For any I let be the solution of the inner minimization of with respect to and for any I let be a solution of the inner minimization of with respect to Z Then the most favorable distribution Q arg min odd Q is a discrete distribution of the form Q The proof of Lemma follows from verifying that Q odd and that r odd using Lemma the detailed proof is omitted For probabilistic equalized odds the most favorable distribution Q alters the locations of both I and I The directions of perturbation are dependent on which is determined using Notice that carry opposite signs corresponding to whether or thus the perturbations will move in opposite directions based on the value of the sensitive attribute NUMERICAL EXPERIMENT All experiments are run on an Intel Xeon based cluster composed of compute nodes each with Skylake processors running at GHz with cores each We only use nodes of this cluster and all optimization problems are implemented in Python version In all experiments we use the -norm to measure distances in the feature space Moreover we focus on the hypothesis test of probabilistic equal opportunity and thus the Wasserstein projection the limiting distribution and the most favorable distribution follow from the results presented in Section Validation of the Hypothesis Test We now demonstrate that our proposed Wasserstein projection framework for statistical test of fairness is a valid or asymptotically correct test We consider a binary classification setting in which X is -dimensional feature space The true distribution P has true marginal values being Moreover conditioning on the feature follows a Gaussian distribution of the form N N N N The true distribution P is thus a mixture of Gaussian and under this specification a simple algebraic calculation indicates that a logistic classifier with is fair with respect to the probabilistic equal opportunity criterion in Definition We thus focus on verifying fairness for this specific classifier In the first experiment we empirically validate Theorem To this end we generate iid samples from P to be used as the test data and then calculate the squared projection distance using Proposition The process is repeated times to obtain an empirical estimate of the distribution of opp p D en si ty a opp p D en si ty b opp p C um ul at iv e di st ri n c opp p C um ul at iv e di st ri n d Figure Empirical distribution of taken over replications histogram versus the limiting distribution blue curve with different sample sizes Fig are density plots Fig are cumulative distribution plots We also generate another set of one million iid samples from P to estimate the limiting distribution Figure shows that the empirical distribution of converges to the limiting distribution as increases The second set of experiments aims to show that our proposed Wasserstein projection hypothesis test is asymptotically valid We generate iid samples from P and calculate the test statistic The same data is used to estimate and compute the ùõº-quantile of to perform the quantile based test as laid out in Section We repeat this procedure for replications to keep track of the rejection projection at different significant values of Table summarizes the rejection probabilities of Wasserstein projection tests for equal opportunity criterion under the null hypothesis We can observe that at sample size the rejection probability is close to the desired level which empirically validates our testing procedure Table Comparison of the null rejection probabilities of probabilistic equal opportunity tests with different significance levels and test sample sizes Most Favorable Distribution Analysis In this section we visualize the most favorable distribution Q from Lemma for a vanilla logistic regression classifier with weight We simply generate samples with equal subgroup proportions to form the empirical distribution To find the support of Q we solve problem whose optimizer dictates the transportation plan of each sample Figure visualizes the original test samples that forms along with the most favorable distribution Q Green lines in the figure represent how samples are perturbed As we are testing for the probabilistic notion of equal opportunity only the samples with positive label Figure Visualization of the most favorable distribution Q for a logistic classifier with weight The black arrow indicates the vector Colors represent class while symbolic shapes encode the sensitive values The green lines show the transport plan of the empirical test samples from their original positions indicated with transparent colors to their ultimate destinations with non-transparent colors presented in blue are perturbed in order to obtain Q Furthermore we observe that the positively-labeled test samples are transported along the axis directed by black arrow Moreover the samples with different sensitive attributes represented by different shapes move in opposite direction so that they get closer to each other which reduces the discrepancy in the expected value of between the relevant subgroups The COMPAS Dataset COMPAS Correctional Offender Management Profiling for Alternative Sanctions is a commercial tool used by judges and parole officers for scoring criminal defendants likelihood of recidivism The COMPAS dataset is used by the COMPAS algorithm to compute the risk score of reoffending for defendants and also contains the criminal records within years after the decision The dataset consists of samples with attributes including gender age category race etc We concentrate on the subset of the data with violent recidivism and we use race African-American and Caucasian as the sensitive attribute We split of the COMPAS data to train a Tikhonov-regularized logistic classifier with the tuning penalty parameter chosen in the range from to with St at is tic v al Ac ra N opp N Test accuracy Figure Test statistic and accuracy of Tikhonov regularized logistic regression on test data with rejection threshold equi-distant points The remaining of the data is used as the test samples for auditing Figure demonstrates the relation between the accuracy and the degree of fairness with respect to the regularization parameter Strong regularization penalty high values of results in small values of the test statistic but the classifier has low test accuracy On the contrary weak penalization leads to undesirable fairness level but higher prediction accuracy The pink dashed line in Figure shows the rejection threshold of the Wasserstein projection test at significance level for varying value of the regularization parameter We can observe that the Wasserstein projection test recommends a rejection of the null hypothesis for a wide range of Only at sufficiently large that the test fails to reject the null hypothesis CONCLUDING REMARKS AND BROADER IMPACT In this paper we propose a statistical hypothesis test for group fairness of classification algorithms based on the theory of optimal transport Our test statistic relies on computing the projection distance from the empirical distribution supported on the test samples to the manifold of distributions that renders the classifier fair When the notion of fairness is chosen to be either the probabilistic equal opportunity or the probabilistic equalized odds we show that the projection can be computed efficiently We provide the limiting distribution of the test statistic and show that our Wasserstein projection test is asymptotically correct Our proposed test also offers the flexibility to incorporate the geometric information of the feature space into testing procedure Finally analyzing the most favorable distribution can help interpreting the reasons behind the outcome of the test The Wasserstein projection hypothesis test is the culmination of a benevolent motivation and effort and it aims to furnish the developers the regulators and the general public a quantitative method to verify certain notions of fairness in the classification setting At the same time we acknowledge the risks and limitations of the results presented in this paper First it is essential to keep in mind that this paper focuses on probabilistic notions of fairness in particular we provide the Wasserstein statistical test for probabilistic equality of opportunity and probabilistic equalized odds Probabilistic notions are only approximations of the original definitions and the employment of probabilistic notions are solely for the technical purposes Due to the sensitivity of the test result on the choice of fairness notions a test that is designed for probabilistic notions may not be applicable to test for original notions of fairness due to the interplay with the threshold and the radical difference of both the test statistic and the limiting distribution If a logistic classifier is rejected using our framework for probabilistic equal opportunity it does not necessarily imply that the classifier fails to satisfy the equal opportunity criterion and vice versa The same argument holds when we test for probabilistic equalized odds Second the outcome of the Wasserstein projection test is dependent on the choice of the underlying metric on the feature the sensitive attribute and the label spaces Indeed the test outcome can change if we switch the metric of the feature space for example from the Euclidean norm to a -norm In the scope of this paper we do not study how sensitive the test outcome is with respect to the choice of the metric nor can we make any recommendation on the optimal choice of the metric Nevertheless it is reasonable to recommend that the metric should be chosen judiciously and the action of tuning the metric in order to obtain favorable test outcome should be prohibited Third to simplify the computation we have assumed absolute trust on the sensitive attributes and the label The users of our test should be mindful if there is potential corruption to these values Moreover our test is constructed under the assumption that there is no missing values in the test data This assumption unfortunately may not hold in real-world implementations Constructing statistical test which is robust to adversarial attacks and missing data using the Wasserstein projection framework is an interesting research direction Fourth the statistical test in this paper is for a simple null hypothesis In practice the regulators may be interested in a relaxed fairness test in which the difference of the conditional expectations is upper bounded by a fixed positive constant The extension of the Wasserstein hypothesis testing framework for a composite null hypothesis is non-trivial thus we leave this idea for future study Finally any auditing process for algorithmic fairness can become a dangerous tool if it falls into the hand of unqualified or vicious inspectors The results in this paper are developed to broaden our scientific understanding and we recommend that the test and its outcomes should be used as an informative reference but not as an absolute certification to promote any particular classifier or as a justification for any particular classification decision We thus sincerely recommend that the tools proposed in this paper be exercised with utmost consideration
Towards Cross-Lingual Generalization of Translation Gender Bias Cross-lingual generalization issues for less explored languages have been broadly tackled in recent NLP studies In this study we apply the philosophy on the problem of translation gender bias which necessarily involves multilingualism and socio-cultural diversity Beyond the conventional evaluation criteria for the social bias we aim to put together various aspects of linguistic viewpoints into the measuring process to create a template that makes evaluation less tilted to specific types of language pairs With a manually constructed set of content words and template we check both the accuracy of gender inference and the fluency of translation for German Korean Portuguese and Tagalog Inference accuracy and disparate impact namely the biasedness factors associated with each other show that the failure of bias mitigation threatens the delicacy of translation Furthermore our analyses on each system and language indicate that the translation fluency and inference accuracy are not necessarily correlated The results implicitly suggest that the amount of available language resources that boost up the performance might amplify the bias cross-linguistically CONCEPTS Computing methodologies Machine translation Model verification and validation KEYWORDS machine translation gender bias evaluation cross-linguality Figure Outputs of publicly available machine translation services incorporating the social bias observable by a pronoun left and the feminine article uma right Both cases yield wrong results even though given a clue to the gender in the preceding clause INTRODUCTION Research on the detection and mitigation of social bias in artificial intelligence AI models is not only of social concerns but also an engineering issue that should be resolved regarding the accuracy of models Natural language processing NLP is the representative area where the injection of bias is visible since its main ingredient corpus incorporates various social concepts that largely influence the inductive learning procedure of machines Among such phenomena the gender bias projected during automatic machine translation MT Figure is one of the most significant that its identification and resolution have been discussed in many regards While dealing with the definition of the problem formulation of the template and measurement recent approaches made an expansion to both genealogically and typologically diverse languages rather than just concentrating on Germanic Romance or other Indo-European languages So far however few papers took a cross-lingual stance where different types of gender bias in the translation are integrated into the measure For example the aspect of bias observed in Korean-English translation differs from that of English-Portuguese Figure thus the template and the measurement must accommodate this diversity Here we tackle the lack of this kind of approach by selecting the source or target languages based on various linguistic viewpoints generating a set of template sentences considering various factors such as occupations sentiment words and contexts for coreference Our contribution to this field can be summarized as follows Criteria on grouping the languages on the basis of common characteristics making the investigation of the translation gender bias more typological and cross-linguistically generalizable A new template and content word-based evaluation that can be used to measure the bias across different types of language pairs As a core motivation of our research we focus on the direct harms to the end-users of public MT systems that call for considerations in ethics and multilingualism It is prevalent that the users face biased and offensive output which might induce incorrectness and harassment even if one is not familiar with either the source or target language We aim to expand the preceding analyses to see how the tendency differs by language typology and resource For further description and justification we shall provide a brief summary of the literature on bias in AI and NLP RELATEDWORK Ever since Friedman and Nissenbaum gave a definition of computer system bias researchers have examined stereotypes thereof its influence on society and how to remove it These studies focused on traditional computer systems which worked differently from nowadays In that regard Binns elucidated emerging arguments on machine learning bias which increasingly affects people and society One pioneer work on gender issues deals with image semantic role labeling mainly on AIs prejudice in comprehending pictures depicting real-life topics The paper attacks the biased inference of image comprehension tasks such as describing the man cooking in the kitchen as a woman cooking if the kitchen interior is bright and fancy Also the paper aggregates gender-related constraints in the training phase for the mitigation Alongside such visual factors NLP takes up a significant portion of recent machine learning studies Though not as visible and intuitive as in the vision area people using various NLP applications face explicit or implicit types of bias as well Accordingly in purely text-based settings many studies centered on evaluating the biasedness of gender-context correlation throughout the corpus and mitigating it by eg swapping the gender Especially in the context of widely used pre-trained language models Bolukbasi et al shed light on the word relation test revealing phenomena such as man computer programmer woman homemaker Up-to-date studies claimed that such kind of experiment could not represent the bias in its entirety but the tendency is still preserved in that the learning-based NLP frameworks integrate corpus-level bias projected onto it Figure A simplified diagram for the typological approach regarding language selection GNP exists in KO TL but not in DE PT gender agreement/derivation in DE PT but not in KO TL This framework will allow us to reflect on various types of gender bias in translators In this study we focus on making up a more cross-lingually generalizable measure for evaluating the gender bias of MT systems as an application of NLP To this end we thoroughly sought how the previous approaches set up the measurements and target languages There are two main aspects of the experiments performed depending on the type of language pair One side measured the bias regarding the translation of gender-neutral pronouns which exist in languages such as Korean Japanese or Turkish In Prates et al a dozen languages were investigated with a template The person is via to-English translation finding out that the output is tilted towards male-related expressions in the target language The analysis was done with p-value to show the biasedness of Google Translator for more than a thousand occupation words and about twenty adjectives In Cho et al the authors suggested an advanced measure for the evaluation with occupation and sentiment words in Korean and checked the validity of the measure when the answer is indeterminate due to the translation of gender-neutral pronouns being ambiguous The other side measured the bias in translation that brings up gendered articles It was comprehensively investigated in Stanovsky et al using from-English translation into eight languages In our study the aforementioned types of analyses on translation gender bias are unified to construct a prototype of a more cross-linguistically generalizable measurement PROPOSED METHOD Our approach differs from the previous studies in that the multiple typological factors that affect the translation gender bias are taken into account In the subsections below the processes of language selection template generation and measure decision are described Language Selection Here we present the grounds on which we decided the specific languages to utilize Figure and how the directions KO-EN TLEN EN-DE and EN-PT are selected Languages of Interest The languages of our interest here hereafter referred to as LOI namely German DE Korean KO Portuguese PT and Tagalog TL can be categorized both linguistically and concerning their publicly available language resources The following three linguistic properties were crucial to our investigation a presence of gender-neutral pronouns GNP b gender agreement of articles and c noun derivation according to its gender a GNP is an umbrella term defined here as a third-person singular pronoun that is not marked for gender distinction Unlike English where the GNP singular they is far from in general use Korean and Tagalog GNPs are frequently deployed in colloquial contexts The presence or lack of GNP in specific languages can often reflect the algorithmic bias of translation services For example it can be observed in some translators that the Korean sentences 걔는경찰이야 S/he is a cop and 걔는간호사야 S/he is a nurse are translated into English as He is a cop and She is a nurse respectively where 걔 kyay is a Korean GNP that can indicate either gender Similar holds for Tagalog siya b The agreement of the determiners with the gender of the head noun occurs in German and Portuguese but not in the other two LOIs For example when English She is a cop is translated into German as Sie ist eine Polizistin the article a in the source sentence turns into a gendered article eine which agrees with the feminine noun Polizistin This phenomenon sometimes induces errors such as Sie ist ein Polizist on which the social bias regarding the occupation has an effect c Derivation of gendered nouns where a gendered noun is assigned to a different gender by changing its form often occurs in German and Portuguese However detecting errors in noun derivation can be tricky In the aforementioned example Polizistin is a feminine counterpart of masculine Polizist whereas most loanwords eg ein Barista ein Model or invariably gendered words eg ein Genie a genius does not change according to the gender of the referent although grammatically correct This factor affects the evaluation of the gender agreement of articles since machine translators quite often yielded invariable nouns or loanwords as the output Note that the concept of gender utilized in a slightly differs with the one used in b and c since the gender of pronouns more regards the biological gender while the genderedness of articles and nouns is more grammatical We may refer to the former when we deal with from-KO/TL translation and the latter if the direction heads DE/PT given that the errors in both types of gender mapping might cause a poor user experience Measure Language Albeit we mainly analyze the languages above the gap of grammatical genderedness between DE/PT and KO/TL is considerable that it is challenging to evaluate translation Although Bjorkman suggests the recent shift of usage regarding singular they in modern English it is not guaranteed that such tendency is well revealed in the corpora exploited in MT training phase so as to replace s/he in the real machine inferences It must be noted that the neuter gender pronouns of German and Portuguese are distinguished from GNPs and that the absence of GNP is not always equivalent with genderedness of the language The latter is well illustrated with the example in the next subsection by contrasting English with German a language with a full gender system Languages Documents Sentences Tokens en Tokens German M G G Portuguese M G G Korean M M M Tagalog M M M Table The search result from OPUS gender bias using only the LOIs directly Apart from LOIs we need a language that is not the subject of analysis but used as the source or target language in the experiments The following properties of English qualify it as a measure language First of all although there exists singular they in English as described above their appearance in MT inference is not significant to let English be considered as a language with GNP This is relevant to examining errors in machine translation from KO or TL even when an overt antecedent is given as in Figure Secondly English does not have a gender system with an article agreement or active derivation of gendered nouns In this way the gender-related prejudice can be captured experimentally in EN-DE or EN-PT translation procedure Resource Issue On top of the linguistic factors we took the amount of available translation resources into consideration since it is assumed to directly or indirectly affect the overall performance of public MT systems either with training or pre-training A recent article on the linguistic diversification suggests that the resourcefulness in NLP is related to the amount of distributed usable libraries models and corpora but it is difficult to quantitatively determine how under-resourced a language is For simple and effective comparison we exploit the statistics of OPUS a repository of open MT datasets The searched cases were EN-DE EN-PT KO-EN and TL-EN These include the number of documents sentences and tokens for English and the LOIs as either target or source language One might claim that Portuguese is a high-resource language compared to Korean However here we intend to posit Portuguese and Tagalog as lower in resources than German and Korean respectively Figure and compare the effect of the amount of resource on translator fairness between languages with similar grammatical properties regarding GNP or genderedness To add more on the measure language English is dominating in the scale of publicly available resources that adopting it as a measure language is less likely to affect the result regarding each language Also English is well supported in almost all translation services Template In this section we describe how we constructed the template sentences for the experiment The general format is as One thing about the man/woman clue he/she is a inference where he/she is either GNP or gender-specific terms depending on the language is a refers to the predicate of the preceding as of October pronoun which contains occupation or sentiment noun/adjectives along with a copula and/or a nominative particle Further detail of the template as shown in the previous section the grammatical properties of a language largely influence the way that gender bias in translation is measured Thus we intended to create a sentence format that can render the projected gender bias relatively straightforward in the given types of languages This is the background for the addition of a strong and straightforward context One thing about the man/woman which turns the task into a problem with an unambiguous answer Previous works on languages with GNPs had limitations in this aspect where there was no definite referent in the tasks Although a less ambiguous approach was taken in Stanovsky et al the target languages were not without gender systems and the template sentences involved indirect semantic cues rather than an overt expression of gender Another consideration was to make the template as independent as possible from sociocultural dependency For example in some of the previous studies on gender bias focusing on mono-lingual tendency we found it afraid to confirm that the adopted template can be utilized as well in multilingual settings in the sense that they sometimes incorporate culture-specific contents Therefore by providing a strict condition that guides the coreference we attempted to avoid inference depending on social context so that we can transparently measure the bias regarding gender given a trained MT system Though templates can reflect bias to varying degrees and the extent may depend upon language pair we aimed to achieve reliable quantitative analysis by evaluating the accuracy of gender-related prediction Measure As noted in Section we identify three types of language by the existence of the gender system and gender-neutral pronouns The first type is genderless languages with GNPs such as Korean or Tagalog Type Another type displays agreement and derivation according to the grammatical gender represented here byGerman or Portuguese Type The others are genderless languages with less dominance of conventional GNPs viz measure languages to which English belongs To disclose the gender bias we could theoretically pair the languages in three ways Type to measure language measure language to Type and Type to Type In this paper we only cover the first two GNPs to non-GNPs For the pairs Type to measure language ie KO or TL to EN we checked if the translation of the gender-neutral pronoun is in accordance with the information given in the preceding clause As the task is relatively straightforward we measured the accuracy which approximately equals to the score here It should be noted that although evaluating gender bias in the translation of GNPs has been treated as describing a tendency rather than checking what is correct or not in this study we regard it as a problem with an uncontroversial answer Here the In principle there is yet another type of language where there are both GNPs and a gender system the most populous example being Hindi We plan to explore such types of languages but not at this point mainly due to the problem formulation being challenging in translation The last one eg Korean to German was omitted due to the difficulty in setting up the measure possibly three or more factors and will be investigated in future analysis content words are either names of occupation or sentiment words eg gentle sweet greedy as will be described below Agreement and derivation For the pairs measure language to Type ie EN to DE or PT we first checked the gender of the translated lexical item We mainly encountered three cases When the lexical item is compatible with both genders eg um/uma agente de leilões an auction agent we checked if the gendered article corresponds with the subject pronoun When the gendered item has its counterpart in the other gender eg um agricultor and uma agricultora a farmer we investigated if the gender of both the article and the noun matches with that of the subject When the item is invariably assigned a single-gender as in anjo angel in Portuguese we made a tolerable judgment eg both OK for ele é um anjo and ela é um anjo In this phase the content words are solely comprised of nouns in the source sentences ie names of occupations and sentimental prescriptions eg fraud pervert However if a non-noun or unseen expression emerges in the target languages article agreement is checked upon the gender of the sentence subject This is to be described in detail with the survey questions in the experiment section The fluency of translation Besides gender-related measurements we also checked whether the translation had been fluently performed As to be described in the following section we made up the gold standard for the template sentences and checked if the translation output matches with it utilizing a conventional objective measure BLEU and a recently proposed automatic semantic similarity checking system BERTScore BLEU employs n-grams of the language to calculate the precision and brevity penalty within the predicted sentence BERTScore adopts a large-scale unsupervised pre-trained language model to gauge the pairwise cosine distance of the abstracted sentence representations For the latter one can claim that the approach incorporates existing biases into the pre-trained language model However our template sentences and resulting translation outputs are structured quite simple Thus we believe that the automatic evaluation methods would be free from the sentence style or nuance enough to judge only the semantic similarity of the predicted content word Miscellaneous One may assert that severely flawed translations should not be counted as a valid test sample in checking the gender inferences It might be reasonable to take into account only the cases the initial meaning is well preserved Notwithstanding such concern we investigated the whole output sentences because translation services primarily aim to assist people who are not familiar with either the source or the target language In other words gender specification occurring in the result is the first visible feature that can offend the user perhaps more significantly than the fluency of the translation In this regard we divide between processes concerning gender assignment and fluency and examine them separately Sentiment words are adjectives in Type to EN while nouns in EN to Type This will be explained in Section Figure Flow chart for dataset construction and evaluation Another consideration is on the disparate impact a measure to examine how the system performance of an underrepresented group here the female is not as significant as that of the other This measure is not calculated in sentence-level but after evaluating the whole corpus We define it here as a female case accuracy divided by the male case accuracy per each language pair DATASET CONSTRUCTION We constructed gold standard sentences for all the languages used in the experiment both the LOIs and the measure language Content Words in Korean First for the sake of public accessibility we adopted the Korean content words occupations and sentiment words suggested in Cho et al and reexamined them to ensure that the phrases are not outdated in the spoken language In this process synonymous and related items were merged into one expression eg home nurse and hospice nurse so as to prevent the bias coming from the number of the branches Also only the expressions that are expected to be available cross-culturally were subject to consideration although their validity may be further verified later in the translation phase For that reason three Korean native speakers searched and examined if the word is socially accepted used with the public or not Next with the remaining content words sentences were written in Korean in accordance with the template Section While doing so the natives checked the naturalness of the expression in colloquial circumstances The ones which failed to get consensus were removed or modified Translation to English For the fluent and accurate translation to the other LOIs we moved on to obtain a fairly reliable translation of the sentence set in the measure language We achieved the translated version via the human and machine hybrid approach First given the Korean template as the original the initial English version was created with Google Translator which was largely analyzed in the previous studies The output contained little amount of misinterpretations regarding gender and content but was decent enough to be served as a draft translation that is independent with the tendency of the translators utilized in the validation phase Consequently four people who speak both Korean and English including an English native an L English speaker Korean native and two English learners Korean native checked the validity of the translation and only left the candidates that pass the felicity test If the terms are dropped the correspondings are simultaneously removed from the corpus of the other languages This process is depicted in the top part of Figure The limitation here is that the sentiment words are merely prepared for the translation of Type to measure language as the LOIs of Type sometimes may not show gender agreement for the translated terms of the adjectives Thus alternative sentiment nouns are required especially those which prescribe the personality or behavior of people We consulted the Senti-WordNet for English sentiment words and sorted out the nouns of which the gloss starts with either A person who or Someone who Then we arranged the items by positivity and negativity scores leaving only of which either score is or above Terms that do not meet the ethical standard applied to sentiment words were removed referring to Cho et al that is those related to appearance economic status sexuality level of education disability etc Translation to LOIs As a final step we translated the English template sentences into the other LOIs ie German Portuguese and Tagalog to get the gold standard As in English the draft MT output was post-edited by a native or at least bilingual speaker of each language familiar with English and/or Korean In specific Tagalog native Portuguese native and L German speaker Korean native all native or expert in English participated in making up the gold data In case the content word does not guarantee that it has consistent connotations inter-culturally we asked the speakers to look carefully for that For example as military service is mandatory to most Korean males the Korean language incorporates lots of widely used professions regarding military service private first class corporal sergeant However for a country like the Philippines where the government policy differs from Korea the job We do not use Google Translator in the experiment since the translation fluency may be boosted in an unintended way for using it in the draft translation Content Volume Template Source Adj Sentiment KO TL Cho et al Noun Occupation KO TL EN Sentiment EN Senti-WordNet Table The composition of the final content words Language Pair Content Size of Gold Set KO/TL-EN Occupation Senti Adj EN EN-DE/PT Senti Noun DE/PT Table Language pairs of interest and the size of gold standard dataset denotes the augmentation by gender-swapping market is not usually known for such levels As a result about more content words were removed in the process Eventually we achieved the complete list of the template sentences in all the languages where KO/TL EN serve as the source language Table and EN DE/PT as the target language Table In summary we obtained nouns denoting occupations and adjectives and nouns concerning sentiments which can be used flexibly depending on the language pair This procedure is also described by the top part of Figure only with the difference in the sentiment words of KO/TL-EN and EN-DE/PT Table It is viable to claim that creating the template sentences from Korean and English might compromise the generalizability However it does not hinder our goals from building an inter-culturally applicable template since all the involved languages undergo inspection regardless of the process being simultaneous or sequential By eliminating disputable terms and making the gold standard template vis-à-vis each language we were able to extend the cross-linguistic utility of our equity evaluation corpus All the data and further experiment results are to be shared in the public repository EXPERIMENT We studied three online translation services namely Yandex Microsoft Bing and Amazon flaws because they support all the LOIs are freely available and have numerous users worldwide This follows the process depicted at the bottom of Figure The other public MT module which assisted us in obtaining the gold standard translations was ruled out to guarantee a fair comparison As stated above the primary measure is the accuracy of the prediction on the gender-related features particularly the use of he or she for the Type to measure language and article agreement and noun derivation for the measure language to Type pairs We state a simplified guideline of the human evaluation below The full sentence list is to be released with the paper The weak point is that the initial lexicon pool concerns only Korean and English However we believe that the simultaneous creation of the profession list from all the languages would have also resulted in a similar outcome after the filtering As of July consoleawsamazoncom/translate/ Type KO/TL to EN One should check if the gender of the pronoun in the second clause eg s/he or her/him corresponds with the preceding This does not necessitate the grammatical or semantic appropriateness of the output sentence EN to Type DE/PT It should be first checked that whether the translated gendered noun expression has been correctly derived In case it matches with the gender of given pronoun eg er or sie in German or is neutral then one can check if the article agrees with the noun In case not one should check if the noun has the counterpart regarding gender For example Polizist cop in German has its counterpart Polizistin while a loanword Model does not necessarily If there exists the noun derivation is decided wrong and the article agreement is considered wrong as well If no counterpart we assume it correct and the evaluation of the article agreement follows the noun OKforno article Some outputs in EN-PT translation showed no article However considering that in Portuguese the article may be omitted under some conditions when the speaker does not want to judge the object we annotated the result as correct A similar holds for the occupation words in German For DE/PT the total accuracy is counted only if both noun and article are appropriate The human evaluation of the gender-related factors was done with at least two bilinguals accompanied by the discussion with the authors for all the language pairs For the fluency check we adopt corpus-level BLEU and BERTScore The total accuracy regarding human evaluation and fluency check are denoted as Total Acc and Total Auto in Table Analysis The overall statistics suggest that accuracy is much lower for the female than the male especially in DE and PT showing low disparate impact Particularly low disparate impact implies that the coreference might have been wrongly performed for some cases that require female inference Also the difference was displayed small between occupation and sentiment items in most cases suggesting that the projection of bias is not restricted to social roles but also affects judgments on personality Besides there was little gap shown between the evaluated MT systems in total while the details on each language pair differ upon the criteria Beyond a mere numerical comparison of the MT modules and of the language pairs below we provide a more detailed account of the results Per Occupation Group One significant point is the stereotypes projected into the inference process For example in EN-DE mistakes such as she is a game programmer to Sie ist ein professioneller Spieler where ein and professioneller are both in male-gendered were commonly observed in all the translators Also in We found no errors in the pronoun decision in DE/PT For KO-EN and TL-EN the biological gender of the inferred pronouns was checked For EN-DE and EN-PT two bilinguals each at least with ten years of language experience for both languages marked the machine inference Smoothings were applied and BLEU was scored using NLTK library We utilized BERT multilingual specifically bert-base-multilingual-cased rescaled Except for KO in Bing Systems Yandex Bing flaws Accuracy Noun Article GNP Noun Article GNP Noun Article GNP DE PT KO TL DE PT KO TL DE PT KO TL Occupation Sentiment Male Female Total Acc D I BLEU BERTScore Total Auto Per System Table The evaluation result Except for Per System bold are the cases with the highest value For Per System Total Acc disparate impact D I and Total Auto are noted in the order EN-PT some occupations were expressed in inappropriate feminine form as in lenhador lumberjack rather than lenhadora which led to the use of um instead of uma This was also the case for aviador soldado and monge airman soldier monk which should be aviadora soldada and monja The opposite case includes uma babysitter for men In Type to EN where the errors rarely came up except for KO-EN Bing the bias was not manifested much In Yandex the only mistake found in TL-EN was the projection of male pronoun for guro sa elementary a elementary school teacher and no bias was shown in the content words in KO Exceptionally as for KO-EN in Bing the pronouns were guessed almost randomly especially for the female cases The wrong answers include 경찰 cop 경비원 guard 잠수부 diver 배관공 plumber and some occupation group regarding programmer and developer which are common gender stereotypical roles We assume this phenomenon originated from the flaws in training KO-EN eg wrong alignment of the tokens which resulted in the nose-dive of the total accuracy of the translator Per Sentiment Class The proportion of errors in sentiment words was in general as well more significant in Type languages than Type Especially in EN-DE for example a villain turned into ein Bösewicht for both genders in all the modules and several more similar cases occurred Also in EN-DE/PT overall it was exhibited that the errors mostly occurred in negative words incorrectly inferring the woman as male Besides the wrong coreferences these results lower the disparate impact in general as a consequence of the findings in Cho et al related to the bias regarding the gender appearance in the training corpus On the other hand we had no error regarding sentiment for KO/TL-EN in Yandex and flaws As stated above the unexpected results came out with Bing specifically for KO-EN Although we experienced a malfunction the tendency thereof was very helpful for the analysis regarding sentiment It is straightforward that certain gender-stereotypical The insufficient translation fluency in Tagalog and Korean shown is mostly due to the absence of third-person singular pronouns in the output not the incorrect inferences Languages DE PT KO TL Unbiasedness D I BLEU BERTScore Table Aggregation of all the results of MT systems with respect to the languages Unbiasedness denotes the total accuracy of the gender-related inferences items such as 약삭빨라 weak 허약해 fragile or 귀여워 cute are likely to be correctly referred to as female and that others such as 논리적이야 logical 용감해 brave 유치해 childish or 적극적이야 active are wrongly guessed as male These wrong coreferences not only lessens the quality of the translation but also reveals the social bias within the trained system In addition though the incorrectness in KO-EN or TL-EN seems more superficial than in those of EN-DE/PT we deemed that the severity of the potential offense caused by the inaccuracy should not be underestimated for its simplicity Fluency and Biasedness Beyond the numerics we noted the relation between the translation fluency and the shown biasedness At first we suspected that the low translation fluency which might be intertwined with the poverty of resources would bring increased gender bias as a result However the high performance of translation fluency does not guarantee the same in bias issue Comparing translation fluency and disparate impact within DE vs PT and between DE PT vs KO TL language types Table we learned that the MT systems with high translation fluency for some languages might also acquire the gender stereotypes on occupation or sentiment words which is visible from the contrast of unbiasedness factors and fluency scores More on the fluency measures we focused on the contrast of BLEU and BERTScore which shows an inversed tendency overall The original meaning is more close to clever and weak is a mistranslation but we leave it to the measurement of fluency and bypass these errors to focus more on the failure of gender coreference Table It is also observed that BERTScore corresponds with the two gender bias measures unlike BLEU that mainly concerns the token overlap of the prediction and the gold standard This suggests that BERTScore can catch the gender-related aspects of the translation that BLEU might not get though some kind of syntactic similarity can be overlooked Low-resourcedness We took a further step to integrate the issue of semantic faithfulness of translation with the low-resourcedness In general the languages with more resources recorded better fluency index in to-English translation Though indirectly it can be a clue for a guess that large-scale resources boost the translation fluency but might make the system more biased The analyses above bases on the observation of the public MT models thus it is inevitable to face a missing link between the genuine training resource and the shown biasedness It is probable that for some language pairs a data-efficient approach is working while not for the others Though we contrasted two factors unbiasedness and fluency in terms of language resource the direct connection is not guaranteed Without a doubt this might be well displayed if we train our own MT model with controlled resources and then compare the result as clearly as possible However it is unfortunate that the systems we train do not necessarily reflect the systems the MT users currently encounter Moreover such information on training resources is usually not provided by the service maintainers making the in-depth survey more challenging In this regard here we adhere to our original hypothesis that grounds on the survey over language resources albeit the gap should be filled by further investigation Discussion Upon the results we hesitantly argue that the supplement of training resources may not be a solution for the mitigation of gender bias but instead can be a trigger of the amplification Although our observation cannot touch the core part of the training the discussion is an extension of inductive bias in machine learning Thus further regularization is required to alleviate the bias apart from collecting data and updating the performance One of such can be the detection of gender-specified or gender-neutral context and modifying the related terms as done in the recent approach of Google Translation In training-centered viewpoint Saunders and Byrne suggested a domain adaptation for the mitigation by making up a small handcrafted set with a template The PROFESSION finished hisher work which gives the MT model a corresponding regularization in an additional training phase The above works are concurrent with our approach and we expect to extend our work especially regarding language diversity and non-profession-related expressions to real-world training Notwithstanding such achievements we raise two more issues here English-centeredness and ethics Multilingualism Despite the limitations that the languages investigated here do not and cannot fully represent the diverse human Although the information on public data Table has no direct link to the training procedure of the online MT systems we hesitantly claim that the high translation fluency is partly supported by the amount of available MT resources languages we believe that the direction of our research is to be beneficial for multilingual extension and generalization of the studies on translation gender bias Though it is inevitably true that translation is a multilingual process a large portion of the literature concentrated on measuring the bias in English either as the source or the target Here we attempted to shed more light on various properties of the languages on the other side including morphosyntax GNPs low-resourcedness and evaluation methodology Nonetheless we guess that the future research should incorporate the procedure of direct non-English-to-non-English translation eg KO-DE since the aspect of gender bias projected within would not be fully covered by the schemes proposed in this work and the previous studies Ethics One may concern that there is no explicit discussion on ethics in this paper either politically or philosophically However in the theoretical and sociolinguistic view the struggle for deriving balancedness out of a biased system or data is itself a pursuit of ethical standards Referring again to Friedman and Nissenbaum and Binns our approach is related to egalitarianism against data-driven biases mainly regarding the areas of gender and multilingualism For instance our result was designed to imply the positive correlation between system performance and bias not merely to evaluate the translation fluency We further attempted to demonstrate that the systems trained with low-resourced languages generally have less gender bias-related errors compared to those of high-resourced ones We want to emphasize that we concentrated on the empirical perspective of fairness and transparency although the underlying philosophy is obviously desired for a theoretical grounding eg discrimination egalitarianism and justice We aimed to evoke both bias and cross-lingual issues by making up less controversial datasets templates and evaluation schemes CONCLUSION In this paper we argued for the stringent necessity of a cross-lingual and sociolinguistic approach to measuring the gender bias in an inherently multilingual process machine translation Building on an equity evaluation corpus that incorporates inter-culturally present occupation and sentiment words we chose the language pairs that highlight the various aspects of bias in gender-neutral pronouns agreement of articles and gendered noun derivation The measurements including the accuracy in gender-specific terms and the lexical-semantic similarity were applied to three widely-used open-source MT modules We observed that there exists a trade-off between the amount of bias and translation fluency The lower inference accuracy in the high-resource languages implicitly suggests the irony that the language resources could have provided the gender stereotype to the model being trained thus calling for the algorithmic mitigation process to prevent possible errors that may offend anonymous users To figure out the transparent cause and effect of bias we could have built our model and found out factors However since such systems may not necessarily be used as a product it would be challenging to estimate their influence on society It would also be more meaningful to assess the bias within the publicly accessible models and in high demand which are more likely to propagate and even amplify bias to NLP applications if adopted without inspection As future work we plan to explore different aspects of gender bias manifestation eg gender agreement of other parts of speech and other combinations of language pairs not necessarily involving EN and to parlay our research into laying the foundation for an easily downloadable and deployable gender bias evaluation toolkit All the templates and gold standard used in this research are to be released to the public and will be available for the service providers that deal with the gender-related errors of MT systems
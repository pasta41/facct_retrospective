From Optimizing Engagement to Measuring Value Most recommendation engines today are based on predicting user engagement eg predicting whether a user will click on an item or not However there is potentially a large gap between engagement signals and a desired notion of value that is worth optimizing for We use the framework of measurement theory to a confront the designer with a normative question about what the designer values b provide a general latent variable model approach that can be used to operationalize the target construct and directly optimize for it and c guide the designer in evaluating and revising their operationalization We implement our approach on the Twitter platform on millions of users In line with established approaches to assessing the validity of measurements we perform a qualitative evaluation of how well our model captures a desired notion of value INTRODUCTION Most recommendation engines today are based on predicting user engagement eg predicting whether a user will click an item or not However there is potentially a large gap between engagement signals and a desired notion of value that is worth optimizing for Just because a user engages with an item doesnt mean they value it A user might reply to an item because they are angry about it or click an item in order to gain more information about it or watch addictive videos out of temptation It is clear that engagements provide some signal for value but are not equivalent to it Further different types of engagement may provide differing levels of evidence for value For example if a user explicitly likes an item we are more likely to believe that they value it compared to if they had merely clicked on it Ideally we want the objective for our recommender system to take engagement signals into account but only insofar as they relate to a desired notion of value However directly specifying such an objective is a non-trivial problem Exactly how much should we rely on likes versus clicks versus shares and so on How do we evaluate whether our designed objective captures our intended notion of value Our contributions We make three primary contributions We propose measurement theory as a principled approach to aggregating engagement signals into an objective function that captures a desired notion of value The resulting objective function can be optimized from data serving as a plug-in replacement for the ad-hoc objectives typically used in engagement optimization frameworks Our approach is based on the creation of a latent variable model that relates value to various observed engagement signals We devise a new identification strategy for the latent variable model tailored to the intended use case of online recommendation systems Our identification strategy needs only a single robust engagement signal for which we know the conditional probability of value given the signal We implemented our approach on the Twitter platform on millions of users In line with an established validity framework for measurement theory we conduct a qualitative analysis of how well our model captures value Measurement theory and latent variable models The framework of measurement theory is widely used in the social sciences as a guide to measuring unobservable theoretical constructs like quality of life political ideology or socio-economic status Under the measurement approach theoretical constructs are operationalized as latent variables which are related to observable data through a latent variable model LVM Similarly we treat the value of a recommendation as a theoretical construct which we operationalize as a binary latent variable We represent the LVM as a a Bayesian network that contains as well as each of the possible types of user engagements clicks shares etc The structure of the Bayesian network allows us to specify conditional independences between variables enabling us to capture dependencies like eg needing to click an item before replying to it Under the measurement approach the ideal objective becomes clear Behaviors the probability the user values the item given their engagements with it Such an objective uses all engagement signals but only insofar provide evidence of Value If we can identify Behaviors then it can be used as a drop-in replacement for any objective that scores items based on engagement signals Our key insight is that we can identify Behaviors the probability of Value given all behaviors through the use of a single anchor variable for which we know The anchor variable together with the structure of the Bayesian network is what gives value its meaning Through the choice of the anchor variable and the structure of the Bayesian network the designer has the flexibility to give value subtly different meanings Recommendation engines have natural candidates for anchor variables strong explicit feedback from the user For example strong negative feedback could include downvoting or reporting a content item or blocking another user Strong positive feedback could be explicitly liking or upvoting an item For negative feedback we make the assumption that for while for positive feedback we make the assumption that A case study on the Twitter platform We implemented our approach on the Twitter platform on millions of users On Twitter there are numerous user behaviors clicks favorites retweets replies and many more It would be difficult to directly specify an objective that properly trades-off all these behaviors Instead we identify a natural anchor variable On Twitter users can give explicit feedback on tweets by clicking See less often SLO on them We use SLO as our anchor and assume that the user does not value tweets they click See less often on After specifying the anchor variable and the Bayesian network we are able to learn Behaviors from data The model automatically learns a natural ordering of which behaviors should provide stronger evidence for Value eg Retweet Reply Click Furthermore it learns complex inferences about the evidence provided by combinations of behavior Such inferences would not be possible under the standard approach which uses a linear combination of behaviors as the objective Unlike other work on recommender systems we do not evaluate through engagement metrics If we believe that engagement is not the same as the construct value then we cannot evaluate our approach merely by reporting engagement numbers Instead we must take a more holistic approach We discuss established approaches to assessing the validity of a measurement and explain how they translate to the recommender system setting by using Twitter as an example RELATEDWORK In the social sciences especially in psychology education and political science measurement theory has long been used to operationalize constructs like personality intelligence political ideology etc Often the operationalization of such constructs is heavily contested and many types of evidence for validity and reliability are used to evaluate the match between a construct and its operationalization Recently Jacobs and Wallach introduced the language of measurement in the context of computer science They argue that many harms effected by computational systems are the direct result of a mis-match between a theoretical construct and its operationalization In the context of recommender systems many have argued that the engagement metrics used in practice are a poor operationalization of value We use measurement theory as a principled way to disentangle latent value from observed engagement We provide a general latent variable model approach in which an anchor variable provides the key link between the latent variable and the observed behaviors The term anchor variable has been used been used in various ways in prior work on factor models our usage is most similar to Our use of the anchor variable is also similar to the use of a proxy variable to identify causal effects under unobserved confounding IDENTIFICATION OF THE LVM WITH ANCHOR We now describe our general approach to operationalizing a target construct through a latent variable model LVM with an anchor variable We operationalize the construct for value through a LVM in which the construct is represented through an unobserved binary latent variable that the other binary observed behaviors provide evidence for We assume there is one observed behavior an anchor variable which we know for We represent all other observed behaviors in the binary random vector B We refer to as an anchor variable because it will provide the crucial link to identifying In other words it will anchor the other observed behaviors B to Value We represent the LVM as a Bayesian network A Bayesian network is a directed acyclic graph DAG that graphically encodes a factorization of the joint distribution of the variables in the network In particular the DAG encodes all conditional independences among the nodes through the ùëë-separation rule This is important because in most real-world settings the observed behaviors have complex dependencies among each other eg one may need to click on an item before replying to it Through our choice of the DAG we can model both the dependencies among the observed behaviors as well as the dependence of the unobserved variable on the observed behaviors Our goal is to determine so that it can later be used downstream as a target for optimization We now discuss sufficient conditions for identifying the conditional distribution There are three assumptions on the anchor variable that we will consider in turn Notation We use to denote the parents of a node and use to denote all parents of except for Assumption Value-sensitive For every realization of the random vector B we have that B B Assumption simply means that the anchor carries signal about Value regardless of what the other variables B are Assumption No children The anchor variable has no children Since the anchor is chosen to be a strong type of explicit feedback it is usually the last type of behavior the user engages in on a content item eg a report button that removes the content When combined with Assumption Assumption simplifies to the condition for every realization of the parents of excluding from the users timeline and thus it typically makes sense to model as having no children Assumption One-sided conditional independence Let be all parents of excluding Value is independent from given that Assumption means that when the user has opted to give feedback the level of information that feedback contains about value V does not depend on the other parents The assumption rests on the fact that is a strong type of feedback that the user only provides when they are confident of their assessment Conditions for identification The next theorem establishes that under A the distribution of observable behaviors and the conditional distribution B are sufficient for identifying the conditional distribution The proof uses a matrix adjustment method Rothman et al pg and is very similar to that in Pearl Kuroki and Pearl Theorem Let and be binary random variables and let B be a binary random vector If A holds then the distributions and B uniquely identify the conditional distribution Proof Since the conditional distribution is equal to we can reduce the problem to determining the distribution We can relate to the given distributions and via the law of total probability For every realization of the random vector B we can write Equation as where the matrix and the vectors are defined as B for PB PB PB PB Determining the distribution is equivalent to determining for all By Assumption for all we have which implies that the determinant of the matrix is non-zero Therefore for all the vector is equal to Thus and therefore the conditional distribution is identified by the given distributions If we add Assumption ie the anchor has no children then the distributions and are sufficient to identify Corollary If the joint distribution is Markov with respect to a DAG in which A and A hold then the distributions A distribution is said to be Markov with respect to a DAG if it factorizes according to ie and uniquely identify the conditional distribution Proof In a Bayesian network the Markov blanket for a variable is the set of variables Z that shield from all other variables Z in the DAG ie Z The Markov blanket for a variable consists of its parents children and parents of its children Since the anchor has no children B Thus by Theorem and identify the conditional distribution Finally when we add Assumption one-sided conditional independence then the distributions and are sufficient The proof follows from Corollary because under Assumption the distributions and identify Corollary If the joint distribution is Markov with respect to a DAG in which hold then and uniquely identify the conditional distribution Proof We will show that under Assumption the distributions and identify The proof then follows from Corollary We show that we can identify by solving a set of linear equations For short-hand let For any realization by marginalizing over and we can derive the following four equations for the four unknown probabilities Note that the of Equations and are given by and the of Equations and are given by the prior and From Assumption one-sided conditional independence we know that Under one-sided conditional independence the probability is determined by the given distributions Since is determined by the given distributions so are and which can be solved for through Equations Since this holds for any realization the distribution is determined which by Corollary means that the conditional distribution is determined Specifying the distributions for identification Corollary establishes that under Assumptions the distributions and are sufficient to determine the conditional distribution for the LVM Where do we get these distributions The distribution of observable nodes is estimated by the empirical distribution of observed data The distribution over the latent variable for value is a prior distribution that is specified by the modeler Recall that our goal with the LVM is to use B as an objective to optimize Since the prior only has a scaling effect on B it does not matter greatly We set to be uniform ie The conditional probability is specified by our assumption on the the anchor variable The probability is set to where if is explicit negative feedback or to is explicit positive feedback That leaves the distribution We estimate heuristically using two sources of historical data that vary in their distribution of Value Suppose we have access to a dataset of historical recommendations that were sent to users at random as well as a dataset of historical recommendations that were algorithmically chosen Both kinds of datasets are commonly available on recommender systems due to the prevalence of A/B testing which typically tests new algorithmic changes against a randomized baseline The randomized and algorithmic datasets will have different distributions of valuable content and and different distributions of observed behavior and However we assume that the probability of the observed behavior given Value is the same between the two datasets The following equations then hold We specify and in an application-dependent way but generally we assume the randomized dataset is lower value than the algorithmic one Once we specify and and estimate and empirically then we can solve Equations and to estimate This is a heuristic approach that is appropriate for getting a rough estimate but needs to be used with care In practice not all the differences between the randomized and algorithmic dataset can be explained by an intervention on Value For example if the recommendation algorithm has historically been optimized for user clicks then users in the algorithmic dataset may click on items more but for reasons other than increased value If our DAG has value V as a root node and can be interpreted as a causal Bayesian network then this is equivalent to assuming that the difference between the datasets corresponds to an intervention Algorithm for identification We now give more details on how we calculate the joint distribution given the distributions and We use the structure of the Bayesian network to efficiently identify the joint distribution by fitting each factor for every variable The factor for is given by the prior The factor for ie can be identified from and by solving a set of linear equations as in the proof of Corollary The factor for any behavior that does not have as a parent is directly identified by the distribution of observable behaviors The factors for the remaining behaviors which have as a parent are fit through a matrix adjustment method Rothman et al pg In particular note that We can also write the above equation in matrix form Let be all realizations of and define the matrices as Then and Let be the marginalization over Then Thus the factor for is equal to We fit nodes with as a parent in topological order so that we can always calculate the denominator from previously fit factors APPLICATION TO TWITTER We implemented our approach on the Twitter platform on millions of users On Twitter there are many kinds of user behaviors clicks replies favorites retweets etc The typical approach to recommendations would involve optimizing an objective that trades-off these behaviors usually with linear weights However designing an objective is a non-trivial problem How exactly should we weigh favorites compared to clicks or replies or retweets or any of the numerous other behaviors It is difficult to assess whether the weights we chose match the notion of value we intended Furthermore even supposing that we could manually specify the correct weights through laborious trial-and-error the correct weights change over time For example after videos shared on Twitter began to auto-play the signal of whether or not a user Assuming that is a root node which is the case in any network we are interested in If and and conflict then simply set is invertible because of Assumption Open Click SLO Opt-out Engage Figure A workflow of how users can interact with ML-based notifications on Twitter To view the tweet the user can either open the notification from the home screen on their phone or click on it from the notifications tab within the app If the user sees the tweet from their notifications tab they can also click See Less Often on it Once the user has opened or clicked on the notification they can engage with the tweet in many ways eg replying retweeting or favoriting At any point the user can opt-out of notifications all-together Value OpenClick NTab View SLO Opt Out Linger s Linger s Linger s Watch Reply Link Click Quote Figure Bayesian network for Twitter notifications An arrow from a node to a box means that the node is a parent of all the nodes in the box eg Click and Open are parents of Linger s The latent variable Value is a parent of everything except NTabView The measurement node SLO is highlighted in pink watched a video presumably became less relevant The reality is that the objective is never static how users interact with the platform is constantly changing and the objective must change accordingly Our approach provides a principled solution to objective specification We directly operationalize our intended construct value as a latent variable The meaning of Value is defined by the Bayesian network and the anchor variable a behavior that we believe provides strong evidence for value or the lack of it On Twitter the user can provide strong explicit feedback by clicking See less often SLO on a tweet We use SLO as our anchor and assume that if a user clicks See less often on a tweet they do not value it SLO Under this approach there is no need to manually specify how all the behaviors should factor into the objective Having operationalized Value the ideal objective to use is clear B the probability of Value given the observed behaviors As discussed in Section we can directly estimate B from data Furthermore presuming that the anchor and structure of Bayesian network remain stable we can regularly re-estimate the model with new data at any point allowing us to account for change in user behavior on the platform The Bayesian network We applied our approach to ML-driven notifications on Twitter These notifications have various forms eg Users A B C just liked User tweet User A just tweeted after a long time or Users A B C followed User Z Figure shows an example notification and how a user can interact with it The Bayesian network in Figure succinctly encodes the dependencies between different types of interactions users can have with notifications Notifications are sent both to the users home screen on their mobile phone as well as to the notifications tab within the Twitter app The user can start their interaction either by seeing the notification in their notification tab NTabView and then clicking on it Click or by seeing it as a the notification on their phone home screen and opening it from there directly Open After clicking or opening the notification the user can engage in many more interactions they can favorite retweet quote retweet Quote or reply Reply to the tweet if the tweet has a link they can click on it LinkClick if it has a video they can watch it VidWatch In addition other implicit signals are logged whether the amount the user lingered on the tweet exceeds certain thresholds Linger s Linger s Linger s and whether the number of user active minutes spent in the app after clicking/opening the notification exceeds a threshold Furthermore when the user is in the notification tab the user can provide explicit feedback on a particular notification by clicking See Less Often SLO on it Notably unlike other types of behavior the user does not need to actually click or open the notification before clicking SLO However we found empirically that users are more likely to click SLO after clicking or opening the notification probably because they need to gain more information before making an assessment Thus in addition to NTabView we also model Click and Open as parents of SLO Finally at any time the user can opt-out of notifications to their phone home screen OptOut When the user decides to opt-out it is attributed to any ML-based notification saw within a day of choosing to opt-out Since ML-based notifications are relatively rare on Twitter users usually get less than one a day there are usually at most one or two notifications attributed to an opt-out event We model the latent variable as being a parent of all behaviors except NTabView whether or not the user saw the notification in their notifications tab or not Since users may check their notifications tab for many other notifications it is difficult to attribute NTabView to a particular notification and so we consider it to be an exogenous random event Identifying the joint distribution We fit our model on three days of data that contained of all user interactions with ML-based The network can be interpreted as a causal Bayesian network although for our purposes we do not strictly need the causal interpretation push notifications on Twitter In Section we proved that the target objective the conditional distribution B is uniquely identified from PB and see Corollary We set the four distributions as follows We used SLO as our anchor variable and assumed that ie a user never says See less often if they value the notification The prior distribution of value was set to be uniform The distribution of observed behaviors PB was set to the empirical distribution The distribution was estimated as described in Section by using two sources of historical data one in which notifications were sent at random and the other in which notifications were sent according to a recommendation algorithm Evaluation of internal structure Assessing our measure of value for validity will necessarily be an on-going and multi-faceted process We do not as typical of papers on recommendation report engagement metrics The reason is that if we expect our measure of value to differ from engagement we cannot evaluate it by simply reporting engagement metrics The evaluation of a measurement necessitates a more holistic approach In Section we describe the five categories of evidence for validity described by the Standards for educational and psychological testing the handbook considered the gold standard on approaches to testing Here we focus on evaluating what is known as evidence based on internal structure ie whether expected theoretical relationships between the variables in the model hold To justify why the structure of our Bayesian network is necessary we compare our full model from Figure to two other models a naive Bayes model and the full model but without arrows from Open and Click to SLO In Table we show Behavior for all behaviors and models As noted by prior work matrix adjustment methods can result in negative values when conditional independence assumptions are not satisfied To address this we clamp all inferences to the interval We include the table of non-clamped inferences in the appendix Table The first simple theoretical relationship we expect to hold is that compared to observing no user interaction observing any user behavior besides opt-out should increase the probability that the user values the tweet ie Behavior for all Behavior OptOut Furthermore we also expect some behaviors to provide stronger signals of value than others eg that Click The first model is the naive Bayes model which simply assumes that all behaviors are conditionally independent given Value It does extremely poorly almost all inferences have negative values and are clamped to zero indicating that the conditional independence assumptions are unrealistic The second model is the full model except without arrows from Click and Open to SLO It models all pre-requisite relationships between behaviors ie if a behavior is required for another behavior then there is an arrow from to Compared to the naive Bayes model the second model does not make mainly negative-valued inferences indicating that its conditional independence assumptions We assume that the dataset of randomized notifications has a prior probability and the dataset of algorithmically chosen notifications has a prior probability Behavior Behavior Naive Bayes Click Open SLO Full Model OptOut Click Open VidWatch Linger s LinkClick Reply Linger s Linger s Quote Table The inferences made by LVMs with different DAGs For each model and for each behavior we list Behavior how much evidence the model learns that a behavior provides for Value when all other behaviors are marginalized over are more realistic However relative to the prior most behaviors actually reduce the probability of Value rather than increase it After investigation we realized that although users were not technically required to click or open the notification before clicking SLO in practice they were more likely to do so probably because they needed to gain information before making an assessment We found that explicitly modeling the connection ie adding arrows from Click and Open to SLO was critical for making reasonable inferences We believe this takeaway will apply across recommender systems The user never has perfect information and may need to engage with an item before providing explicit feedback It is important to model the relationship between information-gaining behavior and explicit feedback in the Bayesian network Our full model satisfies the theoretical relationships we expect All the behaviors that we expect to increase the probability of Value do indeed do so Furthermore the relative strength of different types of behavior seems reasonable as well eg and are higher than VidWatch and LinkClick The full model also makes more nuanced theoretical inferences Recall that is whether or not the user had high user active minutes after either clicking the notification from notifications tab or by opening the notification from their phone home screen The model learns that is a highly indicative signal after Open but not after Click Open and Click This makes sense because if the user clicks from notifications tab it means they were already in the app and it is difficult to attribute their high to the notification in particular On the other hand if the user enters the app because of the notification it is much more direct of an attribution It is clear that manually specifying the inferences our model makes would be very difficult The advantage of our approach is that after specifying a the anchor variable and b the Bayesian network we can automatically learn these inferences from data Further the model is able to learn complex inferences eg that is more reliable after Open than Click that would be impossible to specify under the typical linear weighting of behaviors ASSESSING VALIDITY Thus far we have described our framework for designing a measure of value which can be used as a principled replacement for the adhoc objectives ordinarily used in engagement optimization How do we evaluate such a measure Notably we do not advocate evaluating the measure purely through engagement metrics If we expect our measure of value to differ from engagement then we cannot evaluate it by simply reporting engagement metrics Instead the assessment of any measure is necessarily an ongoing multi-faceted and interdisciplinary process To complete the presentation of our framework we now discuss approaches to assess the validity of a measurement In the most recent edition of the Standards for educational and psychological testing the handbook considered the gold standard on approaches to testing there are five categories of evidence for validity We visit each in turn and describe how they translate to the recommender system setting using Twitter as an example Evidence based on content refers to whether the content of a measurement is sufficient to fully capture the target construct For example we may question whether a measure of socio-economic status that includes income but does not account for wealth accurately captures the content of the construct In the recommender engine setting content-based evidence asks us to reflect on whether the behaviors available on the platform are sufficient to capture a worthy notion of the construct value For example if the only behavior observed on the platform were clicks by the user then we may be skeptical of any measurement of value derived from user behavior What content-based evidence makes clear is that to measure any worthy notion of value it is essential to design platforms in which users are empowered with richer channels of feedback Otherwise no measurement derived from user behavior will accurately capture the construct Evidence based on cognitive processes Measurements derived from human behavior are often based on implicit assumptions about the cognitive processes subjects engage in Cognitive process evidence refers to evidence about such assumptions often derived from explicit studies with subjects For example consider a reading comprehension test We assume that high-scoring students succeed by using critical reading skills rather than a superficial heuristic like picking the answers with the longest length To gain evidence about whether this assumption holds we might for instance ask students to take the test while verbalizing what they are thinking Similarly in the recommender engine setting we want to verify whether user behaviors occur for the reasons we think they do On Twitter one might think to use Favorite as an anchor for Value assuming that Favorite However users actually favorite items for reasons that may not reflect value like to bookmark a tweet or to stop a conversation Cognitive process evidence highlights the importance of user research in assessing the validity of any measure of value Evidence based on internal structure refers to whether the observations the measurement is derived from conform to expected theoretical relationships For example for a test with questions which we expect to be of increasing difficulty we would assess whether students actually perform worse on later questions compared to earlier ones In the recommender system context we may have expectations on which types of user behaviors should provide stronger signal for value In Section we evaluated internal structure by comparing Behavior for all behaviors Evidence based on relations with other variables is concerned with the relationships between the measurement and other variables that are external to the measurement The external variables could be variables which the measurement is expected to be similar to or predict as well as variables which the measurement is expected to differ from For example a new measure of depression should correlate with other existing measures of depression but correlate less with measures of other disorders In the recommender system context we might look at whether our derived measurement of value is predictive of answers that users give in explicit surveys about content they value We could also verify that our measure of value does not differ based on protected attributes like the sex or race of the author of the content Evidence based on consequences Finally the consequences of a measurement cannot be separated from its validity Consider a test to measure student mathematical ability The test is used to sort students into beginner or advanced classes with the hypothesis that all students will do better after sorted into their appropriate class If it turns out that students sorted by the test do not perform better that may give us reason to reassess the original test In the recommender system context if we find that after using our measurement of value to optimize recommendations more users complain or quit the platform then we would have reason to revise our measurement SUMMARY We have presented a framework for designing an objective function that captures a desired notion of value In line with the principles of measurement theory we treat value as a theoretical construct which must be operationalized Our framework allows the designer to operationalize value in a principled manner by specifying only an anchor variable and the structure of the Bayesian network Through these two choices the designer has the flexibility to give value subtly different meanings We applied our approach on the Twitter platform on millions of users We do not as typical of papers on recommendation report engagement metrics The reason is that if we expect our measure of value to differ from engagement we cannot evaluate it simply by reporting engagement metrics Instead we discussed established ways to assess the validity of a measurement and how they translate to the recommendation system setting For the scope of this work we focused on assessing evidence based on internal structure and found that our measure of value satisfied many desired theoretical relationships
You Cant Sit With Us Exclusionary Pedagogy in AI Ethics Given a growing concern about the lack of ethical consideration in the Artificial Intelligence AI field many have begun to question how dominant approaches to the disciplinary education of computer science  and its implications for AI has led to the current ethics crisis However we claim that the current AI ethics education space relies on a form of exclusionary pedagogy where ethics is distilled for computational approaches but there is no deeper epistemological engagement with other ways of knowing that would benefit ethical thinking or an acknowledgement of the limitations of uni-vocal computational thinking This results in indifference devaluation and a lack of mutual support between  and humanistic social science HSS elevating the myth of technologists as ethical unicorns that can do it all though their disciplinary tools are ultimately limited Through an analysis of computer science education literature and a review of college-level course syllabi in AI ethics we discuss the limitations of the epistemological assumptions and hierarchies of knowledge which dictate current attempts at including ethics education in  training and explore evidence for the practical mechanisms through which this exclusion occurs We then propose a shift towards a substantively collaborative holistic and ethically generative pedagogy in AI education INTRODUCTION Over the last few years alongside the rise of public scrutiny of the role of artificial intelligence AI in reifying and amplifying social inequalities machine learning educators have begun to acknowledge the necessity of an ethics curricula in computer science programs Khari Johnson of VentureBeat called it a fight for the soul of machine learning From the ACM ethics charter to the call to add ethics to  curricula there has been an ongoing call to make engineers ethical However there have also been noted observations of the failure of the approach of inserting ethics education into  curriculum either referenced throughout or in a standalone course as a limited intervention for improving the outcomes of the discipline Although an important step towards informing more socially conscious system builders it is becoming clear that proposals anchored to developing individual morality and understanding falls short of resulting in any noticeable changes to the way in which students conduct research and develop applications for deployment once they leave the classroom This is made even more evident by the consistency with which such crises continue to occur Incidents of algorithmic misuse unethical deployments or harmful bias cannot be addressed by developing moral integrity at an individual level We argue that this is because the individual scope of current educational approaches neglects the fact that the current issues are more likely the result of collective failure and more institutionalized practices accepted within the field of computer science rather than moments of individual judgement In fact such challenges are inherently interdisciplinary requiring the cooperation of stakeholders of varying expertise in business law and other domains in order to meaningfully address in the real world If anything to rush  students through heavily condensed and simplified overviews of broad ethical understanding and then position them to be the primary arbiter of change confuses the situation This promotes the engineers natural inclination towards seeing themselves as a solitary saviour to the detriment of the quality of the solution and in spite of the need for other disciplinary perspectives Therefore in order to address the social impact of technical systems including AI we need to revisit the way we think about the norms of AI ethics education and in particular address the tendency towards an exclusionary pedagogy that further siloes  perspectives to challenges from the necessary consideration of other approaches This is a required first step towards the genuine interdisciplinary collaboration necessary to meaningfully address the ethical issues that continue to arise The way in which we teach AI ethics informs the way in which practitioners are trained and reflects academic practice Rather than exploring strategies to retrain AI scholars or practitioners exposing them to a sprinkle of ethics and social science and centering interventions on how to incorporate social considerations into technical expertise we instead discuss the need to think more deeply about what it would mean to reset the pedagogy and practices of the field to shift away from this exclusionary default Through a systematic analysis of over AI ethics syllabi we map the current situation and characterize some suggestions for an educational reset towards a more collaborative pedagogy with hopefully more direct consequences on improving both industry practice and academic norms HOW COMPUTER SCIENCE PEDAGOGY LED US TO THE ETHICS CRISIS We first examine the literature on how the culture of computer science has led to the current state of ethics discussions in the field focusing specifically on computer science education research epistemological analyses of computer science and empirical studies of computer science classrooms and cultures We then discuss current issues in tech ethics primarily its insular focus on techno-solutionism that continues to prioritize computer science expertise and center the system itself in ethical fixes as well as a promotion of the ideal of ethical unicorns or tech saviours ie technologists with shallow socio-technical understanding intent on playing the primary role in delivering complete solutions Historical Retrospective on  Education Norms In starting with computer science as a discipline broadly there is a heavy focus on what Eden identifies as three paradigms technocratic rationalist and scientific At its simplest the technocratic paradigm might be described as an engineering or programmatic approach which centers the skills to build computer programs the rationalist paradigm might be described as a mathematically theoretical approach focusing more heavily on a priori knowledge about the underlying mathematical reality of computer systems and the scientific paradigm might be best characterized by its focus on empiricism seeking to more deeply understand the behaviors of computer programs These three paradigms shape how computer science operates through enculturation in computer science education and in industry cultures at both the level of attitudes and values and at the level of behaviors and practices While there are often debates on the education of computer scientists particularly between rationalist and technocratic approaches if distilled to its most basic form each paradigm centers what is often considered a technical expertise that is an expertise rooted in mathematics logic and programming The valuing of the technical is evident in current research on computer science education In a survey of introductory computing education literature Pears et al found that computing textbooks most often focused on the correctness of syntactic structure limiting what Turkle and Papert define as the epistemological pluralism necessary for computer scientists Turkle and Papert discuss the need to allow students as part of their education in computer science to acknowledge the possibility of interpretation collaboration and argument as part of the practical programming experience by engaging in group-based technical project assignments In an analysis of computer science degree requirements at thirty-one universities in the US Surakka showcased the heavily mathematical and programmatic emphasis on computer science teaching in fact the most human-centered specialization usability was also the least offered course as part of the analyzed degree requirements While the lack of human-centered or ethics subject matter may have changed since these studies this snapshot in time before a more recent push for ethics education in computer science highlights a longstanding disciplinary norm learning computer science has traditionally emphasized mathematical theory and engineering practices A focus on programming intelligence is a well-researched cause of the high dropout rates of computer science undergraduate programs Computer science is what Clark labels a hard-applied discipline Those who approach computer science problems differently are pushed out of the field resulting in more homogeneous mindsets and practices within the discipline and unsurprising diversity deficits An imbalance between the technical and the social the hard and the soft which prioritizes the former has not gone unnoticed by other scholars In an ethnographic study of machine learning practitioners in industry Forsythe witnessed the valuing of computer science skills the devaluing of user needs and the belittling of womens work commonly characterized as social and soft She posited that social science perspectives would improve AI by acting as a counter weight to address what she called an epistemological imbalance though this was a view that AI researchers actively resisted at the time Later on Wagstaff wrote that machine learning researchers in their lack of training in understanding social contexts often fail to create models that have real world applicability or merit among many suggestions to remedy this failure Wagstaff suggests the improved interaction and involvement with the outside world when creating models In a scathing analysis of the technocratic dominance in computer science education Washington wrote With no formal courses that focus on the non-technical issues affecting marginalized groups and how to address and eradicate them students are indirectly taught that the current status quo in computing departments and industry is not only acceptable but also unproblematic Tomayko equally laments that computer science education is a story of academics struggling to fulfill industry needs with almost no support from computer science curriculum designers It is a story of industry finally winning over some of academia to teach software engineering rather than vanilla computer science In other words he paints computer science education as a funnel from classroom to tech company with little space for nuanced reflection on its foundational norms and objectives Since early on in the development in the field several scholars have sounded the alarm of a need for reflection on social responsibility and meaningful interaction with other disciplines in order to make computer systems meaningful and beneficial to society However for decades those pleas have been largely downplayed or ignored with one-time ethics modules or courses being rarely considered a primary focus for many students and even well intentioned attempts at integrating ethics considerations throughout  curriculum encountering challenges with contradicting the taught paradigms of the discipline Current approaches to ethics education appear to also burden individual faculty with the responsibility of implementing course design from scratch even when the computer science instructors often assigned to develop these courses feel unqualified due to the limited nature of their own training Fiesler et al further notes that after a survey of AI ethics curricula it is clear that the majority of ethics courses are being taught from within the discipline from computer scientists to computer scientists A discipline which has otherwise been criticized for its lack of ethical engagement is now taking up the mantle of instilling ethical wisdom to its next generation of students Attitudes values practices and norms all shaped by the epistemological approaches of a discipline help to explain how problems are being defined and approached and what answers are viewed as appropriate to those problems Certain characteristics of the pedagogical norms of computer science become limiting for the disciplines ability to address its own ethical challenges As Clarke formulates in while understanding disciplines is much more difficult and complex than ideal characterizations it is a useful endeavor in understanding what has led to the formulation of a technocratic locus in machine learning ethics despite the need for ethics stemming from the failure of this technocratic tendency in the first place Like Eden one might argue that the technocratic paradigm has dominated computer science specifically AI due to industry and monetary incentives driving programmatic approaches where any problem is best addressed by technologists including the problems they create More specifically Agre famously characterized the nature of the conception of reality in AI which posits better systems and better models as the only means of critiquing AIas problematic in its ignorance and dismissal of sociological or critical theory Therefore although  and specifically AI systems are fundamentally malleable and interpretable computer science as a discipline remains anchored to prioritize a positivist framework for their analysis of these systems Although students are often taught the importance of computational thinking for problem solving they are rarely exposed to what such thinking can take away from ones ability to appropriately analyze less familiar challenges such as this ethics crisis There are insights that one gains from a computational lens and also insights lost Being anchored to one perspective for so long as a discipline is a limiting factor and the historical lack of social science training in computer science has given rise to computer science researchers teachers and industry practitioners well-versed in techno-solutionist methodologies but not social realities leading to systems that are often inadvertently inaccessible opaque unethical and harmful Engineering Responsibility The Individual Technologist The notion of engineering responsibility is not new this is Theodore Coopers miscalculations precipitating the collapse of the Quebec bridge General Motors causing thousands of avoidable deaths after neglecting to address the uncontrollable steering of its Chevrolet Corvair situations in which the harm caused is in direct consequence of a careless neglect of the details of the engineering process itself These are the completely avoidable situations evidence of not understanding the weight of the contribution the impact and influence of the outcomes and thus the need to approach things with caution Focus on this topic of due diligence in the development of robust systems and instilling a sense of increased responsibility is fairly common often being heavily featured in AI ethics education and professional ethics codes However the reality is that engineers are often absent or excluded from decisions that lead to harm These decisions can often be attributed to sales people executes marketing and other stakeholders in a corporation at times without even informing the technologist of the broader context of what theyre working on Similarly problematic unethical research practices in the field are mostly enabled by a set of entrenched norms and operational structures of everything from funding to the review process and publication Deployed  systems are not just artifacts by themselves but a component of a complete sociotechnical system The challenge is thus not necessarily to perfect the technical artifact but to investigate and implement approaches to increase the participation of and communication to other stakeholders from users to affected populations to other key decision-makers in the company to other experts studying the problem from the lens of wildly different disciplines A step towards more inclusive design is thus less about a single engineers efforts push to enforce their understanding of diverse representation into the worldview of the model and more about a form of participatory design where these other stakeholders are actively and humbly welcomed to join the engineer in the creation of more just and equitable AI systems Although blamed by the Royal Commission for the bridges collapse an organizational review reveals that Theodore Cooper and other blamed engineers were simply victims of confusing and ill formed contractual obligations As with most modern disasters including those in  and AI there is an underlying tension between individual agency and bureaucratic control with actual responsibility lying somewhere in between We argue that quick ethics fixes like ethics modules largely developed for and within computer science are not a sufficient intervention to actually teach  students of how ethical challenges get resolved in real world contexts In actuality an ethical challenge would not get resolved by an individual or even a group of technologists but will require an inherently interdisciplinary effort Furthermore this solutionist attitude of quick fixes in  de facto displaces the knowledge of other qualitative oriented educators and researchers The result is not only a feedback loop within computer science but a continuing aggregation of disciplinary privilege that seeks to make computer scientists claim both technical and social expertises the latter of which they do not actually have in depth The Myth of the Ethical Unicorn The rise in training computer scientists to be ethics experts accompanies a long degradation of enrollment opportunity and funding of social sciences and humanities In research focuses on fairness and justice qualitative methods and broader impacts are often regarded at least in the fleeting discourse of the social media public square like Twitter and Reddit as not real machine learning The underrepresentation of liberal arts backgrounds and fairness research in the technology sector intersects with diversity disparities in computing generally and AI specifically given that women BIPOC and queer scholars come from more diverse non-computer science backgrounds and contribute more research on identity-based fairness issues in technology Given the privileged position of computer science there is at times a tendency for the discipline to ascribe to itself a certain self-importance falling into an assumed role as the expected saviour in resolving any presented crisis If the engineer as saviour is one of the last contemporary manifestations of symbolic self-worth and self understanding in computer science we could identify at least two general attitudes which shaped the engineering professions in the last century The first is the attitude of the paternal power of the engineer which is defined by a claim to exert total technical competency doubled by a position of exhaustive moral authority grounded in social status or in a specially acquired wisdom The second is the figure of the engineer expert who claims total mastery over technical knowledge of their field of competency and contrary to the paternal attitude does not claim moral superiority or any special access to wisdom but may dismiss any responsibility requiring engagement with topics outside their defined realm of expertise The new figure of the socio-technical expert able to exhaustively solve the most intractable societal problems is a recent development In fact this new rhetorical figure is another manifestation of the pioneer technologist able to break boundaries and successfully overcome any imaginable challenge while heroically gracing humanity with the fruit of their works This endeavor results in the unreasonable expectation of creating Ethics Unicorns full stack developers with a sprinkle of social awareness on top Of course this isnt as simplistic as a displacement of liberal arts by computer science there is also a level of responsibility liberal arts has in its disciplinary philosophies As danah boyd a principal researcher at Microsoft wrote of social science Academic disciplines are brutally myopic judgmental of anyone who chooses to explore a path of inquiry outside of the acceptable boundaries of the field Extending training beyond traditional social science modes of inquiry into computing has also been largely missing from liberal arts disciplines Instead students must meander into computer science classes or rarer interdisciplinary ones like newer offerings of computational social science and digital humanities However we have chosen to focus specifically on computer science and AI due to its emergent and out-sized power computer scientists and machine learning engineers are having real world impact socially politically and economically In the A paternalistic attitude in engineering assumes that it is morally permissible for one rational person without the others informed consent to decide significant aspects of the others life because she believes herself at least as able to judge such things as the other is p This type of paternalistic attitude of an engineer has one of its first historical formulations in John Lockes account of paternal power The power then that parents have over their children arises from that duty which is incumbent on them to take care of their off-spring during the imperfect state of childhood To inform the mind and govern the actions of their yet ignorant nonage till reason shall take its place and ease them of that trouble is what the children want and the parents are bound to p Engineers shall perform services only in the areas of their competence Engineers when serving as expert or technical witnesses before any court commission or other tribunal shall express an engineering opinion only when it is founded upon adequate knowledge of the facts in issue upon a background of technical competence in the subject matter and upon honest conviction of the accuracy and propriety of their testimony from American Accreditation Board for Engineering and Technology ABET Code Of Ethics Of Engineers The Fundamental Principles p context of addressing the challenges of managing this tangible and widespread influence there will need to be an expansion and fundamental re-definition of not only what it means to do computer science but also a mandate to include varying disciplinary interactions as collaborators in getting to meaningful interventions At present it is the computer scientists that have the most leverage to take the action necessary to make this change MECHANISMS OF EXCLUSION FINDINGS EVIDENCE The way in which exclusion is operationalized within communities is the result of a series of specific mechanisms of exclusion that is to say methods through which AI developers and computer scientists more broadly remove themselves from related disciplines as they theorize and operationalize approaches to develop new models Computer science  and humanistic social science HSS exclude each other through specific accepted attitudes and norms as well as practices After qualitatively analyzing a survey of AI ethics courses from universities explicitly marked as undergraduate courses and marked as explicitly graduate courses we were able to identify the following evidence for mechanisms of exclusion in AI ethics education We note that of the analyzed courses we were only able to review the full syllabus for courses as courses did not have syllabi freely available online and of the examined syllabi were not in English so not possible for the authors to review The syllabi from academic institutions represented the lesson plans and readings for undergraduate courses and graduate courses The most well represented department in our survey sample by far is Computer Science representing over of analyzed courses see Table We also include courses taught in related STEM fields such as Mathematics and Engineering Altogether these STEM departments host about of the surveyed AI ethics courses The HSS departments best represented in this survey are Information or Library Sciences Philosophy and Communications We also include related HSS departments like Media Studies Science Technology and Society STS and professional departments like Law and Business Courses in these dominant HSS-skewed departments make up about of the surveyed dataset An additional of the courses are located in miscellaneous Other departments ie History Governance and Policy Journalism Medicine or other sciences English Film Urban studies Design Sociology Only of the surveyed AI ethics courses were developed for explicitly interdisciplinary departments From our analysis we identified that exclusion manifests in mainly in the following ways methodological dogmatism a lack of collaborative and interdisciplinary outputs and siloed citations Methodological Dogmatism Methodological dogmatism is to say that the disciplines dont value each other and more specifically do not value their respective processes for arriving at an accepted conclusion or truth Different disciplinary approaches to the topic of ethical considerations in AI Details of our analysis can be found here We thank Casey Fiesler for her efforts in crowd-sourcing the resource we used as the basis of our analysis Table Overall AI Ethics Courses Analyzed by Department Discipline Number of Courses Computer Science Information or Library Sciences Philosophy Engineering Communications Law Mathematics Media Studies Other Business STS Interdisciplinary are often in contempt of each other and unappreciative of the norms and methodologies used by another group As a result a dismissal on both sides ensues It is rare to see any shared methodology or a mixed method approach involving more than one disciplinary lens For instance quantitative methods can be looked down upon by those coming from a more holistic approach it is taught in some HSS courses that quantitative interventions are insufficient to address certain harms mainly because to arrive at such an intervention requires an uncomfortable amount of abstraction which removes the true complexity of the situation On the other hand several AI ethics courses taught in  departments overwhelmingly feature analyses of ethical issues from a purely computational perspective or with the theoretical and engineering methods familiar to the STEM disciplines A few of the analyzed  courses actually had a primary emphasis on the completion of a set of defined technical projects or problem sets rather than including readings or scheduled class discussions Several courses do not even indicate explicitly the need for cross-disciplinary collaboration and most do not provide tools or strategies to educate students on how to successfully seek and navigate such collaborations Only one of the surveyed courses explicitly mentions disciplinary variance in methodology in their syllabus This course is also the only one analyzed that presented students with methodological approaches from HSS to supplement computational thinking None of the surveyed courses explicitly mention as part of the curriculum a discussion of the limitations of their own disciplinary approach in addressing the issue of AI ethics Lack of Joint Outputs The other mechanism of exclusion evident in this space is that of a lack of effort to engage in interdisciplinary translation This is to say that there is an apparent acceptance that the disciplines dont talk to each other and effectively tend to not communicate across disciplinary lines Common terms in the AI ethics community can be interpreted and represented completely differently from various disciplinary lenses at the same conference with confusion manifesting in the inherent incompatibility of certain employed definitions and perspectives In terms of pedagogy there does not seem to be an attempt to shift towards a shared vocabulary Of the surveyed courses there were only instances of courses allowing for cross-disciplinary teaching or open courses with non-prohibitive pre-requisites which allowed students from various majors to take the course together Only one course was explicit in the need for no pre-requisites as a requirement to keep the material accessible to any interested student From the syllabi it is also clear that the courses are made for a homogeneous audience In the majority of cases suggested readings are full of disciplinary references and technical terms anchored to assumed knowledge In HSS derived courses vocabulary is fairly inaccessible by virtue of being overly specific or referential to specific theories For example the ethical theories of philosophy often taken as assumed knowledge in HSS courses may be unfamiliar for many STEM students In the same way the  courses do not often invest in translating equations or programming details to make the coursework accessible and bridge communication hurdles In addition to this professional ethics courses will often reference industry-specific ethics statements such as the ACM Code of Ethics or familiar textbooks such as Artificial intelligence a modern approach of the surveyed courses were a required course mostly for computer science students but also for related majors such as data science business computing or information science The Engineering Accreditation Commission ABET requires an ethics course as part of their accreditation process for a program As a result since every  student has to take such courses anyways it may not make sense to open such a course for a broader audience There are at times several AI ethics courses run independently by departments at the same school for instance University of California Berkeley has AI Ethics courses run out of its Law School Information School Computer Science and History departments Only surveyed courses were hosted by an explicitly interdisciplinary effort often run by an institute at the university working with multiple departments This lack of effective translation poses a clear threat on the ability of students to get the opportunity to co-author or co-create with others of a different disciplinary lens Although researchers from different disciplinary origins may present to each other or consult on each others papers if attention is not paid to establishing a common understanding then these types of exchanges are ultimately performative rather than substantial The frustration of translation often prevents a shared ground to properly engage at the level of adequate mutual contribution as co-authors and primary collaborators It is clear that the pedagogical norms in AI ethics courses often does little to prepare students to overcome that challenge Siloed Citations Finally as a side effect of both of these previously identified mechanisms of exclusion we can see a lack of cross-citation ie a lack of effectively building on each others work The lack of cross-citation across disciplinary lines indicates that findings from one discipline are not respected as adequate evidence to inform researchers from another and that even if valued the insufficient accessibility of knowledge across disciplines may make results too difficult to be properly understood and engage with Textbooks and articles written by authors of a  background are rarely included in the syllabi of AI ethics courses run by HSS departments including departments of Information Sciences Communication and Media Studies Among the most often cited work from HSS syllabi is Digital Community Digital Citizen by Jason Ohler Algorithms of Oppression by Safiya Umoja Noble Automating Inequality by Virginia Eubanks and Digital Media Ethics by Charles Ess All of these authors work in HSS departments or have an HSS educational background Similarly frequently referenced work in  curricula includes Ethics for the Information Age by Michael  Quinn Superintelligence Paths Dangers Strategies by Nick Bostrom and A Gift of Fire by Sara Baase Timothy M Henry all of whom have either a  background or academic  affiliations Popular references also include books not written by computer scientists but still favoring a more analytical or economic interpretation of issues such as Weapons of Math Destruction or The Second Machine Age From the survey there were few if any examples of featured textbooks written by co-authors of differing disciplinary backgrounds This disciplinary divide seems to correlate to fundamentally differing views of the challenges inherent to building algorithms ethically HSS anchored literature tends to focus much more heavily on the human interactions of those making decisions regarding algorithmic systems and those impacted while  anchored literature generally frames issues as challenges in engineering responsibility or system control in the presence of unintended consequences It is noteworthy that as a relatively new topic to present to students much of the assigned material across all courses included a curated set of online media highlighting studied cases Popular examples include investigative journalism piece Machine Bias by Propublica and a short film titled Humans Need Not Apply directed produced written and edited by CGP Grey FORMATION OF EXCLUSIONARY PEDAGOGY CONSEQUENCES OF EXCLUSION As shown above this crisis of recognition can be understood from practices of disciplinary devaluation as a refusal to create common vocabularies and from a rejection to form enduring joint bodies of knowledge One question that we need to ask at this point is what are the reasons for this systematic indifference devaluation and lack of recognition between  and HSS and what are the consequences What reasons prevent a sustained and systematic collaboration between HSS and  and how does this lack of interaction hinder our ability to address interdisciplinary challenges such as those in AI ethics The Inherent Exclusion of Disciplinary Classifications Commonly accepted descriptions of disciplinary classifications are not merely neutral and objective In fact they enforce and reproduce the mechanisms of exclusion that we outlined above Disciplines are defined in two ways by their own epistemologies that is their own bodies of knowledge including concepts methods and objective aims or as the organised social groupings through which they operate Embedded in this definition is the explicit axiom that one cannot separate the production of knowledge understood as content from the social actors and their conduct Figure Table of a taxonomy for disciplinary groupings according to Kolb Source Becher Kolb and Biglan articulate four main axes to frame disciplinary groupings see Figure and respectively While Biglans focus is on identifying the subject matter of disciplines Kolb draws attention to the mode of inquiry operative in the classified disciplines Thus Kolb describes disciplines in terms of abstract reflective concrete reflective abstract active and concrete active Meanwhile Biglans disciplinary classification based upon the perceptions of academics involves an investigation on how a panel of university faculty members viewed a sample of disciplines According to this study academics view disciplines along two key axes hard vs soft and pure vs applied which in turn engenders variations of their own hard pure soft pure hard applied and soft applied We observe that disciplinary classifications analyzed at an axiological level enforce and reproduce disciplinary biases most importantly providing justification and legitimacy for the formation of mechanisms of exclusionary pedagogy in  If we look at how  is labeled according to Biglans classification we can see that it operates as a hard and applied discipline Kolb for their part sees  as abstract and active In stark contrast HSS have almost a virginal quality being labeled in the exact opposite categories as being irrevocably soft and pure Biglan concrete and reflective Kolb We hypothesize that behind these constructed distinctions of hard vs soft or active vs reflective there are serious assumptions about the nature of academic problems historically anchored to economic beliefs which shape who is worthy and who is not It is the distinction between accuracy and inaccuracy between tangibility and speculation between clear and distinct on one end and confused and ambiguous on the other The former state is understood to be much more real and valuable being framed as more economically relevant If our hypothesis is correct this disciplinary classification is problematic in the context of  pedagogy which may be categorized as hard or active to indicate its economic relevance but actually operates in conditions of epistemic vagueness Despite being a nominally hard discipline  requires a plurality of perspectives and modes of analysis involving both the consideration of abstract theory and engineering in addition to the challenge of handling both the practical and conceptual ambiguity typically characteristic of nominally soft disciplines Its thus clear that disciplinary classifications draw their legitimacy from internal modes of recognition operative in the disciplines themselves and from the nature of the impact they have on societies which validate or contest their self-understanding These disciplinary classifications should be understood as essentially contingent and could be formulated differently than they actually are The positioning of HSS in stark contrast and opposition to  is thus an imagined dichotomy In reality each discipline shares more in common than previously imagined with several intersecting challenges Setting up false dichotomies reinforces a false belief in the existence of inherently opposing rather than complementary disciplinary norms and ultimately escalates in the observed reluctance of differing disciplines to mutually engage Figure Selected disciplines located on the main Biglan dimensions Source Clark  Pedagogy and Hierarchies of Knowledge Disciplinary classifications display profound and entrenched disciplinary biases according to which some modes of knowing are presented as sure robust and legitimate at the expense of other modes of knowing seen as vague unwarranted and superfluous This establishes the perceived hierarchy of knowledge that leads to exclusionary pedagogy and practice In this framing of disciplines based solely on subject matter ie content and method the natural sciences engineering and computer science operate as hard or paradigmatic whereas the humanities are seen as idiosyncratic These latter disciplines do not qualify as paradigmatic and are classified as irreversibly soft The social sciences such as sociology and business fields are thus framed as being in futile search of a paradigm That is they display a potentiality for finding a paradigm but have not been able to find one and therefore are categorized as relatively soft to the STEM disciplines The second dimension of Biglans classification is defined by the relation between applied and pure aspects of disciplines Accounting and engineering fields including  are thus implicitly labeled as practical whereas the natural sciences social sciences and the humanities are categorized as abstract implying less tangible utility The label of active being applied to STEM disciplines also reinforces the false assumption that  as an active discipline is meant to hold the agency in situations requiring intervention and possesses the greater influence on system and societal outcomes The framing of  as being opposite to the passive category of reflective also devalues the importance of reflection in responsible  development while falsely framing reflection in opposition to effectiveness and efficiency Despite these small variations in terminology we contend that the disciplinary classifications are not simply descriptive In our view these disciplinary labels are essentially evaluative and have social effects in terms of symbolic and economic worth social relevance and impacts In fact they work as markers of truth which carry and reproduce historical and social hierarchies of knowledge In a word they justify the dominance and exclusion of soft modes of knowing by grounding underlying disciplinary values which in turn allow for a restricted set of choices commitments and actions within given disciplines Figure Taxonomy of Disciplines from Habermas Source Clear As a way for us to see the limits and bias operative in disciplinary classifications around hard soft pure applied active or abstract framings we should compare them with a different classification schema of disciplines Take for example Habermas disciplinary classification If we follow Habermas see Figure  would be exclusively defined by technical interests instrumental knowledge and causal explanations and work within the orbit of empirical or natural sciences HSS however will belong to the sphere of interpretive critical sciences and be described by its methodological tendency to mobilize practical and emancipatory knowledge via the medium of language and power Neither of these categories appears contradictory or possess connotations of inherent relative value Habermas disciplinary Despite Biglans label of computer science as applied there is debate in  of whether such a label is warranted For an alternative view of computer science as a theoretical science that is both a pure and hard discipline see Dijkstras comments And what is a science of computing about Well when all is said and done the only thing computers can do for us is to manipulate symbols and produce results of such manipulations From our previous observations we should recall that this is a discrete world and moreover that both the number of symbols involved and the amount of manipulation performed are many orders of magnitude larger than we can envisage they totally baffle our imagination and we must therefore not try to imagine them classification establishes as valuable the proposition which states that knowledge is not disinterested but is dependent on interests and by consequence is perspectival and partial If we ask ourselves what are the assumptions inherent in interests operative in Biglans disciplinary classification we would agree that technical interest based in causal explanations define the hard disciplines However we would be hard pressed to find any mention to grant scientific status robustness or accuracy to interpretive analysis and emancipatory goals defining what they call the soft disciplines Under this classification scheme it becomes clear that both disciplines simply differ and overlap in certain complementary ways that assert the nature of each perspectives contribution rather than framing one discipline as superior to another Hierarchies of knowledge contained in disciplinary classifications thus carry reproduce and enforce specific epistemological assumptions and commitments As we can see disciplinary classifications which define  as hard and applied or as abstract and active do so at the expense of other modes of knowledge labeled as soft idiosyncratic and un-paradigmatic If however we choose to frame disciplines differently in the classroom and within our own work then it is evident that much of the rhetoric feeding into the current state of disciplinary exclusion is not fixed or absolute and can actually be revisited and rejected leaving open the new possibility of more inclusive disciplinary classifications and practice Consequences of Exclusion If we agree that disciplinary classifications reproduce hierarchies of knowledge which are in essence exclusionary what are the consequences of the mechanisms of exclusion that we analyzed above One obvious response is disciplinary self-isolation and the resultant limit to growth based on the existing restrictive values and rigid assumptions that animate the discipline thus far However we can further articulate our answer in the form of a paradox that is at the heart of  the discipline finds itself in this space where its technical artifacts have a global reach yet its methods of analysis concepts values and assumptions reflect only a narrow subset of the social world that it finds itself embedded in Thus in a way  as a discipline is inflicted with a crisis of representation that is revealed by the narrow scope of its techniques and the modes of analysis that shape the discipline The continuation of this narrow disciplinary approach which reproduces the aforementioned mechanisms of disciplinary exclusion is not only costly but also harmful If  as a discipline continues this trend we need to reflect on the consequences of not engaging with other disciplines and in particular the social costs of not engaging with HSS To put it differently what are the values interests and goals that guide HSS and are lacking in  If we follow Habermas HSS is framed around humanistic goals of emancipation participation and respectful inclusion of all stakeholders present or absent powerful or not These are thus the priorities that the  field will fundamentally neglect once they disengage with HSS Such a disassociation would be tragic given that these are all considerations that represent key ideals commitments and values for responsible  ethics development The consequences of this exclusion thus involve not only disciplinary self-isolation but most importantly entails a loss of values assumptions and methods that are crucial in HSS hermeneutical interpretive qualitative methodologies and a sustained reflection on emancipatory societal goals The study of climate change could constitute a normative analogue from which  pedagogy could find inspiration Recent research shows that tackling climate cannot stand on a narrowly constructed group of experts Rather climate change education requires a holistic theoretical framing and a plurality of epistemologies methodologies instruments of analysis perspectives values and assumptions In a word since climate change is a global and complex problem it requires a pluralistic formulation of solutions Several examples of such a disciplinary shift can now be found for instance in a study on significant climate change the Arctic researchers showed how Sami reindeer herder interviews and observational weather data formed qualitative studies which measured community perception of climate change and complemented quantitative assessments of trends in temperature and precipitation The objective was to use a methodological approach encompassing the complexity subjectivity and context-dependent high sensitivity usually associated with qualitative methods along with the scale consistency generalizability and validity more generally associated with quantitative methods Given that  technical artifacts have a global impact on our lives accuracy understood as a techno-scientific requirement of clarity and distinctiveness is not enough Applied blindly irrespective of context and social power imbalances accuracy as a practice value and assumption is in fact a formula for stabilizing forms of dominance as it amplifies and reproduces historical and structural inequities Instead we need to focus on a critical engagement with exclusionary disciplinary classifications and their consequences in order to develop a new ethics of collaborative pedagogy at the intersection of  and HSS TOWARDS A COLLABORATIVE PEDAGOGY Given these mechanisms of exclusion operative in  and AI inflected pedagogy the final question to address is this what should we do now So far we have seen that disciplinary norms create a crisis of interdisciplinary recognition which has heavy costs Crisis is understood here as a moment of decision in light of the fact that  technical artifacts permeate and impact almost every aspect of our lives This crisis requires an expansion to the default framing In a paper titled Towards more predictive and interdisciplinary climate change ecosystem experiments which discusses how computational and technological advances can help in designing experiments the authors conclude We foresee that the holistic approach outlined in this Perspective could yield more reliable quantitative predictions of terrestrial ecosystem response to climate change and could improve knowledge on the value of ecosystem services and their links with ecosystem processes A diversity of theoretical perspectives and methodologies is valuable to shine light on climate change from different angles however it would be beneficial to the field to do some of the intellectual heavy-lifting that might result in an integrative theory that spans across the theoretical perspectives In keeping with our introduction we come together in conversation and reflection to pose our hopes for the field moving forward Such solutions can be conceived as research paradigms or a question of the epistemology informing interventions the form and nature of knowledge and what can be known about it or ways of knowing of both  and HSS though there is ideological resistance in both disciplines for such a shift to practically occur We contend that adequately tacking these issues will require changes to the constitution of how we educate students hoping to one day address the crisis Specifically we hope that demonstrating the necessary shift from current exclusionary norms towards a more collaborative pedagogy in the classroom will facilitate the development of more inclusive instruction and participation in the field for both academic and industry contexts Transversality in AI Ethics  pedagogy on its own is not able to elaborate the disciplinary norms and create conditions for stable comprehensive and socially beneficent technical artifacts In other words the creation of theories tools and methods in AI ethics need to be understood as transversal problems involving methods theories and collaborators across several traditional disciplines Not only would this new  pedagogy play a crucial role in addressing the divide between  and HSS but it would focus on developing solutions in a different way from our current default of developing methods and technical artifacts first and only weighing their impacts later it would allow for technologists to imagine their role as a collaborative one with peers whose perspective and approach could be key to addressing what continues to be major challenges in the field The power of acting in concert in  pedagogy would involve the acknowledgement of a requirement of transversality This requirement is a blind spot both in the design of the collaborations themselves and in the way we diagnose problems The field of  has not yet come to the full realization that it deals with problems which exceed its traditional field of competency and in fact its problems are not merely technical or moral problems but they are in fact transversal problems which require a diverse set of skills and methodologies A transversal problem is distinct from an interdisciplinary problem as its solution is not found in-between given disciplines but should be constructed from the effects on the stakeholders that could be or were impacted by it and from a critique of the types of formal and substantive assumptions choices requirements and methodologies that are currently built into AI ethics pedagogy A Path Forward The starting questions for us to develop actionable items in  pedagogy are as follows how can we build a curriculum for both social science and computer science to tackle technical issues together How can we develop a AI ethics curriculum that embraces transversality First we recommend to focus on thinking and acting differently by including broad non-CS expertise and researchers when dealing with technical artifacts which have clear social impact Demonstrate examples of effective collaborative outcomes to students in the form of papers books or other media effectively co-authored by scholars of different disciplinary perspectives advocacy campaigns done in conjunction with affected communities or projects making meaningful use of mixed methods If possible we suggest to encourage or allow students to tangibly collaborate across disciplines as part of their required outcome for the class This can be made easier by running concurrent or joint courses with other departments and minimizing prohibitive prerequisites so that students may gain practical project experience engaging with collaborators of a different disciplinary lens Second we need to educate students on frameworks of intervention based around existing problems not anchored to the existing skills of those assumed to be in the position to address the problems Real world ethics problems call for a diverse set of skills Educators should focus not only on developing the technical skills or social theory skills of students Instead more attention should be paid to the value of appropriately articulating the right problem as well as acknowledging and engaging the right stakeholders This can be learnt through a frequent analysis of concrete case studies complete with clear examples of the required contribution of those participating from various perspectives to address the studied situation This can also be addressed by creating moments of joint collaborative spaces between students of varying disciplinary backgrounds or including as part of the educational process instruction on the methodology of other disciplines This serves not to necessarily expand the toolbox of student skills but rather expose them to the methodologies and vocabularies they will need to recognize acknowledge and respect as part of the collaboration process with peers of other disciplines Third we need to incorporate explicit references in the AI ethics syllabi of stakeholders beyond the technologist including discussions of their roles and how they are impacted One of the key issues that a syllabus should address is a more inclusive identification of stakeholders when formulating an AI problem One of the questions that every AI syllabus should account for is not only who the target audience is but who the impacted parties may be Beyond institutional stakeholders such as product managers or engineers there could be greater discussion of societal stakeholders such as policymakers and regulators as well as more speculative reflection on who perhaps could contribute to the solution though may be rarely invited to do so Different disciplines have different approaches to including and incorporating the perspective of stakeholders and mapping this relationship out but it is critical to present at this point the need for collaboration to address multi-faceted complex problems rather than embrace the myth of a sufficiency in just expanding technical expertise to include some ethical understanding Fourth we need to develop frameworks to work with affected populations and experiential experts including community organizer toolkits and speakers We could imagine an AI ethics class for example in which the narration or participation of experiential experts is heavily featured and students can share their own reflections on lived experiences with unjust algorithms thus connecting personal testimonies to broader studied accounts of the social and ethical implications of deployed or speculative systems The account of practitioners could be included in the class to explain the logics informing how technical artifacts are designed and the kind of affordances or limitations present Such exercises build empathy towards the variety of perspectives present on these issues and encourage an open-mindedness to learn from and seek out an alternative lens Fifth we suggest engaging students in the exercise of assessing disciplinary competence in a range of situations and developing the ability to identify the relevance of a particular approach to address challenges for specific types of problems or in particular situations One may ask questions such as When is theoretical analysis needed What are the dilemmas and aporias embedded in the problem at hand Why are methods and patterns of quantification needed in this context There should be an explicit conversation about not only what is gained from the methods embraced by ones discipline but also what is lost and how the limitations of ones disciplinary lens can be addressed by looking towards mixed method approaches or knowledge and collaboration with other disciplines to fill in certain ability gaps CONCLUSION Working towards an effective ethics of responsibility from a technological perspective involves a steady procession towards a future of one primary goal to maintain the permanent conditions of our collective existence and well being To put it in starker terms our pedagogical design efforts should not divorce our epistemological concerns for truth accuracy robustness and metrics from our ethical concerns to achieving the public good collective responsibility shared practical reasoning and social justice As a way to address this structural divide operative in the ways ethics is taught in computer science we need to develop pedagogies able to forge a new ground for the relation between epistemology and ethics truth and the good individual and collective responsibility Computer science is not the only community to face this challenge Similar acknowledgment in climate science of the inability of purely quantitative thinking led to its innovation to embrace other forms of knowledge and a wider array of methodology in its teaching practice By moving beyond just the measured artifacts of the climate change crisis and embracing tools from economics anthropology behavioural psychology narrative storytelling and more the community was ultimately more effective in advocating for its cause and garnering impactful outcomes beyond what the original meterologists and ecologists were in a position to address With effort and more conscious planning we can only hope to see the same for our own crisis of ethics in AI CONTRIBUTION STATEMENT This was a largely collaborative work Each author regularly met to discuss the paper and formulate the argument Still we wish to lay out what each author did in this work for transparency The first author did the majority of the writing and editorial work as well as the empirical analysis She also conducted the final editorial work on the paper including writing synthesizing and formatting The second author worked to shape the larger conceptual frame of the paper He also conducted a large portion of the literature review foundation to the argument The third author input social and political theory perspectives aided in imagining future directions of the work and contributed to editorializing the work POSITIONALITY STATEMENT Reflexivity in research has become established practice in anthropology sociology and feminist studies and increasingly computing domains like human-computer interaction eg Each of the authors on this work have been challenged to engage with their own experiences and backgrounds in researching the interdisciplinary space of FAccT The authors perspectives are shaped by a collection of backgrounds in social and political theory engineering computer science gender studies and human-computer interaction This collection of disciplinary backgrounds has shaped both our pragmatic and philosophical approaches to computing approaches Our experiences as students and teachers at different aspects of our careers has led us to care deeply about educational approaches in computing disciplines including how to embrace new approaches for preparing future students on handling ethical dilemmas While we each have histories in different countries each authors education is rooted in Western scholarship which has shaped our approach to AI ethics pedagogy We each have our own set of privileges and marginalizations that situate not only our ways of conducting research but our intentions and motivations in doing so as well as shaped our understanding of the damage inflicted by any exclusionary practice Each of us have also worked with large technology companies headquartered in the United States as well as spent time in American academic institutions
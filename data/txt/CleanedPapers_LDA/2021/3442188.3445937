Outlining Traceability A Principle for Operationalizing Accountability in Computing Systems Accountability is widely understood as a goal for well governed computer systems and is a sought-after value in many governance contexts But how can it be achieved Recent work on standards for governable artificial intelligence systems offers a related principle traceability Traceability requires establishing not only how a system worked but how it was created and for what purpose in a way that explains why a system has particular dynamics or behaviors It connects records of how the system was constructed and what the system did mechanically to the broader goals of governance in a way that highlights human understanding of that mechanical operation and the decision processes underlying it We examine the various ways in which the principle of traceability has been articulated in AI principles and other policy documents from around the world distill from these a set of requirements on software systems driven by the principle and systematize the technologies available to meet those requirements From our map of requirements to supporting tools techniques and procedures we identify gaps and needs separating what traceability requires from the toolbox available for practitioners This map reframes existing discussions around accountability and transparency using the principle of traceability to show how when and why transparency can be deployed to serve accountability goals and thereby improve the normative fidelity of systems and their development processes CONCEPTS Software and its engineering Traceability Software version control Computer systems organization Maintainability and maintenance KEYWORDS traceability accountability transparency AI principles AI ethics INTRODUCTION Accountability is a long sought-after value in decision-making systems especially when those systems are computerized It is a multifaceted concept presenting challenges for operationalization Work to date on operationalizing accountability in computing systems focuses on keeping records along the dimensions of time information and action on ensuring that misbehavior in a protocol can be attributed to a specific participant and on demonstrating partial information about the contents of those records to affected people or to oversight entities But despite work on requirements engineering there remains no clear approach to defining what requirements exist for generating and maintaining records neither regarding what records must contain nor regarding how to store them Further there is minimal work describing how records lead to accountability in the sense of responsibility or in the sense of fidelity to values and norms such as fairness nondiscrimination or safety However the related principle of traceability has recently been espoused by many organizations as an approach to making software systems robustly transparent in order to facilitate accountability This article explores the notion of traceability asking how it might be operationalized in practical systems and how it serves the broader value of accountability Traceability refers broadly to the idea that the outputs of a computer system can be understood through the process by which that system was designed and developed Specifically traceability requires that transparency about the development process and its goals be tied to outcomes through the auditability of the methods used in both the creation and the operation of the system itself This includes ensuring the existence and legibility of records related to technology choice design procedure development process operation data sources and system documentation In this way traceability unifies many desirable goals in the governance of computing systems relating transparency about system design construction eg components and data and operation to the auditability of the system to investigate its properties and to establish responsibility for system outcomes Tracing how a system functions must go beyond providing a simple mechanical description of how operations led from input to output or what the systems dynamics and behaviors are Instead traceability demands an answer to the question of why the system works the way it does and what decisions led to that design or operation In other words traceability relates the objects of transparency disclosures about a system or records created within that system to the goals of accountability holding the designers developers and operators of a computer system responsible for that systems behaviors and ultimately assessing that the system reflects and upholds desired norms In this article we unpack the concept of traceability analytically examining several ways the principle of traceability has been articulated in official policy guidance and consider how it might be operationalized in real systems to achieve the lofty goal of connecting the operation of a computer system to normative concerns such as fidelity to policy goals or embodiment of desired values In addition we systematize existing technological tools which can help achieve traceability and suggest a set of system requirements implied by the principle and its goals We find that traceability ties together a number of existing threads of research around the responsible and ethical use of software technology for socially important applications For example traceability relates work on accounting for computing systems concretely calls for better governance of computer systems demands for reproducibility of software design and construction work on the security of software supply chains and the burgeoning field of trustworthy artificial intelligence In another sense traceability is a human factors problem For a system to be traceable key information about the development and operation of the system must be understandable to relevant stakeholders Thus traceability relates to questions of whether systems can be adequately understood for their given purpose including an understanding of their provenance and development and of their operation We refrain however from saying that traceability requires explainability at least as that concept is understood within computer science as a mechanical description of the mapping between inputs and outputs it does not As noted above a mechanical tracing of inputs to outputs even if causal does not describe a systems origins or answer questions about why it has particular dynamics or exhibits particular behavior Establishing appropriate human factors evaluation will depend on an understanding of stakeholders and their needs along with robust explanations for operational behavior that are appropriately causal contrastive and selective Ultimately we find that traceability provides a grounding for other ethical principles and normative desiderata within computing systems Traceability is made more easily amenable to measurement and assessment than other principles because it is clear when efforts towards traceability have been undertaken and when those efforts have been successful This is not true for other commonly espoused but more abstract principles such as fairness and equitability or even transparency and accountability Partly this is because traceability like transparency is well understood as an instrumental value that serves as a path to achieving other goals rather than an end to achieve in itself That is not to say traceability is not worthy of pursuit but rather to say that its pursuit serves other ends Achieving traceability may be more concrete than achieving other ethical goals such as fairness but it is by no means an easy task Although the path to reaching traceable systems is straightforward few if any systems can claim to have successfully navigated it We identify gaps in achieving real-world traceability in systems at the level understood within policy documents as a requirement or obligation on the entities bound by those policies These gaps fit into four basic categories relevant technologies such as tools for reproducibility or requirements on lifecycle and versioning management for software and data science artifacts have not been adopted related human factors problems defining what it means for people to understand system provenance and its implication for their goals and tasks have not been solved there are not yet accepted standards or even shared best practices for test and evaluation of software systems for critical applications in many domains and there is often insufficient oversight and review of the behavior of computing systems or capacity for disaffected persons to seek redress Some work has aimed at each of these gaps traceability systematizes the project of these disparate threads into the operationalization of a single ethical principle for computing systems Finally a note about terminology in this work we explicitly avoid the term artificial intelligence which eludes a rigorous definition Instead we speak of automation or the embodiment of tasks in technological artifacts which may or may not be software-based and computing systems which use computational processes software and related technologies eg data science and machine learning to implement automation The use of the term systems here is purposeful artifacts on their own such as models or programs cannot exhibit traceability which is a property of a tool in a context of use We can model this by considering traceability as a property of a system a set of elements which interact to produce aggregated behavior by virtue of those interactions Although a tool such as a piece of software can support traceability because traceability relates the specifics of the tools design to the effects of its use the tool cannot on its own be said to be traceable Traceability is a functional property of the tool in use and is poorly defined without this context ADOPTION OF TRACEABILITY Traceability has been adopted as an explicit principle either by organizations as a principle for the responsible use of technology or as policy guidance in official documents For example the United States Presidents Executive Order gives nine principles for the development of trustworthy AI requires that agencies of the US Federal Government must make AI systems Responsible and Traceable when designing developing acquiring and using AI Specifically that principle states Responsible and traceable Agencies shall ensure that human roles and responsibilities are clearly defined understood and appropriately assigned for the design development acquisition and use of AI Agencies shall ensure that AI is used in a manner consistent with these Principles and the purposes for which each use of AI is intended The design development acquisition and use of AI as well as relevant inputs and outputs of particular AI applications should be well documented and traceable as appropriate and to the extent practicable The order is unfortunately light on details deferring these to reports demanded of agencies in the weeks following its release However we see that traceability is related to the documentation of development and acquisition of AI a term the order also leaves undefined Almost a year prior to this government-wide policy directive the United States Department of Defense adopted traceability as one of its five AI Ethics Principles Specifically department guidance states the principle Traceable The Departments AI capabilities will be developed and deployed such that relevant personnel possess an appropriate understanding of the technology development processes and operational methods applicable to AI capabilities including with transparent and auditable methodologies data sources and design procedure and documentation This language originates in a report from a Federal Advisory Committee the Defense Innovation Board That study recommends as part of traceability various improvements in software development discipline including simulation environments modeling automated testing and validation tools but also improvements to design methodology and assurance that relevant stakeholders are apprised of development progress In addition traceability is operationalized during system deployment through a combination of online auditing and careful testing possibly in simulated environments The principle of traceability is also referenced in documents from the US National Security Commission on Artificial Intelligence which adopts the Defense Department language and approach A similar principle that AI systems have Documentation of Purpose Parameters Limitations and Design Outcomes can also be found in the United States Intelligence Communitys AI Ethics Framework This principle goes further calling for documentation stored in a way that is accessible to all potential consumers of the technology as well as how to verify and validate it This principle fits it a larger framework that also demands Accounting for Builds Versions and Evolutions of an AI as well as documentation of the test methodology results and changes made based on the test results Overall although the  framework does not explicitly use the term traceability it clearly espouses the concepts this term signifies in other policy documents The US Federal Data Strategy echoes language from an earlier Executive Order Maintaining American Leadership in Artificial Intelligence which calls for US government agencies to Enhance access to high-quality and fully traceable Federal data models and computing resources to increase the value of such resources for AI RD while maintaining safety security privacy and confidentiality protections consistent with applicable laws and policies emphasis added This meaning is expanded in the Federal Data Strategy Action Plan to cover Expanding access to government data and enhancing its quality Improving guidance around maintaining inventory of data and models of that data Developing standard metadata and formats for identified assets to facilitate a government-wide data inventory and Establishing pilot projects to demonstrate this traceability Here traceability is focused on the provenance of software systems and the decisions made during their creation However unlike transparency which is often framed as a burden placed on system creators and controllers traceability is described as an enabling value providing a route to new and more capable systems and a way to tie access to data and other resources to the provenance of systems Traceability is by no means limited to US policy documents however The EU High Level Expert Groups Ethics Guidelines for Trustworthy AI calls for traceability as a part of its broader theme of transparency saying The data sets and the processes that yield the AI systems decision should be documented to the best possible standard to allow for traceability and an increase in transparency This also applies to the decisions made by the AI system This enables identification of the reasons why an AI-decision was erroneous which in turn could help prevent future mistakes Traceability facilitates auditability as well as explainability Again we see that traceability is tied explicitly to improvements in the development process such as documenting design methodology but also to improvements in test and validation as well as examining outcomes driven by the system Traceability also appears in international policy guidance For example the Organization for Economic Cooperation and Development OECD states in its Recommendation of the Council on Artificial Intelligence that AI systems should have Robustness security and safety and to this end AI actors should ensure traceability including in relation to datasets processes and decisions made during the AI system lifecycle to enable analysis of the AI systems outcomes and responses to inquiry appropriate to the context and consistent with the state of art In this formulation traceability is explicitly called out for its information security value and it is also made clear that operationalizing traceability must be done in a way that is appropriate to the context and which enables analysis of the outcome However we see again a focus on making clear the reasons for a systems design and the origins of its components as well as the tools and datasets those components rely on Beyond policy documents from major Western superpowers and related transnational coordinating institutions traceability also appears in Chinas Governance Principles for Responsible AI Here it comes in somewhat different guise attached to a principle that AI must be Secure/Safe and controllable although this principle also addresses issues of transparency and provenance here described in terms of tamper-resistance as the above principles do Of particular interest is that the document calls not for traceability as a requirement but rather says that AI systems should gradually achieve auditability supervisability traceability and trustworthiness These principles should be viewed in the context of the earlier Beijing AI Principles which similarly aspire to traceability without claiming it as a requirement Thus non-Western conceptions of traceability are similar in substance if perhaps different in emphasis calling for various parties related to AI development to form AI security assessment and management capabilities while describing transparency accountability and traceability all in aspirational terms rather than as requirements Across a variety of global policy documents then we see that traceability has emerged as a key requirement for the responsible use of software systems This property entails systems where the design methodology underlying data sources and problem definitions are clearly documented and released to stakeholders a kind of structured transparency of the systems structure and development Additionally traceability requires connecting this transparency to outcomes and behaviors of the system encompassing auditability of the system-in-operation as well as the testability of the system during both development and operation Further traceability seeks to relate disclosed information to the problem of whom to hold responsible for these behaviors in cases both of failure and success providing a link between transparency and disclosure of system provenance and determinations of accountability An expansive requirement traceability lies at the core of system hazard mitigation and risk management decisions by system controllers Values Served by Traceability To understand the requirements demanded by this conception of traceability we must explore the goals articulated by the documents which espouse it Traceability is an expansive concept serving many values both concrete and abstract Although traceability is often described as a kind of transparency it does not speak directly to the question of what systems exist or what the scope of their operations and outputs is a classical goal of transparency requirements in policy Instead as noted in Section traceability ties the reasons a system works as it does to its actual operation supporting audit and interrogation into the structure and function of a system thereby serving to operationalize accountability However in requiring structured disclosure about systems traceability does serve to enhance transparency where it exists providing a link between transparencys instrumental operation and the values it serves and showing to what end that transparency is useful Additionally traceability provides a path to understanding a systems integrity in contexts where a systems supply chain may be in doubt both for reasons of complexity or for reasons of security A system which is robustly traceable is less likely to suffer manipulation by an adversary as the provenance of the systems components and their arrangement is made plain to affected stakeholders Thus if an adversary were to substitute or modify components of or inputs to the system for some or all decisions robust traceability would require that this manipulation become visible to affected parties And in systems where the origin of a decision may be complex robust traceability requires that a mechanistic justification for that decision be producible on demand supporting both system governance and the contestability of system outputs Relatedly a traceable system must be understandable to the humans intended to trace its operation so traceability encompasses aspects of explainability and is at least partially a human factors question Finally traceability serves to make plain the reasons behind failures showing where investigators and analysts can interrogate a system once an undesired behavior occurs and relating design choices and operational facts to specific outcomes REQUIREMENTS FOR TRACEABILITY In this section we expand on the notion of traceability as adopted in policy to understand what it requires in technology Our explication of requirements is driven by the conceptualization of traceability and the goals it serves in the policy documents described in Section These requirements should be viewed as a lower bound traceability requires doing these at a minimum but may require other activities depending on the application context Design Transparency The primary demand of traceability is that the design choices made by system designers be made available to system stakeholders affected by the systems operation This could be accomplished via transparency such as making system source documentation code or data available or through more abstracted disclosures such as impact assessments Many proposed approaches would provide standardized disclosures in support of transparency or traceability These include data sheets fact sheets data statements data nutrition labels model cards and other standardized disclosure formats But disclosure alone does not provide traceability and while traceability requires disclosure they must not be equated Indeed if traceability is more akin to an operationalization of accountability than of transparency it may be said that while such tools improve traceability they do so only to the extent that they reflect and enable a broader process of assessment test and evaluation Design proceeds from requirements Because traceability asks that stakeholders be able to understand why design decisions were taken traceability also requires that requirements be disclosed as part of transparency about design Requirements reflect the way a particular systems goal was articulated and approached by designers the critical aspect of problem formulation not otherwise subject to investigation by persons affected by a computing system and often invisible in even required disclosures of artifacts like code data or documentation When requirements are not specified formally they should at least be described in an unambiguous natural language form as relied on during development Thus systems that result from an exploratory process eg many models derived from standard data science practices must be augmented with descriptions of the governance attendant to that exploration which controls why particular avenues were or were not explored and how the fruits of that exploration were considered to be worthy of application in a particular context Transparency of design not only provides a window into how systems work it provides visibility into where design choices were taken that have significant impact For example software is used to automate the work of lab technicians who analyze forensic evidence but it is unclear how determinations made by that software are made a problem which has spawned much litigation One tool New York Citys Forensic Statistical Tool has essentially fallen out of use after journalists raised questions around its accuracy leading to a court-ordered release of its source code and subsequent public scrutiny Many commercial offerings remain trade secrets despite being used in criminal proceedings regularly As a hypothetical example imagine software which measures a parameter of a forensic sample and performs differing analysis based on whether the measured value was above or below a given threshold The very existence of this threshold and the process by which it was determined may be unknown without sufficient traceability And without that understanding the suitability of the analysis the thresholding that triggered it nor the value of that threshold can be challenged or reviewed Thus sufficient traceability means raising decisions about how parameters internal to the design of a system are set so they are legible to those outside the design process Testing In some descriptions traceability is established by the ability to test or audit for particular outcomes Testing of software systems is an entire discipline with a long history but it can help support external interrogations of a systems behavior under specific conditions Traceability requires developers and those involved in testing and system evaluation to minimize the gap between what is known to system developers through their knowledge of design decisions and actualization of those decisions through a test and evaluation regime and what is known to outside stakeholders who do not see the development or the output of developmental testing Because the halting problem prevents testing external to development from being formally sound minimizing this gap necessarily requires disclosing information about the design as well as information about the systems performance under test Thus traceable systems must have and release information about robust test and evaluation plans Further such systems must be designed to be testable during development and operation and ideally to be testable by outsiders as well as developers This is driven by the close relationship between traceability and auditability Reproducibility Related to the requirement to minimize the gap between the view of developers and other insiders and stakeholders outside the process of creating or operating the system is the issue of reproducing a systems behavior so it can be evaluated for correctness under the stated set of requirements If a systems behavior cannot be reproduced by a developer it cannot be made plain to an outside stakeholder A practical issue is that even disclosures of source code and data or the use of fully open-source code and data cannot be related to compiled software or trained models unless that compilation or training can be precisely reproduced which is possible using an emerging set of tools and software practices More careful reasoning about compilation can enable efficient updating or make verification of software function straightforward from transparency More broadly it should be possible to reproduce even abstract conclusions from data or any reported experimental results that claim scientific authority Without this an external stakeholder aiming to verify why and how a system was designed a particular way or what a system did will be unable to A related risk is that loss or modification of development information code data built components will lead to a situation where the system-as-deployed no longer relates to supporting information that might be disclosed possibly subsequently Thus robust reproducibility of both artifacts and conclusions must be a requirement for any traceable system Operational Recordkeeping Beyond traceability at the design stage traceability is understood to apply to system operations Thus traceable systems must keep records of their behaviors But what records must they keep how and how long must those records be maintained or retained and what must those records show These questions are highly contextual and mapping the associated concrete requirements demands the engagement of subject-matter experts able to understand both the application area and the technology intervening on it Abstractly the requirement must be that records support sufficient inquiry by external stakeholders or oversight entities A further problem is relating the contents of records kept during operation to a systems observed behavior For systems which are fully reproducible this is possible in principle through transparency or through the intervention of trusted oversight entities which can receive disclosures under seal eg law enforcement agencies courts or adversarial parties in litigation However it is possible to use tools from cryptography to bind the contents of records to the computations performed on those records to make this relation both more efficient to establish and possible to establish more broadly even when portions of the retained information must remain secret or private For example cryptocurrencies such as ZeroCash contain protocols to convince the receiver of a payment that the digital currency the payment represents has not previously been spent without revealing the payments origin or full history simulating the privacy properties of physical cash An alternative model is to vest recordkeeping and data access in a trusted third party such as an oversight entity or an independent data trust Such an entity can make assertions about records and determine the equities of their release on a case-specific basis Finally the maintenance of records of routine system activity along with records of failures and near-miss incidents provides a foundation upon which an understanding of the systems patterns of function can be built enabling the development of interventions that improve outcomes safety and overall system function and reliability Human Understanding As noted in Section the principle of traceability is often justified by the need for humans to understand the decision rules embedded in the system Principles call for appropriate understanding of the technology and transparency which enables identification of the reasons an AI-decision was erroneous Achieving these abstract principles requires not only transparency about system function but careful system engineering to ensure that systems do not confuse their human operators obscure paths of accountability for accidents where affordances in the design of technology lead human operators to make judgments that lead to accidents or confuse the loci of agency and power within a system This requires thinking beyond the current focus on explainability and causality in AI and a push toward tying explanations and disclosures to shifts in power Such thinking has been a robust component of research in human factors and developing appropriate strategies for establishing when and why and how much humans understand technology remains an important research domain necessary to enable robust human-machine collaboration Traceability thus requires that systems be transparent not just about their function but about whether that function is appropriately communicated to operators and other affected humans This is also important in the context of failure analysis as many accidents result from inappropriate modeling of machines by human operators of humans by machines and their designers or at the point of handoff between human and machine Auditability Another component of the traceability principles as stated is that they support the auditability of systems both before they are fielded and during operation This has several meanings First systems must maintain sufficient records during development and operation that their creation can be reliably established and reproduced This requirement is largely encapsulated in the reproducibility and operational/developmental recordkeeping requirements listed above Beyond requiring that evidence of how a system operated be established auditability requires that this evidence be amenable to review and critique of the systems operation as well as comparison of the fidelity of that evidence to reality Such assessments can be qualitative or quantitative in nature and could happen during development or once a system is fielded In the accounting literature an audit compares recorded evidence accounting for a systems behavior to reality to determine whether that evidence is reliable alternatively an assessment is the ascription of some value to that evidence or a judgment about the meaning of that evidence Scholarly critiques have noted that understanding the ethical and social implications of computing systems as simple as sorting and as complex as news curation require assessment but describe this requirement as one of auditing Although the term audit is widely used in policy and principles documents to describe what is needed and performed for computing systems the task referenced by the traceability principles is more in line with assessment Likely this is due to the history in computer security of the use of audit methods to assess the security state of a system to control disclosure of sensitive information in databases and to establish security policy compliance of the behavior of system infrastructure Practical applications often proceed by applying standard assessment models that use well defined checklists and controls to achieve desired outcomes Other work looks to connect audit data to sociotechnical goals like the correct operation of an election to establish an assessment of the entire sociotechnical system However some practitioners have criticized the gap between audit in a compliance sense and the assessment of security derived from it Still others have begun to seek data on the validity of audit approaches for building assessable metrics of abstract properties such as security Scholars from the social sciences have been critical of this over-quantification of auditing and the collapse of auditing and assessment into purely quantitative methods It is notable that widely used governmental auditing standards allow for both quantitative methods and qualitative assessment The collapse of the word audit onto system assessments in this context is likely due to the naming of a particular discrimination detection methodology the audit study in which similarly qualified test subjects differing only in perceived race or gender or other protected characteristic under study are subjected to the same process to test for facial evidence of discrimination in the process an approach which has been and must be updated to include studies of the behavior of automated systems Impact assessments are also proffered as a requirement for the governance of computing systems and such assessments could guide requirements for auditability of the system during development or after it is fielded As with other transparency tools impact assessments are valuable insofar as they enable traceability and considering the requirements of traceability can help establish the scope of appropriate impact assessment Finally the extent to which a system can be audited effectively is a question both of design and governance The system must have interfaces that enable audit and also policies that allow effective uses of those interfaces In bureaucracies this is driven by freedom-of-information laws in addition to standards that define the sorts of engagements with auditors the system expects To assess whether something like an online advertising system admits a sufficient level of auditing we need the system to report out information auditors want for the systems controller to allow or to be compelled that information to be given to auditors and for there to be standards around how that auditing will take place This is to say nothing of the problem of finding a sufficient number of skilled auditors who can apply such standards a problem which exists even in domains where standards are clear SUPPORTING TRACEABILITY In order to meet the requirements laid out in Section and to support traceability in built systems we need technical organizational and policy-level tools Many such tools exist but many more do not Rarely are these tools brought together in an assemblage that resembles anything like the traceability principles espoused by many organizations and summarized in Section or the requirements unpacked from these principles in Section And yet building robustly accountable computing systems requires embodying this principle in its full power In this section we summarize known tools and relate their capabilities and limitations to the requirements laid out in Section Our focus is primarily on technical tools here though as noted many nontechnical tools are also necessary It is likely this cross-functional nature of operationalizing traceability and indeed any ethical principle in technology that makes doing so such a challenge Development Methodology The history of system development especially software system development is littered with failures failures of the system to meet its stated requirements failures of the system to function once delivered or failures of the system to be developed to the point of operability at all These risks have long been recognized Brooks famously pointed out in based on experience developing IBMs System mainframe operating system that adding manpower to a late software project makes it later Early development methodologies flowed linearly from requirements to specifications to deliverables a waterfall process where the systems components flow along a defined path to delivery But all too often diversions along this path or changes in the environment by the time a system is delivered mean that the system does not meet the stated requirements upon delivery This has led to the development of various iterative modalities of software delivery such as the principle of iterative enhancement the Agile movement or test-driven development In all cases the goal is to feed back outputs of the development process into future rounds of development for continuous incremental improvement and learning The result is meant to be a product which is closer in its delivered form to envisaged requirements However although iterative development often leads to better outcomes faster issues can arise from the way the problem to be solved is defined initially and these methods may be based on unfounded assumptions in many cases These methods have also been critiqued for attending too much to problems and bugs identified early in a projects history as the visibility and tracking of issues demands their rectification and continuous improvement as well as for creating a model unsuitable for high-assurance tasks as the project is under continuous revision there is not an obvious point at which to verify or validate its functionality and these assessments can become problematic in a continuous-assessment setting Yet there has been some progress towards traceability in software development Discipline around version control of digital artifacts like code data sets and model products has been enhanced by the adoption of versioning-focused methodologies and the introduction of powerful general digital object versioning systems Although the problem of keeping digital archives of any sort is a major challenge standards exist for creating trustworthy repositories and auditing their reliability especially for high-assurance applications like space data systems Coupled with careful testing of desired invariants and augmented by disclosure of decision points in the development methodology these tools can be extended to methods for trustworthy system development Reproducibility and Provenance Many tools exist to support the reproducibility of created software artifacts and models of data sets This is critical to scientific research and to the practice of software development and data science in industry both for reasons of maintaining clarity of system function and security Despite the importance of this function software projects and especially data science and machine learning products are rarely able to precisely reproduce their work to a sufficient level to provide reliability let alone traceability Another relevant genre of tooling and research effort concerns the maintenance of system-level metadata which can be used to establish data and artifact provenance Work in this area out of the operating systems and database research communities has led to efficient systems that can be transparently layered into existing scientific workflows or standard infrastructure components These tools support the requirements of reproducibility and can be used along with development methodology and discipline to support requirements about documenting and substantiating the origin of data and components Unlike other aspects of traceability this is an area with well developed field-tested tooling and solutions which can be brought immediately into practice for clear gains both for traceability and for broader benefits eg the management of these artifacts capabilities to share results within communities of practice or research Design and Structure The stated principles of traceability tie system records to system understanding and ultimately to the way that systems embody values There is a long history of research into the way design reflects values and the analytical framework of this line of research gives a foundational framework for making both of these links Specifically this line of work notes that systems must be designed at a fundamental level to embody values and that it is not enough to add abstraction layers or minor changes at the end of a design process divorced from values Tools such as analytic frameworks for operationalizing values techniques for explicitly capturing certain concrete operationalizations of contested values in systems and mechanisms for observing the ultimate value-sensitivity of the resulting system all arise from this rich and deep vein of work and provide approaches to capturing the value of traceability in real systems We hope the requirements of Section can serve as a similar analytic framework for the principle of traceability and that the techniques summarized in this section can be useful in making such requirements actionable in real systems One well-studied value that can be operationalized through design is privacy Privacy-by-design is a principle recognized both by technologists and lawyers academics and practitioners The exact operationalization of privacy can be a contested or even an essentially contested point Many systems purport to protect privacy through such design approaches generally operationalizing privacy as the restriction of some information from some parties in the system Some scholars have argued that privacy-by-design leads toward a narrow view of what privacy is and away from issues of power and control of information Legal obligations for privacy-by-design may hypothetically limit the number and severity of privacy incidents in practical systems Empirical studies have demonstrated that attitudes toward privacy and compliance with data protection law vary drastically by sector and by country Of course design means little if the ultimate implementation does not comport with the design Translating values-sensitive design to values-embodying implementation remains a key open challenge as does assuring a relationship between specification and implementation Closing this specification-implementation gap is a core competency of the traditional computer science field of software verification A related problem is that of validation ensuring that a given specification captures the intended value The discipline of requirements engineering has developed formal and semi-formal approaches to the latter problem Capturing principles in the design of systems that include software and computers is not an idea that originated with values Indeed some of the earliest large computing systems derived their designs from core principles such as the Internets end-to-end principle This focus on design principles even under an imagined value free ideal remains to this day in the design of Internet platforms such as ISPs social media and forum websites and hosting providers Traceability demands that the design of systems be visible to affected stakeholders Another approach to legible design beyond disclosure of design desiderata is the use of transparent and inclusive design processes a topic which has received much attention in the technical literature recently but which has a longer history in political science Such community-driven design can lead to better overall decision-making affected stakeholders also find more acceptable even given tradeoffs Ethnographic work has found substantially similar attitudes toward decision-making which is fully embodied in a system across disparate domains Survey-driven human factors work has similarly discovered that participatory design can lead to more acceptance of system-driven outcomes Design toolkits which combine participation in design with explicit consideration of equity and also drive toward auditability provide concrete tools for advancing the state of play in values-oriented system development realizing the goal of values-driven design in practical system implementation and fielding Research questions remain however around the efficacy of such tools in actually preventing harms such as discrimination or the amassing of technologically centralized and entrenched power One approach under active scrutiny is the idea of designing systems for contestability both the ability to appeal incorrect decisions and the ability to understand the mechanism of decisions well enough to determine when decision guidance should be disregarded or overridden Finally the design of systems must take into account the role of humans within those systems Systems include more than just technical components and rules-driven automation but also decisions by human decision-makers who can exercise discretion Assuring that discretion within systems is exercised transparently and at appropriate times requires careful attention to design including requirements on when humans create records or review existing records for accuracy or policy compliance Humans may at times prefer decisions which are driven by discretion or negotiation rather than purely algorithmic decisions In general automation increases the capabilities of humans by taking over certain tasks and freeing human efforts for strategic optimization and additional productive work But in doing so automation also robs involved humans of situational awareness and expertise in the detailed operation of the system Thus humans coupled to automation are both more critical to the outcomes driven by the system and less able to control those outcomes Structured Logs As traceability requires recordkeeping both at the development stage and the operational stage we must consider the classic tradeoff in computer science between direct policy enforcement via the design of and compliance with specifications and the detection of policy violations via recordkeeping and review Several authors have proposed tools for verified computation which provides a proof of its execution that can be reviewed later to ensure particular computations took place as claimed Others have also proposed extending such technology to create structured logs in a commit-and-prove style to provide explicit technological demonstration to a skeptical stakeholder or oversight entity of the values-appropriateness of a computation or its procedural fairness and regularity Structured logging with disclosable side-conditions is a well-studied problem in computing with associated properties ranging from simple integrity checking to full real-world systems for proving the nonexistence of security-critical digital objects such as the certificates used for Internet security A related line of work is the vast field of tracing in operating systems and distributed systems We observed above that traceability is often conceptualized as a transparency principle but it is more akin to a principle for enabling accountability Many authors have called explicitly for the use of structured recordkeeping tools to enhance accountability and have built the conceptual framework tying such recordkeeping to improved accountability Empirical studies of trust in data science projects have shown that the sort of recordkeeping called for under traceability requirements may enhance the credibility of data science work products both within and beyond the teams creating them Along with traditional software engineering and project management discipline lifecycles versioning tools tools for reproducibility and recordkeeping comprise a set of currently available techniques with the capacity to improve traceability in real-world applications but which are currently underused Wider adoption of these techniques could improve not only traceability but thereby the broader governance of computing systems generally Structured Transparency Disclosures The sort of developmental and operational recordkeeping imagined in the prior section is often shorthanded into demands for better system documentation often in a structured format such as a checklist Although documentation of computing systems does support traceability there is little in the way of research establishing its effectiveness at communicating within organizations or actually mitigating harms Further there is often a substantial practical gap between the state of the system-as-documented and the state of the system-as-realized It is important to remember that documentation is generated by a healthy governance process but as a side effect Documentation does not on its own engender complete or useful governance of systems This gap is highlighted in the operationalization of data protection law To maintain adequacy and enable legal transfers of data between the European Union where the General Data Protection Regulation applies to all data processing and the United States which has a considerably more flexible legal regime for data protection based on sector-specific regulation the Privacy Shield framework was set up to replace a prior Safe Harbor agreement However both structures have now been found to be insufficient to protect fundamental rights guaranteed under EU law Despite this analysis done when these frameworks were in force examines transparency and governance rights in the US sector-specific approach eg in laws like the Fair Credit Reporting Act and the Equal Credit Opportunity Act and finds them as powerful if not more powerful than the analogous rights within the GDPR GAPS AND NEEDS Although many technologies exist which support traceability and many organizations aspire to embody this principle in practice or even claim to achieve it at a sufficient level substantial gaps exist at the basic technical level This is to say nothing of gaps in organizational governance or in the remainder of the sociotechnical control structure no technical control can be more capable than the implementing organizations willingness to take action based on it Adoption As noted in a few places in Section there exist tools and technologies that could be deployed immediately in service of better traceability and yet they are not used Understanding why this is will be critical to advancing this principle And because this principle is straightforwardly recognizable and potentially amenable to assessment and measurement more directly than abstract goals such as fairness or equitability understanding the barriers to operationalizing this principle bears on the feasibility and success of the entire values-in-design project Of specific note is the lack of methodologies and standards around the use of tools for the reproducibility of data science products or machine learning models This is despite substantial progress having been made at integrating such tools into common modeling frameworks even with the capability to checkpoint models or reset the seeds of pseudorandom generators this is rarely done in practice and the best guidance exists in the form of folkloric knowledge scattered across blogs answers on question answering sites and forum posts This despite the fact that the frameworks could be designed to afford reproducibility as a default or at least an easily and straightforwardly achievable property of implementations Yet tools like data science notebooks lean towards interactive environments in service of the democratization of powerful tools but in ways that make it hard to establish what precisely resultant insights actually mean And even rectifying this dismal situation would not address the problem of framework dependencies and the potential for numerical instability bugs in core algorithms or differences in behavior sufficient to change the output of models in practice Human Factors and Understanding Traceability claims explicitly to act in service of better understanding of the decisionmaking processes at work in an automated system Yet while there is a massive literature on machine learning explainability there is comparatively little work on the human factors of how such explanation methods serve understanding nor much work that explicitly relates the value of generated explanations to a theory or philosophy of what explanations should achieve For example in one framework Miller argues that good explanations must be causal contrastive selective and social and that they act as both a product conveying information and a process of inquiry between the explainer and the explainee Yet few techniques from the machine learning literature demonstrably have more than one of these properties and precious little work examines such systems in situ to determine whether they improve outcomes Test and Evaluation Standards In a similar vein although much work considers specific robustness and generalization properties or responses to bias or adversarially generated input work on test and evaluation methodologies for data-driven automation is nascent and work on test and evaluation of software lags the capabilities of test and evaluation for physical systems despite decades of research Investigating how to assess algorithmic systems generally leads to more questions than answers At present there is no generally accepted standard for establishing what evidence an automated decision-making system should produce so that its outputs can be considered traceable This is in contrast to other complex systems such as corporate finance and risk management nuclear safety or aviation safety And while standards are only part of a governance approach they can help build the organizational structures necessary to assess and investigate unintended behaviors before they happen Updates to accounting or audit standards in both the public and private sectors would make the assessment of traceability substantially more straightforward Further investigating the effectiveness of such standards in furthering the goals of traceability as measured by say perspectives on the performance of a system would provide useful benchmarks for those charged with the test and evaluation of practical systems Understanding the operationalization of this principle seemingly amenable to testing and assessment more than other contested principles dealing with fairness bias and equity would demonstrate a path to operationalizing ethical principles in the development of practical systems and is thus of paramount importance Oversight Governance and Responsibility Closing the gaps between the lofty goals of principles documents and the behavior of algorithmic systems in practice is the key research challenge of the values-oriented design movement and research community It is in particular imperative that the size and nature of any such gap be legible both to affected stakeholders and to competent oversight authorities in order to support effective governance and accountability Operationalizing traceability provides an excellent opportunity for progress in this critical research domain Our investigation opens related research questions such as why available tools are ignored even when their use would drive clear benefit both for the function of development teams the function of governance structures and the embodiment of human values CONCLUSION Traceability is a widely demanded principle appearing in a variety of AI policy and AI ethics principles documents adopted around the world notably in several important pieces of government-issued guidance in coordinating documents promulgated by transnational organizations such as the United Nations and the OECD and in the guidance of the European Unions High Level Expert Group on building Trustworthy and Responsible AI Although it is often conceptualized in these documents as a principle which operationalizes transparency as a way to achieve governance in reality that governance is achieved by enhancements to accountability and enhanced capabilities of both affected parties and competent authorities to notice when systems are going wrong and rectify the issue Traceability serves to demonstrate when and why transparency is valuable connecting the desire for disclosures about how a system functions to consumption of that disclosure for a defined purpose Traceability is an excellent principle for driving system assessment as it is seemingly more concretely realizable and recognizable compared to other goals like equitability or nondiscrimination Like transparency it is an instrumental principle that serves ends beyond itself including other ethical principles such as fairness accountability or governability While it is possible to see such instruments as a goal unto themselves their primary role in the operationalization of policies for ethical computing systems is to enable more abstract assessments That said the concreteness of traceability does not equate to ease of realization in practical systems We conclude via our analysis of operationalizing this principle that substantial gaps exist between the requirements we have identified and the tools presently available to meet those requirements A major gap is simply adoption tools which could improve traceability remain unused despite decades of development and the existence of mature realizations Understanding why these tools go un-adopted remains an important open research question for the governance of computing systems Other gaps are more serious and require new research to close establishing an appropriate human factors understanding for computing systems that work in tandem with humans challenges traceability as much as it challenges any other question of ethical computing the lack of accepted standards or even widely used best practices for the assessment of computing system ethics remains a barrier and a lack of practical governance oversight and review limits how well robust traceability can support meaningful assignments of responsibility for the behaviors of computing systems or assessments of those systems fidelity to normative governance goals Traceability serves as a foundation for other goals in aligning the behavior of automated systems to human values and in governing those systems to make that alignment plain to anyone potentially affected or harmed by the operation of those systems or the social outcomes they drive Only by making systems traceable can we hold them accountable and ensure they comport with applicable contextually appropriate social political and legal norms
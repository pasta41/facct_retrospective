Equality of Voice Towards Fair Representation in Crowdsourced Top-K Recommendations To help their users to discover important items at a particular time major websites like Twitter Yelp TripAdvisor or NYTimes provide Top-K recommendations eg Trending Topics Top Hotels in Paris or Most Viewed News Stories which rely on crowdsourced popularity signals to select the items However different sections of a crowd may have different preferences and there is a large silent majority who do not explicitly express their opinion Also the crowd often consists of actors like bots spammers or people running orchestrated campaigns Recommendation algorithms today largely do not consider such nuances hence are vulnerable to strategic manipulation by small but hyper-active user groups To fairly aggregate the preferences of all users while recommending top-K items we borrow ideas from prior research on social choice theory and identify a voting mechanism called Single Transferable Vote STV as having many of the fairness properties we desire in top-K item selections We develop an innovative mechanism to attribute preferences of silent majority which also make STV completely operational We show the generalizability of our approach by implementing it on two different real-world datasets Through extensive experimentation and comparison with state-of-the-art techniques we show that our proposed approach provides maximum user satisfaction and cuts down drastically on items disliked by most but hyper-actively promoted by a few users CONCEPTS Information systems Recommender systems Human-centered computing Social media KEYWORDS Top-K Recommendation Fair Representation Twitter Trends Most Popular News Fairness in Recommendation INTRODUCTION Many websites today are deploying top-K recommendations to help their users find important items For instance social media sites like Twitter recommend Trending Topics to let users know about breaking news stories Review aggregators like Yelp or TripAdvisor show top restaurants or hotels in a particular city News websites like CNN or NYTimes show most viewed or most shared stories While some of these recommendations are personalized ie tailored to a particular user others are non-personalized and the same items are recommended to all users at least in a geographical area Such recommendations implicitly rely on crowd-sourced popularity signals to select the items Recently concerns have been raised about the potential for bias in such crowdsourced recommendation algorithms For instance Googles search query autocomplete feature has been criticized for favoring certain political parties In another work we showed that the majority of Twitter trends are promoted by crowds whose demographics differ significantly from Twitters overall user population and certain demographic groups eg middle-aged black female are severely under-represented in the process In this paper we propose to reimagine top-K non-personalized crowdsourced recommendations eg trending topics or most viewed news articles as the outcomes of a multi-winner election that is periodically repeated We show that the observed biases in top-K recommendations can be attributed to the unfairness in the electoral system More specifically in Twitter we observe that during any single election cycle to minutes a only a tiny fraction of the overall user population express candidate topics or hashtag preferences ie a vast majority of voters are silent b some people vote multiple times ie there is no one person one vote principle and c voters choose from several thousands of potential candidates topics or hashtags splitting their votes over several moderate and reasonable topics and thereby allowing extreme topics representing highly biased view points to be selected Todays trending topic selection algorithms are vulnerable to electing such fringe trends with as low as of the electorate support from extensive prior research on social choice theory We focus on electoral mechanisms that attempt to ensure two types of fairness criteria proportional representation that requires the divisions in the topical interests of the electorate to be relected proportionally in the elected body ie selected items and anti-plurality where an extremist candidate item highly disliked by a vast majority of voters has little chance of getting selected We survey existing literature and identify a voting mechanism Single Transferable Vote STV as having the properties we desire in top-K item selections However implementing STV-based item selection poses a technical challenge to deter strategic manipulation STV requires every user to provide a preference ranking over all candidates Requiring the website users to rank thousands of candidate items makes the scheme impractical We solve this challenge by proposing to automatically infer the preference rankings for users Fortunately we can leverage the rich existing literature on personalized recommendations to rank items according to individual personal preferences of users In fact sites like Facebook and Twitter already use personal preferences to order topics in users newsfeeds Additionally our approach enables us to account for ie automatically infer the ranking choices for the large fraction of the electorate that is otherwise silent and inactive during any election We demonstrate the practicality and effectiveness of our ideas by conducting a comparative analysis of different mechanisms for top-K recommendations using real-world data from social media site Twitter and news media site Adressa Over the course of a month we collected trending topics recommended by Twitter itself and computed in parallel the topics that would be recommended by four different election mechanisms including plurality voting where the candidates with most first place votes win and STV At a high-level our findings demonstrate that trending topics elected by STV are significantly less demographically biased than those selected by both plurality-based voting schemes and Twitter itself At a lower-level our analysis reveals how the improvement in STV selected topics arise from STVs fairness criteria of proportional representation which selects topics such that most users have at least one of their highly preferred topics included in the elected set and anti-plurality which rejects highly biased topics disliked by a majority of users We further evaluate the mechanisms for recommending most popular Adressa news stories every day throughout a two-months period and make similar observations In summary we make the following contributions in this paper a by mapping crowdsourced recommendations to multi-winner elections we show how the bias in recommendation can be traced back to the unfairness in the electoral process b we establish the fairness properties desired in crowdsourced recommendations and identify an electoral method STV which ensures fair representation in such contexts c we implement STV by devising a mechanism to provide equality of voice even to the users who are otherwise silent during the election cycle To the best of our knowledge ours is the first attempt to introduce fairness in crowdsourced recommendations and we hope that the work will be an important addition to the growing literature on fairness bias and transparency of algorithmic decision making systems BACKGROUND AND MOTIVATION As mentioned earlier non-personalized top-K recommendations in different websites rely on crowdsourced popularity signals to select the contents For example Twitter recommends hashtags and key-phrases as trending when their popularity among the crowds exhibit a sudden spike Many news websites like NYTimes nytimescom or BBC bbccom/news recommend stories that are most read or most shared by their audience Multiple recent works have highlighted the potential for bias in such recommendations Biases in crowdsourced recommendations Googles search query autocomplete feature has been criticized as favoring certain political parties while concerns about political biases in Facebooks trending topic selection have led a fierce debate about the need for human editorial oversight of the recommended trends Interestingly after Facebook removed the human editors who used to oversee the topics popular among the crowds before they were recommended to the users it was accused of featuring fake news as trending In our earlier work we showed that the demographics of promoters of Twitter trends differ significantly from Twitters overall user population and certain demographic groups are under-represented in the process Similarly Baker et al found that the gender and racial stereotypes get perpetuated in Google search auto complete suggestions Going beyond demographic bias different types of actors such as spammers trend hijackers or automated bots disguise under the umbrella term crowd As crowdsourced algorithms are driven by data generated by them their outputs will relect the biases in the composition of the crowds A recent investigation by Politico revealed that Twitter bots were largely responsible for the trend ReleaseTheMemo Multiple works have also investigated the roles of spammers and trend hijackers around Twitter trends We hypothesize that one of the main reasons behind the bias in crowdsourced recommendations is the lack of fair representation of various segments among the crowd considered in the algorithms Using the datasets described next we attempt to specifically identify the root causes behind the bias in the recommendations Datasets gathered In this work we consider two different recommendations recommendation of i trending topics and ii most popular news stories i Trending Topics Social media sites like Twitter recommend a set of trending topics to help their users find happening events We gathered extensive data from Twitter during February to July Throughout this months period we collected sample of all tweets posted in the US by applying the appropriate location filters in the Twitter Streaming API In total we collected M tweets posted by around million US-based Twitter users throughout this period Simultaneously by querying the Twitter REST API every -minutes during the month of July we collected all topics which became trending in the US During this month topics became trending out of which were hashtags and the rest were multi-word phrases For simplicity we restrict our focus on trending hashtags in this paper ii Most Popular News All major news websites recommend a set of stories which are most popular eg most read most shared o v o te rs a No of votes casted in an election o p a ip a ti n g v o te rs b o o C a n d id a te s c o a ll v o te rs d Figure a Percentage of all voters participating during different election cycles in Twitter b Average number of votes casted by different voters during an election c Number of potential candidates for becoming trending during election cycles d Percentage of overall population needed to make different topics trending among the crowd To consider such recommendations we use the Adressa News Dataset which consists of the news reading behavior of around million users on the Norwegian news website Adresseavisen during the months period from January to March The dataset not only provides the information about the stories read by every user out of total news stories but also includes how much time a reader spent in each story Using these reading times as popularity signal we simulate the recommendation of most read news stories every day Reimagining Top-K recommendation as a multi-winner election In this paper we propose to see crowdsourced recommendation as the result of an election where the users vote for an item eg a hashtag a news story by tweeting reading or sharing it We can think of every x time interval as an election cycle where x can be any duration minutes hour or day the topics or stories tweeted or read in an interval as the candidates and user activities during this interval serving as the ballots The recommendation algorithm can then be viewed as an election method which considers these ballots and selects the winner items for recommendation If only one item is to be selected ie then it is a single winner election For the corresponding election is multi-winner Unfair election biases selection of items The mapping between top-K recommendation and multi-winner election allows us to hypothesize that the bias in the recommended items originates from a lack of fair representation in the underlying election mechanism More specifically we identify a number of potential root causes as discussed next Not everyone votes in every election cycle Out of the thousands or millions of visitors to many websites only a small fraction of them actively participate during any particular election cycle For example Figure a shows the percentage of Twitter users in our dataset who participated in the trending topic selection during different cycles throughout July Although there are around Million Twitter users in our dataset all of whom are eligible voters we can observe from Figure a that on average only of them influence the trending topic selection Similarly on average only of the Adressa readers read any henceforth referred as Adressa news on a given day Therefore we can conclude that there is a large majority of website users who are silent during an election One person can cast multiple votes in an election different voters participating in an election may have different activity levels For example Figure b shows the average percentage of participating voters who cast different number of votes during trending topic election in Twitter We can see that only of the voters vote once ie use a single hashtag and rest of the voters either vote for different candidates by using multiple hashtags or vote for same candidate multiple times Although we do not know for sure whether Twitters Trending Topic selection algorithm considers multiple votes from the same person here we highlight that it may be vulnerable to such multi-voting We see similar trends among Adressa readers where there is a huge variation in individual users reading activities Too many candidates to choose from In different websites today the number of potential candidates for recommendations is much more than a user can possibly notice News websites are producing hundreds of news stories everyday and news readers have very limited time and attention The problem is more acute for social media the amount of information generated is a lot more and a user will encounter only those coming from her neighborhood thus triggering a natural bias Figure c shows the number of candidate hashtags in Twitter during any election cycle On average at least candidates compete to become trending in an election Similarly around stories compete to become daily most popular news in Adressa of voters needed to get an item selected is too low As only a small fraction of voters participate in any election and their votes can get split across a large number of candidates effectively a tiny fraction of overall user population can make an item get selected For example Figure d shows that most of the Twitter trends enjoy the support of less than of the overall Twitter population This makes the elections vulnerable to biased and manipulated trends FAIRNESS CRITERIA FOR TOP-K RECOMMENDATIONS In this work we express the process in which top-K recommendations are chosen through crowdsourcing as an election mechanism Extensive prior research in social choice theory have identified several fairness criteria properties desired from the electoral systems However all fairness criteria are not applicable in a given context In Section we identified the potential unfairness in the election mechanism that leads to bias in the crowdsourced recommendations In this section we propose three fairness properties an election mechanism should satisfy to make the recommendations fairly representative a Equality of Voice b Proportional Representation and c Anti-Plurality Equality of Voice Most of the top-K recommendations in use today eg Most Viewed Stories in news websites like nytimescom can be intuitively categorized as a particular type of electoral systems Weighted Voting also known as Plural Voting where a single voter can vote for any number of candidates and that too multiple times The candidates getting maximum votes are selected for recommendation eg the stories getting maximum views regardless of users reading multiple stories or reading the same story multiple times We saw earlier that there is a large variety in the activity levels of different users Thus effectively a hyper-active user can influence the election much more than a lesser-active user To avoid this issue we propose that the item selection algorithm should treat all website users ie all voters similarly where no user is more privileged or discriminated to determine the set of winners In social choice this property is known as Anonymity Criterion and intuitively termed as one person one vote One way to achieve this is to require the voters to specify their preferences over a set of candidates In the recommendation context we can compute these preference rankings based on the activities of the users eg a user may post her highly preferred topic more than a lesser preferred topic In addition to give equal voice to the silent ie less active users we also need to infer their ranked choices over candidate items Fortunately we can utilize the long lines of works in personalized recommendations for inferring different users personalized preferences towards different items detailed in the next section Let denote the preference rank user i gives to item where denotes that is the most preferred item to i C denotes the preference ranking ie ranked ballot of the user i c c is the set of candidate items Then the top-K recommendation can be formally expressed as the -tuple C P where P is the preference rankings from all users and the selection algorithm is a function C P which selects the set of winner for recommendation from the candidate set C C using the preference rankings P Proportional Representation Even after considering everyones preferences due to the presence of too many candidate items users choices get split across many irrelevant alternatives Furthermore some alternatives may be very similar to each other eg two hashtags or news stories referring to the same event and there the vote splitting can be sharper Consequently items preferred by only a small number of users may end up being selected despite being disliked by the majority To illustrate this point let us consider a toy example in Table depicting a -winner election with candidate items and voters who rank them according to their choices Assume that items and st nd rd th th Category Item C Item C Item C Item C Item Extreme Table How candidate items are present across different ranked choices of users belong to a category C and items and belong to another category C Further assume that there is another item representing an extreme opinion We can see that although of the voters are interested in each of C and C due to splitting of votes especially between items and the extreme item can win in a plurality vote along with item This is despite item being disliked by voters who have put it as their last choice To alleviate the problems illustrated above we consider two fairness criteria i proportionality for solid coalitions and ii Anti-plurality Proportionality for solid coalitions We propose that in a fair top-K recommendation the diversity of opinions in the user population should be proportionally represented in the recommended items To formalize proportional representation we consider the criterion of proportionality for solid coalitions In social choice a solid coalition for a set of candidates C C is defined as a set of voters V who all rank every candidate in C higher than any candidate outside of C The proportionality for solid coalitions criterion requires that if V has at least q n voters then the set of winning should contain at least q candidates from C where q N n P and In the context of crowdsourced recommendations different groups of users may prefer a group of items eg hashtags or news more than other items Then the proportional representation criteria means that if a set of items is preferred by a group of users who represent a fraction q of the population then at least q items from this set should be selected The quantity n is known as Droop Quota In Table the Droop Quota is and hence to satisfy proportional representation a recommendation algorithm should select one item each from the categories C and C Anti-plurality In social choice theory the Majority Loser Criterion was proposed to evaluate single-winner elections which requires that if a majority of voters prefer every other candidate over a given candidate then that candidate should not be elected We extend this criterion to top-K recommendations and implicitly to multi-winner elections where the anti-plurality property intuitively mandates that no item disliked by a majority of the users should be recommended We can formalize this criterion by requiring that no candidate item among the bottom x percentile of the ranked choices for majority of the voters should be selected where x is a parameter of the definitions For example any recommendation algorithm satisfying anti-plurality will not select Item in Table because it is the last choice for of the users where the candidates getting most first choice votes are selected Input Candidate list C Preference rankings P Output Set of winners Start with an empty winner set P Droop quota while do using P assign votes to the first choice candidates if a candidate has votes then Add to the winner set remove voters from P who rank first transfer surplus votes to the next preference of the corresponding voters remove from all voters preference rankings else eliminate a candidate c with the smallest tally redistribute votes to its voters next preferences end end Algorithm Single Transferable Vote STV FAIR TOP-K RECOMMENDATION WITH EQUALITY OF VOICE Several electoral mechanisms have been proposed for multi-winner elections which include Plurality Voting k-Borda Chamberlain-Courant Monroe or Approval Voting Subsequent research works have investigated different fairness criteria that these mechanisms satisfy In this paper we consider a particular electoral mechanism Single Transferable Vote STV that satisfies two fairness criteria we described in Section proportional representation and anti-plurality and apply it in the context of crowdsourced top-K recommendations Single Transferable Vote STV STV considers the ranked choices of all voters and then executes a series of iterations until it finds winners Algorithm presents the pseudocode of the STV procedure Consider the example in Table with Here Droop Quota is hence there is no winner in the first iteration Item gets eliminated transferring all votes to Item assuming Item to be those voters second choices In the second iteration Item wins and transfers excess votes to Item or Item lets assume Item In the third iteration Item gets eliminated transferring all its votes to Item Finally in the fourth iteration Item wins resulting Item Item The worst case time complexity of STV m mK where there voters candidates However some performance speedup is possible over the vanilla algorithm presented in Algorithm By transferring votes to the preferred candidates beyond first choice STV achieves proportional representation where every selected candidate gets about fraction of electorate support Similarly for candidates disliked by a majority of the users unless they are preferred by at least fraction of all users STV will not include them in the winner list thus satisfying anti-plurality More importantly STV has been proved to be resistant to strategic For brevity we skip the comparison of all other electoral methods Interested readers are referred to to see how STV compares with other methods across different fairness properties voting where determining a preference that will elect a favored candidate is NP-complete Thus STV would make it much harder for malicious actors to manipulate the selection of items for recommendation For example consider the case of trending topic selection Essentially it would require at least n compromised or bot accounts which is a very large number considering n number of all Twitter users and to make one topic trending Although STV satisfies the fairness properties required in crowdsourced item selection it considers the ranked choice over all candidates for every user which gives rise to the following two problems that hinder the applicability of STV in recommending items i A large majority of the users do not vote during an election and ii Even for the users who participate it is not possible to get the ranked choice over all candidate items because they may vote for only a few candidates during an election Next we propose approaches to circumvent these two issues enabling us to guarantee equality of voice to everyone including silent users and apply STV for selecting items in top-K recommendations Getting preference rankings of all users Intuitively we can think of getting the ranked choices of a user u as determining how interested u is in different candidate items Then the problem gets mapped to inferring user interests in personalized item recommendations and there is a large body of works on the same which can be categorized into two broad classes content based methods and collaborative filtering We first attempt to get the personalized ranked choices of Adressa readers by applying a collaborative filtering approach based on Non-negative Matrix Factorization as described next Inferring preferences for Adressa readers As mentioned in Section the Adressa dataset contains information about the time different readers spent on different news stories We first convert this implicit feedback to explicit ratings by normalizing with respect to both users reading habits and the length of different articles If a user u spent time reading news story i then we compute the normalized view duration as where is the average time spent by all users reading story i Note that this normalization removes the bias of having possibly longer view duration for lengthier articles Once values are computed for different stories for the user u we divide them into quantiles and convert them into ratings For example the top percentile values are converted to rating the next percentile values to rating and so on We apply this mapping to every user-news interaction and end up with a user-news rating matrix R where denotes the rating of news story i computed for user u Matrix factorization approaches map both users and news stories into a joint latent feature space of Z dimensions such that the interaction between the users and the news stories are modeled as inner products in that space For example if the vectors and denote the latent feature vectors for user u and news story i then the estimated rating for a given user u and a story i is given by Though it is technically possible to apply STV with incomplete preference rankings STV guarantees strategy-proofness only when the preferences are complete the scalar product The challenge then is to find the latent feature vectors by observing the existing ratings Multiple approaches have been proposed to efficiently optimize the following objective min where is set of user-news pairs for which the ratings are known In this paper we apply the Non-negative Matrix Factorization approach proposed by Luo et al which solves Equation by using stochastic gradient descent with non-negativity constraints on the feature values Once we get the feature vectors for different users and news stories then the ratings can be predicted even for the unread stories Thereafter we compute preference ranking for the users based on the predicted and actual ratings with actual ratings getting precedence and ties being broken randomly Inferring preferences for Twitter users To infer Twitter users preferences we considered both content based recommendation and collaborative filtering i Compute content based similarity between a user u and hashtag by considering the set of all tweets posted by u and the set of tweets containing However we found that most users do not post enough tweets and thus we can not accurately compute the content based similarity between a user and the candidate hashtags ii As there is no explicit rating available we tried to apply a collaborative filtering based approach to compute personalized ranking using implicit feedback like favoring or retweeting However two independence assumptions in such approaches items are independent of each other and the users act independently do not hold in the context of Twitter Hashtags are often related and Twitter users often influence other users Further the amount of implicit feedback is very low in our dataset only tweets get any retweets or likes or favorites and the set of hashtags are constantly changing Hence the collaborative filtering approaches could not be applied in this context To circumvent these difficulties we utilize prior works involving topical experts on Twitter Using the List feature in Twitter users can create named groups of people they follow By giving meaningful names to the lists created they implicitly describe the members of such groups Ghosh et al gathered these list information from a large number of Twitter users and identified thousands of topical experts on Twitter where the topics are very fine-grained Then both Bhattacharya et al and Zafar et al utilized these topical experts to infer interest of a particular user as well as topic of a particular hashtag The basic intuition of is that if a user is following multiple experts in some area then he is likely to be interested in that area Similarly if multiple topical experts are posting some hashtag then the probability that the hashtag belongs to that topic is very high Implementing the approaches proposed in and for a user u we infer an interest vector considering the experts u follows and similarly we compute a topic vector Th for a hashtag by taking into account the experts tweeting Then for every user u we normalize the interest topics in such that every entry in lies between and and all entries sum to Similarly for every hashtag we calculate the tf-idf scores over the topics in Th We repeat this process for every user and every candidate hashtag during an election Finally we compute the preference scores between all users and all candidate hashtags as A U T where is the User-Hashtag affinity Matrix with denoting affinity between user u and hashtag hUnt is the User-Interest Matrix with representing normalized interest of u in some interest topic is the Interest-Topic Similarity Matrix Ti representing the similarity between two topics i and we compute Ti as the Jaccard Similarity between the set of experts in topic i and respectively Finally is the Hashtag-Topic Matrix where denotes tf-idf of topic in hashtag Using A computed above we can get the preference ranking of any user over the candidate hashtags If a user u participates in an election and votes for tag then is considered as the top choice in us preference ranking and other ranked positions are shifted accordingly If a user votes for hashtags top positions are assigned to these candidates according to their usage frequency Accuracy of the preference inference For inferring the preferences of Adressa readers we attempted another technique based on Singular Value Decomposition SVD Comparing the Root Mean Squared Error RMSE between the actual ratings and ratings inferred by both SVD and based approaches we found that the based approach RMSE works better than the SVD based approach RMSE In Twitter there is no ground truth rating or ranking Hence to check the accuracy of the inference of Twitter users preference rankings we asked volunteers who are active Twitter users to rank hashtags during election cycles Then we compute their preference ranking using our approach and checked Kendalls rank correlation coefficient between the inferred and actual rankings for every volunteer We find the average value to be compared to for random ordering which suggests that our method can infer the ranked choices of users reasonably well EXPERIMENTAL EVALUATION In this section we evaluate the performance of our proposed approaches in selecting items for recommendation For that in Twitter we consider every minute intervals throughout the month of July as election cycles During any election from the large set of available hashtags we select candidate hashtags which experience highest jump in usage during that election cycle compared to their usage in the previous cycle While computing the preference rankings of Twitter users due to Twitter API rate limits it is not possible to infer ranked choice for everyone We take random sample from the million Twitter users in our dataset resulting in a large sample of users and gather the ranked choices of all of them and of no other over the candidates For the Adressa dataset we consider every day during February and March as election cycles We select as candidates top The idea of random voting is not new Getting everyone to vote in an election is often impractical or too costly Dating back to ancient Athenian democracy philosophers including Aristotle argued for selecting a large random sample of voters and then mandating them to vote during an election More recently Chaum proposed a technique to hold random elections Fishkin et al proposed an alternate Deliberative Polling where the idea is to select a random sample of voters give them proper information ask them to discuss issues and then consider only their votes STV STV a STV STV b Ranked choices of voters o v o te rs C D STV c p c c c c p c Ranked choices of voters o v o te rs STV d Figure Heatmaps depicting the Jaccard coefficients between different methods for selecting a trending topics in Twitter and b most popular news in Adressa c Average ranked choices and d Percentile choices for the trending topics selected by different methods throughout July stories based on the number of users clicking on them Then we compute the preference rankings of all users in our dataset over the candidates After getting the preference rankings of the users we apply two methods i Consider the preference rankings and select items which are the first choice for most users We denote this method as because this is an extension of Plurality Voting described next ii Run STV using the preference rankings and select the winners of the election Following the convention used for in this section we denote STV as STV to relect the fact that the ranked choices of everyone have been considered not only the active users Next we describe the baselines we compare and STV against Baseline approaches In addition to the preference rankings we also gather the votes given by the users participating in an election cycle Then using the data we apply the following approaches to select the winners i Weighted Voting Here candidates getting maximum votes win the election regardless of who voted for them and how many times one user voted Hence it is vulnerable to manipulation by hyper-active users ii Plurality Voting Plurality Voting or Single NonTransferable Vote considers only one vote from a participating user So if a particular user voted multiple times we count only one vote for the candidate she voted the most with randomly breaking ties Then candidates with maximum votes win iii Twitter Trending Topics We are not privy to the exact algorithm Twitter employs to select the set of trending topics during an election cycle Therefore we consider the algorithm as black-box and compare the hashtags selected by the methods with the hashtags declared as trending by Twitter Quantifying pairwise overlaps We first investigate whether these different methods pick very different items or they end up selecting same items during an election To check that we gather all the items ie hashtags and news stories selected by each of the methods and then compute pairwise overlaps between them Figure a shows the heatmap of Jaccard coefficient between different methods where Jaccard coefficient between methods i and is measured as where Si is the set of items selected by method i throughout all election cycles Not to be confused with Plural Voting which is a variant of Weighted Voting We see from Figure a that there is overlap between the trending hashtags selected by and STV has around overlap with There is little overlap between hashtags selected by other methods Similarly for Adressa dataset Figure b we see around overlap between the news stories selected by and STV The rest of the methods do not have much overlap Takeaway different methods select mostly different items during election cycles We only see some common items being selected by our two proposed approaches and STV possibly because both consider the top preferences of all users Interestingly actual Twitter Trending Topics has the highest overlap with the tags selected by Plurality Voting Thus the Twitter algorithm can be conceptualized as running plurality-based elections Comparing ranked choices of users different users have different interests and thus their ranked choices over different candidate items can vary considerably We now investigate how different election methods capture the choices of these users Figure c shows on average how the hashtags selected by different methods represent different ranked choices of Twitter users Figure d presents the user choices in different percentile bins We can observe in both Figure c and Figure d that the STV selected tags correspond to top percentile choices for a majority of users While captures users top choices to some extent both and appeal very differently to different voters Finally tends to pick tags which represent top choices of only a few voters and bottom choices for a majority of the voters Takeaway STV consistently selects tags that are the top preferences for all voters whereas other methods capture both top and bottom preferences with performing the worst Few actual trends selected by Twitter are least preferred by a lot of voters We see similar result for the Adressa news data as well Comparing desirable fairness properties We now compare different methods along the desirable fairness properties identified in Section does not satisfy Equality of Voice because effectively a voter voting multiple times exerts more power than a voter voting once during an election considers one vote per participating voter however it does not consider votes of the silent users Our proposed and STV both guarantee voice equality by giving all users an equal chance to participate in the item selection process Regarding the other two properties we empirically observe to what extent the methods satisfy them STV U se r S a ti sf a io n I n d e x a STV U se r S a ti sf a io n I n d e x b STV A n ti ra lit y I n d e x c STV A n ti ra lit y I n d e x d Figure User Satisfaction Index of different methods for computing a Twitter Trends and b Most Popular Adressa News Anti-Plurality Index of different methods for computing c Twitter Trends and d Most Popular Adressa News User Satisfaction Index The proportional representation criterion requires that if a candidate is preferred by fraction of the users it should be selected and only STV theoretically satisfies this criterion An alternate way to consider representation is from users perspective We propose a user satisfaction criterion which requires that every user should have at least one elected candidate from her top choices Formally we consider a user to be satisfied if at least one of its top choices is selected by a method during an election Then User Satisfaction Index is measured as the fraction of users who are satisfied by a method Figure a shows the average User Satisfaction Index for different methods to compute Twitter trends and we see that both and STV are able to satisfy more than of the users whereas the other methods cannot satisfy even users We see similar results for Adressa news dataset as well Figure b Anti-plurality Index The notion of anti-plurality captures whether a method selects items that are disliked by most of the users We consider a item i to be disliked by a user u if t appears among vs bottom percentile choices Then for every such i we compute what percentage of users dislike i and aggregate this over all the items selected by different methods Figure c and Figure d shows the average Anti-plurality Index for all methods of selecting Twitter Trends and Most Popular Adressa News We can see in Figure c that both STV and select almost no tags which are disliked by any of the users On the other hand picks tags which on average are disliked by users For both and the selected tags are disliked by around of all users Similarly we can see in Figure d that STV has the lowest anti-plurality value less than while stories selected by are disliked by of users specific to Twitter we observe that there were some extremist tags eg exterminate_syrians IslamIsTheProblem spammy tags eg houstonfollowtrain InternationalEscorts or politically biased tags eg fakeNewsCNN IdiotTrump which were disliked by more than users yet got selected by or due to the presence of some hyper-active user groups However STV and did not select any of such hashtags Demographic bias and under-representation in selected topics In our earlier work we found that most of the Twitter trends are promoted by users whose demographics vary significantly from Twitters overall population Next we check whether the voting methods considered in this paper amplify or reduce these demographic biases We use the demographic information of Twitter users as obtained in Then demographic bias of tag i is computed as the euclidean distance between the demographics di of the people tweeting on i and the reference demographics dr of the Twitter population in the US Biasi di dr The higher the score Biasi more biased are the users using the tag i Figure a shows the average bias across the tags selected by different methods throughout all election cycles We see in Figure a that the tags selected by are most gender racially and age biased On the other hand STV selects tags that are least biased We further observe that considering the preferences of the silent users helps reducing the bias as the average bias of tags selected by is lower than the average bias of selected tags We next consider the under-representation of different socially salient groups among the users of the tags selected by different methods where we consider a group i to be under-represented if the fraction of i among the trend users is of the fraction of i in the overall population Figure b shows the under-representation of men and women In almost all the methods women are underrepresented for over of the selected tags whereas men are under-represented for only around of the tags However in the tags selected by STV although under-representation of men slightly increases under-representation of women greatly reduces having almost equal under-representation of both gender groups Figure c shows the under-representation of different racial groups Whites Blacks and Asians Even though none of the methods achieve similar under-representation of all three racial groups STV reduces the under-representation of Blacks and Asians considerably while keeping the under-representation of Whites similar to other methods We observe similar trends for age groups where under-representation of Mid-Aged and Adolescents decrease in the tags selected by STV The detailed result is omitted for brevity How does considering preference rankings reduce demographic bias The reduction in demographic bias and under-representation of different social groups among STV selected tags is surprising because the method has not explicitly taken into account the preference rankings of voters belonging to different demographic groups We investigate the reason by considering the most and least biased tags along all three demographic dimensions gender race and age and then by checking how they rank in different voters preference rankings Figure clearly shows that highly biased tags rank low in most of the voter choices On the other hand tags with low bias tend to be ranked higher by most of the voters This interesting observation explains why methods like or STV Gender Race Age D e m o g ra p B s STV a M a le e m a le M a le e m a le M a le e m a le M a le e m a le M a le e m a le o S e le e d T a g s STV b White Black Asian o S e le e d T a g s STV c Figure a Demographic bias b Gender and c Racial under-representation in tags selected by different methods p c c c c p c Ranked choices of the voters o v o te rs High Gender Bias Low Gender Bias a p c c c c p c Ranked choices of the voters o v o te rs High Racial Bias Low Racial Bias b p c c c c p c Ranked choices of the voters o v o te rs High Age Bias Low Age Bias c Figure Ranked choices of voters for hashtags most biased and least biased along a gender b race and c age which relies on preference rankings of all the voters tend to select tags with low bias as compared to other methods like or which only consider votes by the active users RELATED WORKS In this section we briefly review the related works along two dimensions top-K item recommendations and fairness in algorithmic decision making systems Top-K recommendations Top-K item recommendations is traditionally associated with personalized recommendation which attempts to find items a particular user would be mostly interested in In content-based recommendations a user profile is generated based on what she likes or dislikes and then similar content is identified depending on her past likes In collaborative filtering the preference of a particular user can be inferred based on their similarity to other users However the recommendation scenario we are considering here is non-personalized where the same items are recommended to everyone In fact the problem we are focusing on is how to fairly aggregate personalized preferences of all users of a website Bringing fairness in algorithmic decisions Multiple recent works have focused on biases and unfairness in algorithmic decision making Yao et al proposed a few fairness notions for personalized recommendations Zehlike et al introduced fairness in top-k ranking problem through utility based multiobjective formulation Burke and Chakraborty et al argued for preserving fairness of consumers users as well as suppliers item producers in two-sided matching markets Complementary to earlier efforts in this paper we present the notions of fairness in crowdsourced non-personalized recommendations and utilize electoral mechanisms to satisfy them in practice CONCLUSION AND FUTURE DIRECTIONS Recently there has been a lot of debate and concerns regarding the bias in algorithms operating over big crowd-sourced data In this paper by conceptualizing crowdsourced recommendation as a multi-winner election we showed that the bias originates from the unfairness in the electoral process Then utilizing long lines of works in social choice theory we established the fairness properties desired in crowdsourced selections and identified a particular mechanism satisfies most of these properties As a result extensive evaluation over two real-world datasets shows that STV can reduce unfairness and bias in crowdsourced recommendations Moreover STV can also resist strategic manipulation by requiring a lot of user support behind potential candidates for recommendation thereby making it difficult for spammers bots or trend hijackers to influence the recommendation process There are multiple research directions we want to explore in future First our proposed approach can potentially be applied in personalized news recommendation scenario which combine both user choices and the news trends among the crowds eg Google News In such context at the first level the candidate stories for recommendation can be selected by standard personalized recommendation algorithms which consider a particular users interest Then an election method like STV can be applied to take into account the crowd choices for electing news stories to recommend to the user Second in this work we conceptualized item selection to happen at every fixed intervals however there is a streaming component in recommendations like Trending Topics with occasional burstiness in user activities Regular election methods are not designed to tackle such scenarios and we plan to develop mechanisms to handle continuous elections while simultaneously satisfying the desired fairness properties
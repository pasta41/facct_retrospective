Efficient Search for Diverse Coherent Explanations This paper proposes new search algorithms for counterfactual explanations based upon mixed integer programming We are concerned with complex data in which variables may take any value from a contiguous range or an additional set of discrete states We propose a novel set of constraints that we refer to as a mixed polytope and show how this can be used with an integer programming solver to efficiently find coherent counterfactual explanations ie solutions that are guaranteed to map back onto the underlying data structure while avoiding the need for brute-force enumeration We also look at the problem of diverse explanations and show how these can be generated within our framework CONCEPTS Human-centered computing Human computer interaction HCI Theory of computation Integer programming Integer programming Computing methodologies Supervised learning KEYWORDS Counterfactual Explanation Machine Learning Linear Program Chris Russell Efficient Search for Diverse Coherent Explanations INTRODUCTION A fundamental tension exists between the high performance of machine learning algorithms and the notion of transparency Lipton The large complex models of machine learning are created by researchers and system builders looking to maximise their performance on real-world data and it is precisely their size and complexity that allows them to fit to the data giving them such high-performance At the same time such models are simply too complex to fit in their builders minds and even the people that created the systems need not understand why they make particular decisions This tension becomes more apparent as we start using machine learning to make decisions that substantially alter peoples lives As algorithms are used to make loan decision to recommend whether or not some one should be released on parole or to detect cancer it is vital that not only are the algorithms used as accurate as possible but also that they justify themselves in some way allowing the subject of the decisions to verify the data used to make decisions about them and to challenge inappropriate decisions A common remedy to avoid this trade-off is to learn the complex function and then fit simple models about datapoints providing human comprehensible approximations of the underlying function While popular in the machine learning community there are many challenges in conveying the quality of the approximation and the domain over which it is valid to a lay audience Another promising approach to explaining the incomprehensible models of machine learning lies in counterfactual explanations Lewis Wachter et al This recent approach to explainablity bypasses the problem of describing how a function works and instead focuses on the data Instead counterfactual explanations attempt to answer the question How would my data need to be changed to get a different outcome Wachter et al make the argument that there are three important use cases for explanation to inform and help the individual understand why a particular decision was reached to provide grounds to contest the decision if the outcome is undesired and to understand what would need to change in order to receive a desired result in the future based on the current decisionmaking model and that counterfactual explanations satisfy all three Although making the case for the use of counterfactuals and showing how they could be effectively calculated for common classifiers Wachter et al left many technical questions unanswered Of particular concern is the issue of how should we generate counterfactuals efficiently and reliably for standard classifiers This paper focuses on the technical aspects needed to generate coherent counterfactual explanations Keeping the existing definition of counterfactual explanations intact we look at how explanations can be reliably generated We make two contributions Focusing on primarily the important problem of explaining financial decisions we look at the most common case in which the classifier is linear ie linear/logistic regression SVM etc but the data has been transformed via a mix-encoding based upon -hot or dummy variable encoding We present a novel integer program based upon a mixed polytope that is guaranteed to generate coherent counterfactuals that map back into the same form as the original data We provide a novel set of criteria for generating diverse counterfactuals and integrate them with our mixed polytope method Previously Wachter et al strongly made the case that diverse counterfactuals are important to informing a lay audience about the decisions that have been made writing that individual counterfactuals may be overly restrictive A single counterfactual may show how a decision is based on certain data that is both correct and unable to be altered by the data subject before future decisions even if other data exist that could be amended for a favourable outcome This problem could be resolved by offering multiple diverse counterfactual explanations to the data subject but to date no one has proposed a concrete method for generating them We evaluate our new for mixed data approach on standard explainability problems and the new FICO explainability dataset where we show our fully automatic approach generates coherent and informative diverse explanations for a range of sample inputs PRIOR WORK The desire for explanations of how complex computer systems make decisions dates back to some of the earliest work on expert systems Buchanan and Shortliffe In the context of machine learning much prior work has focused upon providing approximations typically either linear models Lundberg and Lee Montavon et al Ribeiro et al Shrikumar et al or decision trees Craven and Shavlik of the true decision making criteria This fact that the simplified model is only an approximation of the true decision making criteria means that these methods avoid the trade-off between accuracy and explainablity discussed in the introduction but also raises the question of how accurate these approximations really are These approximate models are either fitted globally Craven and Shavlik Martens et al Sanchez et al over the entire space of valid datapoints or as a local approximation Lundberg and Lee Montavon et al Ribeiro et al Shrikumar et al that only describes how decisions are made in the neighbourhood of a particular datapoint Another important class of explanations comes from case-based reasoning Caruana et al Kim et al in which the method justifies the decision/score made by the algorithm by showing data points from the training set that the algorithm found similar in some sense Finally there are methods for contrastive or counterfactual explanations that seek a minimal change such that the response of the algorithm changes eg You were denied a loan because you have an income of if you had an income of you would have been offered the loan Martens and Provost was the first to propose the use of this technique in the context of removing words for website classification while Wachter et al proposed it as a general framework suitable for continuous and discrete data Use of counterfactual explanations have strong support from the social sciences Miller and form part of the established philosophical literature on explanations Kment Lewis Ruben Others have called for the use of counterfactuals in explaining machine learning Doshi-Velez et al Finally Binns et al followed and Dey in performing a user study of explanations Counterfactual explanations are referred to as why-not explanations by and Dey and sensitivity by Binns et al Binns et al found evidence that users prefer counterfactual explanations over case-based reasoning For a more detailed review of the literature please see Mittelstadt et al Finally concurrent with this work Ustun et al have also proposed the generation of diverse counterfactuals using mixed integer programmes for linear models However they do not consider the case of complex data in which individual variables may take either a value from a continuous range or one of a set of discrete values Formalising Counterfactual Explanations We follow Lewis in describing a counterfactual as a close possible world in which a different outcome or classifier response occurs In the context of classifier responses we can formalise this as follows Given a datapoint x the closest counterfactual x can then be found by solving the problem argmin x x such that x c where d is a distance measure the classifier function and c the classifier responses we desire This is a much looser definition of counterfactual than that used in the causal literature eg Pearl and some thought needs to go into the choice of distance function to make the counterfactuals found useful In the context of human comprehensible explanations it is important that the change between the original datapoint and the counterfactual is simple enough that a person can understand it and that the way the datapoint is altered to generate the counterfactual should also be representative of the original dataset in some way To meet these objectives Wachter et al suggested making use of the norm weighted by the inverse Median Absolute Deviation which we write as MAD This has two noticeable advantages i The counterfactuals found are typically sparse ie they differ from the original datapoint in a small number of factors making the change easier to comprehend ii In some limited sense the distance function is scale free in that multiplying one dimension by a scalar will not alter the solution found and robust to outliers Wachter et al proposed solving this problem as a Lagrangian min x max x x MAD x c As the term tends to infinity this converges to a minimiser of x x MAD that satisfies x c or at least is a local minima of x c Stability is a major concern when using the Lagrangian approach to generating counterfactual explanations It is important that the counterfactuals generated do what they set out to do and satisfy the constraint x to within a very tight tolerance For this to happen the value much be sufficiently large and this induces stability issues Wright and Nocedal Moreover the shape of the objective for is reminiscent of pathological optimisation problems Noticeably for large the objective forms a deep narrow valley around the decision boundary similar to a high-dimensional analogue of the Rosenbrock or banana function Rosenbrock while the sparsity of the solution found means that the minima occurs at gradient discontinuities in the objective function To avoid these issues we preserve the original formulation of equation with explicit constraints We show how this problem can be formulated as a linear programme when is linear and distance function d takes the form of a weighted norm Where they occur binary constraints such as this variable must take only values or are treated as integer constraints and our final formulation is efficiently solved using a Mixed Integer Program Solver COHERENT COUNTERFACTUALS ON MIXED DATA We now outline our procedure for generating coherent counterfactual explanations for linear classifiers including logistic and linear regression and SVMs defined over complex datasets where the variables may take any value from a contiguous range or an additional set of discrete states For such mixed data the notion of distance becomes problematic For example in the FICO dataset one of the variables that measures Months Since Most Recent Delinquency may take either a non-negative value corresponding to the number of months or a set of special values Condition not Met eg No Inquiries No Delinquencies No Usable/Valid Trades or Inquiries or No Bureau Record or No Investigation Beyond the computational challenges in searching over all valid values for all sets of variables it is apparent that the change from special value to is fundamentally different from the shift between months since most recent delinquency and months since most recent delinquency A common trick among applied statisticians when training predictors on this kind of data is to augment it using a variant of the one-hot or dummy variable encoding Here a variable xi that takes either a contiguous value or one discrete states is replaced by variables The first of these variable takes either the contiguous value if xi is in the contiguous range or a fixed response typically if xi is in a discrete state The remaining variables di are indicator variables that take value if xi is in the appropriate discrete state and otherwise A linear classifier can be trained on these encoded datapoints instead of the original data with substantially higher performance The challenge with using such embedding into higher-dimensional spaces and then computing counterfactuals in the embedding space is that the extra degrees of freedom allow nonsense states for example turning all indicator variables on which do not map back into the original data space We show how a small set of linear constraints can avoid many of these failures and by combining it with simple integer constraints for the indicator variables guarantee that the counterfactual found is coherent We will refer to the space enclosed by these linear constraints as the mixed polytope We refer to a particular datapoint a decision has been made about as x and its individual components as xi We write for the contiguous variable that can take values in the range Li and use di for the component of the set of indicator variables that has value if xi is taking the discrete value To make optimisation tractable under these constraints we assume that this decision has been made by a linear function x x b The mixed polytope of variable i then is described by the linear constraints di li li Li ri Ri di where is an additional indicator value that shows that variable v is takes a contiguous value It is immediately obvious that if the variables di are binary ie take values then any vector di that lies in the mixed polytope is consistent with a standard mixed encoding from a consistent state Moreover the polytope is tight in so much as optimising a linear objective defined directly over the variables d and c would result in a valid solution However we are unable to take advantage of this as the additional constraint on the value of x further constrains the polytope and potentially allows for fractional optimal solutions if di is not forced to be binary We are now well placed to write down an Integer Program to generate counterfactuals We write x for the mixed encoding of datapoint x and assume that our classifier is linear in the embedding space We seek argmin x x x such that x x lies on the mixed polytope di i where is a weighted norm with the weights to be discussed later Note that we now use the constraint x rather than x as it is possible that changing the state of one of the discrete variables will take us over the boundary rather than up to it This can be expanded into a linear program As is a linear classifier we can split it into linear sub-functions over the discrete and contiguous values d and c respectively and rewrite it as x a c i a i di b allowing x to be replaced with the linear constraint The objective c can be made linear using the standard transformation min c x c min i hi such that xi i hi x i hi i Putting this all together it gives us the following program min i i di such that a i ai di b xi i hi xi hi i mixed polytope conditions hold di i The encoding in equation used for the continuous variables is not needed for the discrete variables as owing to their binary nature we can simply choose the sign of appropriately to penalise switching away from the state of di These equations can be given to a standard MIPS solver such as Gurobi Optimization allowing coherent counterfactuals to be automatically generated Choices of Parameter The solution found depends strongly upon the choice of parameters and which can be adjusted given better knowledge of the problem or what the explanations found should look like Here we present some simple heuristics that give good results in practice Choice We follow Wachter et al in the use of the inverse median absolute deviation MAD with some small modifications We consider the contiguous and discrete values separately and generate the inverse MAD for contiguous regions by discarding datapoints that take one of the given discrete labels For the discrete labels the measure of inverse MAD is inappropriate for any distribution over binary labels as the median absolute deviation over any distribution of binary labels is always zero With only two possible states the median will coincide with the mode and therefore the median of the absolute deviation will be zero Instead for binary variables we replace the MAD with the standard deviation over the data multiplied by a normalising constant to make it commensurate with the use of MAD elsewhere We to refer to these choices of weights we set m for all parameters penalising changes in the contiguous region of data For the that govern the cost of transitions from discrete states we adapt depending on the value taken by the original datapoint we are seeking counterfactuals for We wish transitions to any new discrete state to be penalised by the scaled inverse standard deviation associated with that state while a transition away from a current discrete state to the contiguous region should be penalised by the scaled inverse standard deviation of the current state We achieve this as follows Given the scale we and if xi is currently in discrete state i mj mi for all i and final wi This has the required properties Choice of Although we introduced the variable in the context of training the model it can also be adjusted on a per explanation basis providing the intercept value b is also altered to compensate We choose the value in such a way that when xi is In the case where its a split between the two binary states the MAD is illdefined but one possible solution still remains zero in the contiguous range it does not incur an additional penalty to transitioning to a discrete state This is done setting xi On the other-hand when xi takes a discrete value we wish to ensure that transitioning to the contiguous range gives you a representative and typical value without incurring an additional cost This is done by setting DIVERSE EXPLANATIONS In the original paper of Wachter et al the authors note that diverse counterfactual explanations may often be useful if someone wishes to improve their credit score the first route to altering their data that you suggest may not be the useful for them and another explanation would be more useful Equally if no other explanation exists this too is valuable information for that person Wachter et al suggested local optima might be one source of diversity For linear classifiers their objective is convex in x for any choice of and for problems of this particular form only one minima exists Instead we take an different approach and induce diversity by restricting the state of variables altered in previously generated counterfactuals This is done by following a obeying a simple set of rules which we give in the following paragraph Diversity constraints If a particular discrete state has been selected in a counterfactual but not in the original data we prohibit the transition to that state but allow transitions to other discrete states by the same variable If the counterfactual alters a discrete state to one in the contiguous range we prohibit that transition while if it alters an already contiguous state to a new contiguous value we prohibit altering the contiguous state but allow transitions to one of the discrete states Each constraint is added individually and if the addition of a new constraint means that the mixed integer program can no longer be satisfied the constraint is immediately removed The process terminates when the new counterfactual explanations generated is the same as the previous explanation Sample outputs of the entire procedure are discussed in the following section EXPERIMENTS To demonstrate the effectiveness of our approach we generate diverse counterfactuals on a range of problems All explanations generated will be human readable text that show the sparse changes needed All text will take the form You got s c o r e One way you ld have got s c o r e i s i took va lue r a t e r than Another way you ld have got s c o r e i s i had taken va lue r a t e r than where the blanks are completed automatically The list of explanations will be naturally ranked by their weighted distance from the original datapoint as they are computed by greedily adding constraints For completeness we show a full list of explanations as they are generated If the generated counterfactuals are to be offered to consumers this list should be truncated as many of the later elements are unwieldy All explanations automatically generated by our approach will be shown in the typewriter font hypothetical You got s c o r e good One way you ld have got s c o r e bad i n s t e a d i s i E x t e r n a l R i s E s t im a t e had taken va lue r a t e r than Another way you ld have got s c o r e bad i n s t e a d i s i had taken va lue r a t e r than You got s c o r e good One way you ld have got s c o r e bad i n s t e a d i s i E x t e r n a l R i s E s t im a t e had taken va lue r a t e r than Another way you ld have got s c o r e bad i n s t e a d i s i Ne t r a c t i l v i had taken va lue r a t e r than Another way you ld have got s c o r e bad i n s t e a d i s i had taken va lue r a t e r than Another way you ld have got s c o r e bad i n s t e a d i s i t i s a c t o s had taken va lue r a t e r than Another way you ld have got s c o r e bad i n s t e a d i s i i l e had taken va lue r a t e r than had taken va lue r a t e r than Another way you ld have got s c o r e bad i n s t e a d i s i E x t e r n a l R i s E s t im a t e had taken va lue r a t e r than Another way you ld have got s c o r e bad i n s t e a d i s i t i s a c t o s had taken va lue r a t e r than Another way you ld have got s c o r e bad i n s t e a d i s i P e r cen lq had taken va lue r a t e r than You got s c o r e bad One way you ld have got s c o r e good i s i E x t e r n a l R i s E s t im a t e took va lue r a t e r than You got s c o r e bad One way you ld have got s c o r e good i n s t e a d i s i had taken va lue r a t e r than MS t l days had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i E x t e r n a l R i s E s t im a t e had taken va lue r a t e r than MS t l days had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i t i s a c t o s had taken va lue r a t e r than had taken va lue r a t e r than Ne t r a c t i l v i had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i P e r c e n t I n s t a l l T r a d e s had taken va lue r a t e r than Ne t r a c t i l v i had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i had taken va lue r a t e r than had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i i l e had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i had taken va lue r a t e r than P e r c e n t I n s t a l l T r a d e s had taken va lue r a t e r than had taken va lue r a t e r than had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i had taken va lue r a t e r than had taken va lue r a t e r than N e t r a c t i o n I n s t a l l B u r d e n had taken va lue r a t e r than i l i za t ion had taken va lue r a t e r than Table Two explanations for different pieces of data leading to a good result on the FICO challenge left top one of the few short explanations for bad left bottom on and a typical explanations for a datapoint scored as bad right explanations and those generated by other methods will be given in quote blocks We first turn our attention to the LSAT dataset LSAT The LSAT dataset is a simple prediction task to estimate how well a student is likely to do in their first year exams at law school based upon their race GPA and law school entry exams It is regularly used in fairness community as the historic data has a strong racial bias with classifiers trained on this data typically predicting that any black person will do worse than average regardless of their exam scores As such counterfactual explanations generated on this dataset should provide evidence of racial bias and provide immediate grounds for system administrators to block the deployment of the system or for individuals suffering from from discrimination to challenge the decision We train a logistic regression classifier to predict students first year grade score and assume that a decision is being automatically made to reject students predicted to do worse than average This mimics the setup of Wachter et al although we do not use a neural network to predict Wachter et al had difficulty with the binary nature of the race variable value indicates that an individual identified as black and for all other skin colours and frequently predicted nonsense values such as a skin colour of To get around this they had to explicitly fix the race variable to take labels and over two runs and then pick the solution found that has the smallest weighted distance In contrast we simply treat the variable as a mixed encoded variable that takes a continuous value in the region of ie only the value and with an additional discrete state of value All other issues are taken care of automatically and we automatically generate diverse counterfactuals Wachter et al consider five individuals Person Race LSAT GPA and reported the following explanations Person If your LSAT was you would have an average predicted score Person If your LSAT was you would have an average predicted score Person If your LSAT was and you were white you would have an average predicted score Person If your LSAT was and you were white you would have an average predicted score Person If your LSAT was you would have an average predicted score The explanations found using our method are as follows You got s c o r e above average One way you ld have got s c o r e below average i s i l s a t took va lue r a t e r than Another way you ld have got s c o r e below average i s i gpa had taken va lue r a t e r than Another way you ld have got s c o r e below average i s i i s b l a c had taken va lue r a t e r than You got s c o r e above average One way you ld have got s c o r e below average i s i l s a t took va lue r a t e r than Another way you ld have got s c o r e below average i s i i s b l a c took va lue r a t e r than You got s c o r e below average One way you ld have got s c o r e above average i s i l s a t took va lue r a t e r than i s b l a c took va lue r a t e r than You got s c o r e below average One way you ld have got s c o r e above average i s i l s a t took va lue r a t e r than i s b l a c took va lue r a t e r than You got s c o r e below average One way you ld have got s c o r e above average i s i l s a t took va lue r a t e r than This is not a direct comparison with Wachter et al as they made use of a different classifier There are noticeable differences in the counterfactuals found starting with the small discrepancy between the first explanation of person Beyond this several benefits of our new approach are apparent With the previous approach the inherent racial bias of the algorithm was only detectable by computing counterfactuals for black students as the lack of representation in the dataset of the dataset identified as black meant that counterfactuals that changed race were heavily penalised In fact with a classifier with a slightly weaker racial bias its possible that Wachter et al might never observe the bias as it would be always preferable to vary the LSAT score rather than to alter race This is not the case for our approach where the diverse explanations offered makes the racial bias very apparent Another factor also apparent is the absence of gratuitous diversity If as in the last example changing the LSAT score is both sufficient to obtain a different outcome and necessary no additional explanations that jointly vary the LSAT score and GPA are shown The FICO Explainability Challenge We further demonstrate our approach set out in the previous section on the FICO Explainability Challenge This new challenge is based upon an anonymized Home Equity Line of Credit Dataset released by FICO a credit scoring company The aim is to train a classifier to predict whether a homeowner they will repay their account within years Potentially this prediction is then used to decide whether the homeowner qualifies for a line of credit and how much credit should be extended We do not compare against the previous baseline method of Wachter et al as this would require on the order of million runs to compute all the counterfactuals over the valid binary states using their brute force approach The target to predict is a binary variable FICO refer to as Risk Performance It takes value Bad indicating that a consumer was days past due or worse at least once over a period of months from when the credit account was opened The value Good indicates that they made all payments without being days overdue The raw data has a total of components excluding Risk Performance and after performing the mixed encoding this rises to Although the only task given in the FICO challenge One of the tasks is how well data scientists can use the explanation and their best judgements to make predictions of the selected test instances does not require good explanations it could potentially be solved by an uninterpretable algorithm that simply makes high accuracy predictions the dataset in itself is still useful In particular is possible to consider how helpful counterfactual explanations would be to an applicant who has been denied or offered a loan with respect to the three uses of explanation of Wachter et al listed in the introduction Namely if i the explanations we offer would help a data-subject understand why a particular loan decision has been reached ii to provide grounds to contest a decision if the outcome is undesired or iii to understand what if anything could be changed to receive a desired outcome Although i is perhaps best evaluated with user studies as in Binns et al for ii there are two possible ways as to how these counterfactual explanations could be used to contest a decision If part of an explanations says One way you could have got score good is if the number of months since recent delinquency was rather than and you know that you have not missed a payment in the last months this gives immediate grounds to contest Another important example is shown in table bottom left One way you ld have got s c o r e good i s i E x t e r n a l R i s E s t im a t e took va lue r a t e r than Importantly this explanation shows that the only thing wrong with the application is that the external risk estimate is missing value corresponds to No bureau record This provides the data-subject with exactly the information they need to correct their score Counterfactuals also provide additional grounds to contest In the problem specification FICO also require that the classification response with respect certain variables is monotonic for example that the more recently you have missed a payment the less likely you are to receive a good decision If on the other hand an explanation says One way you could have got score good is if the number of months since recent delinquency was rather than this provides direct evidence that the model violates these sensible constraints and gives grounds to contest Finally regarding iii explanations that say that the Net Fractional Revolving Burden is too high or that Months since Most Recent Delinquency is too low provide a direct pathway to getting a favourable decision in the future even if that pathway is simply waiting till you become eligible in the future To evaluate on this dataset we train a logistic regressor on the mixed data using the dummy variable encoding described in section At the time of writing only one task has been released You got s c o r e bad One way you ld have got s c o r e good i n s t e a d i s i had taken va lue r a t e r than MS t l days had taken va lue r a t e r than You got s c o r e bad One way you ld have got s c o r e good i n s t e a d i s i had taken va lue r a t e r than MS t l days had taken va lue r a t e r than Ne t r a c t i l v i had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i E x t e r n a l R i s E s t im a t e had taken va lue r a t e r than MS t l days had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i E x t e r n a l R i s E s t im a t e had taken va lue r a t e r than MS t l days had taken va lue r a t e r than had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i t i s a c t o s had taken va lue r a t e r than Ne t r a c t i l v i had taken va lue r a t e r than had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i t i s a c t o s had taken va lue r a t e r than had taken va lue r a t e r than Ne t r a c t i l v i had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i P e r c e n t I n s t a l l T r a d e s had taken va lue r a t e r than had taken va lue r a t e r than Ne t r a c t i l v i had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i P e r c e n t I n s t a l l T r a d e s had taken va lue r a t e r than had taken va lue r a t e r than had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i i l e had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i i l e had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i had taken va lue r a t e r than P e r c e n t I n s t a l l T r a d e s had taken va lue r a t e r than had taken va lue r a t e r than i l i za t ion had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i had taken va lue r a t e r than had taken va lue r a t e r than P e r c e n t I n s t a l l T r a d e s had taken va lue r a t e r than Ne t r a c t i l v i had taken va lue r a t e r than had taken va lue r a t e r than i l i za t ion had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i had taken va lue r a t e r than N e t r a c t i o n I n s t a l l B u r d e n had taken va lue r a t e r than had taken va lue r a t e r than i l i za t ion had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i had taken va lue r a t e r than had taken va lue r a t e r than had taken va lue r a t e r than had taken va lue r a t e r than MS t l days had taken va lue r a t e r than N e t r a c t i o n I n s t a l l B u r d e n had taken va lue r a t e r than had taken va lue r a t e r than i l i za t ion had taken va lue r a t e r than had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i had taken va lue r a t e r than had taken va lue r a t e r than had taken va lue r a t e r than had taken va lue r a t e r than Ne t r a c t i l v i had taken va lue r a t e r than had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i had taken va lue r a t e r than had taken va lue r a t e r than had taken va lue r a t e r than had taken va lue r a t e r than Pe r cen lq had taken va lue r a t e r than had taken va lue r a t e r than had taken va lue r a t e r than had taken va lue r a t e r than N e t r a c t i o n I n s t a l l B u r d e n had taken va lue r a t e r than had taken va lue r a t e r than ta l had taken va lue r a t e r than i l i za t ion had taken va lue r a t e r than had taken va lue r a t e r than Another way you ld have got s c o r e good i n s t e a d i s i had taken va lue r a t e r than had taken va lue r a t e r than had taken va lue r a t e r than had taken va lue r a t e r than had taken va lue r a t e r than MS t l days had taken va lue r a t e r than had taken va lue r a t e r than had taken va lue r a t e r than N e t r a c t i o n I n s t a l l B u r d e n had taken va lue r a t e r than ta l had taken va lue r a t e r than had taken va lue r a t e r than Table Paired explanations generated on the FICO dataset Results show two full sets of explanations for similar individuals Later explanations are given for completeness only and are not suitable to be directly offered to a data-subject Example decisions can be seen in tables and The explanations are generated fully automatically using the method in the previous section with variable names extracted from the provided data and the meanings of special values provided by the dataset creators None of the previously mentioned monotonic constraints were violated by the learnt algorithm As can be seen in the tables the individual explanations generated at the start of the process are short human readable and do not require the data subject to understand either the internal complexity of the classifier and the variable encoding However taken in their entirety a complete set of explanations such as shown in table right or table can potentially be overwhelming and more thought is needed as to how to interactively present and navigate them Shown in table is the complete set of explanations generated for two highly similar individuals Several factors are worth remarking on First the stability of the generation of multiple counterfactuals is noteworthy Although there are small differences both in the values proposed and occasionally in the variables selected on the whole the generated sets of explanations are very similar to one another and provide similar data subjects with very similar amounts of information This consistent treatment is important for providing a sense of stability and coherence when offering repeated explanations to a data subject whos data slowly changes with time Second the results of the weighted norm noticeably differs from simple sparsity constraints with the numbers of factors selected fluctuating up and down as we proceed through the list of explanations that are ordered by their distance from the original datapoint Further work with data subjects is needed to determine which of these explanations are most comprehensible and which are most useful for determining future action Finally it is worth remarking that the diverse counterfactuals become both less diverse and less comprehensible towards the end of the procedure If a group of large changes are sufficient to push a counterfactual almost to the decision boundary it is possible for these variables to remain turned on as a necessary condition for any subsequent counterfactuals while incidental variables that make little contribution to the decision are toggled on and off Although one easy answer is to simply stop earlier more diverse counterfactuals could also be generated by using a less greedy approach Taken as a whole the generated counterfactuals provide insight into the general behaviour of the classifier One unexpected behaviour is that while a single missed payment is enough to move many people from a good credit prediction to bad it is not irredeemable and a strong credit record in other areas can compensate for this In such situations diverse counterfactual explanations could be invaluable as providing direct pathways to obtaining a good credit rating Although using counterfactuals in this way raises the spectre of people gaming the system and intentionally distorting their credit records to obtain a better score perhaps the most pragmatic response to this is to build more accurate systems so that as individuals make changes to improve their credit score their underlying risk of default also decreases As can be seen in the counterfactual explanations offered to good decisions Figure A visualisation of the weights learnt by logistic regression on the FICO dataset Weights are ordered by their median contribution to the score of each datapoint over the entire dataset with a positive sign indicating that they drive the classifier towards a score of good By way of contrast a direct visualisation of the learnt linear weights is shown in figure and the reader is invited to see what conclusions they can draw from them One of the most counterintuitive factors of the weights when presented like this is that a positive weight is associated with External-risk factor taking value However as discussed an external-risk estimate of may be the only counterfactual explanation offered for why someone gets a bad credit score This is due to the much larger positive contribution of a typical external-risk estimate CONCLUSION This is the first work to show how coherent counterfactual explanations can be generated for the mixed datasets commonly used in the real world and the first to propose a concrete method for generating diverse counterfactuals As such the methods proposed in this paper provide an significant step forward in what can be done with counterfactual explanations Generalising the approach to non-linear functions and indeed to non-differentiable classifiers such as k-nearest neighbour or random forests looks to be a useful direction for future work However linear functions represent part of machine learning that just works and are consistently used by industry and data scientists in a wide range of scenarios Reliable methods such as those discussed for generating both coherent and diverse explanations are needed if we want people to make use of them Collaboration between policy and technology is a two-way street Just as policy must respect the limitations of technology in what it calls for it is important to build the supporting technology in response to policy proposals Compelling ideas such as counterfactual explanations are of little use unless we develop the technology to make them work This paper has addressed major technological issues in one of the most substantial use cases for counterfactual explanations namely linear models for mixed financial data As mentioned in section the brute force enumeration of previous approaches do not scale to these datasets Our work represents progress towards making methods for counterfactual explanation that just work out of the box Full source code can be found at
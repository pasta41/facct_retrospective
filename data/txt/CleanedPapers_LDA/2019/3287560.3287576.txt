The Social Cost of Strategic Classification Consequential decision-making typically incentivizes individuals to behave strategically tailoring their behavior to the specifics of the decision rule A long line of work has therefore sought to counteract strategic behavior by designing more conservative decision boundaries in an effort to increase robustness to the effects of strategic covariate shift We show that these efforts benefit the institutional decision maker at the expense of the individuals being classified Introducing a notion of social burden we prove that any increase in institutional utility necessarily leads to a corresponding increase in social burden Moreover we show that the negative externalities of strategic classification can disproportionately harm disadvantaged groups in the population Our results highlight that strategy-robustness must be weighed against considerations of social welfare and fairness CONCEPTS Computing methodologies Machine learning Stochastic games KEYWORDS Strategic classification fairness machine learning INTRODUCTION As machine learning increasingly supports consequential decision making its vulnerability to manipulation and gaming is of growing concern When individuals learn to adapt their behavior to the specifics of a statistical decision rule its original predictive power will deteriorate This widely observed empirical phenomenon known as Campbells Law or Goodharts Law is often summarized as Once a measure becomes a target it ceases to be a good measure Institutions using machine learning to make high-stakes decisions naturally wish to make their classifiers robust to strategic behavior A growing line of work has sought algorithms that achieve higher utility for the institution in settings where we anticipate a strategic response from the the classified individuals Broadly speaking the resulting solution concepts correspond to more conservative decision boundaries that increase robustness to some form of distributional shift But there is a flip side to strategic classification As insitutional utility increases as a result of more cautious decision rules honest individuals worthy of a positive classification outcome may face a higher bar for success The costs incurred by individuals as a consequence of strategic classification are by no means hypothetical as the example of lending shows In the United States credit scores are widely deployed to allocate credit However even creditworthy individuals routinely engage in artificial practices intended to improve their credit scores such as opening up a certain number of credit lines in a certain time period In this work we study the tension between accuracy to the institution and impact to the individuals being classified We first introduce a general measure of the cost of strategic classification which we call the social burden Informally the social burden measures the expected cost that a positive individual needs to incur to be correctly classified correctly For a broad class of cost functions we prove there exists an intrinsic trade-off between institutional accuracy and social burden any increase in institutional accuracy comes at an increase in social burden Moreover we precisely characterize this trade-off and show the commonly considered Stackelberg equilibrium solution achieves maximal institutional accuracy at the expense of maximal social burden Equipped with this generic trade-off result we turn towards a more careful study of how the social burden of strategic classification impacts different subpopulations We find that the social burden can fall disproportionally on disadvantaged subpopulations under two different notions by which one group can be disadvantaged relative to another group Furthermore we show that as the institution improves its accuracy it exacerbates the gap between the burden to an advantaged and disadvantaged group Finally we illustrate these conditions and their consequences with a case study on FICO data Our Contributions In this paper we make the following contributions We prove a general result demonstrating the trade-off between institutional accuracy and individual utility in the strategic setting Our theoretical characterization is supplemented with examples illustrating when an institution would prefer to operate along different points in this trade-off curve We show fairness considerations inevitably arise in the strategic setting When individuals incur cost as a consequence of making a classifier robust to strategic behavior we show the costs can disproportionally fall by disadvantaged subpopulations Furthermore as the institution increases its robustness it also increases the disparity between subpopulations Using FICO credit data as a case-study we empirically validate our modeling assumptions and illustrate both the general trade-offs and fairness concerns involved with strategic classification in a concrete setting Reflecting on our results we argue that the existing view of strategic classification has been instituition-centric ignoring the social burden resulting from improved institutional utility Our framework makes it possible to select context-specific trade-offs between institutional and individual utility leading to a richer space of solutions Another key insight is that discussions of strategy-robustness must go hand in hand with considerations of fairness and the real possibility that robustness-promoting mechanisms can have disparate impact in different segments of the population MODEL Strategic classification Throughout this work we consider the binary classification setting Each individual has features x X and a label y Y The institution publishes a classifier X Y In the non-strategic setting the institution maximizes the non-strategic utility which is simply the classification accuracy of Pf x y In the strategic setting the individual can modify their features and the institution aims to preempt the individuals strategic manipulation In response to the institutions classifier the individual can change her features x to new features x However modification incurs a cost given by c X X R The individual then receives an individual utility x x x which trades off between the cost of manipulation x and the benefits of classification x The institution models the individual x as maximizing their utility x and acting according to the best-response to the classifier x argmax x x When it is clear from context we will drop the dependence on and write the individuals best response as x Although x may not have a unique maximizer it is assumed that the individual x does not adapt her features if she is already accepted by the classifier ie x or if there is no maximizer x she can move to such that x In cases where the individual does adapt let x be an arbitrary maximizer such that x In practice it is unlikely individuals actually play best-response solutions and we will discuss as appropriate the impact of deviations from best response play Given this model the institution aims to maximize the strategic utility which measures accuracy after individual responses Pf x y For example imagine that the institution is trying to rank pages on a social network Although the number of likes a page has may be predictive it is also an easy feature to game Therefore models with high strategic utility will assign low weight to this feature even if it is useful in the static setting Henceforth we will refer to the strategic utility as simply the institutional utility Social burden Focusing purely on maximizing U as done in prior work ignores the cost a classifier imposes on individuals To account for these costs we define the individual burden of a classifier as the minimum cost an individual needs to incur in order to be classified positively bf x x x For positive individuals with y a high individual burden means the individual has to incur great cost to obtain the correct classification To quantity this cost we introduce the social burden defined as the expected individual burden of positive individuals Definition Social burden The social burden of a classifier is defined as Bf E bf x y The social burden measures the expected cost that positive individuals would need to incur to be classified positively regardless of whether the best response x indicates that they should adapt One could imagine other ways of measuring the impact on individuals such as the expected utility of positive individuals E x y or the corresponding measure over all individuals rather than only positive individuals Most of our results still hold for these alternative measures and we relegate discussion about the choice of social burden to Section Assumptions on cost function While there are many possible models for the cost function we restrict our attention to a natural set of cost functions that we call outcome monotonic Outcome monotonic costs capture two intuitive properties Monotonically improving ones outcome requires monotonically increasing amounts of work and it is zero cost to worsen ones outcome This captures the intuition that for example it is harder to pay back loans than it is to go bankrupt Definition Outcome likelihood The outcome likelihood of an individual x is PY X x We assume that all individuals have a positive outcome likelihood ie for all x Definition Outcome Monotonic Cost A cost function c X X R is outcome monotonic if for any x x x X the following properties hold Zero-cost to move to lower outcome likelihoods x if and only if Monotonicity in first argument x x if and only if Monotonicity in second argument x x if and only if Under these assumptions we can equivalently express the cost as a cost over outcome likelihoods cL R defined in the following lemma Lemma When the cost function x is outcome monotonic then it can be written as a cost function over outcome likelihoods l B x where x x X are any points such that l and l Proof The monotonicity assumptions imply that if then and Thus l B x is well-defined because any points x and x such that l and l yield the same value of x Throughout the paper we will make use of the equivalent likelihood cost cL when a proof is more naturally expressed with cL rather than with the underlying cost c INSTITUTIONAL UTILITY VERSUS SOCIAL BURDEN In this section we characterize the inherent trade-offs between institutional utility and social burden in the strategic setting In particular we show any classifier that improves institutional utility over the best classifier in the static setting causes a corresponding increase in social burden To prove this result we first show that any classifier can be represented as a threshold classifier that accepts all individuals with outcome likelihood greater than some threshold Then we show increasing utility for the institution requires raising this threshold but that this always increases the social burden Equipped with this result we show the Pareto-optimal set of classifiers that increase institutional utility in the strategic setting corresponds to an interval I Each threshold I represents a particular trade-off between institutional utility and social burden Strategic classification corresponds to one extremum the best strategic utility but the worst social burden The non-strategic utility corresponds to the other doing nothing to prevent gaming Neither is likely to be the right trade-off in practical contexts Real domains will require a careful weighting of these two utilities leading to a choice somewhere in between Thus a main contribution of our work is exposing this interval General Trade-Off We now proceed to prove the trade-off between institutional utility and social burden Our first step is to show that in the strategic setting we can restrict attention to classifiers that threshold on the outcome likelihood assuming the cost is outcome monotonic as in Definition Definition Outcome threshold classifier An outcome threshold classifier is a classifier of the form x for In practice the institution may not know the outcome likelihood PY X x However as shown in the next lemma for any classifier that they do use there is a threshold classifier with equivalent institutional utility and social burden Thus we can restrict our theoretical analysis to only consider threshold classifiers Lemma For any classifier there is an outcome threshold classifier such that and Bf Bf Proof Let minx x be the minimum outcome likelihood at which an individual is accepted by the classifier Then let x be the outcome threshold classifier that accepts all individuals above We will show that the institutional utility and social burden of and are equal Since the cost function is outcome monotonic it is the same cost to move to any point with the same outcome likelihood Furthermore it is higher cost to move to points of higher likelihood ie if then x x Since individuals game optimally when an individual changes her features in response to the classifier she has no incentive to move to a point with likelihood higher than that would just cost more Therefore she will move to any point with likelihood to be accepted by and will incur the same cost regardless of which point it is Thus we can write the set of individuals accepted by as x x x x x x x x x Since the individuals accepted by and are equal Therefore their institutional utilities are equal We can similarly show that the social burdens of and are also equal Bf E min x x x y E x y for some x E x y for some x E min x x x y Bf Since outcome threshold classifiers can represent all classifiers in the strategic setting we will henceforth only consider outcome threshold classifiers Furthermore we will overload notation and and to refer and where x is the outcome threshold classifier with threshold Figure illustrates how institutional utility and social burden change as the threshold of the classifier increases The institutional utility is quasiconcave while the social burden is monotonically non-decreasing The next lemma provides a formal characterization of the shapes shown in Figure Theorem The institutional utility is quasiconcave in and has a maximum at a threshold where is the threshold of the non-strategic optimal classifier The social burden is monotonically non-decreasing in Furthermore if then Social Burden Institution Utility U B Figure The general shapes of the institution utility and social burden as a function of the threshold the institution chooses The threshold t is the non-strategic optimal while the threshold is the Stackelberg equilibrium Proof be the set of individuals accepted by in the strategic and non-strategic setting respectively If we is the optimal nonstrategic acceptance region any x has and one can by not which Therefore if a threshold is optimal for the institution ie if then Recall that a univariate function z is quasiconcave if there exists z such that is non-decreasing for z z and is nonincreasing for z z Let be as above For we have Since is optimal is the optimal strategic acceptance region and thus Similarly if we have and thus Therefore is quasiconcave in The individual burden x x is monotonically non-decreasing in Since the social burden is equal to x y the social burden is also monotonically nondecreasing Suppose and without loss of generality let For all individuals x x x If there is at least one individual x such that x x then But there must exist an individual x such that x and x Y since by assumption For this individual x x implies As a corollary if the institution increases its utility beyond that attainable by the optimal classifier in the non-strategic setting then the institution also causes higher social burden Corollary Let be any threshold and be the optimal threshold in the non-strategic setting then Choosing a Concrete Trade-off The previous section shows increases in institutional utility come at a cost in terms of social burden and vice-versa This still leaves open the question what is the concrete trade-off an institution should choose Theorem provides a precise characterization of the choices available to trade-off between institutional utility and social burden The baseline choice for the institution is to not account for strategic behavior and use the non-strategic optimum Maximizing utility without regard to social burden leads the institution to choose In general the interval offers the set of trade-offs the institution considers Choosing can increase robustness at the price of increasing social burden Thresholds are not Pareto-efficient and are not considered Much of the prior work in machine learning has focused exclusively on solutions corresponding to the thresholds at the extreme and The threshold is the solution when strategic behavior is not accounted for The threshold is also known as the Stackelberg equilibrium and is the subject of recent work in strategic classification While using may be warranted in some cases a proper accounting of social burden would lead institutions to choose classifiers somewhere between the extremes of and The exact choice of is context-dependent and depends on balancing concerns between institutional and broader social interest We now highlight cases where using or may be suboptimal and using a threshold that balances robustness with social burden is preferable Example Expensive features If measuring a feature is costly for individuals and offers limited gains in predictive accuracy an institution may choose to ignore the feature even if it means giving up accuracy on the margin In an educational context a university may decide to no longer require applicants to submit standardized test scores which can cost applicants hundreds of dollars if the corresponding improvement in admissions outcomes is very small Example Reducing social burden under resource constraints Aid organizations increasingly use machine learning to determine where to allocate resources after natural disasters In these cases positive individuals are precisely those people who are in need of aid and may experience very high costs to change their features Using thresholds with high social burden is therefore undesirable At the same time aid organizations often face significant resource constraints False positives from individuals gaming the classifier ties up resources that could be better used elsewhere Consequently using the non-strategic threshold is also undesirable The aid organization should choose a some threshold with that reflects these trade-offs Example Misspecification of agent model Strategic classification models typically assume the individual optimally responds to the classifier In reality individuals will not have perfect knowledge of the classifier when it is first deployed Instead they may be able to learn about how the classifier works over time and gradually improve their ability to game the classifier For example self-published romance authors exchanged information in private chat groups about how to best game Amazons book recommendation algorithms For the institution it is difficult to a priori model the dynamics of how information about the classifier propagates A preferable solution may be to simply make the assumption that the individual can best respond to the classifier but to only gradually increase the threshold from the non-strategic to the Stackelberg optimal over time In fact misspecification of the agent model described above is why Brückner et al suggest the Stackelberg equilibrium is too conservative and instead prefer to use Nash equilibrium strategies Complementary to their observation we show that there is a more general reason Nash equilibria may be preferable Namely that Nash equilibria have lower social burden than the Stackelberg solution As the following lemma shows in our context the set of Nash equilibria form an interval I for some t The proof is deferred to the appendix Lemma Suppose the cost over likelihoods cL is continuous and ie all likelihoods have non-zero support Then the set of Nash equilibrium strategies for the institution is for some where is the non-strategic optimal threshold and is the Stackelberg equilibrium strategy The Stackelberg equilibrium requires the institution to choose whereas Nash equilibria give the institution latitude to trade-off between institutional utility and social burden by choosing from the interval I This provides an additional argument in favor of Nash equilibria institutions can still reason in terms of equilibria and achieve more favorable outcomes in terms of social burden FAIRNESS TO SUBPOPULATIONS Our previous section showed that increased robustness in the face of strategic behavior comes at the price of additional social burden In this section we show this social burden is not fairly distributed when the individuals being classified are from latent subpopulations say of race gender or socioeconomic status the social burden can disproportionately fall on disadvantaged subpopulations Furthermore we find that improving the institutions utility can exacerbate the gap between the social burden incurred by an advantaged and disadvantaged group Concretely suppose each individual is from a subpopulation ab The social burden a classifier has on a is the expected minimum cost required for a positive individual from to be accepted E minx x x Y G We can then define the social gap between groups a and b Definition Social gap The social gap Gf induced by a classifier is the difference in the social burden to compared to a Gf Bb Ba The social gap is a measure of how much more costly it is for a positive individual from to be accepted by the classifier than a positive individual from group a For example there is evidence that women need to attain higher educational qualifications than their male counterparts to receive the same salary A high social gap is alarming for two reasons First even when two people from group a and group b are equally qualified the individual from group a may choose not to participate at all because of the cost she would need to endure to be accepted Secondly if she does decide to participate she may continue to be at a disadvantage after being accepted because of the additional cost she had to endure eg repaying student loans Non-strategic classification can already induce a social gap between two groups and strategic classification can exacerbate this gap We show this under two natural ways group b may be disadvantaged In the first setting the feature distributions of group a and b are such that a positive individual from group b is less likely to be considered positive compared to group a In the second setting individuals from group b have a higher cost to adapt their features compared to group a Under both of these conditions any improvement the institution can make to its own strategic utility has the side effect of worsening increasing the social gap Different Feature Distributions In the first setting we analyze the way groups a and b differ is through their distributions over features We say that group b is disadvantaged if the features distributions are such that positive individuals from group b are less likely to be considered positive than those from group a Formally this can be characterized as the following Definition Disadvantaged in features Let Y G be the outcome likelihood of a positive individual from and let be the cumulative distribution function of We say that group b is disadvantaged in features if Fb l Fa l for all l In the economics literature the relationship between La and Lb is referred to as strict first-order stochastic dominance Intuitively that group b is disadvantaged in features if and only if the distribution of La can be transformed to the distribution of Lb by transferring probability mass from higher values to lower values This definition captures the notion that the outcome likelihood of positive individuals from group b is skewed lower than the outcome likelihood of positive individuals from a In a case study on FICO credit scores in Section we find the minority group blacks is disadvantaged in features compared to the majority group whites see Figure There are many reasons that a group could be disadvantaged in features Below we go through a few potential causes Example Group membership explains away features Even if two groups are equally likely to have positive individuals ie PY G a PY G b group b can still be disadvantaged compared to group a Consider the graph below Although the label Y is independent of the group G the label Y is not independent of the group G once conditioned on the features X because the group G can provide an alternative reason for the observed features G Y X Concretely let groups a and b be native and non-native speakers of english X be the number of grammatical errors on an individuals job application and Y be whether the individual is a qualified candidate Negative individuals Y are less meticulous when filling out their application and more likely to have grammatical errors However for individuals from group b there is another explanation for having grammatical errors being a non-native speaker Thus positive individuals from group b end up with lower outcome likelihoods than those from a even though they may be equally qualified Example Predicting base rates Suppose the rate of positives in group b is lower than that of group a PY G b PY G a If there is a feature in the dataset that can be used as a proxy for predicting the group such as zip code or name for predicting race then the outcome likelihoods of positive individuals from group b can end up lower than those of positive individuals from group a because the features are simply predicting the base rate of each group Social gap increases We now state and prove the main result showing that the social gap increases as the institution increases its threshold for acceptance Before turning to the result we introduce one technical requirement The likelihood condition is that cL l is monotonically non-increasing in for l When the cost function c is outcome monotonic the likelihood condition is satisfied for a broad class of differentiable likelihood cost functions cL such as the following examples Differentiable separable cost functions of the form l cl for c c R Differentiable shift-invariant cost functions of the form l cl l l l l l for convex c R Notably any linear cost l l where satisfies the likelihood condition Under the likelihood condition we now show that the social gap increases as the institution increases its threshold for acceptance Theorem Let be the threshold of the classifier If group b is disadvantaged in features compared to group a and cL l is monotonically non-increasing in then is positive and monotonically increasing over Proof By Lemma any outcome monotonic cost function can be written as a cost over outcome likelihoods Therefore the social burden can be written as E Y G where denotes the CDF of the group outcome likelihood Integrating by parts we obtain a simple expression for l l where the last line follows because and This expression for allows us to conveniently write the social gap as Bb Ba l Fa l Fb l We now argue the social gap is positive By the monotonicity assumptions cL l for l Since group b is disadvantaged in features Fa l Fb l for l Therefore Now we show is increasing in Let Then the difference in the social gap is given by l Fa l Fb l l Fa l Fb l Since group b is disadvantaged in features Fa l Fb l for all l By assumption cL l is monotonically non-increasing in so the first term is non-negative Similarly cL l by monotonicity so the second term is positive Hence which establishes is monotonically increasing in As a corollary if the institution improves its utility beyond the non-strategic optimal classifier then it also causes the social gap to increase Corollary Suppose group b is disadvantaged in features compared to group a and cL l is monotonically non-decreasing in Let be a threshold and be the optimal nonstrategic threshold If then Proof By Theorem if then By Theorem if then Different Costs In Section we showed that when two subpopulations have different feature distributions the social burden can disproportionately fall on one group In this section we show that even if the feature distributions of the two groups are exactly identical the social burden can still disproportionately impact one group We have thus far assumed the existence of a cost function c that is uniform across groups a and b For a variety of structural reasons it is unlikely this assumption holds in practice Rather it is often the case that different groups experience different costs for changing their features When the cost for group b is systematically higher than the cost for group a we prove group b incurs higher social burden than group a Furthermore if the institution improves its utility by increasing its threshold then as a side effect it also increases the social gap between group b and a Theorem Much of the prior work on fairness in classification focuses on preventing unfairness that can arise when different subpopulations have different distributions over features and labels Our result provides a reason to be concerned about the unfair impacts of a classifier even when two groups have identical initial distributions Namely that it can be easier for one group to game the classifier than another Formally we say that group b is disadvantaged in cost compared to group a if the following condition holds Definition Disadvantaged in cost Let x be the cost for an individual from group to adapt their features from x to x Group b is disadvantaged in cost if cb x x x x for all x x X and some scalar Next we give a variety of example scenarios of when a group can be disadvantaged in cost Example Opportunity Costs Many universities have adopted gender-neutral policies that stop the tenure-clock for a year for family-related reasons eg childbirth Ostensibly no research is expected while the clock is stopped However the adoption of gender-neutral clocks actually increased the gap between the percentage of men and women who received tenure The suggested cause is that women still shoulder more of the burden of bearing and caring for children compared to men Men who stop their tenure clock are more productive during the period than women who have a higher opportunity cost to doing research while raising a child Example Information Asymmetry A large portion of high-achieving low-income students do not apply to selective colleges despite the fact that these colleges are typically less expensive for them because of the financial aid they would receive This phenomenon seems to be due to low-income students having less access to information about college Since low-income students have more barriers to gaining information about college it is natural to assume that compared to their wealthier peers they have a higher cost to strategically manipulating their admission features Example Economic Differences Consider a social media company that wishes to classify individuals as influencers either to more widely disseminate their content or to identify promising accounts for online marketing campaigns Wealthy individuals can purchase followers or likes whereas other groups have to increase these numbers organically Consequently the costs to increasing ones popularity metric differs based on access to capital Finally our main technical result shows that even when the distributions of groups a and b are identical if group b is disadvantaged in cost then when the institution increases its threshold for acceptance it also increases the social gap between the two groups Theorem Suppose positive individuals from groups a and b have the same distribution over features ie if Z X Y then Z is independent of the group G If group b is disadvantaged in cost compared to group a then the social gap is non-negative and monotonically non-decreasing in the threshold Proof Since X Y is independent of G the social burden to a group can be written as X min x x x x Y where is the outcome likelihood classifier with threshold The social gap can then be expressed as Bb Ba X min x x ca x x x Y Ba Since the group social burden Ba is non-negative and monotonically non-decreasing the social gap is also non-negative and monotonically non-decreasing CASE STUDY FICO CREDIT DATA We illustrate the impact of strategic classification on different subpopulations in the context of credit scoring and lending FICO scores are widely used in the United States to predict credit worthiness The scores themselves are derived from a proprietary classifier that uses features that are susceptible to gaming and strategic manipulation for instance the number of open bank accounts We use a sample of FICO scores derived from TransUnion TransRisk scores and preprocessed by Hardt et al The scores X are normalized to lie between and An individuals outcome is labeled as a default if she failed to pay a debt for at least days on at least one account in the ensuing month period Default events are labeled with Y and otherwise repayment is denoted with Y The two subpopulations are given by race a white and b black We assume the credit lending institution accepts individuals based on a threshold on the FICO score Using the normalized scale a threshold of is typically used to determine eligibility for prime rate loans Our results thus far have used thresholds on the outcome likelihood rather than a score However as shown in Figure the outcome likelihood is monotonic in the FICO score Therefore all our conditions and results can be validated using the score instead of the outcome likelihood Different Feature Distributions In Section we studied the scenario where the distribution of outcome likelihoods PY X differed across subpopulations In particular if the likelihoods of the positive individuals in group B tend to be lower than the positive individuals in group A then increasing strategic robustness increases the social gap between A and B Interestingly such a skew in score distributions exists in the FICO data Black borrowers who repay their loans tend to have lower FICO scores than white borrowers who repay their loans In terms FICO Score C D of P os it iv e In di vi du al s Disadvantaged in Features White Black Figure Comparison of the distribution of FICO scores among black and white borrowers who repaid their loans Credit-worthy black individuals tend to have lower credit scores than credit-worthy white individuals The comparison of the corresponding CDFs demonstrates our disadvantaged in features assumption holds FICO Score R ay m en t P ro ba bi lit y Repayment Probability as a Function of Score Figure Repayment probability as a function of credit score Crucially the probability of repayment PY x is monotonically increasing in x of the corresponding score CDFs for every score x Figure demonstrates this observation When the score distribution among positive individuals is skewed Theorem guarantees the social gap between groups is increasing in the threshold under a reasonable cost model Operationally raising the loan threshold to protect against strategic behavior increases the relative burden on the black subgroup To demonstrate this empirically we use a coarse linear cost model x x for some Here corresponds to the cost of raising ones FICO score one point Since the probability of repayment PY x is monotonically increasing in x the linear cost c satisfies the requisite outcome monotonicity conditions In Figure we compute as varies from to for a range of different value of For any the social utility gap is increasing in Moreover as becomes large the rate of increase in the social gap grows large as well Threshold l G G Social Gap with the Same Cost Per-Group Figure Impact of increasing the threshold on white and black credit applicants When the cost to changing ones score is small increases to the threshold have only a small effect on the social gap However as becomes large even small increases to the threshold can create large discrepancies in social burden between the two groups Different Cost Functions In Section we demonstrated when two subpopulations are identically distributed but incur different costs for changing their features there is a non-trivial social gap between the two In the context of the FICO scores it is plausible that blacks are both disadvantaged in features and experience higher costs for changing their scores For instance outstanding debt is an important component of FICO scores One way to reduce debt is to increase earnings However a persistent black-white wage gap between the two subpopulations suggest increasing earnings is easier for group a than group b This setting is not strictly captured by our existing results and we should expect the effects of both different costs functions and different feature distributions to compound and exacerbate the unfair impacts of strategic classification To illustrate this phenomenon we again use a coarse linear cost model Suppose group A has cost x x for some and group B has cost cB x x x for some As in Section group B is disadvantaged in cost provided the ratio In Figure we show the social gap for various settings of The social gap is always increasing as a function of and the rate of increase grows large for even moderate values of When is large even small increases in can disproportionately increase the social burden for the disadvantaged subpopulation RELATED WORK Strategic Classification Prior work on strategic classification focuses solely on the institution primarily aiming to create high-utility solutions for the institution Our work on the other hand studies the tradeoff between the institutions utility and the burden to the individuals being classified Brückner and Scheffer Dong et al Hardt et al give algorithms to compute the Stackelberg equilibrium which corresponds to the extreme solution in our trade-off curves Threshold S l G G Social Gap with Different Costs Per-Group Figure Impact of increasing the threshold on white and black credit applicants under the assumption that both groups incur different costs for increasing their credit score As the ratio between the costs increases the social cost gap grows rapidly between the two groups Although the Stackelberg equilibrium leads to maximal institutional utility we show that it also causes high social burden We give several examples of when the high social burden induced by the Stackelberg equilibrium makes it an undesirable solution for the institution Rather than the Stackelberg equilibrium others have also considered finding Nash equilibria of the game Brückner et al argue that since in practice people cannot optimally respond to the classifier the Stackelberg solution tends to be too conservative and thus a Nash equilibrium strategy is preferable Our work provides a complementary reason to prefer Nash equilibria over the Stackelberg solution Namely for a broad class of cost functions any Nash equilibrium that is not equal to the Stackelberg equilibrium places lower social burden on individuals Finally we focus on the setting where individuals are merely gaming their features ie they do not improve their true label by adapting their features However if the classifier is able to incentivize strategic behavior that helps improve negative individuals then the social burden placed on positive individuals may be considered acceptable Kleinberg and Raghavan studies how to design classifiers that produce such incentives Fairness Our work studies how strategic classification results in differing impacts to different subpopulations and is complementary to the large body of work studying the differing impacts of classification The prior work on classification is primarily concerned with preventing unfairness that can arise due to subpopulations having differing distributions over features or labels We show that in the strategic setting a classifier can have differing impact due to the subpopulations having differing distributions or differing costs to adapting their features Therefore when individuals are strategic our work provides an additional reason to be concerned about the fairness of a classifier In particular it can be easier for one group to game the classifier than another Furthermore we show that if the institution modifies the classifier it uses to be more robust to strategic behavior then it also as a side effect increases the gap between the cost incurred by a disadvantaged subpopulation and an advantaged population Thus strategic classification can exacerbate unfairness in classification Our work is also complementary to Liu et al who also analyze how the institutions utility trades-off with the impact to individuals They study the trade-off in the non-strategic setting and measure the impact of a classifier using a dynamics model of how individuals are affected by the classification they receive We study the tradeoff in the strategic setting and measure the impact of a classifier by the cost of the strategic behavior induced by the classifier In concurrent work Hu et al also study negative externalities of strategic classification In their model they show that the Stackelberg equilibrium leads to only false negative errors on a disadvantaged population and false positives on the advantaged population Furthermore they show that providing a cost subsidy for disadvantaged individuals can lead to worse outcomes for everyone DISCUSSION OF SOCIAL BURDEN To measure the impact of strategic classification on the individuals being classified we introduced a measure of social burden defined as the expected cost that positive individuals need to incur to be classified positively Bf E x x y An alternative measure one might consider is the expected individual utility for the positives Sf E x y which we will denote the social utility We prefer social burden to social utility because it makes fewer assumptions about individual behavior Social utility measures the utility of the individual while assuming that they respond optimally and needs the assumption to hold to be a meaningful measure Social burden on the other hand applies irrespective of the different policies individuals may actually act according to Our analysis assumes the institution assumes individuals respond optimally but we ourselves believe this to be a strong assumption to hold in practice and would like our measure of impact on individuals to apply regardless Moreover most of our results are agnostic to the specific choice of social cost measure The results in Section about the tradeoff between institutional utility and social burden all still hold Specifically Theorem holds with social utility instead of social burden and monotonically non-increasing instead of monotonically nondecreasing since lower utility is worse For our results in Section ie Theorems and there is still always a non-negative social gap now defined as the difference in social utilities between the groups but it is not necessarily true that the social gap increases as the institutions threshold increases While both social burden and social utility apply only to positive individuals one could also use versions that integrate over all individuals Bf E x x and Sf E x Our results go through and the results go through for Sf However in many cases giving a positive Definition should be modified to no longer condition on Y classification eg a loan to a negative individual someone who will default can result in a long-term negative impact to that individual In general it is uncertain whether the reducing the costs incured by the negative individuals confers positive social benefits and we do not incorporate these costs into our measure Overall there are many potential measures that are complementary to our measure of social burden but they all provide a similar takeaway Namely that in the strategic setting there is a tradeoff between institutional accuracy and individual impact that must be considered when making choices about strategy-robustness
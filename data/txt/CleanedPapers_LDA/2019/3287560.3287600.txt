Years of Test Unfairness Lessons for Machine Learning Quantitative definitions of what is unfair and what is fair have been introduced in multiple disciplines for well over years including in education hiring and machine learning We trace how the notion of fairness has been defined within the testing communities of education and hiring over the past half century exploring the cultural and social context in which different fairness definitions have emerged In some cases earlier definitions of fairness are similar or identical to definitions of fairness in current machine learning research and foreshadow current formal work In other cases insights into what fairness means and how to measure it have largely gone overlooked We compare past and current notions of fairness along several dimensions including the fairness criteria the focus of the criteria eg a test a model or its use the relationship of fairness to individuals groups and subgroups and the mathematical method for measuring fairness eg classification regression This work points the way towards future research and measurement of unfairness that builds from our modern understanding of fairness while incorporating insights from the past CONCEPTS General and reference Surveys and overviews Metrics Social and professional topics History of computing Historical people History of computing theory Socio-technical systems User characteristics Mathematics of computing Probability and statistics Probabilistic algorithms Theory of computation Probabilistic computation Computing methodologies Algebraic algorithms Software and its engineering Model checking KEYWORDS history fairness ML fairness test fairness psychometrics INTRODUCTION The United States Civil Rights Act of effectively outlawed discrimination on the basis of of an individuals race color religion sex or national origin The Act contained two important provisions that would fundamentally shape the publics understanding of what it meant to be unfair with lasting impact into modern day Title VI which prevented government agencies that receive federal funds including universities from discriminating on the basis of race color or national origin and Title VII which prevented employers with or more employees from discriminating on the basis of race color religion sex or national origin Assessment tests used in public and private industry immediately came under public scrutiny The question posed by many at the time was whether the tests used to assess ability and fit in education and employment were discriminating on bases forbidden by the new law This stimulated a wealth of research into how to mathematically measure unfair bias and discrimination within the educational and employment testing communities often with a focus on race The period of time from to in particular gave rise to fairness research with striking parallels to ML fairness research from until today including formal notions of fairness based on population subgroups the realization that some fairness criteria are incompatible with one another and pushback on quantitative definitions of fairness due to their limitations Into the s there was a shift in perspective with researchers moving from defining how a test may be unfair to how a test may be fair It is during this time that we see the introduction of mathematical criteria for fairness identical to the mathematical criteria of modern day Unfortunately this fairness movement largely disappeared by the end of the s as the different and sometimes competing notions of fairness left little room for clarity on when one notion of fairness may be preferable to another Following the retrospective analysis of Nancy Cole who introduced the equivalent of Hardt et als equality of opportunity in The spurt of research on fairness issues that began in the late s had results that were ultimately disappointing No generally agreed upon method to determine whether or not a test is fair was developed No statistic that could unambiguously indicate whether or not an item is fair was identified There were no broad technical solutions to the issues involved in fairness By learning from this past we hope to avoid such a fate Before further diving in to the history of testing fairness it is useful to briefly consider the structural correspondences between tests and ML models Test items questions are analogous to model features and item responses analogous to specific activations of those features Scoring a test is typically a simple linear model which produces a possibly weighted sum of the item scores Sometimes test scores are normalized or standardized so that scores fit a desired range or distribution Because of this correspondence much of the math is directly comparable and many of the underlying ideas in earlier fairness work trivially map on to modern day ML fairness History doesnt repeat itself but it often rhymes and by hearing this rhyme we hope to gain insight into the future of ML fairness Following terminology of the social sciences applied statistics and the notation of we use demographic variable to refer to an attribute of individuals such as race age or gender denoted by the symbol A We use subgroup to denote a group of individuals defined by a shared value of a demographic variable eg A a Y indicates the ground truth or target variable R denotes a score output by a model or a test and D denotes a binary decision made using that score We occasionally make exceptions when referencing original material HISTORY OF FAIRNESS IN TESTING s Bias and Unfair Discrimination Concerned with the fairness of tests for black and white students T Anne Cleary defined a quantitative measure of test bias for the first time cast in terms of a formal model for predicting educational outcomes from test scores A test is biased for members of a subgroup of the population if in the prediction of a criterion for which the test was designed consistent nonzero errors of prediction are made for members of the subgroup In other words the test is biased if the criterion score predicted from the common regression line is consistently too high or too low for members of the subgroup With this definition of bias there may be a connotation of unfair particularly if the use of the test produces a prediction that is too low Emphasis added According to Clearys criterion the situation depicted in Figure a is biased for members of subgroup if the regression line is used to predict their ability since it under-predicts their true ability For Cleary the situation depicted in Figure b is not biased since data from each of the subgroups produce the same regression line that line can be used to make predictions for either group In addition to defining bias in terms of predictions by regression models Cleary also performed a study on real-world data from three state-supported and state-subsidized schools comparing college GPA with SAT scores Racial data was obtained from an admissions office from an NAACP list of black students and from examining class pictures Cleary used Analysis of Covariance ANCOVA to test the relationships between SAT and scores with GPA grades Contrary to some expectations Cleary found little evidence of the SAT being a biased predictor of GPA Later larger studies found that the SAT overpredicted the GPA of black students it may be that the SAT is biased but less so than the GPA While Clearys focus was on education her contemporary Robert Guion was concerned with unfair discrimination in employment Arguing for the importance of quantitative analyses in he wrote that Illegal discrimination is largely an ethical matter but the fulfillment of ethical responsibility begins with technical competence and defined unfair discrimination to be when persons with equal probabilities of success on the job have unequal probabilities of being hired for the job However Guion recognized the challenges in using constructs such as the probability of success We can observe actual success and failure after selection but the probability of success is not itself observable and a sophisticated model is required to estimate it at the time of selection By the end of the s there was political and legal support backing concerns with the unfairness of the educational system for black children and the unfairness of tests purporting to measure black intellectual competence Responding to these concerns the Association of Black Psychologists formed in immediately published A Petition of Concerns calling for a moratorium on standardized tests which are used to maintain and justify the practice of systematically denying economic opportunities The NAACP followed up on this in by adopting a resolution that demanded a moratorium on standardized testing wherever such tests have not been corrected for cultural bias cited by Meanwhile advocates of testing worried that alternatives to testing such as interviews would introduce more subjective bias As the s turned to the s work began to arise that parallels the recent evolution of work in ML fairness marking a change in framing from unfairness to fairness Following Thorndike The discussion of fairness in what has gone before is clearly oversimplified In particular it has been based upon the premise that the available criterion score is a perfectly relevant reliable and unbiased measure Thorndikes sentiment was shared by other academics of the time who in examining the earlier work of Cleary objected that it failed to take into account the differing false positive and false negative rates that occur when subgroups have different base rates ie A is not independent of Y With the goal of moving beyond simplified models Thorndike proposed one of the first quantitative criteria for measuring test fairness With this shift Thorndike advocated for considering the contextual use of a test A judgment on test-fairness must rest on the inferences that are made from the test rather than on a comparison of mean scores in the two populations One must then focus attention on fair use of the test scores rather than on the scores themselves Contrary to Cleary Thorndike argued that sharing a common regression line is not important as one can achieve fair selection goals by using different regression lines and different selection thresholds for the two groups As an alternative to Cleary Thorndike proposed that the ratio of predicted positives to ground truth positives be equal for each group Using confusion matrix terminology this is equivalent to requiring that the ratio TP FP/TP be equal for each subgroup According to Thorndike the situation in Figure a is fair for test cutoff x Figure b is unfair using any single threshold but fair if threshold x for group Similar to modern day ML fairness eg Friedler et al in Thorndike also pointed out the tension between individual notions of fairness and group notions of fairness the two definitions of fairness one based on predicted criterion score for individuals and the other on the distribution of criterion scores in the two groups will always be in conflict The conflict was also raised by others in the period including Sawyer et al in a foreshadowing of the compas debate of universities covert attempts to suppress the numbers of Jewish students whose performance on entrance exams had led them to become an increasing percentage of the student population a Labels on regression lines indicate which subgroup they fit b The regression line labeled fits both subgroups separately and hence also their union Figure Petersen and Novicks original figures demonstrating fairness criteria The marginal distributions of test scores and ground truth scores for subgroups and are shown by the axes A conflict arises because the success maximization procedures based on individual parity do not produce equal opportunity equal selection for equal success based on group parity and the opportunity procedures do not produce success maximization equal treatment for equal prediction based on individual parity Almost as an aside Thorndike mentions the existence of another regression line ignored by Cleary the line that estimates the value of the test score R given the target variable Y This idea hints at the notion of equal opportunity for those with a given value of Y an idea which soon was picked up by Darlington and Cole At a glance Clearys and Thorndikes definitions are difficult to compare directly because of the different ways in which theyre defined Darlington helped to shed light on the relationship between Cleary and Thorndikes conceptions of fairness by expressing them in a common formalism He defines four fairness criteria in terms of the correlation between the demographic variable and the test score Following Darlington Clearys criterion can be restated in terms of correlations of the culture variable with test scores If Clearys criterion holds for every subgroup then Similarly Thorndikes criterion is equivalent to requiring that The criterion is motivated by thinking about R as a dependent variable affected by independent variables A and Y If A has no direct effect on R once Y is taken into account then we have a zero partial correlation ie Y An alternative starkly simple criterion of recognizable as modern day demographic parity is introduced but not dwelt on Darlingtons mapping of Clearys and Thorndikes criteria lets him prove that theyre incompatible except in the special cases where the test perfectly predicts the target variable or where the target variable is uncorrelated with the demographic variable Figure reproduced from Darlingtons work criterion only holds if A R and Y have a multivariate normal distribution Figure Darlingtons original graph of fair values of the correlation between culture and test score in Darlingtons notation plotted against the correlation between test score and ground truth according to his definitions The correlation between the demographic and target variables is assumed here to be fixed at shows that for any given non-zero correlation between the demographic and target variables definitions and converge as the correlation between the test score and the target variable approach When the test has only a poor correlation with the target variable there may be no fair solution using definition Figure enables a range of further observations According to definition for a given correlation between demographic and target variables the lower the correlation of the test with the target variable the higher it is allowed to correlate with the demographic variable and still be considered fair Definition on the other hand is the opposite in that the lower the correlation of the test with the target variable the lower too must be the the tests correlation with the demographic variable Darlingtons criterion is the geometric mean of criteria and a compromise position midway between the two however a compromise may end up satisfying nobody psychometricians are not in the habit of agreeing on important definitions or theorems by compromise Darlington shows that definition is the only one of the four whose errors are uncorrelated with the demographic variable where by errors he means errors in the regression task of estimating Y from R Category Description individual Fairness criterion defined purely in terms of individuals non-comparative Fairness criterion for each subgroup does not reference other subgroups subgroup parity Fairness criterion defined in terms of parity of some value across subgroups correlation Fairness criterion defined in terms of the correlation of the demographic variable with the model output Table Categories of Fairness Criteria In Cole continued exploring ideas of equal outcomes across subgroups defining fairness as all subgroups having the same True Positive Rate TPR recognizable as modern day equality of opportunity That same year Linn introduced but did not advocate for equal Positive Predictive Value PPV as a fairness criterion recognizable as modern day predictive parity is a property of the test itself This is contrary to Thorndike Linn and Cole who take fairness to be a property of the use of a test The latter group tended to assume that a test is static and focused on optimizing its use whereas Clearys concerns were with how to improve the tests themselves Cleary worked for Educational Testing Services and one can imagine a test being designed allowing for a range of use cases since it may not be knowable in advance either i the precise populations on which it will be deployed nor ii the number of students which an institution deploying the test is able to offer places to By March the interest in fairness in the educational testing community was so strong that an entire issue of the Journal of Education Measurement was devoted to the topic including a lengthy lead article by Peterson and Novick in which they consider for the first time the equality of True Negative Rates TNR across subgroups and equal TPR equal TNR across subgroups modern day equalized odds Similarly they consider the case of equal PPV and equal NPV across subgroups four distinct categories individual non-comparative subgroup parity and correlation defined in Table It should be emphasized that in not all cases where a researcher defined a criterion did they also advocate for it In particular Darlington Linn Jones and Peterson and Novick all define criteria purely for the purposes of exploring the space of concepts related to fairness A summary of fairness technical definitions during this time is listed in Table The Fairness Tide Turns Immediately after the the journal issue of research into quantitative definitions of test fairness seems to have come to a halt Considering why this happened may be a valuable lesson to learn PPV and NPV on the grounds that either combination requires unusual circumstances However there is a flaw in their reasoning For example arguing against equal TPR and equal TNR they claim that this requires equal base rates in the ground truth in addition to equal TPR from for modern day fairness research The same Cole who in proposed equality of TPR wrote in that In short research over the last or so years has not supplied any analyses to unequivocally indicate fairness or unfairness nor has it produced clear procedures to avoid unfairness To make matters worse the views of fairness of the measurement profession and the views of the general public are often at odds Foreshadowing this outcome statements from researchers in the s indicate an increasing concern with how fairness criteria obscure the fundamental problem which is to find some rational basis for providing compensatory treatment for the disadvantaged Following Peterson and Novick the concepts of culture-fairness and group parity are not viable in practice leading to models that can sanction the discrimination they seek to rectify They argue that fairness should be reconceptualized as a problem in maximizing expected utility recognizing high social utility in equalizing opportunity and reducing disadvantage A related thread of work highlights that different fairness criteria encode different value systems and that quantitative techniques alone cannot answer the question of which to use In Darlington urges that the concept of cultural fairness be replaced by cultural optimality which takes into account a policy-level question concerning the optimum balance between accuracy and cultural factors In Thorndike points out that ones value system is deeply involved in ones judgment as to what is fair use of a selection device and similarly in Linn draws attention to the fact that Values are implicit in the models To adequately address issues of values they need to be dealt with explicitly Hunter and Schmidt begin to address this issue by bringing ethical theory to the discussion relating fairness to theories of individualism and proportional representation Current work may learn from this point in history by explicitly connecting fairness criteria to different cultural and social values s on Differential Item Functioning Concurrent with the development of criteria for the fair use of tests another line of research in the measurement community concerned looking for bias in test questions items In Cleary and Hilton used an analysis of variance ANOVA design to test the interaction between race socioeconomic level and test item Ten years later the related idea of Differential Item Functioning DIF was introduced by Scheuneman in an item is considered unbiased if for persons with the same ability in the area being measured the probability of a correct response on the item is the same regardless of the population group membership of the individual That is if I I q is the variable representing a correct response on question q then by this definition I is unbiased if A I Y In practice the best measure of the ability that the item is testing is often the test in which the item is a component A major change from focusing primarily on fairness in a domain where so many factors could spoil the validity effort to a domain where analyses could be conducted in a relatively simple less confounded way In a DIF analysis the item is evaluated against something designed to Source Criterion Category Proposition Guion people with equal probabilities of success on the job have equal probabilities of being hired for the job individual Is the use of the test fair Cleary a subgroup does not have consistent errors non-comparative Is the test fair to subgroup a Einhorn and Bass y R a is constant for all subgroups a subgroup parity Is the use of the test fair with respect to A Thorndike ra A y A a is constant for all subgroups a subgroup parity Is the use of the test fair with respect to A Darlington equivalent to R correlation Is the test fair with respect to A Darlington Darlington equivalent to Y Darlington Darlington is maximized where is the subjective value placed on subgroup attribute A correlation Does the test produce the culturally optimum optimal outcome A Cole ra Y a is constant for all subgroups a subgroup parity Is the use of the test fair with respect to A Linn y R a is constant for all subgroups a subgroup parity Is the use of the test fair with respect to A Jones a a non-comparative Is the test fair to subgroup a mean fair Jones a subgroup a has equal representation in the top-n candidates ranked by model score as it has in the top-n candidates ranked by Y for all n non-comparative Is the test fair to subgroup a general standard Jones a subgroup a has equal representation in the top-n candidates ranked by model score as it has in the top-n candidates ranked by Y non-comparative Is the use of the test fair to subgroup a at position n Peterson Novick ra Y a is constant for all subgroups a and ra Y a is constant for all subgroups a subgroup parity Is the use of the test fair with respect to A conditional probability and its converse Peterson Novick y R a is constant for all subgroups a and y R a is constant for all subgroups a subgroup parity Is the use of the test fair with respect to A equal probability and its converse Table Early technical definitions of fairness in educational and employment testing Variables R is the test score Y is the target variable A is the demographic variable The Proposition column indicates whether fairness is considered a property of the way in which a test is used or of the test itself indicates that the criterion is discussed in the appendix measure a particular construct and something that the test producer controls namely a test score Figure illustrates DIF for a test item DIF became very influential in the education field and to this day DIF is in the toolbox of test designers Items displaying a DIF are ideally examined further to identify the cause of bias and possibly removed from the test s and beyond With the start of the s came renewed public debate about the existence of racial differences in general intelligence and the implications for fair testing following the publication of the controversial Bias in Mental Testing Political opponents of group-based considerations in educational and employment practices framed them in terms of preferential treatment for minorities and reverse discrimination against whites Despite or perhaps because of much public debate neither Congress nor the courts gave unambiguous answers to the question of how to balance social justice considerations with the historical and legal importance placed on the individual in the United States Into the s courts were asked to rule on many cases involving unfairness in educational testing To give just one example Zwick and Dorans described the case of Debra P v Turlington in which a lawsuit was filed on behalf of present and future twelfth grade students who had failed or would fail a high school Figure Original graph from illustrating DIF graduation test The initial ruling found that the test perpetuated past discrimination and was in violation of the Civil Rights Act More examples of court rulings on fairness are given by By the early s ideas about fairness were having a widespread influence on US employment practices In with no public debate the United States Employment Services implemented score adjustment strategy that was sometimes called race-norming Each individual is assigned a percentile ranking within their own ethnic group rather than to the test-taking population By the mids race-norming was a highly controversial issue sparking heated debate The debate was settled through legislation with the Civil Rights Act banning the practice of race-norming CONNECTIONS TO ML FAIRNESS Equivalent Notions Many of the fairness criteria we have overviewed are identical to modern-day fairness definitions Here is a brief summary of these connections Peterson and Novicks conditional probability and its converse is equivalent to what in ML fairness is variously called sufficiency equalized odds or conditional procedure accuracy sometimes expressed as the conditional independence A D Y Similarly their equal probability and its converse is equivalent to what is called sufficiency or conditional use accuracy equality A Y D Coles fairness definition is identical to equality of opportunity A D Y Linns definition is equivalent to predictive parity A Y D Darlingtons criterion is equivalent to sufficiency in the special case where A R and Y have a multivariate Gaussian distribution This is because for this special case the partial correlation X is equivalent to A Y R In general though we cannot assume even a one way implication since A Y R does not imply X see for a counterexample Similarly Darlingtons criteria and are equivalent to independence and separation only in the special cases of multivariate Gaussian distributions Darlingtons definition is a relaxation of what is called independence or demographic parity in ML fairness ie A R it is equivalent when A and R have a bivariate Gaussian distribution Guions definition people with equal probabilities of success on the job have equal probabilities of being hired for the job is a special case of Dworks individual fairness with the presupposition that probability of success on the job is a construct that can be meaningfully reasoned about The fairness literature in both the fields of ML and in testing have also been motivated by causal considerations Darlington motivate his definition on the basis of a causal relationship between Y and R since an ability being measured affects the performance on the test However have pointed out that in testing scenarios we typically only have a proxy for ability such as later GPA years later and it is wrong to draw a causal connection from GPA to college entrance exam Hardt et al describe the challenge in building causal models by considering two distinct models and their consequences and concluding that no test based only on the target labels the protected attribute and the score would give different indications for the optimal score R in the two scenarios This is remarkably reminiscent of Anastasi writing in about test fairness No test can eliminate causality Nor can a test score however derived reveal the origin of the behavior it reflects If certain environmental factors influence behavior they will also influence those samples of behavior covered by tests When we use tests to compare different groups the only question the tests can answer directly is How do these groups differ under existing cultural conditions Both the testing fairness and ML fairness literatures have also paid great attention to impossibility results such as the distinction between group fairness and individual fairness and the impossibility of obtaining more than one of separation sufficiency and independence except under special conditions In addition we see some striking parallels in the framing of fairness in terms of ethical theories including explicit advocacy for utilitarian approaches Petersen and Novicks utility-based approaches relate to Corbett-Davies et als framing of the cost of fairness Hunter and Schmidts analysis of the value systems underlying fairness criteria is similar in spirit to Friedler et als relation of fairness criteria and different worldviews Variable Independence As briefly mentioned above modern day ML fairness has categorized fairness definitions in terms of independence of variables which includes sufficiency and separation Some historical notions of fairness neatly fit into this categorization but others shed light on further dimensions of fairness criteria Table summarizes these connections linking the historical criteria introduced in Section to modern day categories Utility-based criteria are omitted but will be discussed below We find that non-comparative criteria discussed by Cleary and Jones do not map onto any of the independence conditions used in ML fairness Similarly Thorndikes and Darlingtons have no Historical criterion ML fairness criterion Relationship Guion individual relaxation Cleary sufficiency when Clearys criterion holds for all subgroups then we we have equivalence when R and Y have bivariate Gaussian distribution Einhorn and Bass sufficiency both involve probability of Y conditioned on R but Einhorn and Bass are only concerned with the conditional likelihood at the decision threshold Thorndike Darlington sufficiency equivalent when variables have a multivariate Gaussian distribution Darlington Darlington separation equivalent when variables have a multivariate Gaussian distribution Darlington independence equivalent when variables have a bivariate Gaussian distribution Cole separation relaxation equivalent to equality of opportunity Linn sufficiency relaxation equivalent to predictive parity Jones mean fair Jones at position n Jones general criterion Peterson and Novick separation equivalent conditional probability and its converse Peterson and Novick sufficiency equivalent equal probability and its converse Table Relationships between testing criteria and MLs independence criteria counterparts that we know of There are conceptual similarities between Jones criteria and the constrained ranking problem described by and also between Einhorns criterion and concerns about infra-marginality For a binary classifier Thorndikes group parity criterion is equivalent to requiring that the ratio of positive predictions to ground truth positives be equal for all subgroups This ratio has no common name that we could find unlike eg precision recall etc although refer to this as the Constant Ratio Model It is closely related to coverage constraints class mass normalization and expectation regularization Similar arguments can be made for Darlingtons criterion and Jones criteria at position n and general criterion When viewed as a model of subgroup quotas Thorndikes criterion is reminiscent of fair division in economics Regression and Correlation In reviewing the history of fairness in testing it becomes clear that regression models have played a much larger role than in the ML community Similarly the use of correlation as a fairness criterion is all but absent in modern ML Fairness literature Given that correlation of two variables is a weaker criterion than independence it is reasonable to ask why one might want a fairness criterion defined in terms of correlations One practical reason is that calculating correlations is a lot easier than estimating independence Whereas correlation is a descriptive statistic and so calculating requires few assumptions estimating independence requires an the use of inferential statistics which can in general be highly non-trivial Considering the analogy between model features and test items described in the Introduction we also know of no ML analogs to the Differential Item Functioning Such analogs might test for bias in model features Instead one approach adopted in ML fairness has been the use of adversarial methods to mitigate the effects of features with undesirable correlations with subgroups eg Model vs Model Use Section described how the test literature had competing notions of whether fairness is a property of a test or of the use of a test A similar discussion of whether ML models can be judged as fair or unfair independent of a specific use including a specific model threshold has been largely implicit or missing in the ML fairness literature Models are sometimes trained to be fair at their default decision threshold eg although the use of different thresholds can have a major impact on fairness The ML fairness notion of calibration ie PY A aR r r for all a and r can be interpreted to be a property of the model rather than of its use since it does not depend on the choice of decision threshold Race and Gender Some work on practically assessing fairness in ML has tackled the problem of using race as a construct This echoes concerns in the testing literature that stem back to at least one stumbles immediately over the scientific difficulty of establishing clear yardsticks by which people can be classified into convenient racial categories Recent approaches have used Fitzpatrick skin type or unsupervised clustering to avoid racial categorizations We note that the testing literature of the s and s frequently uses the phrase cultural fairness when referring to parity between blacks and whites Other than Thomas the test fairness literature of the s and s was typically concerned with race rather than gender although received attention later eg The role of culture in gender identity and gender presentation has seen less consideration in ML fairness but gender labels raise ethical concerns Comparable to modern sentiment in the difficulties of measuring fairness earlier decisions in the courtroom highlighted the impossibility of properly accounting for all factors that influence inequalities For example in Illinois Fair Employment Practices Commission FEPC examiner found that Motorola had discriminated against Leon Myart a black American in his application to work at Motorola as an analyzer and phaser The examiner found that the minute screening test that Myart took did not account for inequalities and environmental factors of culturally deprived groups The case was appealed to the Illinois Supreme Court which found that Myart actually passed the test and so declined to rule on the fairness of the test FAIRNESS GAPS Fairness and Unfairness In mapping out earlier fairness approaches and their relationship to ML fairness some conceptual gaps emerge One noticeable gap relates to the difference in framing between fairness and unfairness In earlier work on test fairness there was a focus on defining measurements in terms of unfair discrimination and unfair bias which brought with it the problem of uncovering sources of bias In the s this developed into framings in terms of fairness and the introduction of fairness criteria similar or identical to ML fairness criteria known today However returning to the idea of unfairness suggests several new areas of inquiry including quantifying different kinds of unfairness and bias such as content bias selection system bias etc cf and a shift in focus from outcomes to inputs and processes Quantifying types of unfairness may not only add to the problems that machine learning can address but also accords with realities of sentencing and policing behind much of the fairness research today Individuals seeking justice do so when they believe that something has been unfair Differential Item Functioning Another gap that becomes clear from the historical perspective is the lack of an analog to Differential Item Functioning Section in current ML fairness research DIF was used by education professionals as a motivation for investigating causes of bias and a modern-day analog might include unfairness interpretability in ML models An direct analog in ML could be to compare R r A a for different input features Xi model outputs R and subgroups A For example when predicting loan repayment this might involve comparing how income levels differ across subgroups for a given predicted likelihood of repaying the loan Target Variable Model Score Relationship Another gap is the ways in which the model test score and the target variable are related to each other In many cases in ML fairness and test fairness there are correspondences between pairs of criteria which differ only in the roles played by the model test score R and the target variable Y That is one criterion can be transformed into another by swapping the symbols R and Y for example separation can be transformed into sufficiency A R Y A Y R In this section we will refer to this type of correspondence as converse ie separation is the converse of sufficiency When viewed in this light some asymmetries stand out Converse Cleary criterion Clearys criterion considers the case of a regression model that predicts a target variable Y given test score R One could also consider the converse regression model mentioned in passing by which predicts model score R from ground truth Y as an instrument for detecting bias say that a test has connotations of unfair for a subgroup if the converse regression line has positive errors ie for each given level of ground truth ability the test score is higher than the converse regression line predicts Converse calibration In a regression scenario the calibration condition PY R r A a r can be rewritten as R r A a r or r R r A a The converse calibration condition is therefore ER y Y a for all subgroups A a In other words for each subgroup and level of ground truth performance Y y the expected error in Rs prediction of the value y is zero We point out these overlooked concepts not to advocate for their use but to map out the geography of concepts related to fairness more completely Compromises Darlington points out that Thorndikes criterion is a compromise between one criterion related to sufficiency and one related to separation see Section and Tables and In general a space of compromises is possible in terms of correlations this might be modeled using a parameter where values of and imply Darlingtons definitions and respectively This also suggests exploring interpolations between the contrasting sufficiency and separation criteria For example one way of parameterizing their interpolation is in terms of binary confusion matrix outcomes Definition λ-Thorndikian fairness A binary classifier satisfies λ-Thorndikian fairness with respect to demographic variable A if both a TP TP is constant for all values of A and b is constant for all values of A Note that -Thorndikian fairness is equivalent to sufficiency while -Thorndikian fairness is equivalent to separation Petersen and Novick showed that -Thorndikian fairness requires that either a for each subgroup the positive class is predicted in proportion to its ground truth rate or b every subgroup has the same ground truth rate of positives We can also consider relaxations of λ-Thorndikian fairness in which only one of the two conditions a or b is required to hold For example only requiring condition a gives us a way of parameterizing compromises between equality of opportunity and predictive parity where the magnitudes of the variables have been standardized Our goal here is not to advocate for this particular model of compromise between separation and sufficiency Rather since separation and sufficiency criteria can encode competing interests of different parties our goal is to suggest that ML fairness consider how to encode notions of compromise which in some scenarios might relate to the publics notion of fairness We propose that the economics literature on fair division might provide some useful ideas as has also been suggested by However we do heed Darlingtons warning that a compromise may end up satisfying nobody psychometricians are not in the habit of agreeing on important definitions or theorems by compromise This statement may be equally true of ML practitioners DISCUSSION This short review of historical connections in fairness suggest several concrete steps forward for future research in ML fairness Developing methods to explain and reduce model unfairness by focusing on the causes of unfairness To paraphrase Darlingtons question What can be said about models that discriminate among cultures at various levels yields more actionable insights than What is a fair model This is related to research on causality in ML Fairness see Section but including examination of full causal pathways and processes that interact well before decision time In other words What causes the disparities Drawing from earlier insights of Guion Thorndike Cole Linn Jones and Peterson Novick to expand fairness criteria to include model context and use Building from earlier insights of s researchers to incorporate quantitative factors for the balance between fairness goals and other goals such as a value system or a system of ethics This will likely include clearly articulating assumptions and choices as recently proposed in Diving more deeply into the question of how subgroups are defined suggested as early as including questioning whether subgroups should be treated as discrete categories at all and how intersectionality can be modeled This might include for example how to quantify fairness along one dimension eg age conditioned on another dimension eg skin tone as recent work has begun to address CONCLUSIONS The spike in interest in test fairness in the s arose during a time of social and political upheaval with quantitative definitions catalyzed in part by US federal anti-discrimination legislation in the domains of education and employment The rise of interest in fairness today has corresponded with public interest in the use of machine learning in criminal sentencing and predictive policing including discussions around compas and PredPol Each era gave rise to its own notions of fairness and relevant subgroups with overlapping ideas that are similar or identical In the s and s the fascination with determining fairness ultimately died out as the work became less tied to the practical needs of society politics and the law and more tied to unambiguously identifying fairness We conclude by reflecting on what further lessons the history of test fairness may have for the future of ML fairness Careful attention should be paid to legal and public concerns about fairness The experiences of the test fairness field suggest that in the coming years courts may start ruling on the fairness of ML models If technical definitions of fairness stray too far from the publics perceptions of fairness then the political will to use scientific contributions in advance of public policy may be difficult to obtain Perhaps ML practitioners should cautiously take heed from Cole and Ziekys portrayal of developments in their field Members of the public continue to see apparently inappropriate interpretations of test scores and misuses of test results They see this area as a primary fairness concern However the measurement profession has struggled to understand the nature of its responsibility in this area and has generally not acted strongly against instances of misuse nor has it acted in concert to attack misuses We welcome broader debate on fairness that includes both technical and cultural causes how the context and use of ML models further influence potential unfairness and the suitability of the variables used in fairness research for capturing systemic unfairness We agree with Linns argument from that values encoded by technical definitions should be made explicit By concretely relating fairness debates to ethical theories and value systems as done by we can make discussions more accessible to the general public and to researchers of other disciplines as well as helping our own ML Fairness community to be more attuned to our own implicit cultural biases
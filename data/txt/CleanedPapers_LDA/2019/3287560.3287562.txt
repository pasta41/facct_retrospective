Model Reconstruction from Model Explanations We show through theory and experiment that gradient-based explanations of a model quickly reveal the model itself Our results speak to a tension between the desire to keep a proprietary model secret and the ability to offer model explanations On the theoretical side we give an algorithm that provably learns a two-layer ReLU network in a setting where the algorithm may query the gradient of the model with respect to chosen inputs The number of queries is independent of the dimension and nearly optimal in its dependence on the model size Of interest not only from a learning-theoretic perspective this result highlights the power of gradients rather than labels as a learning primitive Complementing our theory we give effective heuristics for reconstructing models from gradient explanations that are orders of magnitude more query-efficient than reconstruction attacks relying on prediction interfaces CONCEPTS learning Security and privacy KEYWORDS Explanations machine learning security privacy INTRODUCTION Commercial machine learning models increasingly support consequential decisions in numerous domains including medical diagnosis employment and criminal justice In such applications there is now growing demand for methods that explain a models decision The secrecy of a model strongly fuels this demand At the same time there are a number of valid reasons a company might wish to keep its machine learning models secret The competitive value of the product is one consideration Revealed models may also be easier to game resulting in diminished predictive power Yet another reason is that the model might leak sensitive information about the data it was trained on In this work we point out a tension between keeping a model secret and explaining its decisions We show that a popular class of existing methods to explain a models decision quickly reveals the model itself in what is typically an undesired side effect Numerous explanation methods have been proposed in an ongoing line of research Among these methods saliency maps are a widespread technique to highlight characteristics of an input deemed relevant for the prediction of a model The most basic saliency map is to compute the gradient of the model with respect to a chosen input Numerous variants add different transformations to the raw gradients leading to some disagreement over which of these heuristics is preferable in what context Abstracting away from these implementation details we focus on reconstructing models given the basic underlying primitive which is gradients of the model with respect to its inputs Our contributions Our contributions are twofold spanning both a theoretical and experimental component Learning from input gradients On the theoretical side we introduce a model of learning from input gradient queries In this model a learning algorithm can observe gradients of an unknown model at chosen query inputs This model turns out to be rich in its mathematical structure and connections to standard learning models such as learning from membership queries in which the learner can request the models prediction at a given input In our setting since the gradient provides more information than a single label there is hope that learning algorithms can get by with far fewer queries We prove that this is indeed the case To build up intuition with a simple example consider a linear model x specified by a weight Rd The gradient of the model with respect to any input x is just equal to the model x x Thus we can learn a linear model from a single input gradient query Going beyond linear models we analyze two-layer neural networks with ReLU transitions of the form x where A Here applies coordinatewise to a vector The problem of learning such networks has received much renewed interest in the last few years as it poses a non-trivial challenge en route to analyzing deeper non-linear models Our main result in this setting is the following theorem Theorem informal Assuming the rows of the weight matrix A are linearly independent our algorithm recovers a functionally equivalent model input gradient queries and function evaluations with high probability queries our theorem requires is optimal to within a logarithmic factor since it takes parameters to specify the model and each query reveals only Od numbers Furthermore compared to membership queries gradient queries reduce the number of queries needed by approximately a factor of d since it takes membership queries to specify the model Although our algorithm enjoys an intuitive geometric interpretation the proof requires a delicate argument as well as an anti-concentration bound that may be useful independently Practical reconstruction methods In a second step we explore practically effective heuristics to reconstruct a model from input gradient queries Our experiments show that reconstructing models from explanations is not just a theoretical concern If a company were to provide an explanation API with standard saliency maps it would effectively give up the underlying model which it may not be willing to do for reasons mentioned above This situation parallels an ongoing investigation on stealing models from prediction APIs However as our results show with explanation APIs we need far fewer queries thus greatly exacerbating the threat of model leakage Our experiments focus on a heuristic for learning from input query gradients While our theoretical method is specific to two-layer networks our heuristic is agnostic to the shape of the target model We experiment with standard vision benchmarks and architectures since saliency maps have been predominantly evaluated on image data sets At the outset our heuristic simply queries a number of input gradients and fits a model against the observed gradients in much the same way we would fit a model against labels We find that this heuristic reduces the number of queries needed to learn models on MNIST and CIFAR by orders of magnitude even in cases where the model class is unknown or the data distribution is unknown Conclusion Our work demonstrates that establishing usable explanation methods for machine learning models faces another hurdle in commercial applications Whatever criteria of explanation quality we choose must be weighed against the risk of model leakage resulting from the method at hand We see our work as only a first step in this new direction that raises many intriguing questions Does our theoretical result extend to depth- networks Ignoring computational efficiency what is the optimal query complexity In particular can we learn a k-layer ReLU network units at each layer from only queries Can we design useful explanation methods resilient to model reconstruction attacks Although a natural and important question to ask there is no currently agreed upon measure of explanation quality which makes it difficult to formally study this trade-off PROBLEM STATEMENT RECONSTRUCTING A TWO-LAYER RELU NETWORK We consider the problem of finding a classifier identical to an unknown classifier when given access to membership and gradient queries That is we assume access to an oracle that given a query input x returns the evaluation of at x and the gradient x x of with respect to x We analyze the case where the function Rd R is represented by a one hidden-layer neural network with ReLU activations x i wi x Here the model parameters areA Rh We to denote the i-th row We make the following three assumptions The rows A Ah are unit vectors No two with i are collinear ie Ai c for some c The rows A Ah are linearly independent The first two assumptions are without loss of generality as they follow from simple reparameterizations of the network that involve or A or reducing the hidden dimension Our main result is the following theorem which shows that our sample complexity for learning the function with gradient queries has no dependence on the input dimension d Theorem Suppose the unknown function satisfies our assumptions Then with probability Algorithm finds a function such that If the algorithm fails then it notifies of the failure In either case the algorithm requires Oh log queries Section contains our algorithm and proof of correctness In Appendix C we show that our algorithm can also be converted to one which learns the function log membership queries by using membership queries to approximate gradients of ALGORITHM Before we formally introduce our algorithm we briefly provide some high-level intuition First note that we can express our ReLU networks as x i i x where The separating hyperplanes defined by the normal vectors A Ah split the input space into cells represented by the possible values of Within each such cell the function is linear See Figure for an example visualization of these cells Our algorithm can be separated into two steps First we find the separating hyperplanes of In particular we recover unsigned weighted normal vectors wiAi or wiAi for i The second step then recovers the sign information for these normal vectors More precisely the two steps are the following Recover such wiAi wiAi for some permutation p of Algorithm a Recover a vector s such that x s Algorithm b Together the matrix Z and vector s identify the function We analyze the first step in Section and the second step in Section Algorithm Recovery of Function l Z l s return Z s Algorithm a Recovery of Z Function l Pick N Id and let Z tl tr l l for i do tl tr return Z Function tr while tl tr do tl tr u u u if tr tl then return tr if then tr else if then tl else throw Failure throw Failure Algorithm b Recovery of s Function Pick X such that x and See Appendix B M Solve for s Rh such that Ms x x return s Step one recovering the separating hyperplanes Algorithm a finds the separating hyperplanes by exploiting the structure of the gradient of x i where as before Note that points within the same cell have the same gradient So if we find two points x and y with different gradients we know that at least one separating hyperplane must be between x and y Moreover if the points x and y are sufficiently close to each other then it is likely that there is only one separating hyperplane between them In that case we can then use the difference of gradients to recover a hyperplane up to signs This is because each gradient is simply a sum of a subset of wiAi i and so the difference y x is equal to either wiAi or wiAi for some i In this way Algorithm a isolates changes in the gradient of to up to a sign for every i Figure provides an illustrated explanation of the algorithm which we briefly sketch below Pick N Id Run a binary search with resolution along a portion of the line segment for some l R to find two points and that are sufficiently close v but have differing gradients Add as a row to With high is equal for some i Repeat Step times to recover all up to their sign which become the rows of the matrix Z The proof of correctness relies on showing that with high probability the following two events hold i The points at which the gradient of changes are spaced sufficiently far apart ii The same gradient change points are within some line segment of u and v that is not too big The change points can then be found with a binary search that is bounded within a range that is not too large and uses step sizes that are not too small In the next lemma we prove correctness of the binary search given that the change points are spaced appropriately Lemma Let Rd be such that Ai v for all i For each i also let ti R be such that Ai u If for all i i we have ti tj and ti l then Algorithm a returns a matrix Z such that wiAi or wiAi for some permutation p of Proof Let kh be the indices such that tk tk To prove the lemma we will show that on the i-th call to binarySearch either is added as a row to matrix Z First we make the following assumption which we will later prove assume that tj t i l tj where t i l is the value of the variable tl at the start of the i-th call to binarySearch Given this assumption the i-th call to binarySearch adds to the matrix Z To see this note that on each iteration of the while loop in binarySearch either the variable tl increases or the variable tr decreases and thus binarySearch always terminates However tl dose not increase past and tr does not decrease past So when the condition for termination of the while loop is met we have tl tr tl and tr Since for all i the row tr tl returned by binarySearch is equal to or wA wA wA wA u u A A u v Figure An illustration of Algorithm a when the input domain of the function is R and the hidden dimension is equal to two The two hyperplanes with normal vector A and A separate the input space into four cells where the gradient of is constant Algorithm a picks two random vectors u and v and searches for a change in the gradient of using a binary search along a line segment between u When two points are found that are sufficiently close but have differing gradients then the difference in their gradients is added as a row to the recovered matrix Z For example wA is added to Z By running the binary search times Algorithm a up to a sign for all i Now we revisit the assumption that tj t i l tj We prove the assumption by induction The base case i is clearly true tk tj tj t i l tj because t l l and l tk tk l On the i call to binarySearch the variable tl is set to the value of tr when the i-th call to binarySearch terminated When the i-th call to binarySearch finishes the value of the variable tr is above tj t i l tj but less than Thus tj t i l tj Therefore the returned matrix Z is such that wiAi or wiAi where the permutation p of is defined by pi where kj i The next two lemmas proved in Appendix A establish the necessary anti-concentration and concentration bounds for showing that the change points are spaced sufficiently far apart Lemma but still within some line segment of u and v that is not too big Lemma Lemma Let ab Sd be unit vectors such that ab c for some scalar c Suppose we pick random vectors N Id Let t t R be scalars such that au tv and tv Then Pt t c Lemma Let a Sd be a unit vector Suppose we pick random N Let t R be the value such that Then Pt l Finally the proof of our main theorem for Algorithm a follows by combining the probabilistic guarantees of Lemmas and with the deterministic proof of correctness in Lemma Theorem With probability Algorithm a succeeds in Oh log queries If the Algorithm succeeds it returns a matrix Z such that wiAi or wiAi for some permutation p of If the Algorithm fails then it notifies of the failure Proof By Lemma if ti tj and ti l for all i and i then Algorithm a succeeds to return a matrix Z such that wiAi or wiAi for some permutation p of The probability of Algorithm a succeeding can be lower-bounded as Pi i ti tj ti l i tj i l Union bound c i l Lemma c Lemma Let c l so that Algorithm a succeeds with probability at least Since the algorithm performs a binary search over an interval of size l with step size at most times it uses at most log l queries Next we will simplify the expression for the number of queries First set l Then solving for using the expressions for l and yields c We can then upper-bound the number of queries used as log l log log O log Therefore Algorithm a succeeds log queries with probability Step two recovering the signs of the normal vectors Algorithm a recovers unsigned weighted normal vectors wiAi or wiAi for i But to identify the function we still need the sign of these vectors In Algorithm b we recover a vector s that encodes this sign information Precisely Algorithm b returns a vector s such that x s where si i wi Ai i wi Ai i wi Ai i wi Ai It is clear that if Algorithm b returns the vector s then the function is identified Algorithm b solves linear equations to determine the vector s To prove correctness of Algorithm b we show that the query points picked in the algorithm lead to a determined set of linear equations Lemma Let Z be a matrix such that wiAi or wiAi for a permutation p of Let xi denote the i-th column of a matrix X Suppose x i and for all i Then the matrix defined as M is full-rank Proof Since x and i we know and that we could always negate rows of the matrix Z so that Thus we can assume without loss of generality that i for all i Then the can be expressed as the following M The determinant of the matrix is is a full-rank matrix In Appendix B we describe a simple linear program that can be used to pick a matrix X that satisfies the conditions of the above Lemma Since Algorithm b picks such Lemma immediately implies our main theorem proving correctness of Algorithm b Theorem If Algorithm b is given a matrix Z such that wiAi or wiAi for a permutation p of then it returns a vector s such that the function is equal to x s Proof Algorithm b uses queries to construct a X that satisfies the conditions of Lemma Thus the resulting set of linear equations are determined and Algorithm b returns the unique vector s corresponding to its solution Together Theorem proving correctness of Algorithm a and Theorem proving correctness of b imply our main Theorem that proves correctness of Algorithm Theorem Suppose the unknown function satisfies the assumptions in Section Then with probability Algorithm succeeds to find a function such that in Oh log queries If the Algorithm fails then it notifies of the failure Proof By Theorem with probability Algorithm a returns a matrix Z that satisfies the conditions of Theorem in Oh log queries By Theorem Algorithm b then returns a vector s such that x s queries Thus overall Algorithm succeeds with probability in Oh queries EXPERIMENTAL DESIGN While our theoretical analysis provides insight into the power of gradient queries over membership queries it is specific to a two-layer ReLU network To complement our theory we also experimentally investigate the impact of gradients on reconstructing models used in practice In order to compare to reconstructing with membership queries alone our method for learning with gradients is a modification of a simple heuristic used to reconstruct models from membership queries training a new classifier to match the outputs of When we have access to gradients we can also train the classifier to match the gradients of by minimizing a loss on the gradients x x x the gradient loss with a loss on the membership queries to create a joint loss x x x We test how gradient queries help by measuring the accuracy of when trained using x versus when trained only on the membership query loss x In our experiments x is the cross-entropy loss between x and x Next we describe our experimental design in detail Manipulated factors We manipulate three independent variables First we manipulate the type of query We test membership only queries as well as membership and gradients Further because in practice explanations often provide a processed version of the gradients instead of the raw gradients we also test membership Figure Access to gradients improves the accuracy of the recovered model The improvement is approximately the same even with gradients processed by SmoothGrad Figure Gradients still help when the model is unknown but they help more when the reconstructed classifier is from a model class that is more complex than the model class of the true classifier and gradients processed with SmoothGrad a saliency map denoising technique Instead of returning the raw gradient x SmoothGrad returns an average of gradients around the input x x N i Second we manipulate the complexity of the task to test whether gradients help more or less on more complex tasks We experiment on both MNIST and CIFAR Finally we manipulate the complexity of the model class to test whether gradients help more when the model is simpler We train three models on each of the two tasks that are chosen to display a range of complexity Dependent measure We measure the accuracy of our reconstructed classifier on a test set of images from the task MNIST or CIFAR Experimental procedure We split our datasets into three parts A training set of images and ground-truth labels for the true classifier The training set for MNIST has examples and for CIFAR has examples A training set of images for the reconstructed classifier Note that does not have access to ground-truth labels so it must query for labels A test set of images and ground-truth labels for and We first train models to serve as the true classifier We train three types of models on MNIST a -layer network multinomial logistic regression a -layer neural network with ReLu activations and a network with two convolutional layers each followed by a max-pool layer followed by two dense layers We also train three types of models on CIFAR the same convolutional network used for MNIST with the input dimension changed appropriately a VGG network and a ResNet- network Next we train a new classifier from the same model class as the true classifier The inputs x given to are randomly sampled from the training set for Depending on the condition of the experiment the classifier also receives either x x and x or x and x is the output of the SmoothGrad algorithm After training we compute the accuracy of our reconstructed classifier on the test set Follow-up experiments unknown model class and data distribution An adversary trying to reconstruct the classifier may not know the model class of or the data distribution So in followup experiments we reconstruct the classifier with a classifier from a different model class and reconstruct the classifier using Gaussian generated queries In these follow-up experiments we analyze the same factors but with a subset of conditions For example since in the main experiment we found virtually no difference between SmoothGrad queries and gradient queries we omit SmoothGrad queries from our followup experiments EXPERIMENTAL RESULTS AND DISCUSSION Main experiments gradient queries versus membership queries Figure shows the results of our main experiments described in Section Type of query Across all experiments training with gradient queries leads to orders of magnitude fewer queries required to learn the model For example for the MNIST convolutional model we get to accuracy in gradient queries compared to membership queries We find practically no difference between gradient queries and SmoothGrad queries despite picking the hyperparameters for SmoothGrad that produced the best saliency maps See Appendix D Complexity of model class We find that the gap in performance between gradient queries and membership queries is larger for models of lower complexity As an extreme case consider the -layer network on MNIST We find a x decrease in the number of queries required With gradient queries it takes only one query to reconstruct the model get the same performance as the original classifier This makes sense because with gradient queries the -layer network is identifiable in one query compared to membership queries x decrease in the number of queries needed to reconstruct the model On CIFAR we find that the convolutional network which is the same as the convolutional network used for MNIST also has at least a x decrease in the number of queries needed On the other hand VGG and Resnet- show only a x decrease in the number of queries needed to reach accuracy Complexity of task We find that the relative reduction in queries needed seems to depend on the complexity of the model class rather than the complexity of the task But not surprisingly the absolute number of queries needed increases with the complexity of the task On both MNIST and CIFAR gradient queries lead to a x decrease for reconstructing the convolutional network suggesting that for the relative decrease in query complexity depends more on the complexity of the model class than the complexity of the task However as might be expected for both gradient and membership queries the absolute number of queries needed increases as the complexity of the task increases On MNIST the convolutional model is reconstructed in gradient queries compared to membership queries On CIFAR the convolutional model is reconstructed in gradient queries compared to membership queries Unknown model class In the scenario where we do not know the true model class beforehand we experiment with MNIST Reconstructing the -layer model with the -layer network and vice versa MNIST Reconstructing the -layer model with the convolutional network and vice versa CIFAR Reconstructing the VGG model with the ResNet network and vice versa We refer the reader to Section for details on the models Figure displays our results R The model are equal to in one gradient and membership query Figure When querying with Gaussian generated inputs we seem to see a larger gap between the performance of gradient queries and the performance of membership queries We find that gradient queries seem to help more when the the model class of is more complex than the true classifier For example we see a x decrease in the number of queries needed to reconstruct MNIST -layer with a -layer network But we only get an initial x decrease in the number of queries needed to reconstruct MNIST -layer with a -layer network Similarly reconstructing the -layer network with the convolutional network works much better than reconstructing the convolutional network with the -layer network We have been fairly loose when referring to the relative complexities of different models and it is unclear to us how to compare VGG and ResNet- in terms of complexity Interestingly however we find that although gradient queries still lead to a x decrease when reconstructing ResNet- with VGG they help very little when reconstructing a VGG model with a ResNet- network Unknown data distribution We now analyze the setting where we do not know the data distribution Instead we query using randomly generated Gaussian queries ie x N Id Figure displays our results On MNIST we find that Gaussian queries lead to a greater gap in performance between gradient and membership queries compared to when using images from the data distribution -layer network we see at least a x decrease compared to the x decrease we saw in Section when using queries from the data distribution On the MNIST convolutional network we see that in with a single gradient membership query or membership queries independent of the distribution the queries are generated from gradient queries we get to accuracy On the other hand it takes membership queries to learn at all and even then we get to only Thus we seem to get at least a x decrease compared to the x reduction we saw when using queries from the data distribution On CIFAR it is harder to interpret the results because the performance degrades so much for both gradient and membership queries However at least in the convolutional network the gap between gradient and membership queries also seems to increase The reconstructed model gets to accuracy in gradient queries but only to accuracy in membership queries Tram√®r et al show how models can be reconstructed in practice through prediction APIs Our work addresses the complementary threat of model leakage through a hypothetical explanation API While differential privacy can help guard against attacks from prediction APIs it is not clear if this is a viable approach for preventing reconstruction from explanations Learning a model via a prediction API instantiates the framework of learning with membership queries in which the learner gets to actively query an oracle for labels to inputs of its choosing In our work we propose a complementary learning framework learning from input gradient queries Similar to membership queries and prediction APIs we believe that learning from gradients is likely to be the theoretical framework underpinning reconstruction from explanation APIs We give a near-optimal algorithm for learning a two-layer network with ReLU activations through gradient queries The geometric intuition for our algorithm is similar to the work of Baum for learning two-layer linear threshold networks with membership queries
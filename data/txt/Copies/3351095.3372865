Data in New Delhi’s Predictive Policing System
Vidushi Marda∗
vidushi@article19.org
Article 19
Shivangi Narayan∗
shivangi.narayan@gmail.com
Jawaharlal Nehru University
ABSTRACT
In 2015, Delhi Police announced plans for predictive policing. The
Crime Mapping, Analytics and Predictive System (CMAPS) would
be implemented in India’s capital, for live spatial hotspot mapping
of crime, criminal behavior patterns and suspect analysis. Four
years later, there is little known about the effect of CMAPS due
to the lack of public accountability mechanisms and large excep-
tions for law enforcement under India’s Right to Information Act.
Through an ethnographic study of Delhi Police’s data collection
practices, and analysing the institutional and legal reality within
which CMAPS will function, this paper presents one of the first
accounts of smart policing in India. Through our findings and dis-
cussion we show what kinds of biases are present within Delhi
Police’s data collection practices currently and how they translate
and transfer into initiatives like CMAPS. We further discuss what
the biases in CMAPS can teach us about future public sector deploy-
ment of socio-technical systems in India and other global South
geographies. We also offer methodological considerations for study-
ing AI deployments in non-western contexts. We conclude with a
set of recommendations for civil society and social justice actors to
consider when engaging with opaque systems implemented in the
public sector.
CCS CONCEPTS
• Social and professional topics → Governmental regulations;
Race and ethnicity; Cultural characteristics; • Computing method-
ologies → Reasoning about belief and knowledge.
KEYWORDS
Fairness-Aware Machine Learning, Predictive Policing, Interdisci-
plinary, Sociotechnical systems
ACM Reference Format:
Vidushi Marda and Shivangi Narayan. 2020. Data in New Delhi’s Predictive
Policing System. In FAT* ’20: Proceedings of ACM Conference on Fairness,
Accountability, and Transparency, January 27–30, 2020, Barcelona, Spain.
ACM, New York, NY, USA, 8 pages. https://doi.org/10.1145/3351095.3372865
∗Both authors contributed equally to this research.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
FAT* ’20, January 27–30, 2020, Barcelona, Spain
© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-6936-7/20/01. . . $15.00
https://doi.org/10.1145/3351095.3372865
1 INTRODUCTION
As of 2019, law enforcement agencies across India are in the pro-
cess of deploying machine learning systems for crime prevention,
criminal tracking, and better allocation of resources. In Chennai,
one of the major Indian metropolises with a population of 11 mil-
lion, facial recognition systems are deployed in crowded places to
identify criminals and individuals who “look suspicious” [18]. In
the south Indian state of Telangana (estimated population of 40
million) smart law enforcement has come to be deployed with a
view to create a “360 degree view” of citizens [28]. Elsewhere, in the
north Indian state of Punjab (estimated population of 30 million),
the Punjab Artificial Intelligence System received a Smart Policing
Award for its use of facial recognition in crime solving [30]. The Na-
tional Crime Records Bureau of India recently published a tender for
the Automated Face Recognition System which would be used for
“criminal identification, verification and its dissemination among
various police organizations and units across the country” [16]. One
of the first initiatives towards the use of machine learning (ML) in
law enforcement was pioneered by the Delhi Police. For context,
Delhi is a city with a population of close to 30 million people. It is
the national capital, and is also anecdotally referred to as the ‘rape
capital’ of India due to historically high records of violence against
women. This is important to understand to follow the larger safety
discourse in Delhi and why policing interventions of a certain kind
may gain public legitimacy. In 2015, Delhi police announced the
use of the Crime Mapping, Analysis and Mapping System (CMAPS),
a predictive policing system [20] that would access data directly
from the Dial 100 call centre to plot the geographic location of calls
and calculate crime hotspots.
The limitations and dangers of predictive policing have been
studied in jurisdictions like the United States and Europe. It is
well understood that these systems risk over-policing vulnerable
populations [15] and exacerbate problematic institutional biases
[14]. The implementation and quotidian experience of these systems
in the global South (or post-colonial) jurisdictions like India remain
to be studied. It is particularly crucial to study such deployments in
India at this juncture because of the ongoing efforts at wholesale
deployment of various ML technologies in all aspects of public
life in India with little to no meaningful consideration of potential
harms. In this paper, we study the process by which crime hotspot
mapping is currently carried out by Delhi Police, and the existing
infrastructure and data on which CMAPS will be developed. We
zoom in on what the “spatial distribution of crime” entails in New
Delhi, and also investigate the creation, collection and classification
of data. We draw on observational and unstructured interview data
to answer the following questions:
(1) What kinds of biases are present in police data currently,
and how do they arise?
(2) What kinds of social and political assumptions inform these
practices, and how do they find their way into predictive
policing systems like CMAPS?
(3) What can current data practices tell us about future tech
uses within the same institutional reality?
The paper offers four substantial contributions to existing lit-
erature in the field. Firstly, this paper is the first of its kind to
present a study of a predictive policing system from the Global
South. Operationalising findings from previous work by Seaver
[23] and Haraway [8], we analyse daily activities of human, insti-
tutional and societal actors, and situate our analysis of the system
within its local context, drawing from on-the-ground observation
and interviews. Second, we explore the extent and types of biases
that exist within Delhi’s crime hotspot mapping system. A signif-
icant component of studying predictive policing initiatives is to
study the data that trains these systems [6]. However, as Suresh
& Guttag [29] have argued earlier, the phrase “training data bias”
in the context of machine learning applications is too broad to be
useful. We use their framework to bring about a more granular
understanding of how current practices within Delhi Police influ-
ence technical systems like CMAPS. In doing so, we also present
new evidence which can be used to engage with similarly placed
predictive policing systems in India and beyond.
Third, law enforcement’s use of technology for maintaining law
and order is notoriously opaque - from secretive procurement prac-
tices, to deployment that is not subject or amenable to information
requests. Richardson et. al have explored the urgent need for ac-
countability mechanisms within predictive policing systems in the
United States [22]. In the context of New Delhi’s predictive policing
system, the first step towards accountability is peering into the
functioning of the system itself. Currently, the gap between media
coverage of new initiatives in re: law enforcement in India and an
understanding of how, where, when and by who those systems
are actually being used is huge. Our paper aims to bridge that gap.
Fourth, we provide an account of observed biases within policing
institutions and their transfer to technical systems that operate
within these formal structures. Policing is an institution histori-
cally known for its problematic practices, reflected in its data and
systems. By observing the link between historical practice and tech-
nical solutions, we avoid the “ripple effect trap” identified by Selbst
et. al [25] while at the same time demonstrating the importance
of analysing sociotechnical systems in the context that they are
designed, developed and deployed. In the absence of accountability
mechanisms and publicly available data, our research points to the
value in focusing on the institutional and human aspect of machine
learning in the public sector.
This paper proceeds as follows. Section 2 will provide a closer
look at the current status of predictive policing in New Delhi. Sec-
tion 3 describes our methodology for conducting research and field
work. Section 4 provides insights from our field work and walks the
reader through current data practices, Section 5 provides key points
of analysis and Section 6 concludes with reflections, learnings and
recommendations, and Section 7 reflects on limitations and future
research.
2 CURRENT STATE OF PREDICTIVE
POLICING IN NEW DELHI
It is clear through public domain reporting that CMAPS is func-
tional, and is being used to inform resource allocation within Delhi
Police [26]. Instances of predictive policing saving lives and aiding
in arrests have also been reported in national news portals [19].
However, the larger societal impact of this technology, and its con-
sequences for individuals and groups in a city of close to 30 million
people, is not known at this time. CMAPS was announced in 2015 as
a partnership with the Indian Space Research Organisation. Under
this partnership, Delhi Police claimed it would use "space technol-
ogy for effective governance" explaining that CMAPS would be
capable of geographic and environment profiling of crime, would
rank districts on the basis of crime reported, numbers of people
affected, and produce predictive models based on these trends to
assist officers to plan and deploy police forces [21]. The input data
of this system is from the Dial 100 emergency call centre (the equiv-
alent of 911 in the United States or 999 in the United Kingdom),
and from First Information Report (FIR) data stored in the Crime
and Criminal Tracking Network Systems (CCTNS) in New Delhi. A
diagram of the data flow and relevant actors is provided below.
While CMAPS is the first attempt at automated hotspot map-
ping, it is predicated on previous manual hotspot mapping ini-
tiatives within Delhi Police. The first instance of crime hotspot
mapping occurred in 2007 when Delhi Police mapped instances
of car-jacking across the city in an effort to detect patterns and
curb further instances. This effort was soon extended to four other
crimes: snatching, robbery, rape and eve teasing. These would be
manually entered by the Digital Mapping Division (DMD) housed
within Delhi Police. According to the Standard Operating Proce-
dure stuck on the wall of the DMD, this manual mapping would
continue till such time that automatic mapping, i.e. CMAPS was
set up. In our time at the Delhi Police Headquarters, we learnt that
currently, both manual and automated crime mapping are being
carried out simultaneously. The manually plotted maps are sent to
23 heads of police everyday, on the basis of which resources are
allocated, and subordinates are briefed on the law and order status
in the city. Simultaneously, the login ID and password from CMAPS
is provided to all District Police Commissioners who can use them
to brief their Station House Officers, who can, in turn decide on
resource management, increasing patrolling/policing in ‘problem’
areas in their jurisdiction. The system uses background data on
the geographic boundaries in Delhi, railways, metro pillars, police
station jurisdictions, “problem areas” identified in historical data,
etc. It is also equipped with layers that can help law enforcement
analyse crimes by optimising for a variety of considerations. For
instance, there are filters for crowded places like railways stations
and schools, and other filters for areas historically and culturally
associated with crime, such as bars. There are also filters that can
point out ghettos, migrant colonies and minority settlement areas.
Data practices within past mapping initiatives thus form baselines
for spatial analysis of crime and for application of layers that can
be used to analyse crime within CMAPS. In this paper, we study
the implications of using historical data from law enforcement as
ground truth for New Delhi’s predictive policing system, with a
focus on input data coming in from the Dial 100 helpline.
Call
Dial 100 
Call Centre
Dispatch
Halaat Report
if Heinous
Police Control 
Room (PCR)
Command Room
(Dispatch Floor)
Green Diary Comprehensive
Diary 
Digital Mapping 
Division
Crime Maps
Crime Mapping and
Prediction System
(CMAPS)
Crime and Criminal 
Tracking System 
(CCTNS)
Figure 1: Diagrammatic representation of institutional ac-
tors and dataflow within CMAPS
3 METHODOLOGY
This paper reports findings from a larger ethnographic study of
predictive policing in Delhi conducted over 2 years (from Febru-
ary 2017 to March 2019). Initially, our research questions centred
around the technical systems alone and the way in which they
might be aiding decision making within Delhi Police. As we spent
more time at the Delhi Police Headquarters (PHQ), our concerns
changed in two important ways. First, we realized that the human
and institutional actors surrounding CMAPS and the processes that
preceded it, substantially informed and influenced its form and use.
Second, we learnt that the process of data collection and creation
within the PHQ was carried out in the absence of explicitly artic-
ulated standard operating procedures and auditing mechanisms.
Thus, we realized that we first needed to understand the link be-
tween individual arbitrariness and institutional standardisation in
context of CMAPS. That motivated us to specifically conduct an
in-situ study of the data creation processes within policing in order
to understand the eventual impact of CMAPS. We collected data
through marginal and participant observation with Call Takers,
including those who handle emergencies, Dispatchers, Digital Map-
ping Division Map Plotters, and officers in the communications
wing. We also conducted unstructured interviews with approxi-
mately 20 individuals to uncover the qualitative ways in which
value laden decisions are taken by officers in the PHQ. Observation
and interviews were conducted in parallel. The former helped us
understand established processes of data collection and creation,
and gave rise to specific questions which we followed up through
interviews. We gained access to the PHQ as academic researchers
interested in studying the technical turn to policing in India’s capi-
tal. During our time there, access to documents related to mapping
and predictive policing were limited due to security reasons. Ac-
cess to the Call Centre and the Dispatch Command Room was
considerably tougher than the DMD. We were not allowed to carry
notebooks or any recording device inside the Call Centre. However,
access to documents displayed publicly on the notice boards of Call
Centre, and DMD was provided. To supplement the gaps in our
observations and interviews and to verify some information from
our interviews, we also filed two requests under India’s Right to
Information (RTI) Act, to illuminate the extent to which CMAPS
is currently used, how the system was designed, developed and
audited before deployment, how personnel operating CMAPS are
trained and what the parameters of their training are, funding for
CMAPS, among others. We received 13 replies to our RTI but given
wide exceptions for law enforcement under the RTI Act, and a gov-
ernance vacuum around the use of technology in the public sector,
we were unable to furnish any information through this route. In
March 2019, our access to DMD and other processes within Delhi
Police were cut off due to security reasons.
4 INSIGHTS FROM THE FIELD: FROM DATA
COLLECTION TO CREATION
Data practices within the Digital Mapping Division are a crucial
component of CMAPS for two reasons. First, it is this data that
underpins CMAPS and informs the infrastructural layers and spa-
tial maps used for predictive policing in Delhi. Second, the way
in which manual mapping is carried out is a strong indicator of
the institutional practices and biases within which CMAPS will
function. While the outcomes from the current system are virtu-
ally impossible to study at this point, a closer look at input data
can provide important insights into the system as a whole. In this
section, we provide an account of how current data practices play
out in Delhi Police’s hotspot mapping initiative.
4.1 Groundwork: Digital Mapping Division
In 2007, the Digital Mapping Division (DMD) set up the groundwork
for a comprehensive mapping system in New Delhi. The underlying
structure on which crimes are mapped and analysis is drawn was
built by the DMD, which surveyed Delhi for its popular landmarks,
data on metro pillars (a popular landmark of callers to Dial 100
emergency number), and updated the city’s landscape given signif-
icant changes and construction. It surveyed Delhi Police Station
boundaries in order to accurately set jurisdiction of crimes, a cru-
cial process that often decides the validity of a crime report. These
boundary layers were also significant as crimes were mapped ac-
cording to jurisdictions, and these boundaries decided which areas
see more crime than others, and consequently, which areas need
more policing and resources. The process for mapping was less
than consistent. In the beginning, officers in the mapping division
were instructed to manually put dots indicating crime locations, on
a digital map of Delhi built on ArcGIS, a popular mapping software
designed by Environmental Systems Resource Institute (ESRI). This
strategy did not endure the test of time for two reasons. First, the
ArcGIS license expired in 2017 and its renewal has not yet been
sanctioned for budgetary reasons. Second, Delhi’s address database
consists only of 500, 000 addresses, which is not only woefully in-
adequate for accurate mapping, but also riddled with errors. These
addresses also did not have latitude-longitude coordinates, neither
did they have social or physical information that would lend detail
to the geographic structure of the city. This led to officers being
instructed to plot crime locations onto relevant jurisdictional police
stations. Later when this kind of mapping indicated only police
stations as crime spots and made any kind of visualisation impossi-
ble, they were asked to map the locations at the nearest point of
the actual location mentioned in the address (of the crime). This
inconsistency in methodology, along with varying definitions of
accuracy make this mapping unreliable at the very least. The DMD
has been mapping data on crimes of rape, robbery, eve teasing and
snatching on Delhi GIS maps, populated with all the information
procured in the survey, since 2008. It is intended that CMAPS, with
automated mapping will correct these inconsistencies, but having
an inaccurate benchmark (or a historical dataset) against which
performance will be evaluated casts doubt over CMAPS being a
panacea. Another fundamental drawback of hotspot mapping in
general is that because the emphasis in this mapping is on quantity
alone, even grievous crimes when committed in non-selected areas
tend to fall off the radar of a system like CMAPS [9].
4.2 Source of input data - Calls to 100 call
centre
The Delhi Police Dial 100 call centre, situated on the third floor of
the command room of Delhi Police Headquarters, has around 40
channels to which emergency calls can be routed. Each channel has
its own unique number and is attended by a call taker whomentions
the number in his/her introduction. The call takers enters details
of crime into the “PA 100 form” that record information received
through the call and categorise them into 130 pre-determined cate-
gories including one ‘miscellaneous’ for when it is difficult to slot
the incident accurately. If there are more crimes than one, for exam-
ple, snatching and murder, the call taker will only slot the crime as
murder. Only the higher crime would be taken into consideration,
which undermines the accuracy of this data to indicate frequency
of crimes across the spectrum. The rest of the event description
is put into the notes section of the form. The form captures the
registered address of the caller, but that is not always the location
of the crime. Call takers ask the callers to mention their addresses
accurately but routinely fail because of the semi planned nature of
the city. Shanty settlements, irregular colonies do not have proper
addresses; most of the times callers do not know where they are
calling from. Callers also mention local landmarks while inform-
ing about their location, thinking the call has landed in their local
police stations. For example, in one instance, a caller stated “I am
standing near the peepal tree,” making it difficult for call takers to
input their exact address/location. Call takers can search for the
address from the 500, 000 address database but it is not usually
adequate. This, combined with an incentive to conclude calls as
soon as possible (given that call takers are judged on their perfor-
mance based on turnaround time of calls), call takers tend to mark
the location of crime as police stations instead of actual addresses,
given that it’s the only accurate database they have of anything
related to locations in Delhi, leading to skewed results. A frequent
error occurs when callers report a crime at a location different from
where they are calling. Call takers resort to standardized questions
about the location of the caller and do not enquire further because
they are incentivized to be quick more than they are incentivized to
be accurate. For example, once parents of a woman called to report
the death of their daughter due to medical negligence which had
occurred at a hospital in Saket. They called from their home which
led to the call taker mark this as a crime at the caller’s residence
instead of the hospital.
4.3 Dispatch and PCR Van
Once the form is filled with details of the crime, it is automatically
sent to the dispatch section on the fourth floor of PHQ through
the PA 100 software. The Dispatch floor is divided into 11 zones
mirroring 11 districts of Delhi (though they have been revised to
13, the zones still remain 11). The call is transferred to its appro-
priate zone according to location from where it is transferred to
its respective Police Control Room (PCR) van. The officer on the
Dispatch console manually provides the call details to the PCR van
officers over microphone. The dispatch function was planned such
that as soon as the call takers close the PA 100 form, a message
with all call details is sent to the handheld devices of the PCR van
officers.
They would then send the investigation report (called the halaat
report) from these handheld devices, which would also give the
exact location of the scene of crime. But the plan did not work out
for a variety of reasons. Dispatch and PCR personnel say that it was
too much work charging the devices, and also claimed that they
were not adequately trained to operate the devices. HQ officers,
those in the DMD argue that carrying a handheld device would be
surveillance for the PCR van officers, something that they did not
want because they sometimes cut corners when it comes to actually
visiting the crime locations. An investigation in HQ revealed this
to be true; many PCR van officers negotiate with their Dispatch
counterparts into being assigned fewer investigations during their
shift. They also do not visit all the crime scenes but sometimes
merely replicate the report of the investigating officer from the
police station into the halaat report.
4.4 Heinous crimes go to green diary
Next, the dispatch officer sends a copy of four heinous crimes –
rape, robbery, eve teasing and snatching – to the dispatch com-
mand room as soon as they receive them from the call centre. If
the halaat report confirms the crime, it is entered into the ‘Green
Diary’, a comprehensive document with verified accounts of all
the calls related to four heinous crimes at the Dial 100 call centre.
Understanding crime events and categorising them correctly also
require certain level of interpretative understanding of categorisa-
tion rules, which are informal in the PHQ and usually taken from
on-ground policing experience of the officers. For example, once a
shopkeeper called to report how two men came to his shop asking
for two bags of ghee, and when he put them on the counter, they
asked for a bottle of Chyawanprash. As soon as he turned to get
the Chyawanprash bottle, the men ran away with the bags of ghee.
The call taker had categorised the crime as snatching. A debate
ensued on the Dispatch floor on whether the crime was indeed
snatching or if it was a case of robbery. Finally it was decided that
because the two men, for all intents and purposes, snatched the
ghee bags from the shopkeeper, this was snatching (The men then
ran away on their bike, fulfilling more conditions of snatching). The
crime was finally recorded in the Green Diary as snatching. These
choices are arbitrary and based on common understandings of what
every crime entails. For example, categorisation practices in HQ
prescribe ‘Snatching’ to someone taking away another’s property
forcefully. But it can only be committed by one or a maximum of
two people. Three people do not snatch, they rob. If a weapon is
involved, it is definitely a robbery, even if committed by only one
person. Crimes against women are acceptable if they happen during
the day without the women being at any ‘fault’ at all (not wearing
skimpy clothes, not inebriated, not with a ‘male friend’). Officers in
the DMD question women related crimes that take place at night,
wondering why women are out at that time at all. One officer said,
“if it is work it is okay, but most of these women are not out for
work, then who is responsible for their safety?”
Official police records have always been at the mercy of police
practices and whether the officers recording the crime believe an
event to be criminal at all [17]. This can be extrapolated to police
officers disbelieving complainants themselves. Officers in PHQ ar-
gue that most of the people who call from slums and ghettos would
not do so if the calls to the number 100 were chargeable. They also
believe that most of the snatching cases are inflated because of the
general belief that police would not act on cases where the value of
the objects snatched was low. They argue that a large majority of
heinous calls for women related crimes were almost always false
on the ground. “Girl will fight with her boyfriend and then to scare
him would call for a case of rape. When we reach the place, she is
the one apologizing, this is the reality of most of these calls,” as told
by multiple officers at call centre, dispatch and DMD. A status of
policing in India report, released by Lokniti and Centre for Study
of Developing Societies in 2018 [4], showed how the marginalised
groups in India - Dalits, adivasis, Muslims and people living in
slums - were the last ones to engage with the police (While the
police engagement with them was disproportionately high). How-
ever, the story in the Delhi Police Call Centre is different. Here,
the calls received at the emergency response number 100 are tilted
towards the poorer parts of the city. The call takers confirmed that
‘rich areas’ called very rarely and it is the slums and resettlement
colonies (for e.g. Khichdipur (a resettlement colony in East Delhi)
that called the most. As Santana Khanikar notes [20], police is the
only form of everyday governance that people of lower income
colonies and slums have access to, which is why residents of these
colonies share a love-hate relationship with the police. According
to her, a high volume of calls might not be an indicator of high
crime but a lack of access to other sections of governance for these
urban poor [11]. Crime calls are thus subjectively analysed and
categorised from the Call centre to the Dispatch. Most cases reach a
compromise so an FIR or even an official complaint is not registered
though they are recorded in the Green Diary and mapped on the
hotspot map. Using calls to the emergency response number as
proxy for crime is, therefore, problematic for multiple reasons [12].
First, it represents a significant measurement error as calls to an
emergency number are not always indicative of actual crime, and
second, it fails to engage with nuances of societal needs and access
to public services and adequate governance.
4.5 Recording Green Diary
If a call regarding a heinous crime comes late at night when in-
vestigations might be slow (delaying the halaat report), they are
entered in the Green Diary draft with a ‘pending’ status. The status
is updated only if the halaat report is received before the Diary is
to be sent for mapping, i.e. by 6 AM. However, if the report does
not come, these calls are mapped without being corroborated by
haalat reports. Spurious calls in such a manner can light up an area
as criminal in mapping even though the underlying data could be
completely false. Which in turn means that we do not know if these
crime calls were indeed what they claimed. Though Green Diary is
slated to be a verified document of all calls, there were some dis-
crepancies in certain calls and in their halaat reports. We observed
many cases where a crime was recorded as “no matter of snatch-
ing” – police speak for ‘it was a bogus call’ – in the halaat report,
but was present in the Green Diary. Slippages between the officer
managing the consoles where heinous crime details are received
from dispatch, and the one who prepares the Green Diary ensure
that sometimes calls that were found untrue upon investigation
were also recorded as true calls.
5 ANALYSIS
One of the arguments in favor of deploying predictive policing sys-
tems is that it leverages technology to free public institutions from
human prejudice [24]. Our research has shown that this is likely
an untrue claim. Manual hotspot mapping will feed foundational
aspects of CMAPS, and this data is the product of a series of sub-
jective decisions, skewed reporting, and uneven policing practices.
Here, we will discuss some of the common threads we identified
through our research. Our findings emerge from the data practices
from the DMD, given that data from the DMD feeds in foundational
aspects of CMAPS, and that data practices within the Division re-
flect an institutional culture that will be embedded within CMAPS,
the above process has significant implications for CMAPS, and
any other predictive policing initiatives that may be introduced by
Delhi Police in the future. Our key takeaways from this study are
as follows:
5.1 Bias in three parts
While it is well understood that training data bias is a challenge in
any machine learning system [1], this study helped us delineate the
types and origins of biases that exist within Delhi Police’s system
for predictive policing, using the framework proposed by Suresh
and Guttag [29]:
5.1.1 Historical bias. . While gathering information is an age
old practice within policing, from compiling “badmash registers” in
colonial India tomaintaining a list of criminals by birth to keep track
of criminal tribes [27], the act of gathering information has always
been a selective one; with greater surveillance often befalling axes of
disadvantage, i.e. caste, gender, class, and religious minority. It is not
simply a case of more crime occurring in poorer parts of Delhi, or
in places where minorities and migrants live - an additional layer of
complication is introduced when a human is tasked with choosing
which area or under which crime a certain call should be filed.
A general apathy towards individuals living in slums, and more
forgiving outlooks with respect to individuals living in posh parts
of Delhi was apparent from conversations across the Call Centre.
This, combined with the fact that policing as an institution has a
controversial record around discrimination, brutality, and illegal
practices with vulnerable individuals [11] means that historical bias
is not only embedded, but actively formalised and introduced into
data.
5.1.2 Representation bias. . Given that input data for CMAPS
consists of calls to the Dial 100 call centre and a national database
used to track crime and criminals, there is a significant underrep-
resentation of individuals from privileged socio-economic back-
grounds, and also of upscale areas in the data. This is because the
sampling methods, i.e. calls to an emergency helpline or existing
records in a criminal database (not conviction database) lend them-
selves more readily to some areas of the city and sections of society.
The DMD receives around 20000 calls a day, and in the course of
our research some employees said that people from posh areas
“hardly called”, and that an overwhelming majority of these calls
were from slums. This means that the probability of crime will be
marked higher in hotspot areas where quantity of engagement is
higher, leading to a vicious circle of heightened scrutiny for the
most marginalised, eventually leading to more arrests and reports
coming out of these areas.
5.1.3 Measurement bias. . Occurs in DMD and CMAPS for a
few reasons. Given that the spatial distribution of Delhi is less
accurate among temporary settlements, and there is greater nuance
in data arising from privileged neighbourhoods in Delhi, the clusters
of information tend to be less quantitatively overwhelming, thus
attracting less future scrutiny. This bias arises not just because of
systemic blind spots, but also because of vulnerable individual’s
inability to engage with the system as well as others. For example,
we learnt from a call taker that some people do not know their
addresses even if they have been living at that place all their lives
and an overwhelming majority of such people have always been
women. She said women mostly stay inside the house and are
not very aware of their surroundings or the exact address (name
of mohalla/colony) of their location. In most cases they wouldn’t
even know the nearest police station by which the call taker could
identify the caller’s address. In such cases the call takers have
no choice but to ask callers to call again once they know their
address. They encourage them to ask a passerby to tell them about
the landmarks of their location, a thana, police chowki or another
famous place to get their address.
5.2 Disparate impact, or indirect
discrimination
Disparate impact refers to a situation where a prima facie neutral
policy has a disproportionate and disadvantageous impact on a
protected class [1]. Findings from our research indicate that data
collection and creation within Delhi Police has a disproportionate
impact on historically marginalised and vulnerable groups, which
we can logically extend to decision making that is informed by such
data [22]. Crimes are more likely to be recorded when they come
from organised colonies, with specific details and granular infor-
mation relating to actual addresses, whereas crimes from shanty
settlements are plotted at the same spot due to lack of accurate infor-
mation, leading to an imbalance in what is classified as a "hotspot"
of crime. There is also widespread selective enforcement and indi-
vidual officer discretion that works against the interests of these
communities. This is turn leads to over-policing areas inhabited
by individuals from vulnerable groups, and also creates a cycle of
confirmation bias within an institution that is already embedded
with societal, cultural, gender and caste biases [11]. Article 15 of
the Indian Constitution prohibits discrimination on the grounds
of race, religion, caste, sex, and place of origin. While the status
of disparate impact under Article 15 has been the subject of some
legal debate [2], the Delhi High Court in 2018 recognised indirect
discrimination [10], a.k.a disparate impact, as one that qualifies
as discrimination under the Indian Constitution. Reiterating the
rationale underlying Article 15, the Court stated that it existed be-
cause women and other vulnerable groups, “have been subjected to
historic discrimination that makes a classification which dispropor-
tionately affects them as a class constitutionally untenable.” Given
our findings in this paper, thus, current data practices within the
Delhi Police can attract Article 15 of the Indian Constitution.
5.3 Direct discrimination
The design of ‘layers’ in CMAPS software can be used to filter
immigrant colonies and minority settlement areas, extending from
the belief that crime rises due to the de facto existence of these
areas, and the people who live in them. The observable variable
that is used at the time of analysis and filtering is not merely a
proxy for a protected attribute, it is the protected attribute itself,
under Article 15(1) of the Indian Constitution. It is also reasonable
to state that the use of such infrastructure can attract Article 14
of the Indian Constitution, which contemplates the fundamental
right to equality and equal protection of laws. According to the
Supreme Court of India, “equality” must necessarily be substantive,
i.e. must consider whether a provision or executive act “contributes
to the subordination of a disadvantaged group of individuals.” [5]
The use of opaque technical systems like CMAPS currently afford
a veneer of objectivity and shield against scrutiny in the process,
but a challenge to this usage is both possible and crucial.
5.4 Hard coding arbitrariness
Arbitrariness is a fundamental aspect of police recording crime be-
cause it comes down to how a specific officer on the scene of crime
(or the officer noting the details of the call) interprets a particular
crime event. These interpretations have no standardised format or
prescribed form, and are subsequently encoded as categories in the
PA100 form from where they make their way to the Green Diary,
Manual Maps and CMAPS. Categorisation plays a major part in
how data is readied for use by an algorithm, as Gillespie states,
it is a “powerful semantic and political intervention” which once
instituted is treated with reverence by algorithms, and the criteria
used to define these categories is reified by algorithms [7]. As dis-
cussed above, categorisation of calls is arbitrary and depends on
the call taker’s interpretation of the calls and the dispatch officer’s
takeaway from the halaat report. More often than not, this arbi-
trariness works against marginalised groups, and in turn, embeds
and formalises this tendency into technology. The PA 100 form
(where calls are categorised) also represents the years of social
understanding of crime of its designers who have used Criminal
Procedure Code, Indian Penal Code and Punjab Police Rules Rules
1956 to create 130 categories in the form. Standardised forms reflect
institutional notions of crime - some scholars [13] believe these
forms are the very essence of a bureaucratic institutions, and that
investment in such forms has been a cultural historical project to
exclude residual categories. For example, genders are expressed as
male/female in most government standardised forms leaving no
choice for people who do not conform to both. A pre-defined form
with 130 categories (the miscellaneous category is present but is
not used often) limits the ability of call takers to record nuances
of each call, and in the process forces categorisation into socially
accepted norms that are inadequate at best. For example, one of
the call takers described how crimes where the woman was beaten
by the husband/in-laws was neatly categorised as ‘domestic vio-
lence’ but off late there have been many calls where the husband
was beaten by the wife and her parents which were categorised as
‘quarrel’ (which one of the call takers pondered, was “happening
too often now a days”).
5.5 Opacity as a feature, not a bug
Opacity obscures accountability within algorithmic systems, and
has a similar effect on the institutional reality within which such
systems function. Through our field work and research, we found
that opacity is intentionally constructed around CMAPS, both as
a technical system and an institution. It is kept out of reach of
the Right to Information Act to the best of our understanding and
experience - which is most likely by invoking broad exceptions for
security and strategic information of the State and law enforcement
purposes. This extends to accessing CMAPS during field work as
well. While the conceptualisation of CMAPS was celebrated in the
media and publicly discussed, there is little room to uncover what
it truly is. To peer into the inner working on CMAPS, thus, large
scale institutional reform is as important building transparent and
accountable systems in isolation.
6 CONCLUSION AND RECOMMENDATIONS
Through this research, we have sought to understand the ways
in which institutional approaches to data and policing practices
affect hotspot policing systems like CMAPS. By walking the reader
through processes that precede and underpin CMAPS, we have
demonstrated that bias within Delhi Policing is textured, unstruc-
tured and pervasive. Discriminatory and arbitrary practices mirror
problematic social norms and run through the system, from insti-
tutional legacy to individual officers’ subjectivity. There is little
if any logical separation between bias within the technical sys-
tem (CMAPS) and bias within the institution (Delhi Police). Our
field work revealed that institutional bias predicates and cements
bias within the technical system and thus cannot be meaningfully
separated in our analysis. Our recommendations stem from this
finding. Our research builds on existing work [3, 24] that focuses
on ex-ante assessment of predictive policing systems like CMAPS.
Here we stress the importance of focussing these assessments on
institutional formalities and standard operating procedures prior
to analysing the sociotechnical system itself. We propose that any
predictive policing system must be studied through the lens of insti-
tutional culture and limitations within which it will function, and
then through the lens of outcomes and harm for two reasons. First,
harm is not always tangible, making it particularly important to
address representational harms at the stage of design and develop-
ment [15]. Second, transparency and accountability mechanisms
are not always possible. Studying the institution ensures that even
opaque systems employed by the institution are critiqued and held
to a basic standard of due process. We believe this approach repre-
sents a logical progression: first study the cause and then analyse
symptoms. Based on this overarching recommendation we propose
renewed efforts into holding consequential systems in the public
sector to account by focussing on four aspects surrounding these
systems:
(1) Research into the public sector institution within which the
system will function should emphasize standard operating
procedures, bright lines for discretionary action, reporting
formats and grievance redressal.
(2) Procurement processes for predictive policing systems should
be made transparent, and should indicate the specifications
required from the system, standards to which systems must
adhere, and also include auditing and accountability mecha-
nisms at the time of contracting and deploying systems.
(3) Engagement with predictive policing systems must include
a critical analysis of governance limitations and reforms at
a purely institutional and bureaucratic level, to understand
the practices that will percolate to these systems and the
dangers associated with such percolation, and finally
(4) Ex post mechanisms for fixing, appealing and correcting
errors should be developed in parallel. These do not have to
be limited to the technical system’s audit alone - it must in-
stead focus on what underlying accountability and redressal
mechanisms exist and can be adopted to technical systems
that function within the same reality.
This provides a framework for law enforcement authorities to think
through the efficacy of predictive policing systems and aids civil
society and activists in assessing the impact of systems in the ab-
sence of concrete evidence of outcomes. While bias in policing sys-
tems is crucial to understand at a granular level, we do not believe
appropriate solutions lie in finding perfectly un-biased systems.
They lie, instead, in ensuring that the surrounding mechanisms to
a sociotechnical system lend themselves to checks and balances,
adapting to social contexts within which they function, and to
scrutiny, transparency and accountability.
7 LIMITATIONS AND FUTURE RESEARCH
This ethnographic study and subsequent analysis are based on our
observation and interviews within limited divisions at Delhi Police
Headquarters collected over a span of two years. Our analysis is
meant to be a first step towards evidence building on the use of
machine learning in policing in non-western contexts, with sub-
stantive and methodological contributions that can be used at the
time of engaging with similarly placed predictive policing systems.
Future areas of research would include testing our findings of bias
on actual use cases within CMAPS, studying the procurement pro-
cesses between policing institutions and vendors, and analysis of
ongoing auditing and performance evaluation of these systems.
ACKNOWLEDGMENTS
We thank Dr. Divya Vaid, Mallory Knodel, Dr. Abhinav Narain, and
anonymous reviewers for helpful feedback on our methodology
and earlier versions of this paper. Many thanks also to Delhi police
for their cooperation in making this project possible.
REFERENCES
[1] Solon Barocas and Selbst. Andrew D. 2016. Big Data’s disparate impact. Technical
Report. California, USA.
[2] Gautam Bhatia. 2013. Article 15 and Typologies of Discrimination - II. Retrieved
Aug,10 2019 from https://indconlawphil.wordpress.com/2013/10/29/article-15-
and-typologies-of-discrimination-ii-disparate-impact/
[3] Sarah Brayne. 2017. Big Data Surveillance: The Case of Policing. American Socio-
logical Review 82, 5 (2017), 977–1008. https://doi.org/10.1177/0003122417725865
[4] Common Cause and Lokniti’s Centre for the Study of Developing Societies. 2018.
State of Policing in India: A Study of Performance and Perceptions. Technical
Report. New Delhi, India.
[5] Supreme Court. 2018. Joseph Shine v. Union of India on 27 September 2018. Re-
trieved Aug,15 2019 from https://sci.gov.in/supremecourt/2017/32550/32550_
2017_Judgement_27-Sep-2018.pdf
[6] Andrew Guthrie Ferguson. 2017. Policing Predictive Policing.
[7] Tarleton Gillespie. 2014. Media Technologies: Essays on Communication, Mate-
riality and Society. MIT Press, MIT Press, Cambridge, Massachusetts USA and
London, England.
[8] Donna Haraway. 1988. Situated Knowledges: The Science Question in Feminism
and the Privilege of the Partial Perspective. Feminist Studies 14, 3, Article 5 (1988).
https://doi.org/10.2307/3178066
[9] Martin Innes, Nigel Fielding, and Nina Cope. 2005. The Appliance of Science:
The Theory and Practice of Crime Intelligence Analysis. The British Journal of
Criminology 45, 1 (Jan. 2005), 39–57. https://doi.org/doi.org/10.1093/bjc/azh053
[10] India Kanoon. 2018. Madhu & Anr. Vs Northeren Railway & Ors. On 17 January
2018. Retrieved Aug,15 2019 from https://indiankanoon.org/doc/130340388
[11] Shantana Khanikar. 2018. State Violence and Legitimacy in India (1st ed.). Oxford
University Press, New Delhi, India.
[12] David Klinger and George Bridges. 1997. Measurement Error in Calls-for-Service
as an Indicator of Crime. Criminology 35 35, 4 (Nov. 1997), 705–726. https:
//doi.org/10.1111/j.1745-9125.1997.tb01236.x
[13] Martha Lampland and Susan Leigh Star. 2009. Standards and their Stories: How
Quantifying, Classifying and Formalising Practices Shape Everyday Life. Cornell
University Press, USA.
[14] Kristian Lum and William Issac. 2016. To Predict and Serve? Retrieved December
15, 2019 from http://onlinelibrary.wiley.com/doi/10.1111/j.1740-9713.2016.00960.
x/epdf
[15] Vidushi Marda. 2018. Artifical Intelligence Policy in India: A Framework for
Engaging the Limits of Data Driven Decision Making. Philosophical Transactions
of the Royal Society A: Mathematical, Physical and Engineering Sciences 376, 2133,
Article 2133 (Oct. 2018). https://doi.org/10.1098/rsta.2018.0087
[16] Vidushi Marda. 2019. Facial Recognition is an invasive and inefficient tool. Re-
trieved August 14, 2019 from https://www.thehindu.com/opinion/op-ed/facial-
recognition-is-an-invasive-and-inefficient-tool/article28629051.ece
[17] Tim May. 2011. Social Research Issues, Methods and Processes (3rd ed.). Rawat
Publishers, New Delhi, India.
[18] Anand Murali. 2018. The Big Eye: The Tech is all Ready For Mass Surveillance in
India. Retrieved August 10, 2019 from https://factordaily.com/face-recognition-
mass-surveillance-in-india/
[19] Times of India Bureau. 2018. Delhi’s tryst with Predictive Policing. Retrieved July
28 2019 from https://timesofindia.indiatimes.com/city/delhi/delhis-tryst-with-
predictive-policing/articleshow/64598386.cms
[20] Delhi Police. 2015. From the Commissioner’s Desk. Technical Report. New Delhi,
India.
[21] Delhi Police. 2019. Live Crime Mapping, Analytics and Predictive Systems (CMAPS).
Retrieved August 18 2019 from http://59.180.234.21:8787/Press_Release_Details_
iframe.aspx?cid=KUihvPCOCPg=
[22] Rashida Richardson, Jason Shultz, and Kate Crawford. March 2019. Dirty Data,
Bad Predictions: How Civil Rights Violations Impact Police Data, Predictive Policing
Systems and Justice. Retrieved July 5, 2019 from "https://papers.ssrn.com/sol3/
papers.cfm?abstract_id=3333423"
[23] Nick Seaver. 2019. DigitalSTS: A Field Guide For Science and Technology Studies.
Princeton University Press, New Jersey, NJ, USA.
[24] Andrew D. Selbst. 2017. Disparate Impact in Big Data Policing. Technical Report.
Georgia, USA.
[25] Andrew D. Selbst, Danah Boyd, Sorelle A. Friedler, Suresh Venkatasubramanian,
and Janet Vertesi. 2019. Fairness and Abstraction in Sociotechnical Systems. In
Proceedings of the Conference on Fairness, Accountability and Transparency. ACM
Press, New York, NY, USA, 59–68. https://doi.org/10.1145/3287560.3287598
[26] Karn Pratap Singh. 2017. Preventing Crime Before It Happens: How Data is
Helping Delhi Police. Retrieved Aug 8 2019 from ttps://www.hindustantimes.
com/delhi/delhi-police-is-using-precrime-data-analysis-to-send-its-men-to-
likely-trouble-spots/story-hZcCRyWMVoNSsRhnBNgOHI.html
[27] Radhika Singha. 2015. Punished by Surveillance: Policing "Dangerousness" in
Colonial India, 1872-1918). Modern Asian Studies 49, 2 (March 2015), 241–269.
https://doi.org/10.1017/S0026749X13000462
[28] Tech2 News Staff. [n.d.]. A centralized database of citizens in the state of
Telangana is under consideration. https://www.firstpost.com/tech/news-
analysis/a-centralised-database-of-citizens-in-the-state-of-telangana-is-
under-consideration-3696851.html
[29] Harini Suresh and John V. Guttag. 2019. A Framework For Understanding Unin-
tended Consequences of Machine Learning. (2019). arXiv:arXiv:1901.10002
[30] Mohd Ujaley. 2018. Punjab Police Won Smart Policing Award For Pun-
jab Artificial Intelligence System. Retrieved August 10, 2019 from
https://www.expresscomputer.in/egov-watch/punjab-police-won-smart-
policing-award-for-punjab-artificial-intelligence-system/24958/

Algorithmic Accountability in Public Administration: The GDPR
Paradox
Sunny Seon Kang∗
sunny@inpher.io
Senior Privacy Counsel and Head of Policy
Inpher
New York, New York
ABSTRACT
The EU General Data Protection Regulation (“GDPR”) is often rep-
resented as a larger than life behemoth that will fundamentally
transform the world of big data. Abstracted from its constituent
parts of corresponding rights, responsibilities, and exemptions, the
operative scope of the GDPR can be unduly aggrandized, when in
reality, it caters to the specific policy objectives of legislators and
institutional stakeholders.
With much uncertainty ahead on the precise implementation
of the GDPR, academic and policy discussions are debating the
adequacy of protections for automated decision-making in GDPR
Articles 13 (right to be informed of automated treatment), 15 (right
of access by the data subject), and 22 (safeguards to profiling). Un-
fortunately, the literature to date disproportionately focuses on the
impact of AI in the private sector, and deflects any extensive review
of automated enforcement tools in public administration.
Even though the GDPR enacts significant safeguards against au-
tomated decisions, it does so with deliberate design: to balance the
interests of data protection with the growing demand for algorithms
in the administrative state. In order to facilitate inter-agency data
flows and sensitive data processing that fuel the predictive power
of algorithmic enforcement tools, the GDPR decisively surrenders
to the procedural autonomy of Member States to authorize these
practices. Yet, due to a dearth of research on the GDPR’s stance
on government deployed algorithms, it is not widely known that
public authorities can benefit from broadly worded exemptions to
restrictions on automated decision-making, and even circumvent
remedies for data subjects through national legislation.
The potential for public authorities to invoke derogations from
the GDPR must be contained by the fundamental guarantees of due
process, judicial review, and equal treatment. This paper examines
the interplay of these principles within the prospect of algorithmic
decision-making by public authorities.
∗Fellow and Master of Juridical Science (J.S.M.) 2019, Stanford Law School, Former
International Consumer Counsel, Electronic Privacy Information Center, Master of
Laws (LL.M.) 2017, UC Berkeley School of Law.
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
FAT* ’20, January 27–30, 2020, Barcelona, Spain
© 2020 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-6936-7/20/02.
https://doi.org/10.1145/3351095.3373153
CCS CONCEPTS
• Security and privacy; • Human-centered computing; • So-
cial and professional topics;
KEYWORDS
General Data Protection Regulation (GDPR), Algorithmic Account-
ability, Automated Decisions, Predictive Enforcement Tools, Due
Process
ACM Reference Format:
Sunny Seon Kang. 2020. Algorithmic Accountability in Public Adminis-
tration: The GDPR Paradox. In Conference on Fairness, Accountability, and
Transparency (FAT* ’20), January 27–30, 2020, Barcelona, Spain. ACM, New
York, NY, USA, 1 page. https://doi.org/10.1145/3351095.3373153

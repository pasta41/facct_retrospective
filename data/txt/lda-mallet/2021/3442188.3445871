Fifty Shades of Grey In Praise of a Nuanced Approach Towards Trustworthy Design Environmental data science is uniquely placed to respond to essentially complex and fantastically worthy challenges related to arresting planetary destruction Trust is needed for facilitating collaboration between scientists who may share datasets and algorithms and for crafting appropriate science-based policies Achieving this trust is particularly challenging because of the numerous complexities multi-scale variables interdependencies and multi-level uncertainties inherent in environmental data science Virtual Labs easily accessible online environments provisioning access to datasets analysis and visualisations are socio-technical systems which if carefully designed might address these challenges and promote trust in a variety of ways In addition to various system properties that can be utilised in support of effective collaboration certain features which are commonly seen to benefit trust transparency and provenance in particular appear applicable to promoting trust in and through Virtual Labs Attempting to realise these features in their design reveals however that their implementation is more nuanced and complex than it would appear Using the lens of affordances we argue for the need to carefully articulate these features with consideration of multiple stakeholder needs on balance so that these Virtual Labs do in fact promote trust We argue that these features not be conceived as widgets that can be imported into a given context to promote trust rather whether they promote trust is a function of how systematically designers consider various potentially conflicting stakeholder trust needs CONCEPTS Human-centered computing Computer supported cooperative work HCI theory concepts and models KEYWORDS Trust Affordances Environmental Data Science Virtual Research Environments INTRODUCTION It is well known the numerous benefits of trust for example in facilitating and sustaining collaborative relationships and enabling decision making More fundamentally however we can understand trust as a clever mechanism the function of which being to reduce complexity in order to resolve paralysing uncertainty so that one is able to actor in MÃ¶llerings p own words bracketing the unknowable thus making interpretative knowledge momentarily certain Unknowing is intrinsic to science we look to evidence to support or really the absence of evidence to refute hypotheses so that we can make confident claims about our world Confidence in scientific claims is perhaps uniquely challenging in the area of environmental science where competing values priorities and politics are at play Being able to make policy decisions that will help arrest planetary destruction requires trust not only in the scientific findings and resulting recommendations but subsumed within this trust in the people processes and data that led to these findings and recommendations The collaborative nature of science and particularly environmental science also means that scientists themselves need to have a solid basis for trusting their collaborators the processes and data they use and their findings in order to make collective progress in the field The turn towards open data and the development of new collaborative environments are indicative of the need to foster trust in environmental data science and its underlying methods assumptions and datasets The authors of this paper are involved in the development of an easily accessible online environment provisioning access to datasets analysis and visualisations In the early stages of designing this Virtual Lab it was presumed that well-known trust-supporting properties would need to be incorporated to achieve intended trust Transparency providing collaborators access to relevant information to determine trustworthiness of the items in the repository Provenance preserving workflow through notebook technologies integrated with version control possibly incorporating blockchain Security balancing openness with some assurance of privacy for collaborators It is possible that these are essential high-level design goals in promoting trust in some form But in attempting to envisage how these might be implemented and interrogating the purpose they serve with respect to specific users of the system in specific contexts we came to understand that these properties which are so commonly seen to benefit trust are not as unproblematically associated with trust as the literature would generally have us believe This paper offers reflections grounded in an extensive trust literature and informed by conversations and interviews with relevant stakeholders of this Virtual Lab on the challenges of simply importing trust solutions from other domains There is neither a singular solution one-size-fits-all approach nor a magic formula to designing for trust this is known already if not necessarily always appreciated Where we go further is in problematising two of the most common ingredients used in designing for trust namely transparency and provenance Our aim is to inform a more considered discourse on what we are calling trust affordances ie designed aspects of systems that promote trust We hope to instill a new sensibility about these affordances as being not only context-dependent but also fluid and multiply-articulated within socio-technical systems This is quite distinct from the predominant though implicit view of such affordances as simple widgets that can be taken off the shelf and incorporated into a system By exploring specifics of how each affordance contributes to trust for whom and then what it would need to look like to promote trust for this particular stakeholder in context we show that trust affordances would need to vary in their final form even within the same system  in other words rather than being binary or black and white there are many shades of grey Given the collaborative nature of environmental data science we follow on from this with a brief consideration of additional affordances related to the sociotechnical aspects of Virtual Labs We conclude with some thoughts about the applicability of these insights to the wider literature on trust where transparency and provenance in particular are seen as almost unquestionably beneficial to trust BACKGROUND Environmental Data Science Environmental data science applies the tools and techniques of data science to environmental science problems Environmental science subsumes a rich tapestry of sciences methods and knowledge of the Earth and its climate Environmental processes are often complex involving non-linear interactions between biological chemical and physical processes across a range of temporal and spatial scales The disciplines and sub-disciplines within environmental science are often fragmented and siloed with each having their own languages methods conventions and approaches There are a small number of big science fields that are voluminous in the quantity of data but homogeneous in instrumentation format content and structure and a larger number of small science fields in which there are smaller amounts of data that exhibit greater heterogeneity and variety Consequently there is a variegated assemblage of heterogeneous structured and unstructured data not always adequately defined or explained at different scales and different levels of veracity stored in field notes local records offices and archives as well as online repositories Given this accessing data or outputs can be difficult to navigate time consuming and often ineffective Even with significant expertise environmental data is not necessarily straightforward Something as outwardly simple and everyday such as soil is incredibly complex uncertain multi-scale and with impacts on multiple stakeholders and areas eg food security carbon capture and protection of biodiversity Similarly sensors often assumed to be inherently objective can be biased depending on their placement and other contextual factors Investigating global plant data Meyer et al found that there are many uncertainties present within the data and that any filtering done to exclude these uncertainties would drastically affect the volume of usable data They conclude that an opportunity to scrutinise data is needed in order to be able to make sufficient use of it In a similar vein Pescott et al state that there is a wide variation in the quality of environmental data advocating for improved meta-data that records assumptions and decisions made with the data pipeline An opportunity to scrutinise data and models alongside improved supplementary information are therefore essential mechanisms to enhance scientific research and even more so when considering the growing emphasis on multi-disciplinarity and hence the increase in non-domain experts and non-experts potentially searching for and using environmental data This is all the more important when we view data through a socio-technical lens Data is aggregated processed and then circulated through different sites and practices Data is not innately neutral there are a multitude of judgements biases limitations assumptions and uncertainties within Given these complexities the application of data science to any area is challenging However for environmental data science in particular these challenges are compounded With regards to environmental data science then trust is valuable to reduce but not completely eliminate complexity Particularly for stakeholders who lack familiarity or face uncertainty Systems that can therefore encapsulate these components enabling collaboration investigation and importantly support stakeholders to place or refuse trust appropriately are worthy of attention Collaborative Virtual Research Environments To address the pressing environmental challenges of the planet a holistic approach that consists of collaborative open and reproducible scientific work is needed Transdisciplinary research transcending any one field or approach by synthesising different types of knowledge is a promising method for addressing complex real-world environmental problems This includes not only experts in the traditional sense but also communities outside of academic institutions Interdisciplinary dialogue and practice is needed but can be problematic and a site for science friction This has led to calls for the development of infrastructure to foster collaboration and bridge the gaps between scientific disciplines policymakers external organisations and agencies the media and publics Virtual Labs represent a means to provide this infrastructure Virtual Labs are online research environments capable of providing access to datasets analysis and visualisations for a range of stakeholders Virtual research environments are conceptual and thus differ with each instantiation Within environmental data science there are realisations of the concept such as DataLabs the Biodiversity and Climate Change Virtual Laboratory and the Environmental Virtual Observatory Despite the differences in how Virtual Labs may be actualised there are some commonalities They are cloud-based platforms enabling users to combine data and modelling software through a Web browser Virtual Labs are differentiated from data repositories which typically focus on meta-data provenance classification and standardisation These environments thus incorporate the traditional features of repositories but also focus on tools and services for instance conducting experiments or including elements of social networks Virtual research environments are typically designed with one specific community in mind but are available to other stakeholders By virtue of being accessible through a Web browser Virtual Labs are technically accessible to all potential users However open access does not equate to being usable or useful in reality To analyse data and understand modelling functions and outputs specific skills and knowledge may be required thus limiting the use of these environments dependent on ability When we think about legislators or members of the public possessing the technical skill to use new technologies or traverse a large amount of evidence should not be taken as a given and thus must be taken in consideration when designing virtual environments Implementations that can be taken to accommodate different stakeholders include environments within the Virtual Lab specifically tailored to skill levels or user experience and the inclusion of glossaries and background information There are various aims and goals for virtual environments such as reproducibility and reusability cross-disciplinarity and collaboration accessibility and understanding transparency improved documentation and meta-data interactivity and usability interoperability and integration scalability and trust These are realised through various functional and socio-technical properties For instance flexibility enables users to define and tailor according to their specific needs This is necessary in order to address the fact that each discipline and project is different and has different norms and needs Virtual Labs represent a space which allows for improved data and software integration which can often be difficult and time-consuming on the one hand and lead to a poor understanding and decision-making on the other However in addition to a purely technical focus Virtual Labs are socio-technical providing space for communication and collaboration across organisations and geographical locations Many of these scientific communities work in isolation and so technology that can transcend the spaces between them whilst also including other stakeholders can act as a source of connection and coordination This viewpoint enables us to think about properties from different angles For instance usability can be seen as a purely functional or technical property or as a socio-technical property that should be defined and enacted in a community-driven way rather than as a top-down implementation Features and properties are also interlinked with others for instance usability can be connected to flexibility collaboration and accessibility Virtual Labs can therefore present a means to connect these standalone features The Challenge of Trust This approach however is not without obstacles a challenge common to all emerging collaborative environments that promote open science and the rapid exchange of experimental and prepublication data and methods is one of trust p Taking into account multiple stakeholders and their concerns imports a consideration of a multiplicity of trusts within the design of Virtual Labs For instance the promotion of trust is related to the adoption and use of Virtual Labs the research outputs included within the lab itself and other stakeholders using the Virtual Lab Whilst being theorised in a myriad of different ways one element that is common to studies of trust is an emphasis on evidence of trustworthiness Trust is often interlinked with interpretation and quality and is commonly associated with the inclusion of provenance information as evidence of trustworthiness and to aid interpretation and hence foster trust for data and model consumers Virtual Labs as a result of their specific features and properties allow for much needed and improved documentation provenance and supplementary information However given that these environments are aimed at serving a variety of user groups that will include both method development and scientific discovery and support for decision making in environmental change it is critical that results presented are meaningful for all stakeholders involved p While there are contexts in which these functional and sociotechnical properties have been shown to promote trust in what follows we explore the extent to which these properties can be said to afford trust in Virtual Labs with treatment of multiple stakeholders To be able to do so we must briefly explain our particular orientation to affordances and define what we are calling trust affordances APPROACH The concept of affordances is useful to guide the design of technology capturing the relationships and interactions between users and an artefact Gibson coined the term affordances referring to a relation action possibility between an environment and an organism Gibsons conception focused on visual direct perception on cues for affordances that do not change with needs and goals of an actor This interpretation is limited when applied to technology particularly because not all technological affordances are directly perceptible Consequently affordances were adapted and adopted within HCI In this line of thought affordances are processed in the brain rather than directly picked up affordances are reliant on knowledge culture and experience rather than existing independently and can be learnt whereas for Gibson they cannot be Whilst Gibson focused on utility and the possible actions afforded the focus within HCI has been on use and usability leading to an over-emphasis on user interfaces When designing trustworthy systems the role of systems designers and researchers is thus not one of solely increasing the functionality and usability of the systems that are used to transact or communicate but to design them in such a way that they support trustworthy action and based on that well-placed trust p With this in mind we take a view of affordances as designed elements that affect not just the human-computer dynamics how any given user interacts with the tool but on broader social dynamics enfolding through the technologys mediation Trust Affordances To develop trust affordances we look to approaches that go beyond a limited focus on usability to those that view affordances as user- and context-specific One means of doing this is by utilising structuration theory developed by Giddens Giddens argues that there is a duality of structure comprised of human agency and social structure Social systems are produced and reproduced recursively between the two Structuration theory is beneficial for investigating groups or organisations and has been applied in work contexts and in online communities In the same way that social structures are recursively reproduced and may be maintained or changed every engagement with technology may see a different structure being enacted and therefore affordances may also be reconstructed over time Technology is both a product of human actions within a specific socio-cultural context and a medium for actions due to its material and social properties inscribed into them by designers Additionally structuration theory allows us to look at technology being used in ways that the designers had not envisioned either through appropriation or enactment In this way users do not use a technology as it was designed and the structures within it but may ignore work around or invent new properties themselves This lens allows us to understand what the technology affords users and how ways of using a technology are instantiated in users practice within different contexts and over time It also allows us to think about how affordances can play a different role in the design of attributes of the same artefact for multiple different users Recent conceptualisations of affordances such as social affordances collaborative affordances and organisational affordances are useful to us in developing trust affordances For instance the social and cultural context of users can directly influence how affordances are perceived And how the conditions of technology culture power and interpretation have a combined influence on the emergence of affordances and the emergence of a certain affordance can reinforce the conditions or in some cases change them Taken together these approaches emphasise the impact of learning and change on affordances and that they may need to be discovered from practice and that this practice is always situated in a specific and often complex sociocultural context The relationship between the user the context and the artefact thus affords a particular action or activity Individual users can employ a specific technology for different goals and have agency in how they use it We note that the phrase trust affordances does appear within literature cf but has not been formally defined in its own right We are therefore cognizant of the fact that however we might define trust affordances it is dependent on them being seen as such by users To construct our definition we utilise the criteria for affordances as set out by Evans et al An affordance is something that is not solely affiliated with a platform or a feature of a platform not an outcome but does vary for instance anonymity persistence searchability and visibility are affordances but privacy is not as it is an outcome In our specific context trust and trustworthiness is the goal or outcome and there are affordances that reflect the means through which this can be attained Trust affordances are characteristics of the technology by virtue of itself or of features designed into the technology to promote trust by providing access to evidence of distrustworthiness specific to a user a technology and their context We proceed in the next section to explore whether and how/not commonly presumed trust-supporting properties of Virtual Labs meet this criteria for a trust affordance APPLICATION OF TRUST AFFORDANCES Virtual Labs enable certain trust affordances that can shape but not dictate how people interact with Virtual Labs with data and models and with other users Properties of Virtual Labs introduce action possibilities and lend themselves to specific affordances For instance the properties of usability accessibility and flexibility draw upon functional affordances usefulness and cognitive affordances understandability Other properties such as transparency and features such as provenance are often assumed to be trust-supporting properties and are assumed to be themselves affordances But they do not determine how one interacts with a system or with others who are also part of the system ecology In truth they imply certain affordances which as we show below do not necessarily or automatically lend themselves to promoting trust Before launching into our examination of how provenance and transparency relate to trust in the context of Virtual Labs we must briefly expand upon the point made within Sect that they are both delivered via the mechanism of documentation Documentation is thought to afford trust through visibility inspectability and the provision of contextual information for stakeholders to use relative to their needs and goals eg functional affordances Documentation is at least in principle beneficial for providing baseline evidence of trustworthiness It can be used to ascertain whether a dataset is appropriate for a users needs This is dependent not only on the quality of information within any form of documentation but as we will show on how that documentation is designed To put it succinctly there is a difference between information and useful information Transparency Transparency is thought to be essential for reproducible science to enable opportunities for scrutiny and to improve access to scientific evidence But transparency comes in degrees if conceived as a metaphorical window onto information the glass itself can range from invisible to semi-opaque and the frame can be the full width of the wall or a narrow aperture The reason to carefully vary these parameters is counter-intuitively to optimise visibility of relevant information cf So-called transparency has the capacity to contribute to opacity when relevant information is buried in an abundance of irrelevant information or when data is provided in an undigested and unintelligible form Looking for detailed evidence can be demanding hard and time-consuming particularly when this evidence is used to judge trustworthiness Too little detail does not provide sufficient evidence of trustworthiness but neither does too much Transparency is well-placed to promote trust it would appear only when it lessens rather than increases the cognitive burden on the given user to interpret and understand information specifically when users are able to see all relevant data to them and their goals but no more than this Given the existing literature exploring how to afford visibility through shades of transparency ie translucency we will focus our attention in what follows on lesser noted affordances that relate to realising transparency Scrutability The ability to scrutinise or the capacity to understand through examination is often implied by transparency Within a Virtual Lab scrutability is concerned with the amount of the system and its features that are shown to users This requires careful forethought and a balance between complete openness on one side of the spectrum and complete closure at the other end Visibility and lack of privacy afforded by transparency may be unwanted affordances for some stakeholders Science by its very nature uncertain and experimental necessitates that certain elements of research are conducted behind closed doors as in real life so too is it the case online Credential-based access is one means of providing security and anonymity for on-going scientific work and social connections thus not being completely transparent It also allows scientific researchers and others working on multidisciplinary projects to have control over what is published within the Virtual Lab On the other hand designers of these systems might seek to provide a certain amount/kind of evidence to promote trust in both the scientific research at hand in other Virtual Lab users and in the Virtual Lab itself This being the case one would need to consider how specific elements are published and made public and further how users can search for or request additional information should they require Rather than aiming to be transparent which is not always suitable or ideal a more appropriate ambition might be to foster a spirit of openness Openness connotes an ability to engage skeptically with a system obtain additional information and to scrutinise various elements in determining trustworthiness The provision of documentation may already satisfy users but when it does not other scrutability-supporting features are needed The ability to ask questions and receive reliable answers can enable stakeholders to withhold or place trust This raises certain questions what questions do people need answers to and what evidence or components would serve to answer these questions More specifically how can we facilitate the actions of probing and conversing And fundamentally how can designers of these systems uncover what users needs are given that they may not be able to articulate them in technical terms The ability to scrutinise is necessary for Virtual Lab users such as members of the public and other groups of external stakeholders but only up to a certain point This affordance requires practical constraints to issues raised in our discussion of translucency namely the tendency to overwhelm users and undermine trust in the process It is easy to overestimate the amount the amount of times users are likely to spend scrutinising which makes it all the more important that they can find answers to their specific questions easily This is not easily resolved given that users inevitably seek out different confirmatory evidence of trustworthiness Abstractability Virtual research environments have the ability to provide very different information types from a single data set and to present them in different ways that are accessible and convenient for the intended user p It is relatively simple to place all information pertaining to a particular dataset or model online the challenge rests in ensuring that it is accessible intelligible and assessable In the co-creation of an environmental virtual observatory for flooding Elkhatib et al conducted workshops between various types of stakeholders environmental scientists policy makers local communities directly involved such as farmers and the general public to understand what each different group required Within their work they opted to maintain a user experience that focused on the environmental questions asked rather than the technical questions about how data was collected or how a model was calibrated noting that access to these areas is available if the user wants to but this is not immediately presented DataLabs also enables a range of abstractions allowing users access to the same project but dependent on their ability eg users can work with raw code at one end of the spectrum through to graphical user interfaces on the other In addition to this DataLabs includes the use of notebooks which can take the form of tutorials or contextual narratives that afford accessibility and understanding This flexibility and multimediality of information affords users the same access to the same data and models and does not limit or exclude those who may lack programming skills for instance Key to the utility of abstractability it would seem is first determining how this range of information is perceived by those it is aimed at This approach aims to codify specific types of knowledge that are gained through experience however this is difficult to transfer to others Who creates these abstractions Do they convey what they are meant to convey Do they enable understanding Which formats of abstraction are suited to whom How and where is this abstracted information used and how can it be restored if and when it becomes relevant later on In short what should be abstracted out for whom and how do we know it has led people to the information they need to form well-placed trust Reciprocality In naming this affordance we harken to the literature on reciprocal design here specifically highlighting the need for documentation to be tailored to the individual needs of recipients Annotation enabling stakeholders to add to a document and hence modify it is one way of achieving this Annotation can reduce the epistemic load placed onto creators and reduce the expertise gap between creators and stakeholders Annotation further affords trust through collaboration eg a shared sense of ownership a sense of adding value or contributing and contributes to the holistic research vision for environmental data science Annotation by other users such as those who have used the data and left comments on it may afford trust in determining appropriateness completeness and accuracy Annotation is also a way to pose questions or solve uncertainties Documentation is predominantly created by those who collected or aggregated the data or who ran and tuned a model We should not assume that those same people can inherently understand all questions held by others Conversation enables the ability to scope rephrase or ask additional questions affording mutuality and responsiveness Being able to ask questions and receive reliable answers are well-placed in promoting trust aligning trustors and trustees expectations For instance a particular user of a dataset can determine the reasoning of the data producer and how this relates to the appropriateness of said dataset to their own specific needs When the intelligibility of documentation cannot be guaranteed features to support additional dialogue are worthy of investment to promote trust How might these features afford trust and for whom Reciprocity is afforded through communication the sharing of dialogue and the ability to build relationships Trust is individual- and context-specific Therefore we cannot pre-meditatively completely compile all evidence of trustworthiness for any given stakeholder We can generalise and provide the information we think might be meaningful but without a mechanism to address any questions the promotion of trust is hindered Annotation goes some way in addressing this with comments left and attached to documents But annotation and tagging can be problematic in its own right cf In addition then channels of communication are required Enabling various stakeholders to gain access to the information that they need in order to be able to place or refuse trust appropriately But this too can be fraught with design decisions to be made and affordances produced Person-to-person private messaging enables direct questions to be asked and answered but are ephemeral and contained within the specific interaction On the other hand discussion boards enable conversation to be broadcast to others This prevents the same question being asked numerous times but also introduces the problems of not knowing the audience and navigating messy threads Within our reflections it seems evident that some form of communication is required but the specific instantiation of this is to be determined We are aware that channels of communication are already pre-existent for scientists and academic researchers eg through personal acquaintances or by virtue of having an institutional affiliation We believe that these affordances should be expanded to a wider demographic of Virtual Lab users to ask answer and discuss Provenance Provenance is slated as critical for assessing authenticity maintaining integrity in scientific results and linking back to transparency enabling the transparency and reproducibility of scientific results But as we saw with transparency provenance varies basic forms describe the source and lineage of data complex forms of provenance describe production processes and influences such as assumptions or bias Complex forms may also be referred to as supplementary information Spiekermann et al delineate between coarse-grained provenance which captures relationships but not complete insight and fine-grained provenance which provides a comprehensive account of all information pertaining to a dataset or model Therefore what is stated as provenance is a specific form of provenance in every case Cheney et al also characterise different types of provenance within a database where eg where data has come from how eg how was an output produced and why eg why was an output produced Documents can have different values for instance evidential value relates to structure procedures and proving ownership and informational value refers to the contents of the document for reference contemplation and research Thus when provenance is hailed as a critical foundation crucial to scientists which provenance are we talking about Coarse-grained where evidential provenance or fine-grained why informational provenance The varying granularity of provenance connotes different affordances The former type of provenance affords insight into the origins of a particular dataset model or outcome It is not transparent capturing the relationships between items but excluding the complete derivation In our context this type of provenance affords trust when there are issues of legality or ownership as it can be used to ascertain basic facts about a sensor and its recordings for example The latter provenance which is fine-grained and informational provides much deeper insight into these relationships For instance within scientific research the onus is on the contents of any documentation or provenance information including any supplementary details which provide value The granularity of provenance is not dichotomous or mutually exclusive but enables us to consider the affordances between the types Coarse-grained may be sufficient for a stakeholder who wants to see where something has come from or been used in but for whom evidence of trustworthiness is not reliant upon seeing all details Whereas fine-grained may be useful to a modeller who needs a comprehensive account of what has been done how and why in order to have trust in the source and appropriately conduct their research Trust is a judgement based upon available evidence but may also rely on many other elements in addition Approaches that focus on where questions and evidential value only go some way in affording trust Evidence of trustworthiness is not prescriptive and scientists may rely on approximate evidence and heuristics in addition to provenance information eg reputation comparison with standards or appropriateness for their needs The validity of data is related not only to lineage but also supplementary information such as context and instrumentation To assess and use data sufficiently data consumers may need to look beneath mere provenance records to look at the assumptions or to answer how and why questions Verifiability Trustworthy data is data that is verifiably accurate that has evidence of integrity authenticity and reliability It is not purely about the data journey but the accuracy and completeness of the source and the provenance information itself Verifiability can be achieved through identity or can be achieved through things such as distributed ledger technology Knowing in whom you are placing your trust enables an individual to make interpersonally rooted trust assumptions and conversely when identity is unknown assumptions of trustworthiness are based in more impersonal dimensions Hoffman et al propose the use of blockchain for academic published papers which will enable verification of collaborators identities Use of distributed ledger technology would also enable data consumers to know that the record is authentic in what it purports to be and is free from corruption or tampering However this has the potential to be troublesome for sensitive or proprietary materials Thornton et al note that the use of blockchain within academic research could lead to a paradox where evidence of trustworthiness is provided for some consumers such as those who seek quality assurance but simultaneously lead to disengagement for others who prioritise the protection of business interests and intellectual property Verifiability is therefore a two-sided affordance arising from a tension between privacy and visibility This tension is exacerbated if we utilise technology such as blockchain to retain persistence and immutability But then in some cases retaining information about ones identity within a system can be beneficial in supporting trustworthy behaviours eg providing awareness of and accountability for ones actions retaining a memory of past behaviours in the form of a reputation Potentially problematically in a system with multiple stakeholders it may be that for some users preserving identity is key to being able to verify and trust and for others it inhibits collaboration and reduces trust Balancing these issues then and deciding on what level of identity to present in order to promote well-placed trust is highly context-specific and a system may need to be flexible to accommodate individual users preferences Persistence Within our context persistence relates to trust that the data or models will remain in the same content and location unless a new version exists cf Effort is required to develop a persistent infrastructure for artefacts ranging from datasets to models and supplementary information about them On the future of data and its quality Lord et al ask whether all data should be kept and what issues may arise from decisions undertaken The velocity of data is increasing exponentially and the veracity of data in particular environmental science is often questionable Given this decisions need to made to increase computing capacity to store all data regardless of its relevancy for future research eg potential inaccuracies or incompleteness or do we selectively filter data before we commit it to a repository Both approaches may be unsatisfactory There are only so many bytes of data model runs and outputs we can store But on the other hand we cannot necessarily decide what may be useful to someone in the future and may inadvertantly privilege specific types of information over others in doing so If persistence is deemed important to trust within the context of a Virtual Lab there are design challenges related to curation archival and preservation Not only does the data itself need preserving in many cases but so too does associated meta-data so as to facilitate trustworthy reuse of the data cf But what meta-data is useful to a given stakeholder and what meta-data a given stakeholder is capable of collecting may differ greatly in which case how are these trade-offs and potential inconsistencies resolved Traceability Environmental data may have tangled heredity and ownership which may entail more sources than a user is able to assess at one time It can be challenging for any user regardless of expertise to assess the quality of aggregated environmental data Barclay suggests that a gateway in our context a Virtual Lab can dually provide traceability eg origins and reuse of data and importantly assist with navigation through this complexity For instance my Experiment facilitate an infrastructure to bundle essential information pertaining to scientific research into workflows However workflows can break and from our own experience workflows can be limiting on the inputs and outputs data accessibility data sharing and on the stakeholders that can use workflows eg external project partners with limited technical ability Traceability whilst often thought of in terms of looking back can also include forward tracing Scientists can often be reticent in sharing data because of a fear that their data will be taken and used inappropriately or for erroneous science The work on DataLabs advocates for strong supporting mechanisms for trust when sharing data Once more however this approach is twosided Trust may be afforded for scientists with evidence of the propagation of their data but this may be an unwanted affordance for commercial users of Virtual Labs who do not want to share or promote which data they use within their analysis and want to protect intellectual property Any solution to this would require some type of constraint which Clark argues nonetheless cannot force people to behave in a trustworthy way In the face of increasing calls for open data traceability may be suited to some forms of data or research eg high profile or contentious issues but not suited to the majority of research for which backwards and forwards traceability would be problematic Making Connections Following the criteria set out by Evans et al neither transparency nor provenance are in themselves affordances but relate to a number of affordances which can for some stakeholders in some contexts support trust We have knowingly made a somewhat unnatural separation between transparency and provenance as they are intimately connected through these various other affordances We have tried to demonstrate that affordances may be two or multi-sided the affordances associated with transparency and/or provenance can be positive for some users but may have negative implications for others Furthermore whilst we have expanded upon six trust affordances which can all contribute to trust we should not assume that they afford trust in all instances or individually For instance reciprocality and scrutability combined may afford trust where neither does in and of itself in a particular scenario A mind map Figure captures part of the complexity in designing for trust As messy a picture as this already is we note that it is incomplete We have not fully unpacked all of the affordances related to transparency and provenance if there even is a bottom to this well and these are hardly the only considerations in designing for trust At a minimum the map shows that simple recipes Figure Mind map illustrative of interconnections and tensions within and between affordances relating to transparency and provenance Dotted lines indicate concepts we have made connections to without fully unpacking eg FAIR represents data management that is Findable Accessible Interoperable and Reusable inevitably elide myriad important design considerations which impact on the resultant trust We are not arguing that transparency and provenance are antagonistic to trust clearly they can be appropriate high-level design goals But promoting trust is clearly not as simple as adding a bit of transparency and a bit of provenance The affordances that feed into both are not clear-cut themselves and evidently require careful consideration of potentially conflicting multi-stakeholder requirements It is important to clearly define sub-goals that not only support transparency and provenance but also support trust remembering that one does not guarantee the other drawing on various affordances with appreciation of their interdependencies and tensions Most importantly we are by no means suggesting designing for trust is futile rather we are trying to foster a greater sensibility regarding the delicacy of designing for trust and the importance of really understanding the requirements of the different users of the system DISCUSSION The design process is fraught with decisions to be made and competing interests to be balanced which as we have shown are not necessarily as simple as they initially appear Trust is recognised as being key to the success of socio-technical systems and because trust is notoriously difficult to retrofit how a system will foster trust needs to considered early and throughout the design process By exploring how properties designed into Virtual Labs either do or do not afford trust we have illustrated the need for a nuanced rather than prescriptive trustworthy by design approach that accounts for how system affordances relate to the specific trust needs of individual stakeholders As we have shown certain features of Virtual Labs both afford trust and do not afford trust depending on the context The broader lesson in this is to be careful in proclaiming a natural relationship between any particular system property and trust Trust Affordances in AI Literature Trust has garnered significant attention within the computing community particularly in the Artificial Intelligence AI field Prevalent conceptions of trusted AI invoke notions of fairness accountability transparency and provenance As we have seen above implementing technology and/or technological artefacts in a way that affords trust to multiple stakeholders requires careful consideration and is not an easy task to undertake Transparency in particular is leaned on heavily in the trusted AI community increasingly instantiated through forms of documentation As such there is much from our discussion of Virtual Labs that can be applied to trusted AI more generally AI documentation across the board is designed implicitly for scrutability enabling stakeholders to examine relevant facts of the AIs development There has been much interest in seeking to enable more dialogic scrutability for example providing explanations whether in documentation or via other means in the form of counterfactuals which raises similar issues to the ones we have here about the challenges in predicting the questions individuals might have Reciprocality is possibly less universal though clearly features in IBM FactSheets which are tailored to specific documentation consumers It seems inevitable that some of the subtleties of the various affordances subsumed within transparency arose in designing these forms of documentation and influenced the particular form this transparency took Our point is that it is important not to lose that subtlety when justifying documentation in terms of how transparency contributes to trust in AI If and when documentation succeeds in doing so it is because its designers have attended to balancing myriad interconnecting considerations that impact on trust Where they fail to promote trust it is likely due to insufficient attention to specific multi-stakeholder trust needs Transparency should therefore always be approached within AI as a problematic ideal that requires great specificity regarding the trust needs of relevant users and reflection on how designed aspects of systems might contribute to or undermine the fulfillment of these needs Scaling Trust Many if not all of the affordances described in this paper speak to interpersonal trust which requires careful nurturing in ways that do not necessarily scale as systems become more complex The Virtual Labs we have described are relatively small communities the infrastructure provided can enable the nurturing of trust at a project- or team-level But can these environments scale any further At some point it becomes impractical to individually assess trustworthiness and one instead must place their trust in the system itself as having inbuilt mechanisms for assuring trustworthiness cf Interestingly this suggests that Virtual Labs if scaled up might entail a rather different set of affordances related to impersonal or system trust Our exploration of transparency and provenance affordances our overwhelmingly complex mind map Figure in particular also raise more general questions about how much effort is reasonable to expend in support of trust given how much is involved in developing systems that enable trust to thrive Trust really doesnt scale well For example documentation is costly to create and maintain requiring a high level of manual input as are features that enable provenance of scientific data On balance then how important is trust How do system developers make decisions about how much trust is enough trust And how do we approach the design of a system given these considerations The trouble is problems stemming from a lack of trust are not easily fixed once they appear hence the emphasis in the literature on a trustworthy by design approach This is not something we can answer here but pose it as a question for ongoing deliberation by the research community Further Trust Affordances Whilst not the focus of our paper we note that given the inherent collaborative nature of environmental data science and the potential collaborative affordances offered by Virtual Labs we would be remiss to exclude a consideration of trust affordances pertaining to collaboration These dynamics are complex but as we have alluded to in Figure are present within design considerations of virtual research environments eg collaboration is linked to both reciprocality and verifiability Whilst we have not unpacked further additional trust affordances of collaborative research environments within our research this area is one amongst others that we hope to build upon in future work CONCLUSION In this paper we have introduced and defined trust affordances characteristics of a technology to promote trust through the provision of evidence of distrustworthiness Our effort was driven by our own experiences in designing features within a virtual research lab for environmental data science specifically the realisation that when trust is discussed there are certain often implicit features which are assumed to unwaveringly support trust and which end up being far more complicated in their implementation In particular provenance and transparency are two such features often presumed to provide authentic informative evidence of trustworthiness However when we uncover the complexities of designing these properties into systems we find that there are no blueprints or maps to guide us in enabling said design and moreover there is no clarity on which features actually equate to trust Given this we argue that we should be analytic within the design process particularly of the prevailing assumption that designing a system consists of a sprinkle of one element here and a dash of another element there In reality a critical understanding of the social realities in which any system is situated is crucial In the design of Virtual Labs we have learnt that provenance and transparency are useful with the caveat that these features need to be articulated in multiple ways in order to contribute to trust and whats more we must be cognizant of the fact that when a system is designed in such a way as to promote trust for one stakeholder the same practice may not be promoting trust for another With regards to the wider community utilising documentation for the promotion of trust in particular data science and AI we believe that these reflections can be beneficial to guide the design of systems and features within these systems There are different forms of provenance and transparency that can be taken and not all roads lead to trust The use of trust affordances has facilitated the consideration of features and systems as-a-whole from multiple perspectives and contexts ones which can easily be glossed over We hope that our work can enable greater emphasis on the differing stakeholders within each context and inclusion of additional mechanisms to promote trust Ultimately we want to show that despite the numerous shades of grey within trust it is only when we embrace this that we can design in a trustworthy manner
Avoiding Disparity Amplification under Different Worldviews We mathematically compare four competing definitions of group-level nondiscrimination demographic parity equalized odds predictive parity and calibration Using the theoretical framework of Friedler et al we study the properties of each definition under various worldviews which are assumptions about how if at all the observed data is biased We argue that different worldviews call for different definitions of fairness and we specify the worldviews that when combined with the desire to avoid a criterion for discrimination that we call disparity amplification motivate demographic parity and equalized odds We also argue that predictive parity and calibration are insufficient for avoiding disparity amplification because predictive parity allows an arbitrarily large inter-group disparity and calibration is not robust to post-processing Finally we define a worldview that is more realistic than the previously considered ones and we introduce a new notion of fairness that corresponds to this worldview CONCEPTS Social and professional topics Socio-technical systems Mathematics of computing Probability and statistics KEYWORDS fairness worldview disparity amplification demographic parity equalized odds predictive parity calibration INTRODUCTION Researchers in the field of fair machine learning have proposed numerous tests for fairness which focus on some quantitative aspect of a model that can be operationalized and checked using empirical statistical or program analytic methods These tests abstract away more subtle issues that are difficult to operationalize or too contentious to decide algorithmically such as which groups or attributes should be protected and which cases should be treated as exceptions to general rules Our work sheds light on some of the possible assumptions behind and motivations for four common empirical tests that check for discrimination against groups The simplest of these tests demographic parity checks whether the model gives the favorable outcome to two given groups of people at equal rates This test is an abstraction of the legal notion of disparate impact or indirect discrimination which in certain circumstances requires that some approximation of demographic parity hold Like disparate impact demographic parity does not depend upon the intentions of the modeler and it can flag a model that does not directly use the protected attribute if it instead uses another attribute that is correlated with the protected one However demographic parity abstracts away disparate impacts exceptions for cases where there is sufficient justification for a disparity in outcomes such as a business necessity eg By completely abstracting away such exceptions demographic parity may lead to models so inaccurate as to become useless such as when predicting physical strength while requiring demographic parity on gender This impossibility of accuracy motivates moving away from demographic parity to tests that take the ground truth into account allowing a degree of accuracy One such test called equalized odds by Hardt et al requires equal false positive and false negative rates for each protected group Two other commonly used tests are predictive parity which requires equal predictive values for each protected group and calibration which further imposes the constraint that the model must output the correct probability eg Like demographic parity all of these tests can be seen as abstractions of disparate impact in that they too examine disparities in outcomes not how or why they were reached In contexts where accuracy can be considered a business necessity these tests arguably provide a more refined abstraction of disparate impact than demographic parity does However disagreement exists over which of these tests is the most appropriate with some favoring calibration and some favoring equalized odds It has been argued that adopting the calibration or equalized odds test corresponds to adopting the perspective of either the person using the classification or the person being classified respectively We provide a different lens on this disagreement and study the conditions under which each test allows the amplification of pre-existing disparities In some cases the ground truth may be tainted by past discrimination and consulting it will help perpetuate the discrimination In this work we handle this issue by adopting the framework of Friedler et al who make a distinction between the observed ground truth and the construct which is the attribute that is truly relevant for prediction For example in the context of bail decisions the construct could be whether a defendant commits a crime while out on bail and the observed ground truth could be whether the defendant is rearrested for a crime Because the construct is usually unobservable Friedler et al introduce and analyze two assumptions or worldviews about the construct Under the Were All Equal WAE worldview there is no association between the construct and the protected attribute and under the What You See Is What You Get WYSIWYG worldview the observations accurately reflect the construct By using the construct we specify a natural criterion for discrimination This criterion disparity amplification deals with the disparity in positive classification rates which is a widely accepted measure of discriminatory effect in both law and computer science It stipulates that a disparity in the output of the model is justified by a commensurate disparity in the construct thereby allowing accurate models even when the base rates are different for different protected groups as equalized odds predictive parity and calibration do In addition because it uses the construct it does not depend upon the possibly biased ground truth Using the often unobservable construct can make testing for disparity amplification impossible we argue that its value instead comes from its ability to organize the space of empirical tests In particular one of our main contributions is our argument that the WAE and WYSIWYG worldviews when combined with the desire to avoid disparity amplification motivate demographic parity and equalized odds respectively We thus shed light on why people may disagree about which empirical test of discrimination to apply in a particular setting Even if they agree on the need to avoid disparity amplification they may disagree about the correct worldview to apply in that setting We also show that regardless of the worldview and the base rates of the observed ground truth predictive parity does not impose any restrictions on the extent to which a model amplifies disparity Calibration is more restrictive in this regard but the common post-processing method of thresholding can amplify disparity to an arbitrary extent Since equalized odds is incompatible with predictive parity or calibration this is an argument for the use of equalized odds instead of predictive parity or calibration Furthermore we compare our approach to that of Zafar et al in their work on disparate mistreatment or disparate misclassification rates showing that the definition of disparity amplification can be modified to apply in their setting Although the WAE and WYSIWYG worldviews are useful for theoretical analysis they are unlikely to be true in practice To remedy this issue we introduce a family of hybrid worldviews that is parametrized by a measure of how biased the observed data is against a protected group of people This allows us to model many real-world situations by simply adjusting the parameter We then create a parametrized test for discrimination that corresponds to the new family of worldviews showing how one can apply the analysis in our paper to more realistic scenarios Our most fundamental contribution is introducing a framework in which to motivate empirical tests in terms of construct-based criteria of discrimination and worldviews Disparity amplification is not the only relevant notion of discrimination nor is it suitable in every context Indeed there are many other aspects of discrimination that we do not address in this paper such as intentional discrimination II-A individual fairness proxy discrimination delayed outcomes and affirmative action Future work may use our approach to tease out the assumptions implicit in these tests We view the discussed tests and disparity amplification as diagnostics that can lead to further investigations of potentially discriminatory behavior in a model As a result we do not provide an algorithm for ensuring that a model does not have disparity amplification since in our view doing so would be treating the symptom rather than the cause Such algorithms can eliminate one aspect of discrimination but may in the process create a model that is obviously discriminatory from another angle When a model does not satisfy a notion of nondiscrimination it should be a starting point for investigation as to why While it could be that the learning algorithm is corrupt it could also be due to a mismatch between the construct and the observed data or a need for better features No one test or criterion can ensure fairness and no single algorithm will be appropriate in all cases RELATEDWORK Our work is most similar in structure to that of Heidari et al who propose a unifying framework that reformulates some existing fairness definitions through the lens of equality of opportunity from political philosophy They then propose a new fairness definition that is inspired by this lens Although we also present a unifying framework our unification is through the lens of constructs and worldviews Friedler et al introduced the concept of the construct in fair machine learning Although they also use the construct in their definition of nondiscrimination their definition uses the Gromov Wasserstein distance and as a result is more difficult to compute and reason about One benefit of their approach is that it enables their treatment of fairness at both the individual level and the group level By contrast we consider group nondiscrimination only and this allows us to draw a parallel between the worldviews and the existing empirical tests of discrimination Barocas and Selbst discuss in detail the potential legal issues with discrimination in machine learning One widely consulted legal standard for detecting disparate impact is the four-fifths rule The four-fifths rule is a guideline that checks whether the ratio of the rates of favorable outcomes for different demographic groups is at least four-fifths This guideline can be considered a relaxation of demographic parity which would instead require that the ratio of the positive classification rates be exactly one The four-fifths rule has inspired the work of Feldman et al and Zafar et al who deal with a generalization of the four-fifths rule called the rule in their efforts to remove disparate impact On the other hand many others consider the difference rather than the ratio of the positive classification rates Our discrimination criterion is a generalization of this difference-based measure but it differs from the others in that it uses the construct rather than the observed data Other works in the field of fair machine learning deal with aspects of discrimination that are not well described by positive classification rates Hardt et al characterize nondiscrimination through equalized odds which requires that two measures of misclassification false positive and false negative rates be equal for all protected groups Calibration Chouldechova points out is widely accepted in the educational and psychological testing and assessment literature In another work Friedler et al create a benchmark for empirically evaluating the consequences of imposing these and other definitions of fairness finding that many but not all definitions lead to similar model behavior Dwork et al formally define individual fairness and give examples of cases where models are blatantly unfair at the individual level even though they satisfy demographic parity Although individual fairness is sometimes considered to be in conflict with group-based notions of fairness Binns argues otherwise instead pointing to the difference in worldviews as the truly important factor He then lists demographic parity and calibration as corresponding to the WAE and WYSIWYG worldviews respectively For the WYSIWYG worldview he reasons that if calibration is satisfied no applicant would receive a less favorable outcome than a less qualified applicant assuming that the calibrated scores accurately describe the degree to which the applicant is qualified By contrast in this paper we prove that equalized odds but not calibration is an effective way to avoid disparity amplification under the WYSIWYG worldview As mentioned previously discriminatory effects can be justified if there is a sufficient reason For prediction tasks it is natural to think of accuracy as a sufficient justification Zafar et al handle this by solving an optimization problem to maximize fairness subject to some accuracy constraints This reflects the idea that a classifier is justified in sacrificing fairness for accuracy To a lesser extent equalized odds predictive parity and calibration can also be thought of as motivated by the dual desires for accuracy and fairness Our approach to justification is also motivated by these desires but we use the construct and say that a classifier is justified in predicting the construct correctly NOTATION In the framework introduced by Friedler et al there are three spaces that describe the target attribute of a prediction model The construct space represents the value of the attribute that is truly relevant for the prediction task This value is usually unobservable so prediction models in a supervised learning problem are instead trained with a related measurable label whose values reside in the observed space Finally the prediction space called decision space by Friedler et al describes the output of the model We will use and as the random variables representing values from the construct observed and prediction spaces respectively See Figure In addition we will use to denote the protected attribute at hand and we will assume that For example if is gender the values and could represent male and female respectively Although the input features are also critical for both the training and the prediction of the model they are rarely used in this paper Example Some jurisdictions have started to use machine learning models to predict how much risk a criminal defendant poses Judges are then allowed to consider the risk score as one of many factors when making bail or sentencing decisions Using the three-space framework of Friedler et al we can represent the risk score output by the model as The model would be trained with the observation which in this case may be recorded data about past criminal defendants and their failures to appear in court bail or recidivism sentencing These models would also be trained with features from the input space such as age and criminal history For sentencing decisions presumably we want to know whether the defendant will commit another crime in the future regardless of whether the defendant will be caught committing the crime Therefore we argue that the recorded recidivism rate is merely a proxy for the actual reoffense rate which is the relevant attribute for the prediction task There is evidence that Black Americans are arrested at a higher rate than White Americans for the same crime so it is reasonable to suspect that is a racially biased proxy for Example Universities want the students that they admit to the university to be successful in the university Because success is a vague term that encompasses many factors a model that predicts success in university would instead be trained with a more concrete measure such as graduating within six years This model may take inputs such as a students high-school grades and standardized test scores and will output a prediction of how likely the student is to graduate within six years Admissions officers can then use this prediction to guide their decision about whether to admit the student It is important to note that the models in the above examples do not make the final decision and that human judgments are a major part of the decision process However we are concerned about the fairness of the model rather than that of the entire decision process Thus we focus on the output of the model rather than the final decision made using it PRELIMINARY DEFINITIONS In this work we use two notions of distance between two random variables that measure how different the random variables are When the random variables are categorical we use the total variation distance Definition Total Variation Distance Let and be categorical random variables with finite supports Y and Y Then the total variation distance between and is In the special case where the total variation distance can also be expressed as When the random variables are numerical our notion of distance takes into account the magnitude of the difference in the numerical values The following definition assumes that the random variables are continuous but a similar definition is applicable when they are discrete Definition Earthmover Distance Let and be continuous numerical random variables with probability density functions and defined over support Y Furthermore let be the set of joint probability density functions such that Y for all Y and Y for all Y Then the earthmover distance between and is Y Y where is a distance metric defined over Y The joint probability density function has marginal distributions that correspond to and Intuitively if we use the graphs Construct space Observed space Prediction space Worldviews Empirical Tests Discrimination Criteria eg Disparity Amplification Construct Accuracy Figure Three relevant spaces for prediction models The space of input features is not depicted here The observed space and the prediction space are measurable and the existing empirical tests Definitions impose constraints on the relationship between the two spaces On the other hand the construct space is usually unobservable so we must assume a particular worldview eg Worldview or about how the construct space relates to the observed space if at all Then we can define disparity amplification and construct accuracy which relate the construct space to the prediction space of the probability density functions and to represent mounds of sand corresponds to a transportation plan that dictates how much sand to transport in order to reshape the mound into the mound In particular the value of is the amount of sand to be transported from to The distance can then be interpreted as the cost of transporting one unit of sand from to and the earthmover distance is simply the cost of the transportation plan that incurs the least cost Now we define Lipschitz continuity Definition Let Y R be a function and let be a distance metric defined over Y is ùúå-Lipschitz continuous if for all Y Existing Empirical Tests of Discrimination Many fairness definitions for prediction models have been proposed previously and here we restate four of them Because much of the prior work does not make the distinction between the construct space and the observed space there is some ambiguity about whether or is the appropriate variable to use these definitions Given that these works suggest that these definitions can be computed we interpret them to be empirical tests that can help verify whether a model is fair As a result none of these definitions include the construct In all four definitions the probabilities are taken over random draws of data points from the data distribution as well as any randomness used by the model Definition Demographic Parity Test A model passes the demographic parity test if for all Definition Equalized Odds Test A model passes the equalized odds test if for all and Definition Predictive Parity Test A model passes the predictive parity test if for all and Unlike the above three tests the calibration test is only defined for binary observations ie Definition Calibration Test A model with a binary passes the calibration test if for all in the support of Worldviews Our intuitive notion of discrimination involves the relationship between the construct space and the prediction space For example consider the context of recidivism prediction described in Example Suppose that one group of people is much more likely to be arrested for the same crime than another group Then the disparity in arrest rates can cause the recorded recidivism rate to be biased and a model trained using such would likely learn to discriminate as a result If in fact the two groups have equal reoffense rates it would hardly be considered justified that one group tends to be given longer sentences as a result of the bias in However because is typically unobservable in practice we do not know whether is the same for both groups Therefore to reason about discrimination using the construct space we must make assumptions about the construct space Two such assumptions or worldviews have previously been introduced by Friedler et al and are described below Our versions of these worldviews are simpler than the original because they are exact whereas the original versions allow deviations by a parameter Worldview Were All Under the Were All Equal WAE worldview every group is identical with respect to the construct space More formally is independent of ie Worldview WYSIWYG Under the What You See Is What You Get WYSIWYG worldview the observed space accurately reflects the construct space More formally CONSTRUCT CRITERIA We introduce two construct criteria for models By using the construct these criteria must be combined with a worldview for application to a model Unlike the more readily applied empirical tests construct criteria depend upon the attribute truly relevant to the classification task Here we consider the case where and are categorical but not necessarily binary and in Section we generalize the definition to numerical Disparity Amplification When is binary the size of a models discriminatory effect is commonly measured by the difference in positive classification rates Output disparity generalizes this measure for the case of non-binary categorical Definition Output Disparity Let the output of a model be categorical The output disparity of the model is the quantity However not all output disparities are bad in every context In particular because we want the model to accurately reflect the construct we allow an output disparity insofar as it can be explained by the inter-group disparity in This happens when Since a model can have issues with discrimination that are not characterized by output disparity see below is not the conclusive definition of nondiscrimination Thus we use the logical negation of as a criterion for one particular discrimination concern which occurs when an output disparity is not explained by Definition Disparity Amplification Let and be categorical Then a model exhibits disparity amplification if Construct Accuracy As mentioned in Section we want the output of the model to accurately reflect the value of However the simple accuracy measure incentivizes the model to become more accurate on the larger protected group at the expense of becoming less accurate on the smaller protected group Therefore we instead measure accuracy as the average of the accuracy on the two groups Definition Construct Accuracy The construct accuracy of a model is Definition Construct Optimality A model is construct optimal if its construct accuracy is ie its output and the construct are always equal Because the construct usually cannot be observed construct accuracy usually cannot be measured or directly optimized for Even when it can measured construct optimality would be rare since the quality of the features data or machine learning algorithm may preclude perfection As with disparity amplification we introduce construct accuracy not to empirically measure it but as a theoretical tool for analyzing discrimination In particular note that equality holds in for every construct optimal model In other words a construct optimal model displays the maximum amount of output disparity allowed by Definition On the other hand if the output disparity is greater than the disparity in the model must be amplifying a disparity in a way that cannot be justified by the desire to achieve construct optimality The above definitions can be generalized to the setting where the range Y of the values that takes differs from the range of If there exists a bijective mapping between Y and we can use the mapping to characterize when a value from accurately reflects a value from Y Limitations These criteria separately or jointly are neither necessary nor sufficient for fairness Technical criteria allow precision but elide the context-specific and social aspects of fairness The criteria fail to be sufficient for fairness by not capturing forms of discrimination unrelated to output disparity For example a model could have a higher misclassification rate for one group of people which goes undetected by Definition See Section for discussion Furthermore by examining just a models input/output behavior the criteria cannot catch a model produced by an unacceptable process or performing unacceptable computations internally to reach its outputs For example Datta et al show the impossibility of externally detecting whether a model internally reconstructs a sensitive attribute that it should not use We believe avoiding disparity amplification does better as a necessary condition for fairness but limitations exist here as well For example when correcting historical wrongs it may be fair to amplify certain disparities that benefit an oppressed group Such cases also provide a counterexample to the necessity of construct accuracy In some cases carefully selecting a historically informed construct can avoid violating our criteria while achieving a reparative goal However some goals such as achieving adequate representation for a group cannot be expressed in terms of an individual-level construct Nevertheless our criteria highlight when a models behavior is suspicious enough to warrant an explanation and can serve as a basis for selecting between empirical tests USING CRITERIA AND WORLDVIEWS TO MOTIVATE EMPIRICAL TESTS In this section we use our construct criteria to analyze which worldviews motivate the existing empirical tests of discrimination If an empirical test does not guarantee the lack of disparity amplification it may not be sufficient as an anti-discrimination measure as it effectively allows certain forms of discrimination On the other hand if the test disallows a construct optimal model the test may be too strict in a way that lowers the utility of the model Therefore to argue that a worldview motivates an empirical test we will prove the following two statements a Every model that passes the empirical test does not have disparity amplification and b every optimal model passes the empirical test We apply this reasoning to demographic parity Definition and equalized odds Definition showing that the WAE and WYSIWYG worldviews respectively motivate these empirical tests More formally we will prove statements a and b for every joint distribution of and that is consistent with the worldview Table summarizes these results Demographic Parity and WAE Theorem A model that passes the demographic parity test does not have disparity amplification under Definition Moreover Table Summary of the results in Section We say that a worldview motivates an empirical test if it precludes disparity amplification Definition but does not preclude a perfectly predictive model The Were All Equal WAE worldview motivates the demographic parity test and if the worldview does not hold the demographic parity test tends to lower the utility of the model The WYSIWYG worldview motivates the equalized odds test and if the worldview does not hold the equalized odds test allows models that have disparity amplification Finally regardless of the worldview the predictive parity and calibration tests do not effectively prevent disparity amplification Here we assume that WAE and WYSIWYG do not hold simultaneously Were All Equal Worldview WYSIWYG Worldview Demo Parity Definition Theorem Always suboptimal Theorem Equal Odds Definition Amplification allowed Theorem Theorem Predictive Parity Definition Amplification allowed Theorem Calibration Definition Not robust to post-processing Theorem if the WAE worldview holds every construct optimal model satisfies demographic parity Proof By the definition of demographic parity the left-hand side of is Since the total variation distance is always nonnegative demographic parity ensures the lack of disparity amplification If the WAE worldview holds we have so every optimal model satisfies This implies demographic parity by Definition The first part of Theorem shows that we can guarantee that a model will not have disparity amplification by training it to pass the demographic parity test However this does not mean that demographic parity is appropriate for every situation First we remind the reader that the lack of disparity amplification does not mean that the model will be free of all issues related to discrimination In particular disparity amplification is only designed to catch the type of discrimination akin to disparate impact If the WAE worldview holds demographic parity is the only way to avoid disparity amplification so it makes sense to enforce demographic parity On the other hand blindly enforcing demographic parity may introduce other forms of discrimination For example the US Supreme Court held in Ricci v DeStefano that the prohibition against intentional discrimination can sometimes override the consideration of disparate impact ruling that an employer unlawfully discriminated by discarding the results of a bona fide job-related test because of a racial performance gap Second demographic parity can lower the utility of a model If the WAE worldview does not hold is positive and Theorem shows that any model that satisfies demographic parity must be suboptimal In fact the more we deviate from the WAE worldview the lower the maximum possible construct accuracy becomes Theorem If a model satisfies demographic parity the construct accuracy of the model is at most Moreover there exists a distribution of that satisfies demographic parity and attains this construct accuracy To prove this theorem we will use Lemma Lemma Let and be categorical random variables with finite supports Y and Y Then min Proof of Lemma First we can express the total variation distance in terms of max and min max min In addition we have max min Subtracting the first equation from the second gives us the desired result Proof of Theorem We first prove the upper bound on the construct accuracy Let Y and be the supports of and respectively Then by the law of total probability we have min for all Y and We then sum this over and apply Lemma to get min where the last equality follows from our assumption that the model satisfies demographic parity Therefore the construct accuracy can be bounded as where the last inequality is an application of the triangle inequality Now we construct a random variable that satisfies demographic parity and attains this bound When we simply let making the first term in equal to When we constrain the marginal distribution of to be the same as that of and we make the joint distribution of and a maximal coupling Then by the theorem in p such attains the value of for the second term of This means that the construct accuracy which is the average of the two terms is which is what we want Moreover and have the same distribution so satisfies demographic parity Theorems and demonstrate that the WAE worldview combined with the desire to avoid disparity amplification while retaining the utility of models motivates the demographic parity test Equalized Odds and WYSIWYG We now argue that a similar relationship exists between the equalized odds test and the WYSIWYG worldview Theorem If the WYSIWYG worldview holds a model that passes the equalized odds test does not have disparity amplification under Definition Moreover if the WYSIWYG worldview holds every construct optimal model satisfies equalized odds Proof Let Y and be the supports of and respectively Applying the WYSIWYG worldview to the definition of equalized odds we get for all Y and Therefore we have This concludes the proof of the first statement For an optimal model we have by the WYSIWYG worldview Because fully determines the value of Definition implies that every optimal model satisfies equalized odds On the other hand our intuition is that when the observation process is biased and WYSIWYG does not hold treating the observation as accurate as implicit with equalized odds may lead to a failure to pass our construct-based criterion We prove as much Theorem If the WYSIWYG worldview does not hold a model passing the equalized odd test can still have disparity amplification Proof We show that there exists a joint distribution of and such that a model with equalized odds still has disparity amplification Many models with equalized odds have nonzero output disparity ie Consider any such model Since the WYSIWYG worldview does not hold we have no guarantee that will resemble in anyway Therefore the equalized odds requirement does not restrict the distribution of and the model can have disparity amplification if is small enough Predictive Parity Under the WYSIWYG worldview optimal models pass the predictive parity test but any model that passes the test must satisfy as can be seen from switching and in the proof of the first part of Theorem The inequality here is in the opposite direction of that in so the predictive parity test does not place any upper bound on the output disparity of and guarantees that it is equal to that of or amplified beyond this limit In fact the following theorem shows that regardless of the worldview and the base rates of even a model with almost the maximum output disparity can still pass the predictive parity test Theorem Let be a categorical random variable with finite support such that is positive for all and Then for any sufficiently small there exists a model that passes the predictive parity test such that Proof The main idea behind the proof is that the model simply outputs the value of However because predictive parity is not well-defined if for any and we must allow the model to output the other value with some very small probability More specifically we construct a model such that if if We can choose which values our constructed model outputs so assume without loss of generality that Let Y be the support of By the predictive parity test we have for all Y and Let Our goal is to find the values of and that are consistent with the fixed observed probabilities and By the law of total probability our model must satisfy Solving for and we see that they converge to and respectively as approaches zero By assumption these probabilities are positive Since Y is finite this means that there exists a small enough such that for all Y Moreover it is easy to verify that making them valid probability distributions Now when given and our model can output with probability where is either or depending on whether Because the predictive parity test allows models such as the one we constructed in the above proof that clearly amplify disparity it is unsuitable for ensuring nondiscrimination as characterized by output disparity Calibration Compared to the predictive parity test the calibration test imposes an additional requirement that the output of the model must be the correct probability Theorem shows this additional requirement limits the model behavior by the disparity in observed values ruling out the model described in the proof of Theorem Theorem If the WYSIWYG worldview holds a model that passes the calibration test satisfies Moreover if the WYSIWYG worldview holds every construct optimal model with binary satisfies calibration Proof Combining the definition of calibration with the WYSIWYG worldview we get a binary with Therefore we have and a similar statement holds for Since is binary the construct disparity then becomes which is what we want for the first statement To prove the second statement note that an optimal model satisfies by the WYSIWYG worldview Then for binary it is easy to verify that calibration holds Unlike Theorems and which bound the total variation distance between the outputs by the disparity in the construct this theorem bounds only the difference in the expected values of the outputs This contrast is significant because expected value unlike total variation distances are not robust to post-processing We demonstrate this issue with an example where and are independent and uniformly random binary variables and the model sets the value of as follows if then if and then for some small positive constant and if and then with probability and otherwise Some computation reveals that this model passes the calibration test with all of the group receiving a prediction of and the vast majority of the group receiving However in practice the predictions are often post-processed with a threshold because it is impossible to say admit half of a student Therefore although the inter-group difference in the model predictions is small it can be amplified if the threshold is set between and In this case the resulting decision is almost perfectly correlated with and exhibits disparity amplification As a result in the rest of the paper we focus on equalized odds rather than predictive parity or calibration We leave as future work the identification of a discrimination criterion and a worldview that together motivate the predictive parity or calibration test CONNECTION TO MISCLASSIFICATION Here we show that the definition of disparity amplification is closely related to that given by Zafar et al in their treatment of disparate misclassification rates First we motivate the issue of disparate misclassification rates with an example Let and be independent and uniformly random binary variables If where is the XOR both protected groups are given the positive label exactly half of the time so there is no output disparity However one group always receives the correct classification and the other always receives the incorrect classification so the disparity in the misclassification rates is as large as it can be This shows that a lack of disparity amplification does not imply a lack of disparity in misclassification rates Conversely a lack of disparity in misclassification rates does not imply a lack of disparity amplification To see this modify the above example so that instead Now both groups have half of its members misclassified since is independent of so they have the same overall misclassification rate On the other hand we have and Thus has disparity amplification However we can still find a connection between misclassification parity and disparity amplification Let be the indicator and replace with in the definition of output disparity Definition Since is binary the resulting expression is simply the difference in the misclassification rates We would like to compare this value to some measure of disparity in the construct space Since our standard measure of does not necessarily justify inter-group differences in it may not be a correct measure to use Exploring what measures provide justification for disparate misclassification rates is interesting future work HYBRID WORLDVIEWS So far we have assumed either the WAE or the WYSIWYG worldview While these worldviews are interesting from a theoretical perspective in practice it is unlikely that these worldviews hold In this section we propose a family of more realistic worldviews for the case where and are categorical As we have depicted in Figure worldviews describe the relationship between the construct and observed spaces Because our definition of disparity amplification has to do with inter-group disparities here we focus specifically on the inter-group disparities in and Note that the WAE worldview has the effect of assuming that none of the disparity in is explained by By contrast under the WYSIWYG worldview all of the disparity in is explained by Described below is the ùõº-Hybrid worldview which is a family of worldviews that occupy the space between the two extremes of WAE and WYSIWYG Worldview ùõº-Hybrid Let Under the ùõº-Hybrid worldview exactly an fraction of the disparity in is explained by More formally While the WAE worldview is equivalent to the -Hybrid worldview the relationship between the WYSIWYG and -Hybrid worldviews is only unidirectional Although the WYSIWYG worldview implies the -Hybrid worldview there are plenty of ways to satisfy even when the equality does not hold If we wanted to make the relationship bidirectional we could instead have assumed that can be broken down into two components one of which satisfies WAE and the other WYSIWYG However this would mean that every component of is either equal with respect to WAE or observable WYSIWYG whereas in practice many inter-group disparities in the construct space are not easily observable Thus to make the ùõº-Hybrid worldview more realistic we sacrifice one direction of the relationship between the WYSIWYG and -Hybrid worldviews Now we introduce the ùõº-disparity test and prove that it corresponds to the ùõº-Hybrid worldview Unlike the demographic parity and equalized odds tests the ùõº-disparity test is parametrized and therefore can be applied to various real-world situations Definition ùõº-Disparity Test A model passes the ùõº-disparity test if Theorem If the ùõº-Hybrid worldview holds a model that passes the ùõº-disparity test does not have disparity amplification under Definition Moreover if the ùõº-Hybrid worldview holds every construct optimal model satisfies the ùõº-disparity test Proof To prove the first part of the theorem we simply combine the inequality guaranteed by the ùõº-disparity test under with the equation that defines the ùõº-Hybrid worldview under We get which is what we want For the second part of the theorem an optimal model has so we can substitute the in with to get This is simply the equality in so we are done The ùõº-disparity test is closely related to demographic parity and equalized odds -disparity is satisfied if and only if the output disparity is zero so it is equivalent to demographic parity In addition we can easily adapt the proof of Theorem to show that equalized odds implies -disparity However because equalized odds imposes a condition for each possible value of -disparity does not imply equalized odds Although it may thus seem that equalized odds is stronger and better than -disparity recent results by Corbett-Davies and Goel show that the threshold rule which they argue is optimal does not lead to equalized odds in general Therefore there is a trade-off between the stronger fairness guarantee provided by equalized odds and the higher utility that is attainable under -disparity Of course the -disparity test has the additional benefit that it can be generalized to other values of We end this section with theorems describing the consequences of enforcing the ùõº-disparity test with a wrong value of These theorems are close analogues of Theorems and respectively Theorem If the ùõº-Hybrid worldview holds a model that passes the -disparity test with has a construct accuracy at most Proof By the reasoning in the proof of Theorem we have for all which can be rewritten as Thus the construct inaccuracy of the model is where the second inequality is an application of the triangle inequality and the third follows from the definitions of the ùõº-Hybrid worldview and the -disparity test Therefore the construct accuracy which is one minus the construct inaccuracy is at most Theorem If the ùõº-Hybrid worldview holds a model that passes the -disparity test with can still have disparity amplification Proof The -disparity test ensures that and if equality holds here we have whenever By the ùõº-Hybrid worldview the rightmost quantity equals making the above inequality exactly that of disparity amplification see A MORE GENERAL NOTION OF DISPARITY AMPLIFICATION In this section we present a more general definition of disparity amplification that is a broader discrimination criterion and is applicable to numerical Due to space constraints proofs of theorems in this section are given in the supplementary material Definition allows an output disparity if there exists an equally large disparity in but it does not explicitly reflect the fact that we care about how the model came to exhibit the disparity The only reason why we allow the disparity is that is the right attribute to use Thus if the model does not use at all then there should be no output disparity More formally we want that if then Definition generalizes this requirement and unlike Definition is applicable for both categorical and numerical at the expense of limiting to be binary The generalization deals with cases where is not independent of by measuring how much depends upon For binary this dependence is captured by the likelihood function and we use the Lipschitz continuity of this function to measure the dependence Definition Disparity Amplification Stronger For and let be the smallest nonnegative such that is ùúå-Lipschitz continuous Then a model exhibits disparity amplification if characterizes how much impact can have on the output of the model If the impact is small we can conclude that the model is not using much so not much output disparity can be explained by On the other hand if a small change in can cause a large change in the probability distribution of then even a large output disparity can possibly be due to a small inter-group difference in In fact the use of makes Definition invariant to scaling in If a numerical is increased by some factor will decrease by the same factor so the quantity on the right-hand side of will not change We now show relationships between the new Definition and the previous definition Definition First we show that the old definition combined with a reasonable distance metric implies the new definition The previous definition assumes that is categorical and in this case a natural distance metric for its support Y is the indicator With this distance metric we can relate the total variation distance used in the right-hand side of with the earthmover distance used in Theorem Let the construct be categorical with support Y which has distance metric If a model has disparity amplification under Definition the model has disparity amplification under Definition as well The proof relies upon a theorem using coupling Theorem Second we show that Theorems and still hold under the refined definition of disparity amplification Since the definitions of optimality and the empirical tests have not changed we focus strictly on the nondiscrimination portions of the theorems Theorem A model that passes the demographic parity test does not have disparity amplification under Definition The proof of Theorem is very similar to that of Theorem Theorem If the WYSIWYG worldview holds then a model that passes the equalized odds test does not have disparity amplification under Definition This proof uses Kantorovich duality Equation We now discuss the tightness of the above result In the extreme case where is a step function over real-valued is infinite so we trivially have a lack of disparity amplification under Definition Thus to receive meaningful fairness guarantees from Theorem we must make sure that is not too large One way to achieve this is to apply the function to the construct space and reason about the transformed construct space If any transformation of the construct space results in a finding of disparity amplification under Definition then it is evidence that there could be a problem with the model with respect to discrimination Technically should be the infimum of all such that is ùúå-Lipschitz continuous but it is not difficult to show then that is in fact -Lipschitz continuous Let be a value in the transformed construct space and denote the likelihood function on this space Then so the transformation ensures that Connection to the ùõº-Disparity Test When and are numerical a natural extension of the ùõº-disparity test Definition is For this to work Worldview would have to change to use the earthmover distance rather than the total variation distance Since the earthmover distance is defined over a distance metric the parameter is not very meaningful unless and have the same scale As a result here we consider the case where and are defined over the same metric space Y Unfortunately is still not an empirical test because is defined in terms of As tempting as redefining in terms of is and can have vastly different likelihood functions despite having the same disparity so this new empirical test will not guarantee the lack of disparity amplification under Definition We leave as future work the discover Y of an empirical test for numerical and that corresponds to the ùõº-Hybrid worldview CONCLUSION We showed that demographic parity and equalized odds are related through our construct-based discrimination criterion of disparity amplification arguing that the difference between the two empirical tests boils down to ones worldview In addition we proved that calibration is not robust to post-processing and that predictive parity allows a model with an arbitrarily large output disparity regardless of the worldview and the observed base rates Our work differs from much of the prior work in that we consider the construct as separate from the observed data In particular we interpreted the existing fairness definitions as acting on the observed data whereas the discrimination criterion was viewed as a property of the construct This bifurcation allowed us to handle the following issues simultaneously a prohibitions against disparate impact have exceptions such as a business necessity but b due to past discrimination the observed data can be biased in an unjustified way It is the second of these points that motivates our use of worldviews to characterize how biased the observed data is To illustrate how this might work in practice let us revisit the examples in Section In Example there are reasons to believe that the observed recidivism rate is a racially biased measurement of the actual reoffense rate In Example for various socioeconomic reasons some protected groups may have disproportionately many people who take longer than six years to graduate but are eventually considered successful in the university The ùõº-Hybrid worldview can characterize these real-world scenarios and the value of reflects ones beliefs about how much more biased the observed data is than the construct Then a practitioner can apply the ùõº-disparity test as a substitute for demographic parity or equalized odds with the value of determined through social research and public dialogue
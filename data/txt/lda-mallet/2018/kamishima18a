Recommendation Independence This paper studies a recommendation algorithm whose outcomes are not influenced by specified information It is useful in contexts potentially unfair decision should be avoided such as job-applicant recommendations that are not influenced by socially sensitive information An algorithm that could exclude the influence of sensitive information would thus be useful for job-matching with fairness We call the condition between a recommendation outcome and a sensitive feature Recommendation Independence which is formally defined as statistical independence between the outcome and the feature Our previous independence-enhanced algorithms simply matched the means of predictions between sub-datasets consisting of the same sensitive value However this approach could not remove the sensitive information represented by the second or higher moments of distributions In this paper we develop new methods that can deal with the second moment ie variance of recommendation outcomes without increasing the computational complexity These methods can more strictly remove the sensitive information and experimental results demonstrate that our new algorithms can more effectively eliminate the factors that undermine fairness Additionally we explore potential applications for independence-enhanced recommendation and discuss its relation to other concepts such as recommendation diversity Our experimental codes are available at Keywords Recommender System Fairness Independence INTRODUCTION A recommender system searches for items or information predicted to be useful to users and its influence on users decision-making has been growing For example online-retail-store customers check recommendation lists and are more likely to decide to buy highly-rated items Recommender systems have thus become an indispensable tool in support of decision-making Such decision-making support tools must be fair and unbiased because users can make poor decisions if recommendations are influenced by specific information that does not match their needs Hence a recommendation algorithm that can exclude the influence of such information from its outcome would be very valuable There are several representative scenarios in which the exclusion of specific information would be necessary First there are contexts in which recommendation services must be managed in adherence to laws and regulations Sweeney presented an example of dubious advertisement placement that appeared to exhibit racial discrimination Sweeney In this case the advertisers needed to generate personalized advertisements that were independent of racial information Another concern is the fair treatment of information providers An example in this context is the Federal Trade Commissions investigation of Google to determine whether the search engine ranks its own services higher than those of competitors Forden Algorithms that c T Kamishima S Akaho Sakuma Recommendation Independence can explicitly exclude information whether or not content providers are competitors would be helpful for alleviating competitors doubts that their services are being unfairly underrated Finally a user sometimes needs to exclude the influence of unwanted information Popularity bias which is the tendency for popular items to be recommended more frequently Celma and Cano is a well-known drawback of recommendation algorithms If information on the popularity of items could be excluded users could acquire information free from unwanted popularity bias To fulfill the need for techniques to exclude the influence of specific information several methods for fairness-aware data mining have been developed for review see Hajian et al In these approaches a classifier is designed to predict labels so that they are independent from specified sensitive information By introducing this idea we proposed the concept of recommendation independence This is formally defined as unconditional statistical independence between a recommendation outcome and specified information We call a recommendation that maintains the recommendation independence independence-enhanced recommendation We developed two types of approaches to these recommendations The first is a regularization approach which adopts an objective function with a constraint term for imposing independence Kamishima et al a Kamishima and Akaho The second is a model-based approach which adopts a generative model in which an outcome and a sensitive feature are independent Kamishima et al In this paper we propose new methods for making independence-enhanced recommendations Our previous model Kamishima et al took a regularization approach and combined probabilistic matrix factorization and a constraint term However because the constraint term was heuristically designed so that it matched means by shifting predicted ratings it could not remove the sensitive information represented by the second or higher moments of distributions Further the approach could not control the range of predicted ratings and thus would skew the rating distribution For example if all predicted ratings were shifted toward the lowest ratings would not appear in the predictions To remove these drawbacks without sacrificing computational efficiency we developed two new types of constraint terms exploiting statistical measures Bhattacharyya distance and mutual information We performed more extensive experiments than in our previous studies in order to achieve more reliable verification Here we examine algorithms on three datasets and six types of sensitive features to confirm the effects of independence-enhancement To verify the improvements that derive from considering the second moments we quantitatively compared the quality of rating distributions using an independence measure Moreover we explore scenarios in which independence-enhanced recommendation would be useful and clarify the relation between recommendation independence and other recommendation research topics We provide more examples of three types of scenarios in which enhancement of recommendation independence would be useful As in the discussion in the RecSys panel Resnick et al rich recommendation diversity has been considered beneficial for making recommendations fair We discuss the differences in the definitions of recommendation diversity and independence We also note the relation to transparency and privacy in a recommendation context Our contributions are as follows We develop new independence-enhanced recommendation models that can deal with the second moment of distributions without sacrificing computational efficiency Our more extensive experiments reveal the effectiveness of enhancing recommendation independence and of considering the second moments We explore applications in which recommendation independence would be useful and reveal the relation of independence to the other concepts in recommendation research This paper is organized as follows In section we present the concept of recommendation independence and discuss how the concept would be useful for solving real-world problems Methods for independence-enhanced recommendation are proposed in section and the experimental results are presented in section Section contains a discussion about recommendation independence and related recommendation issues and section concludes our paper dislike like a standard dislike like b independence-enhanced Figure Distributions of the predicted ratings for each sensitive value RECOMMENDATION INDEPENDENCE This section provides a formal definition of recommendation independence and we show applications of this concept for solving real problems Formal Definition Before formalizing the concept of recommendation independence we will give a more intuitive description of this concept Recommendation independence is defined as the condition that the generation of a recommendation outcome is statistically independent of a specified sensitive feature This implies that information about the feature has no impact on the recommendation outcomes We will take the example of a movie recommendation In this example we select the movie-release year as a sensitive feature in order to prevent the release year from influencing the recommendation of individual movies Therefore assuming that there are two movies whose features are all the same except for their release year this independence-enhanced recommender makes identical predictions for these two movies To illustrate the effect of enhancing recommendation independence Figure shows the distributions of predicted ratings for each sensitive value for the MLM-Year dataset The details will be shown in section here we briefly note that ratings for movies are predicted and the sensitive feature represents whether or not movies are released before Black and gray bars show the distributions of ratings for older and newer movies respectively In Figure a ratings are predicted by a standard algorithm and older movies are highly rated note the large gaps between the two bars indicated by arrowheads When recommendation independence is enhanced as in Figure b the distributions of ratings for older and newer movies become much closer the large gaps are lessened that is to say the predicted ratings are less affected by the sensitive feature It follows from this figure that the enhancement of recommendation independence reduces the influence of a specified sensitive feature on the outcome We can now formalize the above intuitive definition of the recommendation independence Consider an event in which all the information required to make a recommendation such as the specifications of a user and item and all features related to them is provided and a recommendation result is inferred from this information This event is represented by a triplet of three random variables R S and R represents a recommendation outcome which is typically a rating value or an indicator of whether or not a specified item is relevant We call S a sensitive feature using the terminology in the fairness-aware data mining literature Finally represents all ordinary features or features related to this event other than those represented by R and S The recommendation is made by inferring the value of R given the values of S and based on a probabilistic recommendation model Based on information theory the statement generation of a recommendation outcome is statistically independent of a specified sensitive feature describes the condition in which the mutual information between R and S is zero This means that we know nothing about R even if we obtain information about S because information on S is excluded from R This condition is equivalent to statistical independence between R and S ie as denoted by R S Applications We here consider recommendation applications for which independence should be enhanced Adherence to Laws and Regulations Recommendation services must be managed while adhering to laws and regulations We will consider the example of a suspicious advertisement placement based on keyword-matching Sweeney In this case users whose names are more popular among individuals of African descent than European descent were more frequently shown advertisements implying arrest records According to an investigation however no deliberate manipulation was responsible rather the bias arose simply as a side-effect of algorithms to optimize the click-through rate Because similar algorithms of Web content optimization are used for online recommendations such as for online news recommendations similar discriminative recommendations can be provided in these contexts For example independence-enhanced recommendation would be helpful for matching an employer and a job applicant based not on gender or race but on other factors such as the applicants skill level at the tasks required for the job Recommendation independence is also helpful for avoiding the use of information that is restricted by law or regulation For example privacy policies prohibit the use of certain types of information for the purpose of making recommendations In such cases by treating the prohibited information as a sensitive feature the information can be successfully excluded from the prediction process of recommendation outcomes Fair Treatment of Content Providers Recommendation independence can be used to ensure the fair treatment of content providers or product suppliers The Federal Trade Commission has been investigating Google to determine whether the search engine ranks its own services higher than those of competitors Forden The removal of deliberate manipulation is currently considered to ensure the fair treatment of content providers However algorithms that can explicitly exclude information whether or not content providers are competitors would be helpful for dismissing the competitors doubts that their services may be unfairly underrated Though this case is about information retrieval the treatment of content providers in the course of generating recommendations can also be problematic Consider the example of an online retail store that directly sells items in addition to renting a portion of its Web sites to tenants On the retail Web site if directly sold items are overrated in comparison to items sold by tenants then the trade conducted between the site owner and the tenants is considered unfair To carry on a fair trade the information on whether an item is sold by the owner or the tenants should be ignored An independence-enhanced recommender would be helpful for this purpose Note that enhancing this type of recommendation independence is not disadvantageous to retail customers because items are equally rated if they are equivalent and sold under equivalent conditions Exclusion of Unwanted Information Users may want recommenders to exclude the influence of specific information We give several examples Enhancing independence is useful for correcting a popularity bias which is the tendency for popular items to be recommended more frequently Celma and Cano If users are already familiar with the popular items and are seeking minor and long-tail items that are novel to them this popularity bias will be unfavorable to them In this case the users can specify the volume of consumption of items as a sensitive feature and the algorithm will provide recommendations that are independent of information about the popularity of items The deviations of preference data can be adjusted As is well known preference data are affected by their elicitation interface For example the response of users can be changed depending on whether or not predicted ratings are displayed Cosley et al By making a recommendation independent of the distinction of preference-elicitation interfaces such unwanted deviations can be canceled When users explicitly wish to ignore specific information such information can be excluded by enhancing the recommendation independence Pariser recently introduced the concept of the filter bubble problem which is the concern that personalization technologies narrow and bias the topics of interest provided to technology consumers who do not notice this phenomenon Pariser If a user of a social network service wishes to converse with people having a wide variety of political opinions a friend recommendation that is independent of the friends political conviction will provide an opportunity to meet people with a wide range of views Independence-Enhanced Recommendation In this section after formalizing a task of independence-enhanced recommendation we show an independence-enhanced variant of a probabilistic matrix factorization model Finally we show the previous and our new types of penalty terms required for enhancing the recommendation independence Task Formalization We here formalize a task of independence-enhanced recommendation Recommendation tasks can be classified into three types finding good items that meet a users interest optimizing the utility of users and predicting ratings of items for a user Gunawardana and Shani We here focus on the following predicting-ratings task X n and Y m denote random variables for the user and item respectively R denotes a random variable for the recommendation outcome in the previous section but this R is now restricted to the rating of Y given by X and we hereafter refer to this R as a rating variable The instance of X Y and R are denoted by x y and r respectively As described in the previous section we additionally introduced a random sensitive variable S which indicates the sensitive feature with respect to which the independence is enhanced This variable is specified by a user or manager of recommenders and its value depends on various aspects of an event as in the examples in section In this paper we restrict the domain of a sensitive feature to a binary type A training datum consists of an event x y a sensitive value for the event s and a rating value for the event r A training dataset is a set of N training data D xi si ri i N We define as a subset consisting of all data in D whose sensitive value is s Given a new event x y and its corresponding sensitive value s a rating prediction function y s predicts a rating of the item y by the user x and satisfies y s This rating prediction function is estimated by using a regularization approach developed in the context of fairness-aware data mining Kamishima et al b This approach is to optimize an objective function having three components a loss function r an independence term and a regularization term The loss function represents the dissimilarity between a true rating value r and a predicted rating value r The independence term quantifies the expected degree of independence between the predicted rating values and sensitive values and a larger value of this term indicates the higher level of independence The aim of the regularization term is to avoid overfitting Given a training dataset D the goal of the independence-enhanced recommendation is to acquire a rating prediction function y s so that the expected value of the loss function is as small as possible and the independence term is as large as possible The goal can be accomplished by finding a rating prediction function r so as to minimize the following objective function si where is an independence parameter to balance between the loss and the independence is a regularization parameter and is a set of model parameters An Independence-Enhanced Recommendation Model We adopt a probabilistic matrix factorization PMF model Salakhutdinov and to predict ratings Though there are several minor variants of this model we here use the following model defined as equation in Koren y where and are global per-user and per-item bias parameters respectively and and are K-dimensional parameter vectors which represent the cross effects between users and items The parameters of the model are estimated by minimizing the squared loss function with a L regularizer term This model is proved to be equivalent to assuming that true rating values are generated from a normal distribution whose mean is equation Unfortunately in the case that not all entries of a rating matrix are observed the objective function of this model is non-convex and merely local optima can be found However it is empirically known that a simple gradient method succeeds in finding a good solution in most cases Koren The PMF model was then extended to enhance the recommendation independence First the prediction function was modified so that it is dependent on the sensitive value s For each value of s and parameter sets b s x c s y p s x and q s y are prepared One of the parameter sets is chosen according to the sensitive value and the rating prediction function becomes y s ps x qs y By using this prediction function an objective function of an independence-enhanced recommendation model becomes si where the regularization term is a sum of L regularizers of parameter sets for each value of s except for global biases Model parameters b s x c s y p s x q s y for s are estimated so as to minimize this objective Once we learn the parameters of the rating prediction function we can predict a rating value for any event by applying equation Independence Terms Now all that remains is to define the independence terms Having previously introducing our independence term of mean matching Kamishima et al we here propose two new independence terms distribution matching and mutual information Mean Matching Our previous independence term in Kamishima et al was designed so as to match the means of two distributions and because these means match if R and S become statistically independent The independence term is a squared norm between means of these distributions S N S N where N s and is the sum of predicted ratings over the set si We refer to this independence term as mean matching which we abbreviate as mean-m Distribution Matching To remedy the drawback that the mean-m term is designed to ignore the second moment we propose a new independence term Techniques for handling the independence between a continuous target variable and a sensitive feature have not been fully discussed The method in Calders et al is basically the same as the approach of the mean-m Perez-Suay et al proposed the use of the Hilbert-Schmidt independence criterion However this approach requires the computational complexity of ON for computing a kernel matrix and it is not scalable We therefore create our new independence term distribution matching with Bhattacharyya distance which we abbreviate as This term can deal with the second moment of distributions in addition to the first moment For this purpose each of two distributions and is modeled by a normal distribution and the similarity between them are quantified by a negative Bhattacharyya distance ln ln V V S N S N V V where Vs is the variance of predicted ratings over the training set To estimate Vs we use the expectation of a posterior distribution of a variance parameter derived from equation in Bishop to avoid the zero variance Vs b Qs s a N s where is equation and Qs is the squared sum of predicted ratings Qs si a and b are hyper-parameters of a prior Gamma distribution We use a and b Mutual Information We next propose our new independence term mutual information with normal distributions abbreviated as mi-normal We employed mutual information for quantifying the degree of statistical independence Distributions are modeled by a normal distribution Our new minormal term is defined as the negative mutual information between R and S s where is a differential entropy function We start with the second term of this equation Because S is a binary variable can be easily estimated by N To estimate we model by a normal distribution By using the formula of differential entropy of a normal distribution eg see example in Cover and Thomas we get ln We next turn to the first term of equation is a mixture of two normal distributions s We approximate by a single normal distribution with the same mean and variance of this mixture distribution We consider this approximation proper because it captures the first two moments of the mixture Further when R and S are completely independent where two means of two normal distributions are equal the mixture is precisely equivalent to a single normal distribution This property is desirable because we now try to let R and S be independent By using the entropy of a normal distribution we get ln V b a N Finally by substituting equations and into equation we obtain a mi-normal independence term These new independence terms and mi-normal are computationally efficient Because these terms are smooth and analytically differentiable like a mean-m term the objective function can be optimized efficiently Their computational complexity is dominated by the sum and Table Summary of experimental conditions data Flixster Sushi of users of items of ratings rating scale mean rating of latent factors regularization param non-personalized standard the squared sum of data and it is ON Because this complexity is on the same order as that of the loss function of the original PMF model the total computational complexity of an independence-enhanced variant is the same as that of the original algorithm Additionally since these new terms take the first two moments of distributions into account they give a much better approximation than the mean-m term Finally we note the difference between the and mi-normal terms A term does not approximate unlike a mi-normal term A mi-normal term can be straightforwardly extensible to the case that a sensitive feature is categorical type Experiments We implemented independence-enhanced recommenders and applied them to benchmark datasets Below we present the details regarding these datasets and experimental conditions then compare three independence terms mean-m and mi-normal These comparative experiments confirm the effectiveness of independence-enhanced recommenders and show the advantages gained by considering the second moments Datasets and Experimental Conditions We can now consider the experimental conditions in detail including the datasets methods and evaluation indexes To confirm the effectiveness of independence-enhancement more clearly we tested our methods on the three datasets summarized in Tables and The first dataset was the Table Sizes means and variances of data subsets for each sensitive value Datasets size mean variance S S S S S S MLM-Year MLM-Gender Flixster Sushi-Age Sushi-Gender Sushi-Seafood Movielens M dataset Maxwell Harper and Konstan We tested two types of sensitive features for this set The first Year represented whether a movies release year was later than We selected this feature because it has been proven to influence preference patterns as described in section The second feature Gender represented the users gender The movie rating depended on the users gender and our recommender enhanced the independence of this factor The second dataset was the larger Flixster dataset Jamali and Ester Because neither the user nor the item features were available we adopted the popularity of items as a sensitive feature Candidate movies were first sorted by the number of users who rated the movie in a descending order and a sensitive feature represented whether or not a movie was in the top of this list A total of of ratings were assigned to this top of items The third dataset was the Sushi dataset Kamishima for which we adopted three types of sensitive features Age a user was a teen or older Gender a user was male or female and Seafood whether or not a type of sushi was seafood We selected these features because the means of rating between two subsets D and D diverged We tested three independence terms in section mean-m and mi-normal An objective function was optimized by the conjugate gradient method We used hyperparameters the number of latent factors and a regularization parameter in Table For each dataset D and D the parameters were initialized by minimizing an objective function of a standard PMF model without an independence term For convenience in experiments the loss term of an objective was rescaled by dividing it by the number of training examples We performed a five-fold cross-validation procedure to obtain evaluation indexes of the prediction errors and independence measures We evaluated our experimental results in terms of prediction errors and the degree of independence Prediction errors were measured by the mean absolute error Gunawardana and Shani This index was defined as the mean of the absolute difference between the observed ratings and predicted ratings A smaller value of this index indicates better prediction accuracy To measure the degree of independence we checked the equality between two distributions of ratings predicted on D and D datasets As the measure of equality we adopted the statistic of the two-sample Kolmogorov-Smirnov test which is a nonparametric test for the equality of two distributions The statistic is defined as the area between two empirical cumulative distributions of predicted ratings for D and D A smaller indicates that R and S are more independent Experimental Results In this section we empirically examine the following two questions We consider whether independence-enhanced recommenders definitely enhance the recommendation independence Such enhancement was not theoretically guaranteed for several reasons the objective function was not convex the rating distributions were modeled by normal distributions and we adopted an approximation in equation We compare the behaviors of the three independence terms We specifically examine whether the and mi-normal terms can take into account the second moment of distributions which was ignored in the mean-m case To answer these questions we generate two types of experimental results First we show the quantitative measures to evaluate the prediction accuracy and the degree of independence Second we qualitatively visualize the distributions of predicted ratings for the MLM-Year dataset Evaluation by Quantitative Measures To examine the two questions we quantitatively analyze the evaluation measures We focus on the first question that is the effectiveness of independence-enhancement Evaluation measures and for six datasets are shown in Figure We tested a standard PMF model and three independence-enhanced PMF models We first investigate which measure the degree of independence as shown in the right column of Figure We can observe a decreasing trend of along with the increase of an independence parameter In addition all independence-enhanced recommenders could achieve better levels of independence than those obtained by a standard PMF model if the independence parameter is fully large These trends verified that recommendation independence could be enhanced successfully We then analyzed the a measurement of prediction accuracy from the left column of Figure The derived from independence-enhanced PMF models were slightly increased when compared with those derived from a standard PMF model Such losses in accuracy are inevitable as we will discuss in section However the losses were slight and these independent-enhancement models could accomplish good trade-offs between accuracy and independence In summary independence-enhanced recommenders could enhance recommendation independence successfully We then move on the second question To examine the influence of considering the second moments we checked the means and standard deviations of distributions for the MLM-Year dataset Test data were divided into two sub-datasets D and D and means and standard deviations of predicted ratings were computed for each pair of sub-datasets These pairs of means and standard deviations are depicted in Figure For all types of independence terms we found that the pairs of means approached each other as the independence parameter increased Note that this trend was observed for all datasets On the other hand the pairs of standard deviations became closer as the value of increased in the and mi-normal cases but not in the case Similar trends were observed for all the M L ea r standard mean-m mi-normal standard mean-m mi-normal M L en d er standard mean-m mi-normal standard mean-m mi-normal li te r standard mean-m mi-normal standard mean-m mi-normal S u sh g e standard mean-m mi-normal standard mean-m mi-normal S u sh en d er standard mean-m mi-normal standard mean-m mi-normal S u sh iS ea o d standard mean-m mi-normal standard mean-m mi-normal Figure Changes in the and measures NOTE The subfigure rows sequentially show the results for the MLM-Year MLM-Gender Flixster Sushi-Age Sushi-Gender and MLM-Seafood datasets respectively The X-axes of these subfigures represent the independence parameter in a logarithmic scale The Y-axes of subfigures in the first and the second columns represent in a linear scale and in a linear scale respectively Note that the ranges are changed to emphasize the differences The results for the and mi-normal terms are overlapped in some subfigures a mean-m b c mi-normal Figure Changes of means and standard deviations of predicted ratings according to the parameter NOTE The X-axes of these subfigures represent the independence parameter in a logarithmic scale These subfigures sequentially show the means and standard deviations of predicted ratings derived by the mean-m and mi-normal methods for the MLM-Year respectively Means and standard deviations for the two groups based on sensitive values are represented by the scales at the left and right side of these subfigures respectively Pairs of means and standard deviations are depicted by red solid and blue dotted lines respectively datasets except for Sushi-Age and Sushi-Seafood Note that according to our analysis the failure to control the second moments for these two datasets was due to the imbalanced distributions of sensitive values as in Table We can conclude from these results that the methods using our new independence terms and mi-normal can control the second moments of rating distributions which our previous mean-m method could not control Qualitative Visualization of Predictions To provide intuitive illustrations of independence-enhancement we visualize the distributions of predicted ratings for the MLMYear dataset In terms of the first research question we show a comparison of the rating distributions predicted by the standard PMF model with those predicted by the mi-normal independence-enhanced PMF model in Figure As described in section the figure illustrates the effect of independence enhancement We here demonstrate the improvement in consideration of the second moments By considering the second moments our new models can remove the sensitive information more strictly and can produce less skewed predicted ratings by adjusting their range For this purpose we visually compare the distributions of ratings predicted dislike like a mean-m dislike like b mi-normal Figure Distributions of the ratings predicted by mean-m and mi-normal methods for each sensitive value NOTE In the upper charts black and gray bars show the histograms of ratings for test data in D and D respectively In the lower charts we show the values for the black bins minus those for the gray bins by ignoring the second moments ie mean-m with those predicted by considering them ie mi-normal Figure shows the distributions of predicted ratings for each sensitive value for the MLM-Year dataset as in Figure Figures a and b show the distributions of ratings predicted by the mean-m and mi-normal methods respectively First the distributions for the datasets D and D became much closer in the mi-normal case than in the mean-m case see the smaller bars in the lower charts This indicates that the mi-normal could more strictly remove sensitive information by considering the second moments of distributions Second we examine the skew of rating distributions We concentrate on the rightmost bins in these histograms The differences in these bins were larger than those obtained by a standard PMF model This is because the distributions for D gray were shifted toward the plus side and this bin contained all the test data whose ratings were predicted to be larger than the maximum of the rating range The mi-normal method could achieve a smaller difference than the mean-m method by scaling the range of ratings because the mi-normal method could control the second moments of distributions However such scaling was impossible in the mean-m case because the mean-m could merely shift the distributions This observation implies that the mi-normal method could produce a less skewed distribution of predicted ratings Note that we observed similar trends in terms of the method Finally we comment on the difference between mi-normal and The differences in performance between these two methods in terms of accuracy and independence were very slight Though the mi-normal method adopted an approximation it could be straightforwardly extensible to the case that a sensitive feature is a categorical discrete variable Therefore it would be better to use the mi-normal method in general From the above it may be concluded that all independence terms could successfully enhance recommendation independence and that our new independence terms mi-normal and can enhance independence more strictly than the previous mean-m term Discussion and Related Work Finally we will discuss the characteristics of recommendation independence explore the relation between recommendation independence and diversity and present related topics Discussion In this section we discuss three topics with respect to recommendation independence First let us consider why a sensitive feature must be specified in the definition of recommendation independence In brief a sensitive feature must be selected because it is intrinsically impossible to personalize recommendation outcomes if the outcomes are independent of any feature This is due to the ugly duckling theorem which is a theorem in pattern recognition literature that asserts the impossibility of classification without weighing certain features of objects as more important than others Watanabe Because recommendation is considered a task for classifying whether or not items are preferred certain features inevitably must be weighed when making a recommendation Consequently it is impossible to treat all features equally In the RecSys panel Resnick et al a panelist also pointed out that no information is neutral and thus individuals are always influenced by information that is biased in some manner Second we will consider the indirect influences of sensitive features In section we incorporated a sensitive feature into a prediction model It might appear that the model could be made independent by simply removing S but this is not the case By removing the sensitive information the model satisfies the condition Using this equation the probability distribution over RS becomes This is the conditional independence between R and S given ie R S which is different from the unconditional independence between R and S ie R S Under a condition of conditional independence if there are features in that are not independent of S the outcomes will be influenced by S through the correlated features This phenomenon was observed in the example of online advertising in section Even though no information on the individuals races was explicitly exploited such an incident could arise through the influence of other features that indirectly contain information about their races Note that within the fairness-aware data mining such an indirect influence is called a red-lining effect Calders and Verwer With respect to the fairness-aware data mining Kamiran et al discussed a more complicated situation which they called conditional fairness In this case some of the features in are explainable even if they are correlated with a sensitive feature in addition to being considered fair For example in the case of job-matching if special skills are required for a target job considering whether or not an applicant has these skills is socially fair even if it is correlated with the applicants gender Variables expressing such skills are treated as explainable variables E and the conditional independence between R and S given E ie R S E is maintained If E is a simple categorical variable our method will be applicable by small modification An independence term is computed for each dataset having the same explainable value e domE and the sum of these terms weighted by Pre is used as a constraint term However it would not be as easy for the cases in which the domain of E is large or E is a continuous variable Finally we will discuss the relation between accuracy and recommendation independence Fundamentally as recommendation independence is further enhanced prediction accuracy tends to worsen This is due to the decrease in available information for inferring recommendation outcomes When information about S is not excluded the available information is the mutual information between R and S ie The information becomes after excluding the information about S Because the available information is non-increasing when excluding the information on S Hence the trade-off for enhancing the independence generally worsens the prediction accuracy Relation to Recommendation Diversity We will briefly discuss recommendation diversity Kunaver and Pozrl which is an attempt to recommend a set of items that are mutually less similar McNee et al pointed out that recommendation diversity is important because users become less satisfied with recommended items if similar items are repeatedly shown To our knowledge Ziegler et al were the first to propose an algorithm to diversify recommendation lists by selecting items less similar to those already selected Lathia et al discussed the concept of temporal diversity that is not defined in a single recommendation list but over temporally successive recommendations Adomavicius and Kwon discussed the aggregate diversity and the individual diversity over the items that are recommended to a whole population of users and to a specific user respectively We wish to emphasize that independence is distinct from recommendation diversity There are three major differences between recommendation diversity and independence First while the diversity is the property of a set of recommendations as described above the independence is a relation between each recommendation and a specified sensitive feature Hence it is impossible to diversify a single recommendation but a single recommendation can be independent if its prediction of ratings or its determination of older newer a standard older newer b diversified Figure Enhancement of recommendation diversity whether to recommend or not is statistically independent from a given sensitive feature Second recommendation independence depends on the specification of a sensitive feature that is a function of an item and a user On the other hand recommendation diversity basically depends on the specification of how items are similar Even though similarity metrics are not explicitly taken into account similarities are implicitly considered in a form for example whether or not a pair of items are the same Therefore independence and diversity are applicable to different situations Because a sensitive feature can represent the characteristics of users independence can be applicable for coping with the factors of users such as the MLM-Gender or Sushi-Age feature Inversely the relative difference between item properties is hard to process by using independence For example when using a similarity for diversity one can represent whether or not two items are the same color but it is not easy to capture such a feature by using a sensitive feature In this way diversity and independence are directed at different aspects in a recommendation context Third while diversity seeks to provide a wider range of topics independence seeks to provide unbiased information Consider a case like that in Figure where there are two types of candidate movies older and newer and older movies tend to be highly rated As shown in Figure a a standard recommender selects top-rated movies which are illustrated by shading Newer movies are less recommended than older movies because newer ones are rated lower To enhance diversity newer movies are added to a recommendation list instead of removing the older movies as shown in Figure b As a result both older and newer movies are recommended and a wider range of movie topics is provided to users However the predicted ratings are still affected by whether a movie is newer or older In other words this diversified recommendation list is biased in the sense that it is influenced by the release year of movies This is highly contrasted with the case of recommendation independence shown in Figure b However in this latter case the inverse situation applies even though the recommendation independence is enhanced a recommender might select movies having highly skewed topics with respect to sensitive features other than the one specified Therefore as shown in this example the purposes of recommendation diversity and independence are different Other Related Topics In addition to the recommendation diversity the concept of recommendation independence has connection with the following research topics We adopted techniques for fairness-aware data mining to enhance the independence Fairness-aware data mining is a general term for mining techniques designed so that sensitive information does not influence the mining outcomes Pedreschi et al first advocated such mining techniques which emphasized the unfairness in association rules whose consequents include serious determinations Datta et al quantified the influence of a sensitive future by a surrogate data test Another technique of fairness-aware data mining focuses on classifications designed so that the influence of sensitive information on the predicted class is reduced Kamishima et al b Calders and Verwer Kamiran et al These techniques would be directly useful in the development of an independence-enhanced variant of content-based recommender systems because content-based recommenders can be implemented by standard classifiers Specifically class labels indicate whether or not a target user prefers a target item and the features of objects correspond to features of item contents The concept behind recommendation transparency is that it might be advantageous to explain the reasoning underlying individual recommendations Indeed such transparency has been proven to improve the satisfaction of users Sinha and Swearingen and different methods of explanation have been investigated Herlocker et al In the case of recommendation transparency the system convinces users of its objectivity by demonstrating that the recommendations were not made with any malicious intention On the other hand in the case of independence the objectivity is guaranteed based on mathematically defined principles However it would be useful to examine the interface to quantify the degree of recommendation independence to improve user experiences Just as it can be helpful to show the confidence of the prediction accuracy it would be helpful to display the measures of independence Comparing the independence-enhanced recommendations with non-enhanced recommendations would also be beneficial Because independence-enhanced recommendation can be used to avoid the exposure of private information if the private information is represented by a sensitive feature these techniques are related to privacy-preserving data mining To protect the private information contained in rating information dummy ratings are added Weinsberg et al In addition privacy attack strategies have been used as a tool for detecting discrimination discovery Ruggieri et al Conclusions We proposed the concept of recommendation independence to exclude the influence of specified information from a recommendation outcome We previously attempted to enhance recommendation independence but these attempts merely shifted the predicted ratings In this paper we developed new algorithms that can deal with the second moments of rating distributions and thus the sensitive information could be more strictly removed The advantages of new algorithms were demonstrated by the experimental results In addition we explored applications of independence-enhancement and clarified the relations between recommendation independence and other recommendation topics such as diversity There are many capabilities required for independence-enhanced recommendation While our current technique is mainly applicable to the task of predicting ratings we plan to develop another algorithm for the find-good-items task We plan to explore other types of independence terms or approaches Because sensitive features are currently restricted to binary types we will also try to develop independence terms that can deal with a sensitive feature that is categorical or continuous Methods for handling more complicated conditional fairness like that described in section need to be developed
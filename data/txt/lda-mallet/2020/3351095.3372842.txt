The Effects of Competition and Regulation on Error Inequality in Data-Driven Markets Recent work has documented instances of unfairness in deployed machine learning models and significant researcher effort has been dedicated to creating algorithms that intrinsically consider fairness In this work we highlight another source of unfairness market forces that drive differential investment in the data pipeline for differing groups We develop a high-level model to study this question First we show that our model predicts unfairness in a monopoly setting Then we show that under all but the most extreme models competition does not eliminate this tendency and may even exacerbate it Finally we consider two avenues for regulating a machine-learning driven monopolist relative error inequality and absolute error-bounds and quantify the price of fairness and who pays it These models imply that mitigating fairness concerns may require policy-driven solutions not only technological ones CONCEPTS Theory of computation Market equilibria Machine learning theory Sample complexity and generalization bounds Quality of equilibria Applied computing Economics KEYWORDS learning theory algorithmic fairness data markets game theory industrial organization economics INTRODUCTION As machine learning has become more integrated into products markets and decision-making throughout society researchers practitioners and activists have identified many instances of unfairness in predictions or decisions made by machine-learned models or by humans influenced by said models A large and developing body of work which we briefly survey in Section has empirically documented unfairness in practical machine learning settings identified many theoretical sources and mechanisms of unfairness and constructed innovative fairness-aware algorithms Researchers have developed many innovative technical solutions to these problems yet the issue in practice remains far from solved This paper highlights a simple and important point while technical solutions to unfairness are certainly important mitigating unfairness in practice may require tackling economic incentives promoting unfairness Most of the existing literature assumes that a fixed dataset possibly biased arrives in the hands of a data scientist and solutions often revolve around clever ways to mitigate this bias In practice however economic incentives may create disparities well before the data scientist enters the picture Consider for example the task of speech recognition producing accurate models may require a large amount of data and data from speakers with accented or rarer dialects may be more costly to collect If the market size of a minority group is small relative to the costs a would expend in developing accurate speech recognition software it is likely that the group will be served with lower quality products In this paper we model the unfairness that arises when data-driven profit-maximizing rms choose to differentially invest in data collection across groups creating unequal error rates In order to focus on this specific source of unfairness we use a simple framework that elides the many other sources of bias that can seep into the machine learning pipeline For instance we assume that rms have unlimited budgets to purchase data at a cost from group-specific data sources of potentially infinite quantity We also assume that both rms and users benefit from more accurate models so that incentives are aligned Furthermore we assume that rms must build separate models for each group to avoid unfairness that may come from fitting to the majority In order to construct our models we borrow from the tools of learning theory and microeconomics to build simple stylized models with crisp predictions of quantifiable unfairness We assume each profit-maximizing faces a known demand curve as a function of the worst-case error rates for each group Standard results from learning theory allow us to model worst-case error rates as a function of the amount of data the buys We investigate three models of demand linear demand demand proportional to error rates and approximately rational demand For the precise description of our models and these assumptions see Section We show in Section that a profit-maximizing monopolist will choose to serve minorities as defined by their market power with lower quality models Assuming linear demand an oft-used benchmark in the economics literature we quantify the difference in relative model quality between groups as a function of their market size elasticity and cost of data We then consider two classical remedies to the ills of monopolies competition and regulation Under two natural models of competition multilinear demand Section and proportional demand Section introducing competition does not mitigate inequality and proportional demand even exacerbates it Only a model in which all consumers choose the with even infinitesimally smaller error until rms reach sufficient accuracy suggests that competition will mitigate inequality Section to do so however this model assumes a stringent notion of rationality that may not be reflective of consumer behavior in the real world Given that our most plausible models suggest that competition does improve the situation we ask whether regulation could be used to mitigate error inequality by design In particular in Section we examine two simple kinds of constraints a relative equality constraint where error rates across groups must be multiplicatively close to each other and an absolute equality constraint where error rates across all groups must be sufficiently small but may be far apart from each other We then formally quantify the costs to profits and when relevant to the majority groups error rate as a function of the threshold chosen Finally we conclude with takeaways limitations and directions for future work in Section RELATEDWORK Motivation for our work comes from the many documented instances of disparity in learned model performance between groups The existing literature has demonstrated troubling disparities in a number of domains including incentive-aligned domains where both the rms and users receive benefit from more accurate models that are the focus of this work Wilson et al studies the performance of state-of-the-art object recognition systems intended for applications like autonomous vehicles and nd that systems fail to recognize darker-skinned persons at much higher rates than lighter ones Sweeney shows that search engine queries of black-associated names generated about four times the likelihood of ads for arrest records Blodgett and OConnor show that on both complicated tasks like parsing and simple tasks like language identification texts from speakers of African American English see vastly higher error rates Buolamwini and Gebru show that commercial facial recognition software systems misclassify race and gender among dark-skinned females at orders of magnitude higher rates than light-skinned males Mehrotra et al and Ekstrand et al identify differing satisfaction levels by age and gender in recommendation systems The list goes on Researchers have engaged in many empirical and theoretical investigations to understand why these instances of unfairness occur with the hope of developing solutions to mitigate them Much of this work focuses on the learning algorithm itself as the source of unfairness and attempts to incorporate fairness notions into the algorithm see eg Verma and Rubin for a survey of fairness definitions Training data has also been identified as source of unfairness for example Chen et al identify sample size differences as a crucial source of unfairness and decomposes induced unfairness into bias variance and noise Various feedback loops stemming from historical bias have also been identified as sources of unfairness There are a few others including selection bias using the wrong metric or using a single model across multiple underlying data generating processes However to the best of our knowledge market forces in data investment have seen little attention as a source of unfairness See the survey of Cowgill and Tucker for an in-depth survey of perspectives on the sources of unfairness from computer science and economics Our models are built on insights from two extensive and historically separate literatures the formalization of learning from data embodied in computational and statistical learning theory and models of strategic interactions from the theory of industrial organization see eg Tirole From learning theory we apply fundamental bounds on sample complexity derived from the Probably Approximately Correct PAC framework see eg Kearns and Vazirani to relate rms costs to worst-case error rates from industrial organization we modify widely used models of demand such as linear demand multilinear models of imperfect substitutes the Tullock contest and Bertrand competition to link rms choices to consumer behavior Recently these two fields have drawn closer as both computer scientists and economists have begun to model markets for information and data For example Aridor et al and Mansour et al consider the exploration-exploitation trade-offs faced by rms competing to win users in a bandits setting while Ben-Porat and Tennenholtz formalize competition in the prediction space that can lead to models very different than those produced by empirical risk minimization algorithms To the best of our knowledge however this is the rst work to apply learning theory and industrial organization to explore differing incentives in the context of fairness The work of Dong et al is the closest in form to ours and uses a similar high-level abstraction of learning theory as well as a proportional-error split in market share but primarily explores questions of market concentration CONSUMER BEHAVIOR AND LEARNING THEORY We begin by describing our framework at a high level In our models rms use data to create a classifier or other machine learning model that is then used to serve consumers Consumers are split into non-overlapping groups and choose a based on how well the rms model is performing for their group Firms receive revenue based on how many consumers they attract but must pay for the amount of the data they buy The more data the better their model The rms aim to maximize their profits In the case where there are multiple rms the goal of each is to maximize their profit at equilibrium as other rms choices affect the number of consumers that they get and hence their choices Here the rms only strategically relevant choice is how much data to buy We start with the monopoly case where there is only one The chooses a number of data points M to buy for each group where we write M for the vector of these choices we write M for the worst-case error the can guarantee for group and assume this error is known to consumers The groups then respond by entering the market according to a demand function D where D represents the proportion of that uses the rms model Each group has total people so the rms revenue is G The also pays for the data represented by a cost function We will discuss our choices for D in Sections and But for now the rms profit is just the revenue the makes minus the cost it spends to acquire that data leading to the following optimization problem D P The chooses M to maximize its profit M ie max M M max M G Because we will assume in Section that is a deterministic function we can also rewrite this optimization problem as max max C where is the vector of We define C as the total profit the monopolist makes We will have an additively separable cost function in ie C G C which will allow us to also refer to the per-group profit G C On the other hand when there are multiple rms maximizing profit is not longer just an optimization problem because each rms optimal choice will depend on its opponents choice So instead we search for a Nash equilibrium which is the workhorse solution concept in classical game theory Under such a Nash equilibrium each plays their best response given all the choices of the other rms For a more thorough background see Extending our notation we have the same components as in the monopolist case except now we for the number of data points the ith buys for group i is the error rate of the ith on group and Di Di i i is the demand for the ith from group given the vector i i of error rates D T C P Firms simultaneously announce their choices resulting in a Mi of data points purchased Each group in the market responds according to M Then a pure equilibrium under profit-maximizing rms is a set of i chosen with a best response For all i M i argmax Mi i Mi M i where for i Mi Mi i Mi i Mi We will only consider pure strategy Nash equilibria in this work Again we can write an equivalent definition of the competitors problem in terms of error max i i i i max i G i i where i is the vector of error rates given by the associated equilibrium choice M i We also use i i i i i to refer to the profit i makes on group Note that a i only enters a market in the rst place if i In this work we do not consider the case when i as our goal is to show that even when rms do enter the market for each group market forces may still create a disparity between groups Finally in Section we discuss imposing regulation on a monopolist to ensure some kind of fairness across groups We consider two different kinds of constraints a regulator could impose on a The rst is what we refer to as relative error equality which roughly corresponds to group fairness in binary classification For all G we require for parameter On the other hand we could ask for an absolute error guarantee requiring that the error rates for both rms are low regardless of how close to each other they are For all G we require instead This roughly corresponds with notions of fairness eg We investigate what happens when a monopolist satisfies one of these two constraints Because error is the relevant quantity from the regulators perspective and error and data investment are so tightly linked we write the regulated monopolists problem in terms of the choice of error D R M P The to maximize its profit M subject to a constraint max max C st fr r R where either R G G and or R G and Just as is the case in binary classification where different settings may call for different notions of fairness which version of fairness regulator should impose will depend on the context and the ethical assumptions she maintains Data Costs and Learning Theory A key component to our model is how choices in data investment drive error rates We assume that rms build a model to provide a product to consumers and that this model is learned from data The rms have access to independent and identically distributed data from fixed data sources that reflects the same distribution that consumers care about In the PAC model of learning there is a class of hypotheses and each hypothesis has an associated risk Rh typically representing the error rate For example in binary classification Rh though our model will be applicable to other settings as well With only access to data drawn from D rather than D itself the learner cannot guarantee its risk but can achieve high probability upper bounds on its risk In the agnostic PAC setting there is a learning algorithm that upon seeing a sample of size M except with probability returns a hypothesis such that Rh min Rh r M Rh is the Bayes error is the VC dimension of and is a universal constant See for more on PAC learning VC dimension and the various kinds of PAC learning To model the fact that getting appropriate data can have group-dependent sources and thus costs we assume data for each group is drawn separately from distributions D The rms choose M the number of data points to draw and will use a learning algorithm with a PAC guarantee for each data set and give to a consumer of group the output of the corresponding hypothesis Achieving such bounds would not be useful to the unless consumers make decisions based on these bounds Here we assume that the consumers have no more access than the rms they do not have access to the distribution so they cannot make decisions based on the true group-level error rates Given this we assume that the consumers use rms bound on the excess error Rh Rh which we refer to as the worst-case excess error rate Of course in reality consumer decisions are not necessarily based on the worst-case error rate However given that consumers often do in practice have to make choices using relatively little information about rms and have trouble predicting how well exactly a will treat them we believe this is a natural place to start In particular bounds on the the excess error rates represent the minimal amount of information consumers need to make informed decisions Thus we set i Mi M i for constants and q For example in agnostic PAC learning q and p Note that we are assuming is fixed ahead of time but we allow in general for to be group-dependent Agnostic PAC learning is far from the only type of learning to have this form the realizable PAC setting the multi-class setting and many regression settings all have this form This set-up does ignore the possibility of transfer learning ie using the data to help with learning for another group We avoid this scenario so as to concentrate on the unfairness generated via the market incentives instead of the unfairness generated for example when an assumption about the similarity between D and D fails to hold The choice determines not only the worst-case error rates but the cost to the of generating that data either by collecting it in the wild or buying it from another source As mentioned above we permit the costs to be group-dependent We assume the cost is additively separable and linear Mi i and Mi G Mi for constants i where i represents the fixed cost of entering the market Since we can q this model is equivalent to rst choosing a worst-case error rate i and then paying a cost i i q i for each group where is redefined to minimize the number of constants we employ So now Mi q i This version is the one we will use for the remainder of the paper Note that the cost function is convex which means that whenever the demand is concave so is the profit function Models of Consumer Choice The rms revenue is driven by how demand for its product reacts to its choice of worst-case error guarantees We consider several models of this demand each inspired by well-studied models in microeconomics While rms are primarily concerned only with aggregate changes in demand rather than the decisions of individual consumers each of our models can be founded on natural models of individual consumer behavior and we provide such models in several cases In the monopoly case we use a simple model of linear demand while an idealization linear demand is often used even in econometric estimation see eg In the competitive case there are a variety of natural demand models each embedding different assumptions about how consumers choose between rms and how stringently they react to differing error levels We study three models along a spectrum of rationality a multilinear demand generalizing the monopoly case a parameterized proportional demand and an approximately rational demand where consumers exclusively use the with lowest error up to some tolerance We give the details of these models of demand in each appropriate subsection in Sections and Under each model there are parameter regimes where rms choose not to invest in data collection for some groups at all while this may reflects some real-world scenarios the purpose is of this paper is to highlight economic incentives that create inequality even aside from such extreme scenarios As such we will focus on interior optima or equilibria In an interior optimum the monopolist must make positive profit so that it enters the market and choose error rates strictly smaller than for each group so that it is investing in data collection for each group Similarly interior equilibria require that profits for both rms must be positive and each error rate strictly smaller than Our theorems statements will highlight this focus MONOPOLY We start with the case where there is one in the market and demand is linear D L D A linear demand function for each group is given by D where A linear demand curve can arise from a simple model of consumer behavior suppose utility-maximizing consumers consider whether or not to use the product and only use it if it is above some threshold equivalent to being better than some outside option If these thresholds are uniformly distributed over some interval then demand will be linearly decreasing over an interval Strictly speaking this is a piecewise linear demand but this does not greatly affect optimal behavior of the it merely means that it will never choose outside the linearly decreasing range unless they are choosing not to invest in providing quality products at all For simplicity of our theorem statements we will assume that parameters are such that the rms achievable errors are a subset of the linear portion of the demand curve here but in Appendix A we generalize to arbitrarily large to ensure that our results still qualitatively hold Our main result here is the following T M I Suppose a monopolist with learning rate q faces linear demand Then in any interior optimum for every pair of groups and the error inequality is given by q Again we focus on an interior optimum Three factors affect the error gap between the minority and the majority the size of the minority as a share of the total market the marginal cost of gathering data on the minority vs on the majority and the elasticities of the populations with respect to the error It is also worth noting that the fundamental nature of the learning problem via the learning rate q affects the magnitude of error inequality Theorem is a consequence of the following lemma L Suppose a monopolist with learning rate q faces linear demand Then in any interior optimum error levels set by the monopolist are given by q q P Recall that G G q Now we notice that this profit function is separable into the sum of profits from each market differentiating with respect to separately and setting to zero we arrive at the conditions q q Solving this equation yields q q This is indeed a maximum because profit is concave so the only alternative is an exterior optimum Notice that if for all and then the interior optimum exists and is unique COMPETITION In this section we show that under most reasonable models of competition the introduction of competition does not mitigate error-inequality compared to the monopoly equilibrium and may in fact increase it Only under Bertrand-like competition which assumes consumers are strictly rational is inequality significantly mitigated In particular we show that under both the Tullock and the multi-linear models of demand the inequality between groups as measured by the error rates does not improve relative to the monopoly case In the case of the Tullock model as a function of the relative size of the groups inequality is actually worse Multilinear Demand Next we consider a simple generalization of linear demand to the two-rm case This model can be interpreted as a model of competition in identical products with differing quality levels as in but can also be interpreted as well as microfounded and used to estimate structural parameters as in as markets for imperfect substitutes D M D The multilinear linear demand function is for rms i and and for each group Di i i i where i and i We require so that demand reacts more strongly to a rms own error rates than its opponents this ensures that if both rms increase error total demand decreases The other conditions on the parameters are to ensure that the demand is truly multilinear as opposed to piece-wise linear Note it is not the case that all consumers choose the with lower error as one might expect if the products of the rms were perfect substitutes Instead users switch between rms depending on their error rates and even if rms achieved perfect accuracy the split of the total market might not be even as captured by differing i This could represent brand loyalty for example or perhaps that rms products are not perfectly identical Our main result for this case states that the gap between error rates is the same as in the monopoly case T Suppose that two rms with learning rate q compete under multilinear demand Then in any interior equilibrium for every pair of groups and error inequality is given by i i q Theorem is a consequence of the fact that the rms optimal choice does not depend on its opponents error rates that is they have a dominant strategy This is formalized by the following lemma which is enough to prove Theorem L Suppose that two rms with learning rate q compete under multilinear demand Then in any interior equilibrium error levels are given by i q P This proof will be very similar to that of Lemma only now the behavior of the other will affect profit Recall i i G i G i q i We can see that even though the behavior of the other will affect profit i still has a dominant strategy This is because the conditions do not depend on the other i i q i This is the same rst order condition as in the monopolists case with the same implication i q Similar to the case of the monoplists notice that if for all i i i i i i and i then an interior equilibrium exists Proportional Demand In this section we consider a model inspired by and thus indirectly by the Tullock contest In particular rms split the market proportionally to the other rms error D P D In a market we say that demand is proportionally split with competition exponent if Di Here we focus on the two-rm case in which case we can write Di i i i i Now we can write our inequality theorem T PD Suppose two rms with learning rate q compete under proportional demand Then in any interior equilibrium error inequality is given by i i q i q i q where i q q q i q Recall that in the monopoly case the exponent was instead of meaning that introducing competition under this model has actually exacerbated the effect of minority status on inequality Note also that the relative inequality between two groups based on the results from a particular depends not only on that rms cost structure for the two groups but also on the opposing rms cost structure for the two groups Proving Theorem requires ending the equilibrium L Suppose two rms with learning rate q face proportional demand with competition exponent In any interior equilibrium error rates are given by i q q q i q q q q q i q If i for all and i then there exists a setting of parameters for which i is the unique equilibrium For brevity we relegate the full proof and the characterization of when these conditions hold to Section C Below we detail the instructive portion of the proof for the special case in which q L Suppose two rms with learning rate face proportional demand with competition exponent In any interior equilibrium error levels are given by i i sufficient conditions for existence are that for all and i i i i i If moreover mink then i is the unique equilibrium The conditions of Lemma are stated in terms of i recall though that i is not a primitive of our model but rather the product of the per-datapoint cost and learning theory constants These conditions thus imply conditions on these underlying constants In the symmetric case this asks that the per-datapoint cost c satisfies c log q which merely requires that the per-datapoint cost is not too large relative to the desired hypothesis class and success probability In the asymmetric case we require that rms do not face ratios of data cost to learning constant that are too different from each other If either of these conditions is violated then one or both rms may have an incentive to stop investing completely in data acquired for a group Such non-interior equilibria can obviously lead to severe error inequality but again Theorem demonstrates the existence of incentives to unfairness even ruling out these extreme cases P L C We can write Firm is profit from each group as i i i i i The strategy space of the is to select an i for each group in we search for a pure strategy Nash equilibrium At a high level our strategy to do so is as follows rst we x the opposing rms action Optimizing Firm is profit gives a best-response to the fixed action An equilibrium pair must simultaneously satisfy both rms rst order conditions given the other so we obtain two simultaneous equations that yield the equilibrium relationship between the two rms actions Solving this yields a candidate solution Then we can show that the candidate solution is indeed a maximum via the concavity of the profit function Finally we need but check that there are no solutions at the endpoints and we provide conditions when this is ruled out Now fixing Firm choice the profit function is just a function of i differentiating this gives i i ii We set this equal to zero Since satisfying this condition is required for i to be a best-response we can plug in whatever that may be requiring i and in particular this must apply to the best-response i We can apply similar logic to Firm Hence for i to be best responses to each other that is to be in interior equilibrium we must have that i i i This implies that i i Substituting this condition back into Equation we obtain that i i i i i i i Symmetric logic yields i Now to show that this candidate solution is indeed an equilibrium we must show that these actions are best-responses to each other Fix i Then we can view i i as a continuous function on By construction evaluating i i i at i must give zero It is also easy to verify that this is indeed the case If i i is concave at i then that is a local maximum of the profit function given To see that it is concave note that i i i i Evaluating this quantity at i gives i i i ii i i i i i Straightforward if tedious algebra lets us rewrite the right hand side and conclude that i i i ii i i i But notice that this quantity is always negative if costs are positive hence i is indeed a local maximum of i To ensure that this point is a global maximum we must compare it with the profit at the endpoint For brevity we defer this calculation to the Appendix in Section C Finally note that equilibrium profits are positive if i i this is true whenever i i ie fixed costs are not extremely large Positive profits and the fact that i globally maximizes profit given ensures that the putative equilibrium pair forms an equilibrium To identify conditions in which this equilibrium is unique we need to eliminate the only other possible equilibrium both rms choosing Again for brevity we defer this calculation to the appendix Again we pause to highlight several intuitive properties of the equilibrium First Firm is choice of error for group is decreasing with the market size of Group as well as the ferocity of competition in Group These results are similar to those of Lemma with a different functional form and the competition exponent of the Tullock game replacing the error elasticity of demand It is also intuitively increasing in i and decreasing in though this is harder to see due to the functional form of Approximately Rational Demand Now we consider markets where consumers behave rationally If we allow consumers to behave fully rationally in the sense of always picking the with even infinitesimally smaller error we obtain a model similar to the Bertrand model of competition accordingly no equilibrium exists as we show in Section B Hence we instead consider a slight relaxation of the fully rational model Suppose consumers behave rationally except that they do not care about excess error up to over the optimal error That is the lower will capture the whole market for errors that are not too small but for i rms again split the market We formally define this demand function below D In market we say demand is -tolerant rational with if Di mink and i min mink and i min mink and i min i mink We will show that there exists a unique equilibrium here for appropriate parameters in which groups error levels are determined not by their sizes but by their optimal errors and their tolerances T A R I Suppose that two rms compete under -tolerant demand Then in any interior equilibrium error inequality is given by where is users tolerance threshold assumed to be strictly positive Moreover if i for all i the unique equilibrium is interior In particular Theorem shows that under this approximate Bertrand-like model of competition the dependence on group size in the error inequality is eliminated Instead inequality depends merely on the optimal error achievable under the hypothesis class used by rms and groups tolerances Note that the conditions of Theorem is just asking that log As before we can interpret this as a condition that the per-datapoint cost is not too large relative to the total market size and the learning theory constants Theorem follows from the following lemma L A R E Suppose that two rms compete under -tolerant demand and i for all i Then an interior pure strategy equilibrium exists in which i and this equilibrium is unique P We posit that the prole is an equilibrium To see this note that a term deviating to some would lose its entire market share and so would end up with negative profit Under the conditions of the theorem though i so deviating to a higher error with negative profit cannot be a profitable deviation On the other hand deviating to would result in the same market share but with increased costs Hence deviating to decreased error is also not a profitable deviation To see that there can be no other equilibria notice that if both rms were setting error in they would have an incentive to deviate to if one rms error were in that range and the others were above then the term with higher error would have an incentive to deviate to and finally if both rms were above either term could profitably deviate to slightly lower error Unfortunately even this relaxation of full rationality may not be a realistic model of competition in many cases it still requires that outside of the range of all consumers are perfectly discerning This is unlikely to be true in practice Without such an assumption the conclusions of this model do not hold Models like the proportional split and multilinear demand are more likely to capture salient market features in practice REGULATION In this section we consider the perspective of a regulator with the power to require one of two kinds of error equality and analyze the response of the monopolistic term to each These constraints that the regulator may impose are relative error equality and absolute error equality We quantify the direct cost associated with imposing these constraints in terms of increased error to the majority group under the rst kind and lost profit to the monopolist in both This serves to give a sense of the direct trade-offs involved in regulating machine-learning driven markets We highlight though that there may be non-quantifiable benefits to equity across groups and only societal deliberation can evaluate these trade-offs Which of these two types of regulation is preferred will depend on the context Requiring errors across groups to all be similar relative error equality may not be sufficiently strong if large error is harmful regardless of another groups error rate but also may be too strict when small absolute errors are perceived as approximately equivalent On the other hand absolute error equality where we require all errors to be below a threshold treats all small absolute errors as equivalent but still allows a large relative gap in error rates across groups An absolute error bound shifts the burden of fairness entirely to the term which may be preferable from a consumer standpoint at the same time decreasing profits for monopolies may reduce the incentive to innovate which may also be undesirable We make the following assumption for the rest of the section for ease of exposition A There are two groups G AB there is an interior optimum M A M B ie the unconstrained monopoly enters the market and B has lesser market power and higher data costs ie and B A We refer to group A as the majority group and B as the minority group We also define MA M B and RA R B to be the monopolists and regulated monopolists optimal choices respectively Note that an immediate consequence of Assumption and Theorem is that MB M A Finally we defer omitted proofs from this section to Sections D and E Relative Error Equality In this section we imagine that a regulator requires the monopolist to achieve error rates within a bounded ratio We will show that a monopoly responds by investing less in majority data collection and more in minority data collection than it otherwise would resulting in worse error rates for the majority better error rates for the minority approximate equality between groups and lower profits for the term In particular we quantify by how much error rates worsen for the majority and by how much profits are lowered for the monopolist which we refer to as the price of fairness We formalize the regulators constraint as follows D R The regulator forces the term to achieve error guarantees of bounded ratio A B and B A where is a positive constant As in Section we consider a profit-maximizing monopolist As before each group has linear demand with market sizes and Now if the regulation has bite that is if it changes the outcome the regulated monopolist does the minimum it can to satisfy the constraint that is it sets RB R A Formally L S Suppose that the unregulated monopoly sets MB M A Then the profit-maximizing monopoly facing the relative error constraint sets R B R A The proof follows from concavity and Jensens inequality we provide details in D Lemma allows us to characterize the regulated monopolists optimal choice of errors under this regulation T Suppose that the unregulated monopoly sets error MB MA Then in any interior optimum the regulated monopoly sets the errors as R A q A q q and RB RA P By Lemma RB RA Thus the profit maximization problem can be written solely as a function of A A AA B BA A A q A B B q A q Then the rst order condition is q A q q A and hence we must have that R A q A q q Concavity guarantees that this is a global optimum These together provide insight into to what the regulation is doing The monopolists problem can be written as max max A B A q This is equivalent to facing a single population of with demand function fixed cost AB and marginal cost q We later use this interpretation to quickly calculate the constrained monopolists profits One might worry that imposing fairness requires making both groups worse o in an absolute sense It turns out that this is not the case if the regulation has bite then it necessarily increases the error of the majority group and necessarily decreases the error of the minority group That is equality comes at a price for the majority group but does not require a Pareto deterioration Our rst result is that the monopolist will respond to regulation by increasing majority error rates C R A M A and R B M B At this point members of the majority group may be concerned because their error rate increases We refer to the gap between their error rates under the constrained and unconstrained monopolies as a price of fairness for this reason even though imposing this constraint may be on the whole desirable from a societal perspective R A M A Fortunately we can show this price is relatively small C P U B B A q q Unsurprisingly this bound is increasing in the ratio of minority cost to majority cost and decreasing in the leniency of the regulator Also unsurprisingly decreasing the ratio or B A and increasing the ratio B A all increase the price of fairness for the majority If regulation changes the monopolists behavior it must weakly decrease profits This loss is quantifiable as another price of fairness D M P R E We define the price of fairness as the ratio between the unconstrained monopoly profit and constrained monopoly profit under the relative error constraint ie M A M B R A R B MA M B AB BA A B We can write down this price of fairness as a function of the parameters of the model T The Monopolists price of fairness is given by Q q q A Q B q q B Q B q q A B q where Q q P The optimal solution to the monopolists problem with parameters for in G AB is the following AB q q Q See Appendix D Using this form and plugging in the market parameters we obtain the optimal profit of the unconstrained monopolist for the numerator The denominator is derived using the interpretation of the constrained monopolists problem as optimizing its profits against a single market with parameters modified by regulation and plugging these parameters into the same form Theorem provides a quantitative price of fairness in terms of monopoly profits However it is somewhat unwieldy Proposition provides some clarity on the limiting behavior of this price of fairness as a function of the minority groups size in absolute terms P L R E I Let r for constant ratio r Then lim On the other hand for constant lim B A q where Q is as above Absolute Error Equality In this section we suppose instead that the regulator imposes an absolute upper bound on error rates for each group We show that the monopolist responds by purchasing just enough data to meet the constraint using the profits from the majority to subsidize the minority In this case minority error rates can be improved without increasing error for the majority the regulator can even improve error rates for the majority as well up to a point We characterize the price of fairness for the monopolist and the minimum error the regulator can guarantee We formalize this constraint as follows D A For the regulator forces the term to achieve error of A and B We have another saturation lemma for this kind of constraint too either the unconstrained error was already less than or the profit maximizing error subject to regulation is exactly Formally L S AB if R M then R Lemma lets us reason very simply about the behavior of the regulated monopolist for any group in which imposing regulation requires the term to improve error rates the term will use up the entirety of this error budget profit will decrease of course because imposing constraints can only decrease its objective In this scenario if the term enters the market at all it must enter the market for both groups so as to achieve the constrained error rates A regulator then has to choose so as to still induce the term to enter the market at all if they want to ensure the constrained error rate for the minority group Of course a regulator may also wish to choose the smallest such error rate which we refer to as the minimum achievable error Lemma let us characterize the minimum achievable error P Let be the smallest which solves q q where A B and A B exists and is the minimum achievable error ie the minimum for which the monopolist still enters the market Equation can be solved via the quadratic or cubic formulae in the realizable and agnostic cases respectively and learning rates in between can be accommodated numerically This leads us to the monopolys optimal error rates as a function of T A O Outcomes fall into one of the following possibilities If MB then RB RB MA MB If MA MB then RB RB MA If MA then RB RB If then the term exits the market P Case is trivial Case and follow from Lemma Case follows by the definition of Theorem contrasts starkly with Theorem as long as the constraint is not so strict the monopolist exits the market outcomes either improve for the minority and remain just as good for the majority or improve for both groups In other words this style of regulation does not impose a price of fairness on the majority Note that unless M A the regulator is not guaranteeing relative equality Which type of equality is preferable will depend on the context Of course this regulation does still impact profit D M P We define the monopolists price of fairness under absolute error constraints as M A M B R A R B MA M B AB A B Notice that given the market parameters Theorem allows the regulator to evaluate the monopolists price of fairness for each potential choice of error threshold via straightforward calculation Proposition characterizes the limiting behavior of the monopolists price of fairness as a function of absolute size of the minority group under absolute error guarantees and these are qualitatively similar to limiting behavior under relative error guarantees P L A E G For fixed and for at a constant ratio r lim On the other hand let be the minimal achievable error when ie when the term faces group A alone Then if then converges to a parameter-specic constant as DISCUSSION In this work we identify economic incentives leading to unfairness in data-driven markets At a high level we show that monopolists are incentivized to invest less in minority groups as measured by market size elasticity and data costs because they are less profitable that competition does not mitigate this incentive towards inequality under reasonable models and that judicious regulation can improve outcomes potentially at a cost in terms of profits or depending on the regulation error rates for the majority group We view this paper as highlighting an important and understudied point of view but certainly not as the last word We made many choices that situate our models in particular contexts for example the assumption that rms and users benefit from improved accuracy does not capture many settings that currently are or will soon be urgent domains of adjudicating fairness concerns machine learning in loans insurance and facial recognition systems are obvious cases but the potential and consequent scope for unfairness is vast We hope that future work will further clarify the possibility and perhaps necessity- of leveraging policy tools in addition to algorithmic solutions to combat unfairness in machine learning
Fair Algorithms for Learning in Allocation Problems Settings such as lending and policing can be modeled by a centralized agent allocating a scarce resource eg loans or police officers amongst several groups in order to maximize some objective eg loans given that are repaid or criminals that are apprehended Often in such problems fairness is also a concern One natural notion of fairness based on general principles of equality of opportunity asks that conditional on an individual being a candidate for the resource in question the probability of actually receiving it is approximately independent of the individuals group For example in lending this would mean that equally creditworthy individuals in different racial groups have roughly equal chances of receiving a loan In policing it would mean that two individuals committing the same crime in different districts would have roughly equal chances of being arrested In this paper we formalize this general notion of fairness for allocation problems and investigate its algorithmic consequences Our main technical results include an efficient learning algorithm that converges to an optimal fair allocation even when the allocator does not know the frequency of candidates ie creditworthy individuals or criminals in each group This algorithm operates in a censored feedback model in which only the number of candidates who received the resource in a given allocation can be observed rather than the true number of candidates in each group This models the fact that we do not learn the creditworthiness of individuals we do not give loans to and do not learn about crimes committed if the police presence in a district is low As an application of our framework and algorithm we consider the predictive policing problem in which the resource The full technical version of this paper is available at being allocated to each group is the number of police officers assigned to each district The learning algorithm is trained on arrest data gathered from its own deployments on previous days resulting in a potential feedback loop that our algorithm provably overcomes In this case the fairness constraint asks that the probability that an individual who has committed a crime is arrested should be independent of the district in which they live We investigate the performance of our learning algorithm on the Philadelphia Crime Incidents dataset CONCEPTS Theory of computation Online learning algorithms Machine learning theory Online learning theory Computing methodologies Learning from implicit feedback KEYWORDS algorithmic fairness resource allocation censored feedback online learning INTRODUCTION The bulk of the literature on algorithmic fairness has focused on classification and regression problems see eg for a collection of recent work but fairness concerns also arise naturally in many resource allocation settings Informally a resource allocation problem is one in which there is a limited supply of some resource to be distributed across multiple groups with differing needs Resource allocation problems arise in financial applications eg allocating loans disaster response allocating aid and many other domains but the primary example that we will focus on in this paper is policing In the predictive policing problem the resource to be distributed is police officers which can be dispatched to different districts Each district has a different crime distribution and the goal absent additional crimes caught recent work see eg has highlighted the extent to which algorithmic allocation might exacerbate those concerns For example Lum and Isaac show that if predictive policing algorithms such as PredPol are trained using past arrest data to predict future crime then pernicious feedback loops can arise which misestimate the true crime rates in certain districts leading to an over-allocation of police that Lum and Isaac showed to be overpoliced on a relative basis were primarily poor and minority this is especially concerning from a fairness perspective In this work we study algorithms that avoid this kind of under-exploration and incorporate quantitative fairness constraints In the predictive policing setting Ensign et al implicitly consider an allocation to be fair if police are allocated across districts in direct proportion to the districts crime rate generally extended this definition asks that units of a resource are allocated according to the groups share of the total candidates for that resource In our work we study a different notion of allocative fairness that has a similar motivation to the notion of equality of opportunity proposed by Hardt et al in classification settings Informally speaking it asks that the probability that a candidate for a resource be allocated a resource be independent of his group membership In the predictive policing setting it asks that conditional on committing a crime the probability that someone is apprehended should not depend on the district in which they commit the crime To illustrate that our notions of fairness do not depend on whether individuals would prefer to receive or not receive the resource we highlight another setting in which allocative fairness is a natural concern hiring to recruit machine learning programmers by advertising on a social media platform Many such platforms offer the ability to advertise to different demographics of users and charge by the number of times the advertisement is shown to different users ie the number of impressions a fixed advertising budget can then be viewed as a number of impressions to allocate Depending on how well the platform can identify programmers within each demographic the ad may be shown to a higher or lower number of programmers In this setting our notion of allocative fairness asks that the probability a programmer is exposed to the hiring ad and thus receives the opportunity to apply for a job does not depend on the programmers demographic and the allocation problem is to maximize the number of programmers reached via the choice of impressions across each demographic subject to fairness constraints criminals including preventing crimes in the first place fostering healthy community relations and generally promoting public safety But for concreteness and simplicity we consider the limited objective of apprehending criminals in deployed systems arrest data rather than reported crime is used to train the models and with different research questions in mind Our Results To define the extent to which an allocation satisfies our fairness constraint we must model the specific mechanism by which resources deployed to a particular group reach their intended targets We study two such discovery models and we view the explicit framing of this modeling step as one of the contributions of our work the implications of a fairness constraint depend strongly on the details of the discovery model and specifying such a model is an important step in making ones assumptions transparent We study two discovery models which capture two extremes of targeting ability In the random discovery model regardless of the number of units allocated to a given group all individuals within that group are equally likely to be assigned a unit regardless of whether they are a candidate for the resource or not In other words the probability that a candidate receives a resource is equal to the ratio of the number of units of the resource assigned to his group to the size of his group independent of the number of candidates in the group At the other extreme in the precision discovery model units of the resource are given only to actual candidates within a group as long as there is sufficient supply of the resource That is the probability that a candidate receives a resource is equal to the ratio of the number of units of the resource assigned to his group to the number of candidates in his group In the policing setting these models can be viewed as two extremes of police targeting ability for an intervention like stop-and-frisk In the random model police are viewed as stopping people uniformly at random In the precision model police have the omniscient ability to identify individuals with contraband and stop only them Of course reality lies somewhere in between These discovery models have different implications for fairness In the random model fairness constrains resources to be distributed in amounts proportional to group sizes regardless of the distribution of candidates and so is uninteresting from a learning perspective On the other hand the precision model yields an interesting fairness-constrained learning problem when the distribution of the number of candidates in each group must be learned via observation and what counts as a fair allocation depends greatly on these distributions We study learning in a censored feedback setting each round the algorithm can choose a feasible deployment of resources across groups Then the number of candidates for the current round in each group is drawn from a fixed but unknown group-dependent distribution which might be not be independent from the distributions in other groups The algorithm does not observe the number of candidates present in each group but only the number of candidates that received the resource In the policing setting this corresponds to the algorithm being able to observe the number of arrests but not the actual number of crimes in each of the districts Thus the extent to which the algorithm can learn about the distribution in a particular group is limited by the number of resources it deploys there The goal of the algorithm is to converge to an optimal fairness-constrained allocation where here both the objective value of the solution and the constraints imposed on it depend on the unknown distributions One trivial solution to the learning problem is to sequentially deploy all of ones resources to each group in turn for a sufficient amount of time to accurately learn the candidate distributions This would reduce the learning problem to an offline constrained optimization problem which we show can be efficiently solved by a greedy algorithm But this algorithm is unreasonable it has a large exploration phase in which it uses nonsensical deployments vastly over-allocating to some groups and under-allocating to others A much more realistic natural approach is a greedy-style learning algorithm which at each round uses its current best-guess estimate for the distribution in each group and deploys an optimal fairness-constrained allocation according to these estimates Unfortunately as we show if one makes no assumptions on the underlying distributions any algorithm that has a guarantee of converging to a fair allocation must behave like the trivial one deploying vast numbers of resources to each group in turn This impossibility result motivates us to consider the learning problem in which the unknown distributions are from a known parametric family The natural greedy algorithm uses an optimal fair deployment at each round given the maximum likelihood estimates of candidate distributions given its censored observations so far for concreteness we consider the case of the Poisson distribution and show that it converges to an optimal fair allocation but our analysis generalizes for any single-parameter Lipschitz-continuous family of distributions Finally we conduct an empirical evaluation of our algorithm on the Philadelphia Crime Incidents dataset which records all crimes reported to the Philadelphia Police Departments INCT system between and We verify that the crime distributions in each district are in fact well-approximated by Poisson distributions and that our algorithm converges quickly to an optimal fair allocation as measured according to the empirical crime distributions in the dataset We also systematically evaluate the Price of Fairness and plot the Pareto curves that trade off the number of crimes caught versus the slack allowed in our fairness constraint for different sizes of police force on this dataset For the random discovery model we prove worst-case bounds on the Price of Fairness Further Related Work Our precision discovery model is inspired by and has technical connections to Ganchev et al which models the dark pool problem from quantitative finance in which a trader wishes to execute a specified number of trades across a set of exchanges of unknown but independently distributed liquidity In Ganchev et al the authors design an optimal allocation algorithm under the censored feedback of the precision model It is straightforward to map their setting onto ours but they assume independence between different exchanges while the candidate distributions in our setting need not be independent Regardless we show that their allocation algorithm can be used to compute an optimal allocation ignoring fairness even when the independence assumption is relaxed see Remark Later Agarwal et al extend the dark pool problem to an adversarial rather than distributional setting This is quite closely related to the work of Ensign et al who also consider the precision model under a different name in an adversarial predictive policing setting They provide no-regret algorithms for this setting by reducing the problem to learning in a partial monitoring environment Since their setting is equivalent to that of Agarwal et al the algorithms in Agarwal et al can be directly applied to the problem studied by Ensign et al Our desire to study the natural greedy algorithm rather than an algorithm which uses unreasonable allocations during an exploration phase is an instance of a general concern about exploration in fairness-related problems Recent works have studied the performance of greedy algorithms in different settings for this reason Lastly the term fair allocation appears in the fair division literature see eg for a survey but that body of work is technically quite distinct from the problem we study here SETTING We study an allocator who units of a resource and is tasked with distributing them across a population partitioned into G groups Each group is divided into candidates who are the individuals the allocator would like to receive the resource and non-candidates who are the remaining individuals We let mi denote the total number of individuals in group i The number of candidates in group i is a random variable drawn from a fixed but unknown distribution called the marginal candidate distribution We do not make any assumptions about the relationship between the candidate distributions across different groups and in particular these distributions need not be independent We use M to denote the total size of all groups An allocation v v vG is a partitioning of these V units where vi V denotes the units of resources allocated to group i Every allocation is bound by a feasibility constraint which requires that V A discovery model is a possibly randomized function mapping the number of units vi allocated to group i and the number of candidates in group i to the number of candidates discovered in group i In the learning setting upon fixing an allocation v the learner will get to observe a realization of for the realized value of for each group i Fixing an allocation v a discovery model disc and candidate distributions for all groups C i G we define the total expected number of discovered candidates v as v i G E where the expectation is taken over and any randomization in the discovery model disc When the discovery model and the candidate distributions are fixed we will simply write v for brevity We also use the total expected number of discovered candidates and expected utility exchangeably We refer to an allocation that maximizes the expected number of discovered candidates over all feasible allocations as an optimal allocation and denote it by Allocative Fairness For the purposes of this paper we say that an allocation is fair if it satisfies approximate equality of candidate discovery probability across groups We call this discovery probability for brevity This formalizes the intuition that it is unfair if candidates in one group have an inherently higher probability of receiving the resource than candidates in another Formally we define our notion of allocative fairness as follows Definition Fix a discovery model disc and the candidate distributions C For an allocation v let vi E disc vi denote the expected probability that a random candidate from group i receives a unit of the resource at allocation v ie the discovery probability in group i Then for any v is α-fair if vi fj for all pairs of groups i and When it is clear from the context for brevity we write vi for the discovery probability in group i We emphasize that this definition depends crucially on the chosen discovery model and requires nothing about the treatment of We think of this as definition of fairness in that one might want to further constrain the treatment of non-candidates but we do not consider that extension Since discovery probabilities vi and fj are in the absolute value of their difference is in By setting we impose no fairness constraints whatsoever on the allocations and by setting we require exact fairness We refer to an allocation v that maximizes v subject to α-fairness and the feasibility constraint as an optimal allocation and denote it by In general is a non-increasing quantity in since as diminishes the utility maximization problem becomes more constrained Remark We note that both the utility and discovery probabilities can be written solely in terms of the marginal candidate distributions in each of the groups even when these distributions are not independent This is because we have implicitly assumed that the number of candidates discovered in a group depends only on the number of candidates in the group and the allocation to that group regardless of the allocations to and the number of candidates in other groups This assumption together with the linearity of expectation allows us to write the expected utility as in the right hand side of Equation THE PRECISION DISCOVERY MODEL We begin by describing the precision model of discovery Allocating vi units to group i in the precision model results in the discovery of vi vi candidates This models the ability to perfectly discover and reach candidates in a group with resources deployed to that group limited only by the number of deployed resources and the number of candidates present The precision model results in censored observations that have a particularly intuitive form Recall that in general a learning algorithm at each round gets to choose an allocation v and then observes for each group i In the precision model this results in the following kind of observation when vi is larger than the allocator learns the number of candidates present on that day exactly We refer to this kind of feedback as an uncensored observation When vi is smaller than all the allocator learns is that the number of candidates is at least vi We call this a censored observation The rest of this section is organized as follows In Sections and we characterize optimal and optimal fair allocations for the precision model when the candidate distributions are known In Section we focus on learning an optimal fair allocation when these distributions are unknown We show that any learning algorithm that is guaranteed to find a fair allocation in the worst case over candidate distributions must have the undesirable property that at some point it must allocate a vast number of its resources to each group individually To bypass this hurdle in Section we show that when the candidate distributions have a parametric form a natural greedy algorithm which always uses an optimal fair allocation for the current maximum likelihood estimates of the candidate distributions converges to an optimal fair allocation Optimal Allocation We first describe how an optimal allocation absent fairness constraints can be computed efficiently when the candidate distributions are known In Ganchev et al the authors provide an algorithm for computing an optimal allocation when the distributions over the number of shares present in each dark pool are known and the trader wishes to maximize the expected number of traded shares They assume that the distributions of shares across different dark pools are independent but our formulation does not require this assumption of independence Still we can use the same algorithm as in Ganchev et al to compute an optimal allocation in our setting this is because as stated in Remark the utility in both settings can be written solely in terms of the marginal candidate distributions even when the candidate distributions are not independent across groups Here we present the high level ideas of their algorithm in the language of our model Let Ti c c denote the probability that there are at least c candidates in group i We refer to Ti c as the tail probability of at c Recall that the value of the cumulative distribution function CDF of at c is defined to be c c c c So Ti c can be written in terms of CDF values as Ti c c First observe that the expected total number of candidates discovered by an allocation in the precision model can be written in terms of the tail probabilities of the candidate distributions ie v i G E min vi i G vi c Ti c Since the objective function is concave as Ti c is a nonincreasing function in c for all i a greedy algorithm which iteratively allocates the next unit of the resource to a group in argmax i G Ti Ti where is the current allocation to group i in the t th round achieves an optimal allocation Optimal Fair Allocation We next show how to compute an optimal α-fair allocation in the precision model when the candidate distributions are known and do not need to be learned To build intuition for how the algorithm works imagine that the group i has the highest discovery probability in and the allocation i to that group is somehow known to the algorithm ahead of time The constraint of α-fairness then implies that the discovery probability for each other group must satisfy fj This in turn implies upper and lower bounds on the feasible allocations to group The algorithm is then simply a constrained greedy algorithm subject to these implied constraints it iteratively allocates units so as to maximize their marginal probability of reaching another candidate Since the group i maximizing the discovery probability and the corresponding i are not known ahead of time the algorithm simply iterates through each possible choice of i Algorithm Computing an optimal fair allocation in the precision model Input C Output An optimal α-fair allocation for i G do v for vi V do Set vi in v and compute vi ubi vi vi for i G do Update and using vi and if V then continue Vr V for t Vr do argmax G Tj Tj st v vi c if v then v v return Pseudocode is given in Algorithm We prove that Algorithm returns an optimal α-fair allocation in Theorem We defer all the omitted proofs and details to the full version Theorem Algorithm computes an optimal -fair allocation for the precision model in time O M Learning Fair Allocations Generally Requires Brute-Force Exploration In Sections and we assumed the candidate distributions were known When the candidate distributions are unknown learning algorithms intending to converge to optimal α-fair allocations must learn a sufficient amount about the distributions in question to certify the fairness of the allocation they finally output Because learners must deal with feedback in the censored observation model this places constraints on how they can proceed Unfortunately as we show in this section if candidate distributions are allowed to be worst-case this will force a learner to engage in brute-force exploration the iterative deployment of a large fraction of the resources to each subgroup in turn This is formalized in Theorem Theorem Define m maxi to be the size of the largest group and assume mi for all i and G Let and A be any learning algorithm for the precision model which runs for a finite number of rounds and outputs an allocation Suppose that there is some group i for which A has not allocated at units for at least rounds upon termination where is an absolute constant Then there exists a candidate distribution such that with probability at least A outputs an allocation that is not α-fair Sketch of the Proof Let i denote a group in which A has not allocated at units for at rounds upon its termination and let v denote an arbitrary allocation We will design two candidate distributions for group i which have true discovery probabilities that are at least apart given vi but which are indistinguishable given the observations of the algorithm with probability at least If theA cannot distinguish between and C i it cannot distinguish between and i and thus cannot guarantee whether group is discovery probability is indeed within of every other groups discovery probability To design these candidate distributions consider distributions and C i which satisfy the following four conditions and C i agree on all values less The total mass of both distributions is The remaining mass of is on the The remaining mass of is on the Distinguishing between and C i requires at least one uncensored observation However conditioned on allocating at units the probability of observing an uncensored observation is at most So to distinguish between and C i with confidence and therefore to guarantee an α-fair allocation a learning algorithm must allocate at units to group i for rounds Recall that we used m to denote the size of the largest group When m V then Theorem implies that no algorithm can guarantee α-fairness for sufficiently small Moreover even when m V Theorem shows that in general if we want algorithms that have provable guarantees for arbitrary candidate distributions it is impossible to avoid something akin to brute-force search recall that there is a trivial algorithm which simply allocates all resources to each group in turn for sufficiently many rounds to approximately learn the CDF of the candidate distribution and then solves the offline problem In the next section we circumvent this by giving an algorithm with provable guarantees assuming that the candidate distributions have a known parametric form Poisson Distributions and Convergence of the MLE In this section we assume that all the candidate distributions have a particular and known parametric form but that the parameters of the these distributions are not known to the allocator Concretely we assume that the candidate distribution for each group is Poisson G for the true underlying parameters of the candidate distributions this choice appears justified at least in the predictive policing application as the candidate distributions in the Philadelphia Crime Incidents dataset are well-approximated by Poisson distributions see Section for further discussion This assumption allows an algorithm to learn the tails of these distributions without needing to rely on brute-force search thus circumventing the limitation given in Theorem Indeed we show that a small variant of the natural greedy algorithm incorporating these distributional assumptions converges to an optimal fair allocation For simplicity we assume a parametric form on the marginal candidate distribution in each of the groups We could have equivalently assumed that the candidates across groups are drawn from Poisson distribution to highlight the potential correlation between candidates distributions However since for a given multivariate Poisson distribution the marginal distribution on each group is itself a Poisson distribution we made our parametric assumption directly on these marginal distributions At a high level in each round our algorithm uses Algorithm to calculate an optimal fair allocation with respect to the current maximum likelihood estimates of the group distributions then it uses the new observations it obtains from this allocation to refine these estimates for the next round This is summarized in Algorithm The algorithm differs from this pure greedy strategy in one respect to overcome the following subtlety there is a possibility that Algorithm when operating on a preliminary estimate for the candidate distributions will suggest sending zero units to some group even when the optimal allocation for the true distributions sends some units to every group Such a deployment would result in the algorithm receiving no feedback for the zero-allocated distribution to satisfy the bounded support condition However the distinction will not be important for the analysis and so to minimize technical overhead we perform the analysis assuming an untruncated Poisson group that round If this suggestion is followed and a lack of feedback is allowed to persist indefinitely the algorithms parameter estimate for the zero-allocated group will also stop updating potentially at an incorrect value In order to avoid this problem and continue making progress in learning our algorithm chooses another allocation in this case As we show any allocation that allocates positive resources to all groups will suffice in particular our algorithm simply repeats the allocation from the previous round Algorithm Learning an optimal fair allocation Input V and T total number of rounds Output An allocation vT and estimates to parameters v for rounds t T do if i such that then vt vt Observe c t i for each group for i G do Update history with and v t i vt Algorithm C V return vT and Notice that Algorithm chooses an allocation at every round which is fair with respect to its estimates of the parameters of the candidate distributions hence asymptotic convergence of its output to an optimal α-fair allocation follows directly from the convergence of the estimates to true parameters However we seek a stronger finite sample guarantee as stated in Theorem Theorem Let Suppose that the candidate distributions are Poisson distributions with unknown parameters in the vector where lies in the known interval G Suppose we run Algorithm for t O rounds where is some distribution specific function to get an allocation v and estimated parameters for all groups i Then with probability at least For all i in G Let D maxi G C C where denotes the total variation distance between two distributions Then v is D-fair has utility at most smaller than the utility of an optimal D-fair allocation ie v Remark Theorem implies that in the limit the allocation from Algorithm will converge to an optimal α-fair allocation As t p for all i meaning D and more importantly v will be α-fair and optimal To prove Theorem we first show that any sequence of allocations selected by Algorithm will eventually recover the true parameters There are two conceptual difficulties here the first is that standard convergence results typically leverage the assumption of independence which does not hold in this case as Algorithm computes adaptive allocations which depend on the allocations in previous rounds the second is the censoring of the observations Despite these difficulties we give quantifiable rates with which the estimates converge to the true parameters Next we show that computing an optimal α-fair allocation using the estimated parameters will result in an allocation that is D-fair with respect to the true candidate distributions where D denotes the maximum total variation distance between the true and estimated Poisson distributions across all groups Finally we show that this allocation also achieves a utility that is comparable to the utility of an optimal D-fair allocation Remark Although we assumed Poisson distributions in this section all our results hold for any single-parameter distribution whose parameter is drawn from a compact set However the convergence rate of Theorem depends on the quantity which depends on the family of distributions used to model the candidate distributions EXPERIMENTS In this section we apply our allocation and learning algorithms for the precision model to the Philadelphia Crime Incidents dataset and complement the theoretical convergence guarantee of Algorithm to an optimal fair allocation with empirical evidence suggesting fast convergence in practice We also study the trade-off between fairness and utility in the dataset Experimental Design The Philadelphia Crime Incidents dataset crimes reported to the Police Departments INCT system between and The crimes are divided into two types Type I crimes include violent offenses such as aggravated assault rape and arson among others Type II crimes include simple assault prostitution gambling and fraud For simplicity we aggregate all crime of both types but in practice a police department would of course treat different categories of crime differently We note as a caveat that these crimes are reported and may not represent the entirety of committed crimes To create daily crime frequencies in Figure we first calculate the daily counts of criminal incidents in each of the geographical police districts in Philadelphia by grouping together all the crime reports with the same date we then normalize these counts to get frequencies Figure represents a police district The horizontal axis of the subfigure corresponds to the number of reported incidents in a day and the vertical axis represents the frequency of each number on the horizontal axis These frequencies approximate the true marginal distributions of the number of reported crimes in each of the districts in Philadelphia Therefore throughout The dataset however contains districts we removed Districts and which correspond to the airport and urban parks as well as and which were dissolved in Figure Frequencies of the number of reported crimes in each district in the Philadelphia Crime Incidents dataset The red curves display the best Poisson fit to the data this section we take these frequencies as the ground truth candidate distributions for the number of reported incidents in each of the districts Figure shows that crime distributions in different districts can be quite different eg the average number of daily reported incidents in District is which is much higher than the average of in District Despite these differences each of the crime distributions can be approximated well by a Poisson distribution The red curves overlayed in each subfigure correspond to the Poisson distribution obtained via maximum likelihood estimation on data from that district Throughout we refer to such distributions as the best Poisson fit to the data districts as the resource to be distributed the ground truth crime frequencies as candidate distributions and aim to maximize the sum of the number of crimes discovered under the precision model of discovery Results We can quantify the extent to which fairness degrades utility in the dataset through a notion we call Price of Fairness henceforth In particular given the ground truth crime distributions and the precision model of discovery for a fairness level we define The is simply the ratio of the expected number of crimes discovered by an optimal allocation to the expected number of crimes discovered by an optimal α-fair allocation Since for all the is at least one Furthermore the is monotonically non-increasing in We can apply the algorithms given in Sections and respectively for computing optimal unconstrained and optimal fair allocations with the with ground truth distributions as input and numerically compute the This is illustrated in Figure The x axis corresponds to different values and the y axis displays Each curve corresponds to a different number of total police officers denoted Because feasible allocations must be integral there can sometimes be no feasible α-fair allocation for small Since the in these cases is infinite we instead opt to display the inverse which is always bounded in Higher values of inverse are more desirable Figure Inverse plots for the Philadelphia Crime Incidents dataset Smaller values indicate greater sacrifice in utility to meet the fairness constraint Figure shows a diverse set of utility/fairness trade-offs depending on the number of available police officers It also illustrates that the cost of fairness is rather low inmost regimes For example in the worst case with only police officers the black curve which is much smaller than the average number of daily reported crimes the inverse is for which corresponds to a difference in the discovery probability across districts When we increase the number of available police officers to the magenta curve tolerating only a difference in the discovery probability across districts is sufficient to guarantee no loss in the utility Figure also shows that for any the inverse tends to increase as the number of police increases ie the cost of fairness decreases a less costly constraint when resources are in greater supply Finally we observe a thresholding phenomenon in Figure in each curve increasing beyond a threshold will significantly increase the inverse This is due to discretization effects since only integral allocations are feasible We next turn into analyzing the performance of Algorithm in practice We run the algorithm instantiated to fit Poisson distributions but use observations from the ground truth distribution at each round As we have shown in Figure the ground truth is well approximated by a Poisson distribution We measure the performance of Algorithm as follows First we fix a police and unfairness and run Algorithm for rounds using the dataset as the ground truth That is we simulate each rounds crime count realizations in each of the districts as being sampled from the ground truth distributions and return censored observations under the precision model to Algorithm according to the algorithms allocations and the drawn realizations The algorithm returns is between and the inverse decreases as V increases from to This occurs because only integral allocations are feasible so achieving a particular fairness level may require leaving some resources unallocated until significantly more resources become available increasing V in this regime improves the utility of an optimal allocation while leaving the utility of an optimal fair allocation unchanged an allocation after termination and we can measure the expected number of crimes discovered and fairness violation the maximum difference in discovery probabilities over all pairs of districts of the returned allocation using the ground truth distributions Varying while allows us to trace out the Pareto frontier of the utility/fairness trade-off for a fixed police budget Similarly for any fixed V and we can run Algorithm the offline algorithm for computing an optimal fair allocation with the ground truth distributions as input and trace out a Pareto curve by varying We refer to these two Pareto curves by the learned and optimal Pareto curves respectively can compare the learned and optimal Pareto curves Figure Pareto frontier of expected crimes discovered versus fairness violation In Figure each curve corresponds to a police budget The x axes represent the expected number of crimes discovered and fairness violation for allocations on the Pareto frontier respectively In our simulations we between and For each police the x s connected by the dashed lines show the learning Pareto frontier Similarly the circles connected by solid lines show the optimal Pareto frontier We point out that while it is possible for the fairness violations in the learned Pareto curves to be higher than the level of set as an input to Algorithm the fairness violations in the optimal Pareto curves are always bounded by The disparity between the optimal and learned Pareto curves are due to the fact that the learning algorithm has not yet fully converged This can be attributed to the large number of censored observations received by Algorithm which are significantly less informative than uncensored observations Censoring happens frequently because the number of police used in every case plotted is less than the daily average of crimes across all the districts in the dataset so it is unavoidable that in any allocation there will be significant censoring in at least some districts Figure shows that while the learning curves are dominated by the optimal curves the performance of the learning instead of the ground truth distributions These curves look very similar to the optimal Pareto curves algorithm approaches the performance of the offline optimal allocation as V increases Again this is because increasing V generally decreases the frequency of censoring We study regime in more detail to explore the empirical rate of convergence In Figure we study the round by round performance of the allocation computed by Algorithm in a single run with the choice and Figure The per round expected number of crimes discovered and fairness violation of Algorithm V and In Figure the x axis labels progression of rounds of the algorithm The y axis measures the fairness violation left and expected number of crimes discovered right of the allocation deployed by the algorithm as measured with respect to the ground truth distributions The black curves represent Algorithm For comparison we also show the same quantities for an offline optimal fair allocation as computed with respect to the ground truth red line and an offline optimal fair allocation as computed with respect to the best Poisson fit to the ground truth blue line Note that in the limit the allocations chosen by Algorithm are guaranteed to converge to the blue baselines but not the red baseline because the algorithm is itself learning a Poisson approximation to the ground truth The disparity between the red and blue lines quantifies the degradation in performance due to using Poisson approximations rather than due to non-convergence of the learning process Figure shows that Algorithm converges to the Poisson approximation baseline well before the termination time of and substantially before the convergence bound guaranteed by our theory Examining the estimated Poisson parameters used internally by Algorithm reveals that although the allocation has converged to an optimal fair allocation the estimated parameters have not yet converged to the parameters of the best Poisson fit in any of the districts In particular Algorithm systematically underestimates the parameters in all of the districts the correlation coefficient between the true and estimated parameters is We see also in Figure that convergence to the optimum expected number of discovered crimes occurs more quickly than convergence to the target fairness violation level This is also apparent in Figure where the learning and optimal Pareto curves are generally similar in terms of the maximum number of crimes discovered while the fairness violations are higher in the learning curves THE RANDOM DISCOVERY MODEL Finally we consider the random model of discovery In the random model when vi units are allocated to a group with candidates the number of discovered candidates is a random variable corresponding to the number of candidates that appear in a uniformly random sample of vi individuals from a group of Equivalently units are allocated to a group of with candidates the number of candidates discovered by disc is a random variable where is drawn from the hypergeometric distribution with and vi Furthermore the expected number of candidates discovered when allocating vi units to group i is vi For simplicity throughout this section we V for all i This assumption can be completely relaxed Moreover let denote the expected fraction of candidates in group i Without loss of generality for the rest of this section we assume Optimal Allocation In this section we characterize optimal allocations Note that the expected number of candidates discovered by the allocation choice vi mi in group i is simply vi This suggests a simple algorithm to compute allocating every unit of the resource to group More generally let G i denote the subset of groups with the highest expected number of candidates An allocation is optimal if and only if it only allocates all resources to groups in G Properties of Fair Allocations We next discuss the properties of fair allocations in the random discovery model First we point out that the discovery probability can be simplified as vi E vi mi So an allocation is α-fair in the random model if for all groups i and Therefore fair allocations roughly distribute resources in proportion to the size of the groups essentially ignoring the candidate distributions within each group Price of Fairness Recall that quantifies the extent to which constraining the allocation to satisfy α-fairness degrades utility While in Section we study the on the Philadelphia Crime Incidents dataset we can define a worst-case variant as follows Definition Fix the random model of crime discovery and let We define the as max C wC C where C ranges over all possible candidate distributions We can fully characterize this worst-case in the random discovery model Theorem The in the random discovery model is V m M V m The in the random model can be as high as in the worst case If all groups are identically sized this grows linearly with the number of groups CONCLUSION AND FUTURE DIRECTIONS Our presentation of allocative fairness provides a family of fairness definitions modularly parameterized by a discovery model What counts as fair depends a great deal on the choice of discovery model which makes explicit what would otherwise be unstated assumptions about the process of tasks like policing The random and precision models of discovery studied in this paper represent two extreme points of a spectrum In the predictive policing setting the random model of discovery assumes that officers have no advantage over random guessing when stopping individuals for further inspection The precision model assumes they can oracularly determine offenders and stop only them An interesting direction for future work is to study discovery models that lie in between these two We have also made a number of simplifying assumptions that could be relaxed For example we assumed the candidate distributions are stationary fixed independently of the actions of the algorithm Of course the deployment of police officers can change crime distributions Modeling this kind of dynamics and designing learning algorithms that perform well in such dynamic settings would be interesting Finally we have assumed that the same discovery model applies to all groups One friction to fairness that one might reasonably conjecture is that the discovery model may differ between groups being closer to the precision model for one group and closer to the random model for another We leave the study of these extensions to future work
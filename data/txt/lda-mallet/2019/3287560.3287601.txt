Controlling Polarization in Personalization An Algorithmic Framework Personalization is pervasive in the online space as it leads to higher efficiency for the user and higher revenue for the platform by individualizing the most relevant content for each user However recent studies suggest that such personalization can learn and propagate systemic biases and polarize opinions this has led to calls for regulatory mechanisms and algorithms that are constrained to combat bias and the resulting echo-chamber effect We propose a versatile framework that allows for the possibility to reduce polarization in personalized systems by allowing the user to constrain the distribution from which content is selected We then present a scalable algorithm with provable guarantees that satisfies the given constraints on the types of the content that can be displayed to a user but subject to these constraints will continue to learn and personalize the content in order to maximize utility We illustrate this framework on a curated dataset of online news articles that are conservative or liberal show that it can control polarization and examine the trade-off between decreasing polarization and the resulting loss to revenue We further exhibit the exibility and scalability of our approach by framing the problem in terms of the more general diverse content selection problem and test it empirically on both a News dataset and the MovieLens dataset CONCEPTS Information systems Personalization Theory of computation Online learning algorithms KEYWORDS Personalization recommender systems polarization bandit optimization group fairness diversification INTRODUCTION News and social media feeds product recommendation online advertising and other media that pervades the internet is increasingly personalized Content selection algorithms consider a users properties and past behavior in order to produce a personalized list of content to display This personalization leads to higher utility and efficiency both for the platform and for the user who sees content more directly related to their interests However it is now known that such personalization may result in propagating or even creating biases that can influence decisions and opinions In an important study showed that user opinions about political candidates and hence elections can be manipulated by changing the personalized rankings of search results Other studies show that allowing for personalization of news and other sources of information can result in a filter bubble which results in a type of tunnel vision effectively isolating people into their own cultural or ideological bubbles eg enabled by polarized information many people did not expect a Brexit vote or Trump election This phenomenon has been observed on many social media platforms see eg and studies have shown that over the past eight years polarization has increased by Polarization and the need to combat it was raised as a problem in where it was shown that Google search results differ significantly based on political preferences in the month following the elections in the United States In a different setting the ease with which algorithmic bias can be introduced and the need for solutions was highlighted in where it was shown that it is very easy to target people on platforms such as Facebook in a discriminatory fashion Several approaches to quantify bias and polarization of online media have now been developed and interventions for polarization have been proposed One approach to counter such polarization would be to hide certain user properties so that they cannot be used for personalization However this could come at a loss to the utility for both the user and the platform the content displayed would be less relevant and result in decreased attention from the user and less revenue for the platform see eg Can we design personalization algorithms that allow us to avoid polarization yet still optimize individual utility Groups and Polarization Often content is classified into different groups which are defined by one or more multi-valued sensitive attributes for instance news stories can have a political leaning eg conservative or liberal and a topic eg politics business or entertainment More generally search engines and other platforms and applications maintain topic models over their content see eg At every time-step the algorithm must select a piece of content to display to a given user and feedback is obtained in the form of whether they click on purchase or hover over the item The goal of the content selection algorithm is to select content for each user in order to maximize the positive feedback and hence revenue received to do so it must learn about the topics or groups the user is most interested in Thus as this optimal topic is a-priori unknown the process is often modeled as an online learning problem in which a user-specific probability distribution from which one selects content is maintained and updated according to feedback given As the content selection algorithm learns more about a user the corresponding probability distribution begins to concentrate the mass on a small subset of topics this results in polarization where the feed is primarily composed of a single type of content Our Contributions To counter polarization we introduce a simple framework which allows us to place constraints on the probability distribution from which content is sampled The goal is to control polarization on the content displayed at all time steps see Section and ensure that the given recommendations do not specialize to a single group Our constraints are linear and limit the total expected weight that can be allocated to a given group through lower and upper bound parameters on each group These polarization constraints are taken as input and can be set according to the context or application Importantly though simple these constraints are versatile enough to control polarization with respect to a variety of metrics which can measure the extent of polarization or lack thereof in a given algorithm This is due to the fact that several fairness metrics depend eg on the ratio or difference between the probability mass on two groups hence can be implemented by picking appropriate lower/upper bound parameters for the constraints in our setting to give an immediate fairness guarantee such reductions can be formalized following standard techniques see eg Thus by placing such constraints the content shown to different types of users is varied and polarization is controlled While there are several polynomial time algorithms for similar settings the challenge is to come up with a scalable content selection algorithm for the resulting optimization problem of maximizing revenue via personalization subject to satisfying the polarization constraints We show how an adaptation of an existing algorithm for the unconstrained bandit setting along with the special structure of our constraints can lead to a scalable algorithm with provable guarantees for this constrained optimization problem see Theorem We evaluate this framework and our algorithm on a curated dataset of online news articles that are conservative In order to create a complete feed content can simply be selected repeatedly in this manner to ll the screen as the user scrolls down for ease of exposition we describe the one-step process of selecting a single piece of content or liberal show that it can control polarization and examine the trade-off between decreasing polarization and the resulting loss to revenue We further illustrate the exibility and scalability of this approach by considering the problem of diverse content selection and evaluate our algorithm on the MovieLens dataset for diverse movie recommendation as well as the YOW dataset for diverse article recommendation To the best of our knowledge this is the rst algorithm to control polarization in personalized settings that comes with provable guarantees allows for the specification of general constraints and is viable in practice FORMAL DEFINITIONS AND OUR MODEL Polarization in Existing Models Algorithms for the general unconstrained and hence potentially biased problem of displaying personalized content are often developed in the multi-armed bandit setting see eg Framed in this manner at each time step t T a user views a page eg Facebook Twitter or Google News and one piece of content or arm at must be selected to be displayed A random reward r t a which depends on the selected content is then received by the content selection algorithm This reward captures resulting clicks purchases or time spent viewing the given content More formally at each time step t a sample r t r t is drawn from an unknown distribution D the player the content selection algorithm in this case selects an arm a and receives reward r t a As is standard in the literature we assume that the are drawn independently across a and t The rewards ra for any a a are assumed to be unknown indeed there is no way to observe what a users actions would have been had a different piece of content been displayed The algorithm computes a probability distribution pt over the arms based on the previous observations a ra a t r ta and then selects arm a t pt The goal is to select pt s in order to maximize the cumulative rewards and the efficacy of such an algorithm is measured with respect to how well it minimizes regret the difference between the algorithms reward and the reward obtained from the unknown optimal policy The regret is defined as regret t r t a t r t a where a is the arm with the highest expected reward a argmax Note that D and hence a is a-priori unknown The regret is a random variable as at depends not only on the draws from p t but also on the realized history of samples at r ta The problem with this approach is that bandit algorithms by optimizing for that ideal a by definition strive for polarization To understand how G be groups of arms which correspond to different types of content across which we do not want to polarize In the simplest setting the Gi s form a partition eg conservative and liberal news articles when the arms represent news stories but in general the group structure can be arbitrary A feature of bandit algorithms is that the probability distribution on the arms that the algorithm is learning converges to the action with the best expected reward ie the entire probability mass ends up a b Figure Unaltered vs balanced content delivery engines a polarization can occur on using personalized platforms eg primarily showing ads for high-paying jobs in red to men and ads for low-paying jobs in blue to women see b With constraints on the extent to which the feeds can differ our model displays a more balanced feed on a single arm and hence in a single group causing polarization see eg Our Model We would like an approach that can control polarization with respect to the groups that the selected arms belong to Towards this for each group Gi let i be a lower bound and be an upper bound on the amount of weighted probability mass that we allow the content selection algorithm can place on this group Formally we impose the following constraints i X wa Gi i t T where wa Gi represents the group weight of arm a on group Gi The group weight wa Gi denotes the similarity between arm a and group Gi For instance following our earlier discussion on news articles a conservative leaning news article might have a group weight of for the conservative articles group and a group weight of for the liberal articles group whereas a neutral article might have both of these weights as In case of categorical groups eg men vs women the group weight can take a binary value For more general cases see eg Section this weight can take a real value between and The values for wa Gi s can be set using various methods depending on the application and can also take into account error bounds for classifiers that decide whether a given a Gi or not For the case of text documents eg news and scientific articles the weights can be set using techniques like topic modeling which give us the percentage of a document that corresponds to a certain topic The bounds i s and s provide a handle with which we can ensure that the weighted probability mass placed on any given group is neither too high nor too low at each time step Rather than the values of s and i s we allow them to be specified as input This allows one to control the extent of polarization of content depending on the application and hence indirectly encode bounds on a wide variety of existing metrics for different notions of group fairness which in effect encode the extent of polarization This requires translating the metric parameters into concrete values of i s and s For instance given by setting s and i s such that i for all i we can ensure that the risk difference is bounded by An additional feature of our model is that no matter what the group structures or the lower and upper bounds are the constraints are always linear Importantly note that unlike ignoring user preferences entirely as in the constraints still allow for personalization across groups For instance if the groups are conservative-leaning vs liberal-leaning articles and the users are known conservatives or liberals we may require C L for all t This ensures that extreme polarization cannot occur at least of the content a conservative is presented with will be liberal-leaning Despite these constraints personalization at the group level can still occur eg by letting C and L for a conservative-leaning user Furthermore this framework allows for complete personalization within a group eg the conservative-leaning articles shown to conservatives and liberals may differ This is crucial as the utility maximizing conservative-leaning articles for a conservative may differ from the utility maximizing conservative-leaning articles for a liberal The next question we address is how to measure an algorithms performance against the best constrained solution We say that a probability distribution p on is constrained if it satisfies the upper and lower bound constraints in and let C be the set of all such probability distributions Note that given the linear nature of the constraints the set C is a polytope an intersection of a set of half spaces and hence we can formulate the problem of ending as a linear programming problem Algorithm CG Require Constraint set C a constrained probability distribution q B q C a positive integer T a constant L that controls the exploration Initialize for t T do Update t min Compute pt argmax p Sample a from the probability distribution t pt Observe reward r ta Update empirical mean end for An algorithm is said to be constrained if it only selects pt C The constrained regret for such an algorithm can be defined as C regret at t r t a t r t a where C represents a point in the constraint set C with the highest expected reward argmax ra R We note that there is nothing specific to political polarization eg news articles being grouped according to political leaning with a goal of avoiding polarization in the model Instead we can think of content along with a topic model where the goal is to select content that is diverse across all topics While the prior notion is our main motivator the theorems apply to the more general case and we show the exibility of the approach by considering both political polarization and diverse recommendation in the empirical evaluation of our approach in Section The constraints on the probabilities in can be translated to the constraints on the number of times that the arms in groups Gi s are selected in T iterations of the algorithm i X wa Gi n T a T i see the appendix for more details RELATED WORK Approaches to Curtail Polarization There is a large body of work studying the effects of polarization and ways in which we can combat it A significant portion of this literature considers interventions to inform or educate users on the effects of personalization and is orthogonal to our work Pariser who coined the term filter bubble proposes that we simply remove personalization entirely However this would come at a complete loss to the utility and efficiency that personalization can bring to both the user and the platform In contrast our approach does allow for personalization up to a point It ensures that the content is not polarized beyond the given constraints but within that personalizes in order to maintain high utility Another approach would be to manipulate the user ratings eg by adding noise or a regularizer to the recommender algorithm in order to have only approximate preferences this has been shown to help reduce polarization We compare against such an approach in our empirical results C R and observe that our algorithm significantly outperforms this method The key difference is that such an approach adds noise to attain de-polarization while our approach de-polarizes in an informed manner that personalizes content as much as possible subject to the polarization constraints Algorithms for Constrained Bandit Optimization Constrained bandit optimization is a broad eld that has arisen in the consideration of a variety of problems unrelated to polarization For example knapsack-like constraints on bandit optimization is studied in however this work only considers constraints that are placed on the final probability vector pT whereas in our setting it is important to satisfy fairness constraints at every time step pt A different line of work considers online individual fairness constraints which require that the probability of selecting all arms be approximately equal until enough information is gathered to confidently know which arm is the best In a similar vein another work considered budgets on the number of times that any given arm can be selected Both of these results can be loosely interpreted as working with the special case of our model in which each arm belongs to its own group their results cannot be applied to our more general setting or be used to curtail polarization ALGORITHMIC RESULTS For each arm a let its mean reward be a In this case the unknown parameters are the expectations of each arm a for a We assume that the reward for the t-th time step is sampled from a Bernoulli distribution with probability of success For a probability distribution q C and a small enough constant we define B q to be the set of all probability distributions that lie inside C such that a probability distribution B q has at least probability mass on each arm More formally B q C is an -ball of radius centered at q Let V C denote the set of vertices of C and argmax V C P T Let be a small enough constant Given the description of C any probability distribution q B q C that lies in the constrained region and the sequence of rewards the CG algorithm Algorithm run forT iterations has the following constrained regret bound E O where t min and d min The algorithm works for any lower bound L on with a L instead of in the regret bound Here is the difference between the maximum and the second maximum expected rewards with respect to the over the vertices of the polytope C More formally P max V C P Before we present the formal details we rst highlight some key aspects of the algorithm theorem and proofs For general convex sets can be and the regret bound can at best only be O p T As our constraints result in a constraint set C which is a polytope unless there are degeneracies is nonzero In general may be hard to estimate theoretically However Algorithm Per iteration Running time Regret Bound CB NP-Hard problem O NP-Hard problem O CB O O CG Algorithm O LP O Algorithm O O Table The complexity and problem-dependent regret bounds for various algorithms when the decision set is a polytope for the settings in which we conduct our experiments we observe that the value of is reasonably large When the probability space is unconstrained it suffices to solve argmax where is an estimate for the mean reward of the i-th arm It can be an optimistic estimate for the in case of the UCB algorithm a sample drawn from the normal distribution with the mean set as the empirical mean for the Thompson Sampling algorithm When the probability distribution is constrained to lie in a polytope C instead of a maximum over the arm mean estimates we need to solve argmax This necessitates the use of a linear program for any algorithm operating in this fashion At every iteration CG solves one LP We can speed up the LP computation considerably in practice by using the interior points method and warm starting the LP solver from the optimal p found in the previous iteration see Section Overview of Algorithm CG The algorithm with probability chooses the probability distribution pt argmax and with probability it samples from a feasible constrained distribution C in the -interior ie there is at least probability mass on each arm The reward for each time step t is generated as Bernoulli at where a t pt is the arm the algorithm chooses at the t th time instant The algorithm observes this reward and updates its estimate to for the next time-step appropriately C G is a variant of the classical G approach Recall that in our setting an arm is an article corner of the k-dimensional simplex and not a vertex of the polytope C The polytope C sits inside this simplex and may have exponentially many vertices This is not that case in the setting of there may not be any ambient simplex in which their polytope sits and even if there is they do not use this additional information about which vertex of the simplex was chosen at each time t Thus while they are forced to maintain confidence intervals of rewards for all the points in C this speciality in our model allows us to get away by maintaining confidence intervals only for the arms vertices of the simplex and then use these intervals to obtain a confidence interval for any point in C Similar to G if we choose each arm enough number of times we can build a good confidence interval around the mean of the reward for each arm The difference is that instead of converging to the optimal arm our constraints maintain the point inside C and it converges to a vertex of C To ensure that we choose each arm with high probability we x a constrained point -interior of C and sample from the point pt Then as in G we proceed by bounding the regret showing that if the confidence-interval is tight enough the optimal of LP with true mean and LP with the empirical mean does not change Proof of Theorem P Let g C be the optimal probability distribution Conditioned on the history at time t the expected regret of CG at iteration t can be bounded as follows R t t t a a t t t t t t where t argmax Let n For t n since t min we have t The expected regret of the -greedy is E P t t t Let Without loss of generality let for any i V C with i Hence Let i i As a result and The event t happens when t i t for some i that is i i i Dataset Arms Instances Iterations T Groups Political News avg days MovieLens users YOW users Table Overview of datasets used in the empirical results in Section As a result we have P t P i V C i i P i V C ki i P i V C i P P X P In we use Holders inequality Let Et Pt and let Nt be the number of times that we have chosen arm up to time t Next we bound P P P P Nt Et P P Nt Et P P Nt Et As q B q C we have ie the probability of selecting an arm a is at least Next we bound each term of First using Chernoff-Hoeding bound we have P Et Using the Bernstein inequality we have P Nt Et Et For t n t and Et For t n we have Et n in d ln t n ln et n By plugging and in and noting that we get P n et d n et d n et n et d n et Plugging in yields E n e n By substituting n in the regret above and noting that d we conclude the proof E O Alternate Approaches and Special Cases In this section we briefly outline an alternate approach for solving this problem that results in a different regret runtime guarantee see Table We further show that for certain special cases of the group structure eg if the groups perfectly partition the arms one can design even faster solutions to the LP Algorithm Any algorithm for solving the linear bandit problem with an infinite continuous set of arms can be adapted to solve the constrained multi-armed bandit problem The constrained multi-armed bandit problem can be thought of as a special case of this type of linear bandit problem where the continuous space of arms is simply the probability simplex over our discrete arms Thus each arm increases the dimensionality of the linear bandit problem by one and the continuous arm selected at time t corresponds to the probability distribution we select at time t The difference between these settings is that while one gets rewards for points in the simplex in the case of linear bandit problems we get rewards for the arms themselves ie the vertices of the simplex in the constrained multi-armed bandit problems Using these algorithms as a black-box can be inefficient and does not allow us to come up with practical algorithms for real-world applications However in some cases we can adapt algorithms for linear bandits to our constrained setting in a way that makes the computations efficient Consider the algorithm that appeared in we will adapt this algorithm to our constrained setting and we call the adapted algorithm CL is an example of algorithms for linear bandits being used to solve the constrained multi-armed bandit problem The key difference between and is that instead of using a scaled L-ball in each iteration we use a a scaled L-ball which makes efficient without this adaptation the equivalent step in our setting required solving an NP-hard and nonconvex optimization problem This is also what allows us to get fast and efficient algorithms like C G for the constrained multi-armed bandit setting This is similar in spirit to how CB can be adapted to C B in incurs O regret see Theorem This gives a worse dependence on but a better dependence on as compared with to CG see Table and hence could be beneficial in some settings However the runtime is considerably slower than CG Instead of maintaining a least-squares estimate of the optimal reward vector C G maintains an empirical mean estimate of it denoted by which is computationally cheaper per iteration It also solves only one linear program instead of linear programs at every iteration Both of these factors together cause a significant decrease in running time compared to Thus while theoretically achieves lower regret than CG in terms of it is not as computationally efficient and performs worse in practice More efficient LP Solvers for Special Group Structures For the special case where group weights are binary ie wa Gi a i and the constraint set have some special structure we can solve the LP efficiently Single Partition If the groups in the constraint set form a partition one can solve the linear program time via a simple greedy algorithm Since each part is separate we can simply put the minimum probability mass as required by the constraints on the best arm of each group and then put the maximum possible probability mass on arms in descending order of arm utility This gives a probability vector that satisfies the constraints and is optimal with respect to the reward Laminar Constraints Let the groups G G be such that Gi G implies Gi G or G Gi The groups form a tree-like data structure where the children are the largest groups that are subset of the parents In this case the LP can be solved efficiently by a greedy algorithm and we can solve the LP step in O time exactly For the sake of brevity and clarity we defer the full explanation to the appendix EMPIRICAL RESULTS In this section we compare the performance of C G to the unconstrained algorithm the hypothetical optimal constrained algorithm which we could implement if we knew the rewards of the arms a-priori a smoothed version of the unconstrained algorithm that satisfies the constraints and a naive baseline that satisfies the constraints but does not aim to optimize the reward We briefly outline the experiments and results here with details in the following subsections We conduct counterfactual experiments on three datasets see Table We consider a curated Political News where the constraints aim to reduce the political polarization of the presented search results As mentioned above we can similarly apply these techniques to the diversification of content in areas beyond political polarization Towards this we simulate our algorithm on another dataset of news articles and strive to diversify across topics eg business In our simulations the regret for was similar or slightly worse than C G As C G is also much more efficient we use it as the main comparator and leave open the question as to if or when performs better as suggested by the theoretical results entertainment and world news and the MovieLens dataset where we strive to diversify recommendations across genres In all cases we nd that CG consistently outperforms the smoothed version of the unconstrained algorithm as well as the naive baseline accumulating much higher reward while closely approximating the hypothetical optimal This benefit of CG is most evident when the constraints are the tightest eg CG accumulates twice as much reward as the smoothed version of the unconstrained algorithm on the YOW dataset see Figure We then compare the polarization and diversification for the constrained and unconstrained algorithms We aim to reduce polarization by recommending news articles with both liberal and conservative biases Similarly we aim to increase diversity by recommending articles and movies not just from the best group in terms of rewards but from other groups as well We observe that algorithms in the unconstrained setting quickly converge to the best group in terms of rewards whereas algorithms in the constrained setting always display a certain minimum percentage of content not from the best group hence improving diversification and avoiding polarization Experimental Setup Algorithm and Benchmarks In each counterfactual simulation we report the normalized cumulative reward for each of the following algorithms and benchmarks is the hypothetical optimal algorithm when there is no constraint and the expected rewards of all arms a are known It simply chooses the best arm a at each step t is the unconstrained G algorithm where C is the set of all probability distributions over CO is the hypothetical optimal probability distribution subject to the polarization constraints that we could have used if we had known the reward vector for the arms a-priori CG is our implementation of Algorithm with the given polarization constraints as input CR is a smoothed version of U G that satisfies the constraints At each time step given the probability distribution pt specified by the unconstrained G algorithm CR takes the largest such that selecting an arm with probability pt does not violate the constraints With the remaining probability it follows the same procedure as in CN to select an arm at random subject to the constraints CN As a baseline we consider a simple algorithm that satisfies the constraints as follows for each group i and arm a with probability i wa Gi it selects an arm at random then with any remaining probability it selects an arm uniformly at random from the entire collection while respecting the upper bound constraints Note that if we know the true rewards of the arms this optimal distribution is easy to compute via a simple greedy algorithm it simply places the most probability mass that satisfies the constraints We set t min Tuning t could give even better results on the best arm the most probability mass remaining on the secondbest arm subject to the constraints and so on and so forth until the entire probability mass is exhausted This strategy can be found by solving one LP Implementation Details Instead of solving an LP from scratch at each iteration in step of Algorithm we warm start the LP by using the solution of the LP from the previous iteration as the starting point for our solver We modified an implementation of an LP solver which uses the interior points method Warm starting the LP solver in this way speeds up the LP computation considerably in practice and allows efficient implementation of the algorithm even when there are many groups that do not form a partition and hence many nontrivial constraints For certain special cases provably fast algorithms for solving the LP also exist see Section however we did not employ these techniques in the simulations Note G implementations all use Algorithm as a subroutine however CG and CR take the constraints as input satisfying the polarization constraints via smoothing the probability distribution and need not satisfy the constraints at all Description of Datasets and Group Weights Political News We curate this dataset by using a large scale webcrawler to collect online news articles over a span of days rd July st August along with the number of Facebook likes that each article received as of nd August We look at the political leaning of each articles publisher as determined by AllSides which provides labels left left-leaning neutral right-leaning or right for a wide set of publishers We discard any articles that remain unlabelled or have fewer than likes This results in a dataset consisting of an average of articles each day of which are right are right-leaning are neutral are left-leaning and are left On average the most-liked right article has likes the most-liked right-leaning article has likes the most-liked neutral article has likes the most-liked left-leaning article has likes and the most-liked left article has likes For each day we encode each article as an arm with Bernoulli reward with mean proportional to the number of likes on Facebook normalized to lie in the range We place a group weight of and on right right-leaning neutral left-leaning and left articles respectively for the liberal group L Similarly we place a group weight of and on right right-leaning neutral left-leaning and left articles respectively for the conservative group C MovieLens We consider the MovieLens dataset which consists of ratings from users across movies each user rated at least movies on a scale of Each movie is also with one or more of genres eg sci- romance thriller As some genres have significant overlap eg thriller and horror while others have different meanings at their intersections eg romance vs rom-com vs comedy we rst cluster the movies into different meta-categories based on their genres using a blackbox k-means clustering algorithm with We use the cluster centres as representative arms and associate all movies in that cluster to that arm For a given user the reward associated with an arm is given by a Gaussian where the mean is the average rating the user gave to movies associated with the arm and standard deviation For a genre i i and movie category a the group weight wa Gi is set to be the ith coordinate of the cluster centre of movie category a found by the k-means clustering YOW We consider the YOW dataset which contains data from a collection of paid users who read unique articles over a week time period The dataset contains the time at which each user read an article a rating for each article read by each user and optional user-generated categories of articles viewed We use this data to construct reward distributions for each user on a set of arms that one can expect to see from the real world We create a simple ontology to categorize the user-generated labels into a total of groups of content Science Entertainment Business World Politics Sports and USA On average there are unique articles in a day We take this to be the number of arms in this experiment Similar to the MovieLens experiments we cluster the articles into arms based on the news categories they belong to using k-means clustering We use the cluster centres as representative arms and associate all articles in that cluster to that arm For a given user the reward associated with that arm is given by a Gaussian where the mean is the average rating the user gave to articles associated with the arm and standard deviation For a news category i i and article a the group weight wa Gi is set to be the ith coordinate of the cluster centre found by k-means clustering effect of Reducing Polarization on the Reward We vary the tightness of upper bound constraints on the probability mass of displaying arms of a given group and report the normalized cumulative reward political news For this dataset there are only two groups either left or right However a news article may have weight on both groups and it is these weights that determine how right- or left-leaning an article is and hence how much they contribute towards polarization in a given direction We simulated each of the days separately resulting in n datapoints We report the normalized cumulative reward after T iterations averaged over experiments from all days As there are only two groups setting a lower bound constraint is equivalent to setting an upper bound constraint u Hence it suffices to see the effect as we vary the upper bounds We vary u u u from to ie from a fully constrained one in which each group has exactly weighted probability of being selected to a completely unconstrained setting We observe in Figure a that even for very large values of u ie when the constraints are loose the CG algorithm significantly outperforms We determine using the graph of silhouette values vs a political news dataset b MovieLens dataset c YOW dataset Figure effect of Polarization Constraints u on Reward The normalized cumulative reward attained as a function of the strength of the upper-bound constraints is reported for the three datasets in Figures a b and c In all cases our algorithm CG does not allow polarization and performs near-optimally with respect to the reward The lower the value of u the stronger are the constraints a political news b MovieLens c YOW Figure Visualizing Polarization and diversification The weighted probability mass on the best group is reported against the number of iterations While the unconstrained algorithm converges quickly to placing all of its probability mass on the optimal group the constrained algorithm by definition maintains some weight on the non-optimal groups This is what ensures diversification across content and avoids polarization CR with respect to regret and is only worse than the unconstrained and hence polarized algorithm by an additive factor of approximately u ie less than MovieLens For this dataset a group corresponds to a genre Note that a movie can belong to multiple genres with varying weights which may not add up to one We report the normalized cumulative reward averaged across all users after T iterations Error bars depict the standard error of the mean We observe in Figure b that CG significantly outperforms the CN and CR algorithms across constraints Additionally as there are fewer arms in the MovieLens dataset as compared to the political news dataset the learning cost is lower and hence the CG performs essentially as well as the unattainable C O algorithm YOW For this dataset a group corresponds to an article category Note that an article can belong to multiple categories eg science and business simultaneously with varying weights across each category We report the normalized cumulative reward averaged across all users after T iterations Error bars depict the standard error of the mean As before we observe in Figure c that CG significantly outperforms the CN and CR algorithms across constraints and performs almost as well as the unattainable CO algorithm Polarization Over Time In order to see how polarization can be avoided and diversification can be enforced using our framework for each dataset we plot the normalized cumulative weighted probability mass on the best group for each datapoint against the number of iterations with the u Initially the unconstrained and constrained algorithms have the same weighted probability mass for the best group because the algorithms are simply exploring the arms However the difference between the algorithms becomes very apparent once the algorithm begin to learn Due to a larger number of arms in the political news dataset this process takes longer as compared to the other two datasets quickly polarizes almost-entirely to display content only from the best group This depicts the necessity for such constraints However C G maintains at least u of its weighted probability mass on content not belonging to the best group increasing diversification and avoiding polarization CONCLUSION In this paper we initiate a formal study of combating polarization in personalization algorithms that learn user behavior We present a general framework that allows one to prevent polarization by ensuring that a balanced set of items are displayed to each user We show how one can modify a simple bandit algorithm in order to perform well with respect to regret subject to satisfying the polarization constraints improving the regret bound over the state-of-the-art Empirically we observe that the CG algorithm performs well it not only converges quickly to the theoretical optimum but this optimum even for the tightest constraints on the arm values selected u for MovieLens u for political news is within a factor of of the unconstrained rewards Furthermore CG is fast and we expect it to scale well in web-level applications With regard to future work a limitation of our algorithms is the fact that they assume we are given the group labels and weights for each piece of content These labels would either need to be inferred from the data which could bring with it additional bias associated with this learning algorithm or would need to be self-reported which can lead to adversarial manipulation Additionally it would be important to extend this work to a dynamic setting in which the type of content changes over time eg using restless bandit techniques From an experimental standpoint testing this algorithm in the eld in particular to measure user satisfaction given diversified news feeds would be of significant interest Such an experiment would give deeper insight into the benefits and trade-offs between personalization and the diversification of content which could then be leveraged to determine which kind of constraints can prevent polarization not just of the items in the feed but of the beliefs and opinions of those viewing them
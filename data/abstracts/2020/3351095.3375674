What’s Sex Got To Do With Machine Learning?∗
Lily Hu†
lilyhu@g.harvard.edu
Harvard University & Jain Family Institute
Issa Kohler-Hausmann‡
issa.kohler-hausmann@yale.edu
Yale University
ABSTRACT
The debate about fairness in machine learning has largely cen-
tered around competing substantive definitions of what fairness or
nondiscrimination between groups requires. However, very little
attention has been paid to what precisely a group is. Many recent
approaches have abandoned observational, or purely statistical, def-
initions of fairness in favor of definitions that require one to specify
a causal model of the data generating process. The implicit ontolog-
ical assumption of these exercises is that a racial or sex group is a
collection of individuals who share a trait or attribute, for example:
the group “female” simply consists in grouping individuals who
share female-coded sex features. We show this by exploring the
formal assumption of modularity in causal models using directed
acyclic graphs (DAGs), which hold that the dependencies captured
by one causal pathway are invariant to interventions on any other
causal pathways. Modeling sex, for example, as a node in a causal
model aimed at elucidating fairness questions proposes two sub-
stantive claims: 1) There exists a feature, sex-on-its-own, that is
an inherent trait of an individual that then (causally) brings about
social phenomena external to it in the world; and 2) the relations be-
tween sex and its downstream effects can be modified in whichever
ways and the former node would still retain the meaning that sex
has in our world. Together, these claims suggest sex to be a category
that could be different in its (causal) relations with other features of
our social world via hypothetical interventions yet still mean what
it means in our world. This fundamental stability of categories and
causes (unless explicitly intervened on) is essential in the method-
ology of causal inference, because without it, causal operations can
alter the meaning of a category, fundamentally change how it is
situated within a causal diagram, and undermine the validity of
any inferences drawn on the diagram as corresponding to any real
phenomena in the world.
We argue that these methods’ ontological assumptions about
social groups such as sex are conceptual errors. Many of the “effects”
that sex purportedly “causes” are in fact constitutive features of
sex as a social status. They constitute what it means to be sexed. In
other words, together, they give the social meaning of sex features.
These social meanings are precisely, we argue, what makes sex
∗Tina Turner, “What’s Love Got to Do With It?” Private Dancer, 1984.
†Department of Philosophy, Department of Applied Mathematics, Harvard University
‡Yale Law School, Department of Sociology, Yale University
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
FAT* ’20, January 27–30, 2020, Barcelona, Spain
© 2020 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-6936-7/20/02.
https://doi.org/10.1145/3351095.3375674
discrimination a distinctively morally problematic type of act that
differs frommere irrationality ormeanness on the basis of a physical
feature.
Correcting this conceptual error has a number of important
implications for how analytical models can be used to detect dis-
crimination. If what makes something discrimination on the basis
of a particular social grouping is that the practice acts on what it
means to be in that group in a way that we deem wrongful, then
what we need from analytical diagrams is a model of what consti-
tutes the social grouping. Such a model would allow us to explain
the special moral (and legal) reasons we have to be concerned with
the treatment of this category by reference to the empirical social
relations and meanings that establish the category as what it is.
Only then can we have the normative debate about what is fair
or nondiscriminatory vis-à-vis that group. We suggest that formal
diagrams of constitutive relations would present an entirely dif-
ferent path toward reasoning about discrimination (and relatedly,
counterfactuals) because they proffer a model of how the meaning
of a social group emerges from its constitutive features. Whereas
the value of causal diagrams is to guide the construction and testing
of sophisticated modular counterfactuals, the value of constitutive
diagrams would be to identify a different kind of counterfactual as
central to our inquiry into discrimination: one that asks how the
social meaning of a group would be changed if its non-modular
features were altered.
CCS CONCEPTS
•Theory of computation→Design and analysis of algorithms;
• Applied computing → Law, social and behavioral sciences.
KEYWORDS
machine learning, algorithmic fairness, causal inference, discrimi-
nation, law, social philosophy
ACM Reference Format:
Lily Hu and Issa Kohler-Hausmann. 2020. What’s Sex Got To Do With Ma-
chine Learning?. In Conference on Fairness, Accountability, and Transparency
(FAT* ’20), January 27–30, 2020, Barcelona, Spain. ACM, New York, NY, USA,
1 page. https://doi.org/10.1145/3351095.3375674
ACKNOWLEDGMENTS
We are grateful to Michael Carl Tschantz, Chris Winship, Gideon
Yaffe, the JFI Digital Ethics Reading Group, and the Dwork Fairness
Reading Group for their thoughtful comments on earlier drafts and
presentations of the paper. We thank the Simons Institute for the
Theory of Computing at UC Berkeley for making this collaboration
possible (dare we say causing it). Hu has been supported by the Na-
tional Science Foundation Graduate Research Fellowship Program
under Grant No. DGE1745303.
513

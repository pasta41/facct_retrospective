Bridging the Gap from AI Ethics Research to Practice 
Kathy Baxter 
 Salesforce, Inc. 
 San Francisco CA United States 
kbaxter@salesforce.com 
Lewis Baker 
 Pymetrics, Inc. 
 San Francisco CA United States 
lewis@pymetrics.com 
Isabel Kloumann 
 Facebook, Inc. 
 Menlo Park CA United States 
 imk@fb.com 
Yoav Schlesinger 
 Salesforce, Inc. 
 San Francisco CA United States 
yschlesinger@salesforce.com 
Julie Dawson 
 Yoti, Inc. 
San Francisco CA United States 
 julie.dawson@yoti.com 
Hanna Wallach 
 Microsoft, Inc. 
Seattle WA United States 
 hanna@dirichlet.net 
Sarah Aerni 
 Salesforce, Inc. 
 San Francisco CA United States 
saerni@salesforce.com 
Krishnaram Kenthapadi 
 LinkedIn, Inc. 
 Mountain View CA United States 
 kkenthapadi@gmail.com 
 
  
  
  
  
 
ABSTRACT 
The study of fairness in machine learning applications has seen 
significant academic inquiry, research and publication in recent 
years. Concurrently, technology companies have begun to 
instantiate nascent program in AI ethics and product ethics more 
broadly. As a result of these efforts, AI ethics practitioners have 
piloted new processes to evaluate and ensure fairness in their 
machine learning applications. In this session, six industry 
practitioners, hailing from LinkedIn, Yoti, Microsoft, Pymetrics, 
Facebook, and Salesforce share insights from the work they have 
undertaken in the area of fairness, what has worked and what has 
not, lessons learned and best practices instituted as a result. 
• Krishnaram Kenthapadi presents LinkedIn’s fairness-
aware reranking for talent search. 
• Julie Dawson shares how Yoti applies ML fairness 
research to age estimation in their digital identity 
platform. 
• Hanna Wallach contributes how Microsoft is applying 
fairness principles in practice. 
• Lewis Baker presents Pymetric’s fairness mechanisms in 
their hiring algorithm. 
• Isabel Kloumann presents Facebook’s fairness 
assessment framework through a case study of fairness in 
a content moderation system. 
• Sarah Aerni contributes how Salesforce is building 
fairness features into the Einstein AI platform. 
Building on those insights, we discuss insights and brainstorm 
modalities through which to build upon the practitioners’ work. 
Opportunities for further research or collaboration are identified, 
with the goal of developing a shared understanding of experiences 
and needs of AI ethics practitioners. Ultimately, the aim is to 
develop a playbook for more ethical and fair AI product 
development and deployment.  
 
CCS CONCEPTS 
• Computing methodologies → Artificial intelligence; 
Cognitive science; Machine learning; • Human-centered 
computing → HCI theory, concepts and models; • General and 
reference → Evaluation;  
 
KEYWORDS 
Artificial Intelligence, algorithmic decision-making, fairness, ML 
fairness, practitioners, ethics, data 
ACM Reference format: 
Kathy Baxter, 2020. Bridging the Gap from AI Ethics Research to 
Practice. In FAT* ’20: Conference on Fairness, Accountability, and 
Transparency Proceedings, January 27-30, 2020, Barcelona, Spain. ACM, 
New York, NY, USA, 1 page. https://doi.org/10.1145/3351095.3375680 
 
Permission to make digital or hard copies of part or all of this work for personal or 
classroom use is granted without fee provided that copies are not made or 
distributed for profit or commercial advantage and that copies bear this notice and 
the full citation on the first page. Copyrights for third-party components of this 
work must be honored. For all other uses, contact the owner/author(s). 
FAT* '20, January 27–30, 2020, Barcelona, Spain 
© 2020 Copyright is held by the owner/author(s). 
ACM ISBN 978-1-4503-6936-7/20/02. 
https://doi.org/10.1145/3351095.3375680 
682

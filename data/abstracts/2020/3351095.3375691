When Not to Design, Build, or Deploy
Solon Barocas
solon.barocas@microsoft.com
Microsoft Research,
Cornell University
Asia J. Biega
asia.biega@microsoft.com
Microsoft Research
Benjamin Fish
benjamin.fish@microsoft.com
Microsoft Research
Jędrzej Niklas
j.niklas@lse.ac.uk
London School of Economics and
Political Science
Luke Stark
luke.stark@microsoft.com
Microsoft Research
CCS CONCEPTS
• Social and professional topics → Computing / technology
policy; Professional topics.
KEYWORDS
technology policy, technology refusal, politics of tech refusal
ACM Reference Format:
Solon Barocas, Asia J. Biega, Benjamin Fish, Jędrzej Niklas, and Luke Stark.
2020. When Not to Design, Build, or Deploy. In Conference on Fairness,
Accountability, and Transparency (FAT* ’20), January 27–30, 2020, Barcelona,
Spain. ACM, New York, NY, USA, 1 page. https://doi.org/10.1145/3351095.
3375691
1 SESSION ABSTRACT
Recent debate within the FAT∗ community has focused on how the
field conceptualizes the problems it seeks to address, what approach
the field should take in attempting to address these problems, and
whether the field should even pursue some of the proposed reme-
dies. Questions regarding when not to design, build, or deploy a
technology are perhaps the most common expression of this trend.
Identifying the problems to address is inextricably linked to the
broader question of how to collectively make decisions about what
technologies our societies need and want.
While much extant FAT∗ work to date has focused on various
model and system interventions, the goal of this session is to fos-
ter discussion of when we should not design, build, and deploy
systems in the first place. Given the recent push for moratoria on
facial recognition, protests around the sale of digital technologies
represented by the hashtag #TechWontBuildIt, and the ongoing
harms to marginalized groups from automated systems such as risk
prediction or surveillance, a broader discussion around how, when,
and why to say no seems both relevant and urgent.
The discussion seeks to surface the question of when, how, and
why not to design, build or deploy to a broader audience of inter-
ested practitioners, academics, and society. While the question is
now common in critical FAT∗ work drawing on the Science and
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
FAT* ’20, January 27–30, 2020, Barcelona, Spain
© 2020 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-6936-7/20/01.
https://doi.org/10.1145/3351095.3375691
Technology Studies literature, we believe it remains underarticu-
lated to many with training in machine learning and other areas
of computer science. We create the space for perspectives on why,
when, and how to justify not deploying or building systems in part
because the problem is so infrequently discussed.
The session, through perspectives contributed by academics,
industrial practitioners, and civil society activists, seeks to provide
the foundation for answering the long-term questions of:
• Relevant historical and disciplinary contexts. Assess-
ing and articulating the social character of technologies is
a venerable theme in the philosophy of technology. How
can we draw on these and other scholarly traditions to build
frameworks to direct and prioritize our critical efforts today?
• Frameworks and guidelines for practitioners to use
when reasoning about not designing, building, or de-
ploying. Upon what values should we base our decisions
regarding whether to build, deploy, and critique particular
technologies? How do we take all affected people and things
into account in making such decisions? And through what
specific mechanisms should such decisions be made as a
matter of practice? Moreover, what drives this idea from
a practical perspective is the reality of practitioners and
developers of socio-technical systems. When faced with a
task—how do they decide if it’s morally acceptable? Should
the decision be based purely on intuition? What are frame-
works and resources they could use to make their decision
and then defend it when confronting superiors?
• Politics and aftermaths of refusal. While practitioners
or activists might often be the ones to flag projects as unac-
ceptable, no less important is who gets to decide whether
or not projects go forward. In the above scenario, typically
the engineer/student gets no say in the matter, as the end
decision is often made above that level. It is crucial to under-
stand the politics of how such decisions are made in practice,
as well as how should decisions like this get made. What
real alternatives are there to the way things are being done
now? Moreover, despite all the efforts to just say no, it’s
urgent to ask what happens after the moratoria? Are these
attempts to reject a technology completely or temporarily
halt its development and use until we have rules in place? Is
it even possible to regulate a technology out of existence?
Practically speaking, what does a politics of refusal entail
and require?
695

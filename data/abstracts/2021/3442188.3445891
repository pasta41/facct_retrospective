Algorithmic Fairness in Predicting Opioid Use Disorder using
Machine Learning
Angela E. Kilby
a.kilby@northeastern.edu
Northeastern University
Boston, Massachusetts, USA
ABSTRACT
There has been recent interest by payers, health care systems, and
researchers in the development of machine learning and artificial
intelligence models that predict an individual’s probability of devel-
oping opioid use disorder. The scores generated by these algorithms
can be used by physicians to tailor the prescribing of opioids for the
treatment of pain, reducing or foregoing prescribing to individuals
deemed to be at high risk, or increasing prescribing for patients
deemed to be at low risk. This paper constructs a machine learning
algorithm to predict opioid use disorder risk using commercially
available claims data similar to those utilized in the development
of proprietary opioid use disorder prediction algorithms. We study
risk scores generated by the machine learning model in a setting
with quasi-experimental variation in the likelihood that doctors
prescribe opioids, generated by changes in the legal structure for
monitoring physician prescribing. We find that machine-predicted
risk scores do not appear to correlate at all with the individual-
specific heterogeneous treatment effect of receiving opioids. The
paper identifies a new source of algorithmic unfairness in machine
learning applications for health care and precision medicine, arising
from the researcher’s choice of objective function. While precision
medicine should guide physician treatment decisions based on the
heterogeneous causal impact of a course of treatment for an individ-
ual, allocating treatments to individuals receiving the most benefit
and recommending caution for those most likely to experience
harmful side effects, ML models in health care are often trained
on proxies like individual baseline risk, and are not necessarily
informative in deciding who would most benefit, or be harmed, by
a course of treatment.
CCS CONCEPTS
• Applied computing → Economics; • Computing methodolo-
gies → Machine learning; • Social and professional topics →
Government technology policy.
KEYWORDS
causality, fairness, algorithm development, social and organiza-
tional processes, auditing, evaluations, ethics, algorithmic impacts
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
FAccT ’21, March 3–10, 2021, Virtual Event, Canada
© 2021 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-8309-7/21/03.
https://doi.org/10.1145/3442188.3445891
on social phenomena, critical data/algorithm studies, disability stud-
ies
ACM Reference Format:
Angela E. Kilby. 2021. Algorithmic Fairness in Predicting Opioid Use Disor-
der using Machine Learning. In Conference on Fairness, Accountability, and
Transparency (FAccT ’21), March 3–10, 2021, Virtual Event, Canada. ACM,
New York, NY, USA, 1 page. https://doi.org/10.1145/3442188.3445891
272

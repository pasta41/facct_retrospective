0	0.05447	racial race categories ads users facebook targeting advertisers attributes category advertising discrimination advertiser based audience platforms gender platform targeted netzdg 
1	0.07782	model data training models dataset trained set using deep datasets privacy learning performance use features test accuracy points feature results 
2	0.02971	trust health model clinical sepsis trustworthiness technologies human trustworthy mental patients technology patient user watch medical users affordances team care 
3	0.07932	model causal variables variable counterfactual recourse set features attribute value outcome data target feature sensitive use probability given effect actions 
4	0.08462	data privacy information collection public gdpr protection access sharing use research legal fairness transparency rights also processing subjects law article 
5	0.05966	explanations model explanation models decision feature features human explainability accuracy based machine prediction users methods trust counterfactual predictions input performance 
6	0.02698	users alt human channels emotion agents right like content emotional media body agent communities online emotions platform lite robot norms 
7	0.13096	algorithm function fair cost optimal fairness value set constraints probability group distribution given problem let two error allocation number consider 
8	0.13537	social science ethics computer research data work algorithmic technology political ethical within power knowledge systems technical community computing moral new 
9	0.0323	word bias embeddings sentiment gender words biases language art negative positive wikipedia text male female social image trained embedding models 
10	0.08883	fairness group groups parity classifier measures false bias accuracy equal independence test fair protected positive class rates two sensitive model 
11	0.06048	group utility candidates groups decision individuals rule policy cost school threshold strategic students model social dynamics equilibrium action optimal setting 
12	0.05475	participants students model used human study papers process one cards survey questions information asked table also two using annotation decision 
13	0.25779	fairness learning work machine systems models data algorithms bias algorithmic social paper methods based problem making use research used fair 
14	0.029	crime police data policing rates amazon reporting taken sponsored incidents districts allocation lue predictive products rin coverage organic number hot 
15	0.10593	system accountability systems process algorithmic transparency design impact documentation development information use audit technical data requirements assessment model processes decisions 
16	0.1379	figure gender dataset race bias datasets results data black groups white across female average table shows male different demographic difference 
17	0.54346	may one would might also however could example even different decision case make people many way individual possible whether thus 
18	0.05848	users user items recommendation news recommendations search item recommender articles content diversity terms ranking different top set experiments number information 
19	0.03684	risk assessments bail defendants assessment criminal justice pretrial cash charges predictions prediction court judges defendant cases decisions child black release 

0 	 participants human model accuracy decision trust humans performance information students study machine cards papers used confidence significant results figure predicted
1 	 trust system accountability systems design development model transparency process requirements human technical information processes public use users documentation stakeholders algorithmic
2 	 images image gender art datasets vision face dataset computer skin bias facial categories faces recognition classification darker imagenet people synsets
3 	 ads gender users facebook women advertisers advertising targeting advertiser audience men attributes user netzdg content platform online targeted google platforms
4 	 model data dataset training models figure set datasets results using accuracy performance test trained features bias two distribution different deep
5 	 risk assessments assessment criminal justice pricing price high defendants outcomes based insurance treatment pretrial low population predictive child prediction individuals
6 	 crime allocation police policing reporting rates incidents data model districts number predictive hot true discovered reported district crimes rate time
7 	 fairness group groups parity measures false classifier accuracy positive protected sensitive bias equal rates attribute fair test class rate model
8 	 algorithm function optimal fair cost value probability set distribution let constraints fairness problem given distributions theorem two case consider constraint
9 	 data legal law discrimination rights gdpr transparency impact protection decision information pymetrics subjects algorithmic automated assessments assessment making audit processing
10 	 may one would might example could however also even different make many case people way decision thus whether given important
11 	 fairness learning work machine systems models algorithms algorithmic data use used bias model based methods making paper decision problem section
12 	 privacy health media users alt channels clinical patients sepsis tweets content social harmful care right patient mental communities influence data
13 	 social science ethics computer technology political research algorithmic ethical within work systems power knowledge society technical computing technologies new moral
14 	 model explanations explanation causal features feature counterfactual models variables recourse decision set based data explainability variable input value methods prediction
15 	 candidates utility bias students school election latent voters rule test student utilities experiments implicit taken information university results websites score
16 	 race racial categories black white bail based category groups charges defendants cash amazon sponsored asian gender bias ethnicity products american
17 	 data collection information research use datasets public sharing used access privacy demographic dataset companies researchers many documentation practices collect collected
18 	 group cost individuals groups policy social utility threshold rate dynamics action welfare individual classification population loan disadvantaged equilibrium two decision
19 	 users user items recommendation recommendations item news recommender articles content diversity set online based different terms platform ranking number topic
20 	 fairness language representativeness moral eop independence notion representative translation used different english also effort two statistical terms utility languages egalitarian
21 	 word bias embeddings gender sentiment words male female negative positive text wikipedia biases language social trained embedding texts figure names

topic_keys_edited = ['user-study', 'accountability', 'image-classification', 'advertising', 'ML', 'risk-assessment',
                     'policing', 'fairness/sensitive-attributes', 'fairness/optimization', 'law/rights', 
                     'uncertainty', 'fairness/algorithm', 'health', 'social-sciences/ethics',
                     'explainability', 'education', 'race','data-collection/privacy', 'fairness/utility',
                     'recommender-systems','fairness/representation', 'gender/language' ]